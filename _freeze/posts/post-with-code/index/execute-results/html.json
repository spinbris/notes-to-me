{
  "hash": "82a1e361e13b163665604c7008e636c5",
  "result": {
    "markdown": "---\ntitle: \"Titanic from Kaggle\"\nauthor: \"Stephen Parton\"\ndate: \"2022-09-01\"\ncategories: [code, analysis,titanic]\nwebsite:\n  sidebar:\n    style: \"docked\"\n    search: true\n    contents:\n      - section: \"Data Exploration\"\n      - index.qmd\nformat: \n  html: \n    toc: true\n    toc-title: Contents\n    number-sections: true\n    number-depth: 3\n    code-fold: true\n---\n\n\n![](thumbnail.jpg){width=\"215\"}\n\n## Summary\n\nThis is just a first test with code in a blog using the new Quarto framework! Guess what I am using..\n\n\n\n\n\n## Review Data\n\n### Load Some Kaggle Data\n\nNot the...? Yes, the Titanic again....\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain <- read_csv(\"data_raw/train.csv\",show_col_types = FALSE) %>% clean_names() %>% mutate(train_test = \"train\")\ntest <- read_csv(\"data_raw/test.csv\",show_col_types = FALSE) %>% clean_names() %>% \n  mutate(train_test = \"test\")\nall <- train %>% bind_rows(test)\n\n# colnames(data)\n# cwd()\n```\n:::\n\n\n### Some Initial EDA\n\nA quick look.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain %>% skim() \n```\n\n::: {.cell-output-display}\nTable: Data summary\n\n|                         |           |\n|:------------------------|:----------|\n|Name                     |Piped data |\n|Number of rows           |891        |\n|Number of columns        |13         |\n|_______________________  |           |\n|Column type frequency:   |           |\n|character                |6          |\n|numeric                  |7          |\n|________________________ |           |\n|Group variables          |None       |\n\n\n**Variable type: character**\n\n|skim_variable | n_missing| complete_rate| min| max| empty| n_unique| whitespace|\n|:-------------|---------:|-------------:|---:|---:|-----:|--------:|----------:|\n|name          |         0|          1.00|  12|  82|     0|      891|          0|\n|sex           |         0|          1.00|   4|   6|     0|        2|          0|\n|ticket        |         0|          1.00|   3|  18|     0|      681|          0|\n|cabin         |       687|          0.23|   1|  15|     0|      147|          0|\n|embarked      |         2|          1.00|   1|   1|     0|        3|          0|\n|train_test    |         0|          1.00|   5|   5|     0|        1|          0|\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate|   mean|     sd|   p0|    p25|    p50|   p75|   p100|hist  |\n|:-------------|---------:|-------------:|------:|------:|----:|------:|------:|-----:|------:|:-----|\n|passenger_id  |         0|           1.0| 446.00| 257.35| 1.00| 223.50| 446.00| 668.5| 891.00|▇▇▇▇▇ |\n|survived      |         0|           1.0|   0.38|   0.49| 0.00|   0.00|   0.00|   1.0|   1.00|▇▁▁▁▅ |\n|pclass        |         0|           1.0|   2.31|   0.84| 1.00|   2.00|   3.00|   3.0|   3.00|▃▁▃▁▇ |\n|age           |       177|           0.8|  29.70|  14.53| 0.42|  20.12|  28.00|  38.0|  80.00|▂▇▅▂▁ |\n|sib_sp        |         0|           1.0|   0.52|   1.10| 0.00|   0.00|   0.00|   1.0|   8.00|▇▁▁▁▁ |\n|parch         |         0|           1.0|   0.38|   0.81| 0.00|   0.00|   0.00|   0.0|   6.00|▇▁▁▁▁ |\n|fare          |         0|           1.0|  32.20|  49.69| 0.00|   7.91|  14.45|  31.0| 512.33|▇▁▁▁▁ |\n:::\n:::\n\n\n### Some Initial Wrangling\n\n\n::: {.cell}\n\n```{.r .cell-code}\nall_proc <- all %>% \n  mutate(title = str_extract(name,\"(\\\\w)([a-z]+)(\\\\.)\")) %>% \n  mutate(pax_type = case_when(\n    title %in% c(\"Miss.\",\"Ms.\",\"Mlle.\")         ~ \"F_unmarried\",\n    title %in% c(\"Mme.\",\"Mrs.\")                 ~ \"F_married\",\n    title %in% c(\"Countess.\",\"Lady.\",\"Dona.\")   ~ \"F_titled\",\n    title %in% c(\"Capt.\",\"Col.\",\"Major.\")       ~ \"Military\",\n    title %in% c(\"Dr.\",\"Rev.\")                  ~ \"M_Professional\",\n    title %in% c(\"Don.\",\"Jonkheer.\",\"Sir.\")     ~ \"M_titled\",\n    TRUE ~ title\n  ),\n  surname        = str_extract(name,\"(\\\\w+)(\\\\,)\"),\n  survival       = ifelse(survived==0,\"No\",\"Yes\"),\n  ticket_preface = str_extract(ticket,\"([:graph:]+)(\\\\s)\"),\n  ticket_preface = ifelse(is.na(ticket_preface),\"none\",ticket_preface),\n  cabin_preface  = ifelse(is.na(cabin),\"nk\",\n                    substr(cabin,1,1)),\n  embarked       = ifelse(is.na(embarked),\"S\",embarked)\n  ) %>% \n  group_by(pax_type,pclass) %>% \n  mutate(age     = ifelse(is.na(age),median(age,na.rm = T), age)) %>% \n  ungroup() %>% \n  add_count(ticket,name = \"ticket_group\") %>% \n  mutate(ticket_group = case_when(\n    ticket_group == 1 ~ \"single\",\n    ticket_group == 2 ~ \"couple\",\n    TRUE              ~ \"group\"\n  ),\n    family_group = as.numeric(sib_sp)+as.numeric(parch)+1\n  ) %>% \n  mutate(family_group = factor(\n    case_when(\n        family_group < 2  ~ \"single\",\n        family_group < 3  ~ \"couple\",\n        TRUE              ~ \"family\"\n        ),\n    ordered = TRUE)\n  ) %>% \n  mutate(age_group = factor(case_when(\n    age < 13      ~ \"child\",\n    age < 20      ~ \"teen\",\n    age < 30      ~ \"20s\",\n    age < 40      ~ \"30s\",\n    age < 50      ~ \"40s\",\n    age < 60      ~ \"50s\",\n    TRUE          ~ \"60+\"\n    \n  ),\n  ordered = TRUE)\n  ) %>% \n  mutate(across(where(is.character),as_factor)) %>% \n  mutate(pclass = factor(pclass,levels = c(\"1\",\"2\",\"3\")),\n         survived = factor(survived)\n         ) %>% \nselect(-c(title,ticket_preface))\n  \n#all_proc %>% glimpse() \n```\n:::\n\n\n### A bit more EDA\n\n\n::: {.cell}\n\n```{.r .cell-code}\nall_proc %>% \n  select(-c(name,ticket,cabin,surname,train_test)) %>% \n  DataExplorer::plot_bar()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/EDA_1-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/EDA_1-2.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nall_proc %>% DataExplorer::plot_histogram(ggtheme = theme_light() )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/data_explorer1-1.png){width=672}\n:::\n:::\n\n\n### Eyeballing Survival Graphs on Training Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nno_f <- all_proc %>%\n  filter(train_test == \"train\") %>% \n  select(passenger_id,pclass,sex,embarked,pax_type,ticket_group,family_group,age_group,cabin_preface,survival) %>% \n  droplevels() %>%\n  mutate(across(where(is.factor),~ factor(.x,ordered = FALSE))) %>%\n  pivot_longer(cols = c(pclass:cabin_preface)) \n\n\ng_l <- no_f %>% \n  split(.$name) %>% \n  map(~ ggplot(.,aes(y=value,fill=survival)) +\n                geom_bar() +\n              ggtitle(.$name) +\n        theme_bw() +\n        labs(x=NULL,y=NULL)+\n        scale_fill_viridis_d(option = \"cividis\")\n      \n            ) \n\nlibrary(patchwork)\nwrap_plots(g_l, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/eye_ball_survival-1.png){width=672}\n:::\n:::\n\n\n### Split Data back to Train/Test/Validation\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_proc_adj_tbl <- all_proc %>% \n  filter(train_test ==\"train\") %>% \n  select(-c(survival))\n  \ntrain_split <- initial_split(train_proc_adj_tbl,strata = survived)\n```\n:::\n\n\n## Recipe-Base\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrecipe_base <- \n  recipe(survived ~ ., data = training(train_split)) %>% \n  update_role(passenger_id, name,surname,ticket,cabin,new_role = \"ID\") %>%\n  step_impute_knn(all_numeric_predictors()) %>% \n  step_dummy(all_nominal_predictors()) %>%\n  step_factor2string(all_nominal_predictors()) %>% \n  step_zv(all_predictors()) %>% \n  step_pca()\nrecipe_base\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRecipe\n\nInputs:\n\n      role #variables\n        ID          5\n   outcome          1\n predictor         13\n\nOperations:\n\nK-nearest neighbor imputation for all_numeric_predictors()\nDummy variables from all_nominal_predictors()\nCharacter variables from all_nominal_predictors()\nZero variance filter on all_predictors()\nPCA extraction with <none>\n```\n:::\n:::\n\n\n### Save Files\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# write_rds(all_proc,\"artifacts/all_proc.rds\")\n# write_rds(train_split,\"artifacts/train_split.rds\")\n# write_rds(recipe_base,\"artifacts/recipe_base.rds\")\n# \n# all_proc <- read_rds(\"artifacts/all_proc.rds\")\n# train_split <- read_rds(\"artifacts/train_split.rds\")\n# recipe_base <- read_rds(\"artifacts/recipe_base.rds\")\n```\n:::\n\n\n## Models\n\n### Logistic Regression\n\n#### LR Model Spec\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlr_spec <-  \n  logistic_reg() %>% \n  set_engine(\"glm\")\n\nlr_spec\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n```\n:::\n:::\n\n\n#### LR Workflow\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlr_wflow <- \n  workflow() %>% \n  add_model(lr_spec) %>% \n  add_recipe(recipe_base)\n\nlr_wflow\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n```\n:::\n:::\n\n\n#### LR Fit Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlr_fit <- \n  lr_wflow %>% \n  last_fit(train_split)\n\n#lr_fit\n\nlr_final_metrics <- lr_fit %>% collect_metrics()\nlr_final_metrics \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.830 Preprocessor1_Model1\n2 roc_auc  binary         0.819 Preprocessor1_Model1\n```\n:::\n\n```{.r .cell-code}\n#show_notes(.Last.tune.result)\n```\n:::\n\n\n#### LR Predict\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlr_test_predictions <- lr_fit %>% collect_predictions()\nlr_test_predictions\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 224 × 7\n   id               .pred_0 .pred_1  .row .pred_class survived .config          \n   <chr>              <dbl>   <dbl> <int> <fct>       <fct>    <chr>            \n 1 train/test split  0.0518 0.948       2 1           1        Preprocessor1_Mo…\n 2 train/test split  0.929  0.0709      5 0           0        Preprocessor1_Mo…\n 3 train/test split  0.465  0.535       7 1           0        Preprocessor1_Mo…\n 4 train/test split  0.914  0.0863     13 0           0        Preprocessor1_Mo…\n 5 train/test split  0.997  0.00329    14 0           0        Preprocessor1_Mo…\n 6 train/test split  0.131  0.869      20 1           1        Preprocessor1_Mo…\n 7 train/test split  0.946  0.0543     36 0           0        Preprocessor1_Mo…\n 8 train/test split  0.104  0.896      44 1           1        Preprocessor1_Mo…\n 9 train/test split  0.326  0.674      45 1           1        Preprocessor1_Mo…\n10 train/test split  0.915  0.0851     52 0           0        Preprocessor1_Mo…\n# … with 214 more rows\n```\n:::\n:::\n\n\n#### LR Performance on validation set\n\n##### AUC Curve\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlr_test_predictions %>% \n  roc_curve(truth = survived,.pred_1,event_level=\"second\") %>% \n  autoplot()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/LR_auc-1.png){width=672}\n:::\n:::\n\n\n##### Confusion Matrix\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlr_test_predictions %>% \n  conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/LR_confuse-1.png){width=672}\n:::\n:::\n\n\n#### LR Resampling\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfolds <- vfold_cv(training(train_split), strata = survived, v=5)\n#folds\n\ncontrol <- control_resamples(save_pred = TRUE,save_workflow = TRUE)\n\ncores <- parallel::detectCores()\nset.seed(1234)\ndoParallel::registerDoParallel(cores = cores)\n\nlr_fit_cv <- \n  lr_wflow %>% \n  fit_resamples(folds, control = control)\n\n#show_best(lr_fit_cv,metric= \"accuracy\")\n\n#lr_fit_cv\nlr_metrics_resample <- collect_metrics(lr_fit_cv)\nlr_metrics_resample\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy binary     0.802     5  0.0208 Preprocessor1_Model1\n2 roc_auc  binary     0.854     5  0.0146 Preprocessor1_Model1\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlr_assess_res <- collect_predictions(lr_fit_cv)\nlr_assess_res\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 667 × 7\n   id    .pred_0 .pred_1  .row .pred_class survived .config             \n   <chr>   <dbl>   <dbl> <int> <fct>       <fct>    <chr>               \n 1 Fold1   0.677  0.323     16 0           0        Preprocessor1_Model1\n 2 Fold1   0.140  0.860     18 1           0        Preprocessor1_Model1\n 3 Fold1   0.920  0.0802    20 0           0        Preprocessor1_Model1\n 4 Fold1   0.825  0.175     24 0           0        Preprocessor1_Model1\n 5 Fold1   0.884  0.116     27 0           0        Preprocessor1_Model1\n 6 Fold1   0.889  0.111     28 0           0        Preprocessor1_Model1\n 7 Fold1   0.930  0.0704    38 0           0        Preprocessor1_Model1\n 8 Fold1   0.903  0.0975    44 0           0        Preprocessor1_Model1\n 9 Fold1   0.913  0.0872    47 0           0        Preprocessor1_Model1\n10 Fold1   0.932  0.0677    55 0           0        Preprocessor1_Model1\n# … with 657 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\nlm_fit <- lr_wflow %>% fit(data = train_proc_adj_tbl)\nextract_recipe(lm_fit, estimated = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRecipe\n\nInputs:\n\n      role #variables\n        ID          5\n   outcome          1\n predictor         13\n\nTraining data contained 891 data points and 687 incomplete rows. \n\nOperations:\n\nK-nearest neighbor imputation for age, sib_sp, parch, fare [trained]\nDummy variables from pclass, sex, embarked, train_test, pax_type, cabin_prefac... [trained]\nCharacter variables from <none> [trained]\nZero variance filter removed train_test_test [trained]\nNo PCA components were extracted from <none> [trained]\n```\n:::\n:::\n\n\n## Regularised Logistic Regression - GLMNET\n\n### RLR Model Spec\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrlr_model <- \n  logistic_reg(penalty = tune(), mixture = tune()) %>% \n  set_engine(\"glmnet\")\nrlr_model\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = tune()\n\nComputational engine: glmnet \n```\n:::\n:::\n\n\n### RLR Parameter Tuning\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrlr_grid <- grid_latin_hypercube(\n  penalty(),\n  mixture(),\n  size = 30\n)\nrlr_grid %>% tidy()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Data frame tidiers are deprecated and will be removed in an upcoming\nrelease of broom.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 13\n  column      n   mean    sd  median trimmed     mad      min   max range   skew\n  <chr>   <dbl>  <dbl> <dbl>   <dbl>   <dbl>   <dbl>    <dbl> <dbl> <dbl>  <dbl>\n1 penalty    30 0.0360 0.106 1.00e-5 0.00632 1.00e-5 1.30e-10 0.484 0.484 3.36  \n2 mixture    30 0.499  0.296 4.89e-1 0.498   2.47e-1 1.80e- 2 0.983 0.965 0.0119\n# … with 2 more variables: kurtosis <dbl>, se <dbl>\n```\n:::\n:::\n\n\n### RLR Workflow\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrlr_wflow <- \n  workflow() %>% \n  add_model(rlr_model) %>% \n  add_recipe(recipe_base)\nrlr_wflow\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = tune()\n\nComputational engine: glmnet \n```\n:::\n:::\n\n\n### RLR Hyper-parameter Tuning\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# rlr_folds <- vfold_cv(training(train_split), strata = survived, v=10,repeats = 5)\n# rlr_folds %>% tidy()\n\ndoParallel::registerDoParallel(cores = cores)\n\nset.seed(234)\nrlr_tuning_result <- tune_grid(\n  rlr_wflow,\n  resamples = folds,\n  grid      = rlr_grid,\n  control   = control_grid(save_pred = TRUE, save_workflow = TRUE)\n)\n\nrlr_tuning_metrics <- collect_metrics(rlr_tuning_result)\nhead(rlr_tuning_metrics)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 8\n   penalty mixture .metric  .estimator  mean     n std_err .config              \n     <dbl>   <dbl> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n1 1.56e- 2  0.0180 accuracy binary     0.819     5  0.0214 Preprocessor1_Model01\n2 1.56e- 2  0.0180 roc_auc  binary     0.863     5  0.0173 Preprocessor1_Model01\n3 2.23e- 9  0.0656 accuracy binary     0.804     5  0.0204 Preprocessor1_Model02\n4 2.23e- 9  0.0656 roc_auc  binary     0.856     5  0.0150 Preprocessor1_Model02\n5 5.40e-10  0.0698 accuracy binary     0.804     5  0.0204 Preprocessor1_Model03\n6 5.40e-10  0.0698 roc_auc  binary     0.856     5  0.0150 Preprocessor1_Model03\n```\n:::\n:::\n\n\nReview hyper-parameter tuning results and select best\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrlr_tuning_result %>%\n  collect_metrics() %>%\n  filter(.metric == \"accuracy\") %>%\n  select(mean, penalty,mixture) %>%\n  pivot_longer(penalty:mixture,\n               values_to = \"value\",\n               names_to = \"parameter\"\n  ) %>%\n  ggplot(aes(value, mean, color = parameter)) +\n  geom_point(alpha = 0.8, show.legend = FALSE) +\n  facet_wrap(~parameter, scales = \"free_x\") +\n  labs(x = NULL, y = \"AUC\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/rlr_tune-1.png){width=672}\n:::\n\n```{.r .cell-code}\nshow_best(rlr_tuning_result, \"accuracy\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 8\n  penalty mixture .metric  .estimator  mean     n std_err .config              \n    <dbl>   <dbl> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n1 0.00886  0.923  accuracy binary     0.826     5  0.0218 Preprocessor1_Model28\n2 0.0255   0.983  accuracy binary     0.823     5  0.0199 Preprocessor1_Model30\n3 0.0156   0.0180 accuracy binary     0.819     5  0.0214 Preprocessor1_Model01\n4 0.00349  0.598  accuracy binary     0.817     5  0.0176 Preprocessor1_Model18\n5 0.00193  0.946  accuracy binary     0.817     5  0.0168 Preprocessor1_Model29\n```\n:::\n\n```{.r .cell-code}\nbest_rlr_auc <- select_best(rlr_tuning_result, \"accuracy\")\nbest_rlr_auc\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  penalty mixture .config              \n    <dbl>   <dbl> <chr>                \n1 0.00886   0.923 Preprocessor1_Model28\n```\n:::\n:::\n\n\n### RLR Predict\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrlr_final_wflow <- finalize_workflow(\n  rlr_wflow,\n  best_rlr_auc\n)\n\nrlr_final_wflow\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = 0.00885574773491923\n  mixture = 0.923322001239285\n\nComputational engine: glmnet \n```\n:::\n\n```{.r .cell-code}\nrlr_final_wflow %>%\n  last_fit(train_split) %>%\n  extract_fit_parsnip() %>%\n  vip(geom = \"col\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/rlr_predict1-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrlr_final_fit <- rlr_final_wflow %>%\n  last_fit(train_split)\n\nrlr_final_metrics <- collect_metrics(rlr_final_fit)\nrlr_final_metrics\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.830 Preprocessor1_Model1\n2 roc_auc  binary         0.857 Preprocessor1_Model1\n```\n:::\n\n```{.r .cell-code}\nrlr_test_predictions <- rlr_final_fit %>% collect_predictions()\nrlr_test_predictions\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 224 × 7\n   id               .pred_0 .pred_1  .row .pred_class survived .config          \n   <chr>              <dbl>   <dbl> <int> <fct>       <fct>    <chr>            \n 1 train/test split   0.105  0.895      2 1           1        Preprocessor1_Mo…\n 2 train/test split   0.914  0.0862     5 0           0        Preprocessor1_Mo…\n 3 train/test split   0.469  0.531      7 1           0        Preprocessor1_Mo…\n 4 train/test split   0.897  0.103     13 0           0        Preprocessor1_Mo…\n 5 train/test split   0.978  0.0218    14 0           0        Preprocessor1_Mo…\n 6 train/test split   0.211  0.789     20 1           1        Preprocessor1_Mo…\n 7 train/test split   0.869  0.131     36 0           0        Preprocessor1_Mo…\n 8 train/test split   0.115  0.885     44 1           1        Preprocessor1_Mo…\n 9 train/test split   0.349  0.651     45 1           1        Preprocessor1_Mo…\n10 train/test split   0.899  0.101     52 0           0        Preprocessor1_Mo…\n# … with 214 more rows\n```\n:::\n\n```{.r .cell-code}\n# rlr_pred <- predict(rlr_final_fit,train_2 )%>% \n#   bind_cols(predict(rlr_final_fit, train_2,type=\"prob\")) %>% \n#   bind_cols(train_2 %>% select(survived))\n# \n# rlr_pred %>% \n#   roc_auc(truth = survived, .pred_1, event_level = \"second\")\n# \n# rlr_pred %>% \n#   roc_curve(truth = survived, .pred_1,event_level=\"second\") %>% \n#   autoplot()\n# \n# \n# rlr_metrics <- rlr_pred %>% \n# metrics(truth = survived, estimate = .pred_class) %>% \n#   filter(.metric == \"accuracy\")\n# rlr_metrics\n# survive_rlr_pred <- \n#   augment(survive_lr_fit, train_2)\n# survive_rlr_pred\n```\n:::\n\n\n### RLR Confusion Matrix\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrlr_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/rlr_confusion_matrix-1.png){width=672}\n:::\n:::\n\n\n## Random Forest\n\n### RF Model Spec - Ranger\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_model <- \n  rand_forest(trees = 1000) %>% \n  set_engine(\"ranger\") %>% \n  set_mode(\"classification\")\n```\n:::\n\n\n### RF Workflow\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_wflow <- \n  workflow() %>% \n  add_model(rf_model) %>% \n  add_recipe(recipe_base)\n```\n:::\n\n\n### RF Fit Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_fit <- \n  rf_wflow %>% \n  last_fit(train_split)\n\nrf_final_metrics <- collect_metrics(rf_fit)\nrf_final_metrics\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.821 Preprocessor1_Model1\n2 roc_auc  binary         0.862 Preprocessor1_Model1\n```\n:::\n:::\n\n\n### RF Predict\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_final_fit <- rf_wflow %>% fit(testing(train_split))\nclass(rf_final_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"workflow\"\n```\n:::\n\n```{.r .cell-code}\n rf_test_predictions <- \n  predict(rf_final_fit, new_data = testing(train_split)) %>% \n   bind_cols(predict(rf_final_fit, testing(train_split),type = \"prob\")) %>% \n   bind_cols(testing(train_split) %>% select(survived))\n\n \n head(rf_test_predictions)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 4\n  .pred_class .pred_0 .pred_1 survived\n  <fct>         <dbl>   <dbl> <fct>   \n1 1            0.0467   0.953 1       \n2 0            0.868    0.132 0       \n3 0            0.679    0.321 0       \n4 0            0.894    0.106 0       \n5 0            0.826    0.174 0       \n6 1            0.216    0.784 1       \n```\n:::\n:::\n\n\n### RF Performance on Training Set\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_test_predictions %>% \n  roc_auc(truth = survived, .pred_1,event_level = \"second\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.974\n```\n:::\n\n```{.r .cell-code}\nrf_metrics_accuracy <- rf_test_predictions %>% \n  metrics(truth = survived, estimate = .pred_class) %>% \n  filter(.metric == \"accuracy\")\nrf_metrics_accuracy\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.924\n```\n:::\n\n```{.r .cell-code}\nrf_test_predictions %>% \n  roc_curve(truth = survived, .pred_1,event_level = \"second\") %>% \n  autoplot()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/rf_perf-1.png){width=672}\n:::\n:::\n\n\n### RF Confusion Matrix\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/rf_confusion_matrix-1.png){width=672}\n:::\n:::\n\n\n### RF Resampling\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#folds <- vfold_cv(training(train_split), strata = survived, v=5)\n#folds\n\ncontrol <- control_resamples(save_pred = TRUE,save_workflow = TRUE)\n\ncores <- parallel::detectCores()\nset.seed(1234)\ndoParallel::registerDoParallel(cores = cores)\n\nrf_fit_cv <- \n  rf_wflow %>% \n  fit_resamples(folds, control = control)\n\n#show_best(lr_fit_cv,metric= \"accuracy\")\n\n#lr_fit_cv\nrf_metrics_resample <- collect_metrics(rf_fit_cv)\nrf_metrics_resample\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy binary     0.820     5  0.0182 Preprocessor1_Model1\n2 roc_auc  binary     0.883     5  0.0159 Preprocessor1_Model1\n```\n:::\n:::\n\n\n\n## XG Boost - Usemodel\n\n### XGB - Usemodel Library specs\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(usemodels)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'usemodels' was built under R version 4.2.1\n```\n:::\n\n```{.r .cell-code}\nuse_xgboost(survived ~ .,\n            data=training(train_split),\n            verbose = TRUE\n  \n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nxgboost_recipe <- \n  recipe(formula = survived ~ ., data = training(train_split)) %>% \n  step_novel(all_nominal_predictors()) %>% \n  ## This model requires the predictors to be numeric. The most common \n  ## method to convert qualitative predictors to numeric is to create \n  ## binary indicator variables (aka dummy variables) from these \n  ## predictors. However, for this model, binary indicator variables can be \n  ## made for each of the levels of the factors (known as 'one-hot \n  ## encoding'). \n  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>% \n  step_zv(all_predictors()) \n\nxgboost_spec <- \n  boost_tree(trees = tune(), min_n = tune(), tree_depth = tune(), learn_rate = tune(), \n    loss_reduction = tune(), sample_size = tune()) %>% \n  set_mode(\"classification\") %>% \n  set_engine(\"xgboost\") \n\nxgboost_workflow <- \n  workflow() %>% \n  add_recipe(xgboost_recipe) %>% \n  add_model(xgboost_spec) \n\nset.seed(33729)\nxgboost_tune <-\n  tune_grid(xgboost_workflow, resamples = stop(\"add your rsample object\"), grid = stop(\"add number of candidate points\"))\n```\n:::\n:::\n\n\n### XGB - Parameters\n\nThis grid is used for both versions of XG Boost.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxgb_grid <- grid_latin_hypercube(\n  tree_depth(),\n  min_n(),\n  trees(),\n  loss_reduction(),\n  sample_size = sample_prop(),\n  finalize(mtry(), training(train_split)),\n  learn_rate(),\n  size = 30\n)\n\nhead(xgb_grid)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 7\n  tree_depth min_n trees loss_reduction sample_size  mtry   learn_rate\n       <int> <int> <int>          <dbl>       <dbl> <int>        <dbl>\n1          9    20  1622        4.07e-9       0.580    15 0.000000110 \n2          3    10   655        3.12e-4       0.523    13 0.0000000132\n3          1    36   208        9.59e-8       0.201    16 0.00000115  \n4         14    13  1672        1.16e-8       0.266    17 0.000000307 \n5         15    14   489        1.72e+1       0.689     8 0.0000000101\n6          4    16  1039        2.34e-2       0.986    12 0.0163      \n```\n:::\n:::\n\n\n### XGB - Usemodel Code\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(usemodels)\n\nuse_xgboost(survived ~ .,\n            data=training(train_split),\n            verbose = TRUE\n  \n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nxgboost_recipe <- \n  recipe(formula = survived ~ ., data = training(train_split)) %>% \n  step_novel(all_nominal_predictors()) %>% \n  ## This model requires the predictors to be numeric. The most common \n  ## method to convert qualitative predictors to numeric is to create \n  ## binary indicator variables (aka dummy variables) from these \n  ## predictors. However, for this model, binary indicator variables can be \n  ## made for each of the levels of the factors (known as 'one-hot \n  ## encoding'). \n  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>% \n  step_zv(all_predictors()) \n\nxgboost_spec <- \n  boost_tree(trees = tune(), min_n = tune(), tree_depth = tune(), learn_rate = tune(), \n    loss_reduction = tune(), sample_size = tune()) %>% \n  set_mode(\"classification\") %>% \n  set_engine(\"xgboost\") \n\nxgboost_workflow <- \n  workflow() %>% \n  add_recipe(xgboost_recipe) %>% \n  add_model(xgboost_spec) \n\nset.seed(97445)\nxgboost_tune <-\n  tune_grid(xgboost_workflow, resamples = stop(\"add your rsample object\"), grid = stop(\"add number of candidate points\"))\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nxgboost_usemodel_recipe <- \n  recipe(formula = survived ~ ., data = training(train_split)) %>% \n  step_novel(all_nominal_predictors()) %>% \n  ## This model requires the predictors to be numeric. The most common \n  ## method to convert qualitative predictors to numeric is to create \n  ## binary indicator variables (aka dummy variables) from these \n  ## predictors. However, for this model, binary indicator variables can be \n  ## made for each of the levels of the factors (known as 'one-hot \n  ## encoding'). \n  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>% \n  step_zv(all_predictors()) \n\nxgboost_usemodel_model <- \n  boost_tree(trees = tune(), mtry = tune(),min_n = tune(), tree_depth = tune(), learn_rate = tune(), \n    loss_reduction = tune(), sample_size = tune()) %>% \n  set_mode(\"classification\") %>% \n  set_engine(\"xgboost\") \n\nxgboost_usemodel_wflow <- \n  workflow() %>% \n  add_recipe(xgboost_usemodel_recipe) %>% \n  add_model(xgboost_usemodel_model) \n\ndoParallel::registerDoParallel(cores = cores)\n\nset.seed(234)\nxgboost_usemodel_tune <-\n  tune_grid(xgboost_usemodel_wflow, resamples = folds, grid = xgb_grid)\n```\n:::\n\n\n\n### XGB - Usemodel Best Parameter Settings \n\n\n::: {.cell}\n\n```{.r .cell-code}\nxgb_tuning_metrics_usemodel <- collect_metrics(xgboost_usemodel_tune)\nxgb_tuning_metrics_usemodel\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 60 × 13\n    mtry trees min_n tree_…¹ learn…² loss_…³ sampl…⁴ .metric .esti…⁵  mean     n\n   <int> <int> <int>   <int>   <dbl>   <dbl>   <dbl> <chr>   <chr>   <dbl> <int>\n 1    16   208    36       1 1.15e-6 9.59e-8   0.201 accura… binary  0.616     5\n 2    16   208    36       1 1.15e-6 9.59e-8   0.201 roc_auc binary  0.5       5\n 3     6  1202     4       2 4.27e-7 9.25e-4   0.944 accura… binary  0.618     5\n 4     6  1202     4       2 4.27e-7 9.25e-4   0.944 roc_auc binary  0.809     5\n 5     4   559    39       2 7.47e-3 5.95e+0   0.410 accura… binary  0.616     5\n 6     4   559    39       2 7.47e-3 5.95e+0   0.410 roc_auc binary  0.5       5\n 7    18  1107     3       3 3.83e-3 1.10e-4   0.492 accura… binary  0.696     5\n 8    18  1107     3       3 3.83e-3 1.10e-4   0.492 roc_auc binary  0.811     5\n 9    13   655    10       3 1.32e-8 3.12e-4   0.523 accura… binary  0.696     5\n10    13   655    10       3 1.32e-8 3.12e-4   0.523 roc_auc binary  0.808     5\n# … with 50 more rows, 2 more variables: std_err <dbl>, .config <chr>, and\n#   abbreviated variable names ¹​tree_depth, ²​learn_rate, ³​loss_reduction,\n#   ⁴​sample_size, ⁵​.estimator\n```\n:::\n\n```{.r .cell-code}\nxgboost_usemodel_tune %>%\n  collect_metrics() %>%\n  filter(.metric == \"roc_auc\") %>%\n  select(mean, mtry:sample_size) %>%\n  pivot_longer(mtry:sample_size,\n               values_to = \"value\",\n               names_to = \"parameter\"\n  ) %>%\n  ggplot(aes(value, mean, color = parameter)) +\n  geom_point(alpha = 0.8, show.legend = FALSE) +\n  facet_wrap(~parameter, scales = \"free_x\") +\n  labs(x = NULL, y = \"AUC\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/xgb_usemodel_para_sel-1.png){width=672}\n:::\n:::\n\n\n\n\nNow select best from above\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshow_best(xgboost_usemodel_tune, \"roc_auc\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 13\n   mtry trees min_n tree_d…¹ learn…² loss_…³ sampl…⁴ .metric .esti…⁵  mean     n\n  <int> <int> <int>    <int>   <dbl>   <dbl>   <dbl> <chr>   <chr>   <dbl> <int>\n1    10  1571    24       14 3.48e-2 8.60e-7   0.877 roc_auc binary  0.831     5\n2    17  1672    13       14 3.07e-7 1.16e-8   0.266 roc_auc binary  0.820     5\n3    12  1039    16        4 1.63e-2 2.34e-2   0.986 roc_auc binary  0.817     5\n4     9   967    32        7 5.09e-2 2.78e-2   0.710 roc_auc binary  0.817     5\n5    18  1107     3        3 3.83e-3 1.10e-4   0.492 roc_auc binary  0.811     5\n# … with 2 more variables: std_err <dbl>, .config <chr>, and abbreviated\n#   variable names ¹​tree_depth, ²​learn_rate, ³​loss_reduction, ⁴​sample_size,\n#   ⁵​.estimator\n```\n:::\n\n```{.r .cell-code}\nxgb_usemodel_best_params <- select_best(xgboost_usemodel_tune, \"roc_auc\")\nxgb_usemodel_best_params\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 8\n   mtry trees min_n tree_depth learn_rate loss_reduction sample_size .config    \n  <int> <int> <int>      <int>      <dbl>          <dbl>       <dbl> <chr>      \n1    10  1571    24         14     0.0348    0.000000860       0.877 Preprocess…\n```\n:::\n\n```{.r .cell-code}\nxgb_usemodel_final_wflow <- finalize_workflow(\n  xgboost_usemodel_wflow,\n  xgb_usemodel_best_params\n)\n\nxgb_usemodel_final_wflow\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: boost_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_novel()\n• step_dummy()\n• step_zv()\n\n── Model ───────────────────────────────────────────────────────────────────────\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = 10\n  trees = 1571\n  min_n = 24\n  tree_depth = 14\n  learn_rate = 0.0348129952678471\n  loss_reduction = 8.60498209075984e-07\n  sample_size = 0.877007868885994\n\nComputational engine: xgboost \n```\n:::\n:::\n\n### XGB - Usemodel Parameter Ranking - VIP\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxgb_usemodel_final_wflow %>%\n  fit(data = training(train_split)) %>%\n  extract_fit_parsnip() %>%\n  vip(geom = \"point\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: There are new levels in a factor: NA\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/xgb_usemodel_vip-1.png){width=672}\n:::\n:::\n\n\n### XGB - Usemodel Performance\n\n#### XGB - Usemodel Accuracy Measured on Test Set\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(234)\nxgb_usemodel_final_res <- last_fit(xgb_usemodel_final_wflow, train_split)\nxgb_usemodel_final_res\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits            id               .metrics .notes   .predictions .workflow \n  <list>            <chr>            <list>   <list>   <list>       <list>    \n1 <split [667/224]> train/test split <tibble> <tibble> <tibble>     <workflow>\n\nThere were issues with some computations:\n\n  - Warning(s) x2: There are new levels in a factor: NA\n\nRun `show_notes(.Last.tune.result)` for more information.\n```\n:::\n\n```{.r .cell-code}\nxgb_usemodel_final_metrics <- collect_metrics(xgb_usemodel_final_res)\nxgb_usemodel_final_metrics\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.786 Preprocessor1_Model1\n2 roc_auc  binary         0.836 Preprocessor1_Model1\n```\n:::\n:::\n\n\n\n#### XGB - Usemodel AUC on Test Set (within train)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxgb_usemodel_final_res %>%\n  collect_predictions() %>%\n  roc_curve( truth = survived,.pred_1, event_level = \"second\") %>%\n  ggplot(aes(x = 1-specificity, y = sensitivity)) +\n  geom_line(size = 1.5, color = \"midnightblue\") +\n  geom_abline(\n    lty = 2, alpha = 0.5,\n    color = \"gray50\",\n    size = 1.2\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/xgb_usemodel_auc-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nxgb_usemodel_test_predictions <- collect_predictions(xgb_usemodel_final_res)\nhead(xgb_usemodel_test_predictions)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 7\n  id               .pred_0 .pred_1  .row .pred_class survived .config           \n  <chr>              <dbl>   <dbl> <int> <fct>       <fct>    <chr>             \n1 train/test split   0.205   0.795     2 1           1        Preprocessor1_Mod…\n2 train/test split   0.863   0.137     5 0           0        Preprocessor1_Mod…\n3 train/test split   0.496   0.504     7 1           0        Preprocessor1_Mod…\n4 train/test split   0.867   0.133    13 0           0        Preprocessor1_Mod…\n5 train/test split   0.828   0.172    14 0           0        Preprocessor1_Mod…\n6 train/test split   0.574   0.426    20 0           1        Preprocessor1_Mod…\n```\n:::\n:::\n\n\n### XGB - Usemodel Confusion Matrix\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxgb_usemodel_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\n\n\n## XG Boost - Base Recipe\n\n### XGB Model Spec\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxgb_model <- \n  boost_tree(\n    trees = tune(),\n    tree_depth = tune(),\n    min_n = tune(),\n    loss_reduction = tune(),\n    sample_size = tune(),\n    mtry = tune(),\n    learn_rate = tune()) %>% \n  set_engine(\"xgboost\") %>% \n  set_mode(\"classification\")\n\nxgb_model\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = tune()\n  min_n = tune()\n  tree_depth = tune()\n  learn_rate = tune()\n  loss_reduction = tune()\n  sample_size = tune()\n\nComputational engine: xgboost \n```\n:::\n:::\n\n\n\n\n### XGB Workflow\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxgb_wflow <- \n  workflow() %>% \n  add_model(xgb_model) %>% \n  add_recipe(recipe_base)\n```\n:::\n\n\n\n\n\n### XGB Hyper-Parameter Tuning\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# xgb_folds <- vfold_cv(training(train_split), strata = survived)\n# xgb_folds\n\n\ndoParallel::registerDoParallel(cores = cores)\n\nset.seed(234)\nxgb_tuning_result <- tune_grid(\n  xgb_wflow,\n  resamples = folds,\n  grid      = xgb_grid,\n  control  = control_grid(save_pred = TRUE,save_workflow = TRUE)\n)\nxgb_tuning_result\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Tuning results\n# 5-fold cross-validation using stratification \n# A tibble: 5 × 5\n  splits            id    .metrics           .notes           .predictions\n  <list>            <chr> <list>             <list>           <list>      \n1 <split [532/135]> Fold1 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n2 <split [534/133]> Fold2 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n3 <split [534/133]> Fold3 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n4 <split [534/133]> Fold4 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n5 <split [534/133]> Fold5 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nxgb_tuning_metrics <- collect_metrics(xgb_tuning_result)\nxgb_tuning_metrics\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 60 × 13\n    mtry trees min_n tree_…¹ learn…² loss_…³ sampl…⁴ .metric .esti…⁵  mean     n\n   <int> <int> <int>   <int>   <dbl>   <dbl>   <dbl> <chr>   <chr>   <dbl> <int>\n 1    16   208    36       1 1.15e-6 9.59e-8   0.201 accura… binary  0.616     5\n 2    16   208    36       1 1.15e-6 9.59e-8   0.201 roc_auc binary  0.5       5\n 3     6  1202     4       2 4.27e-7 9.25e-4   0.944 accura… binary  0.772     5\n 4     6  1202     4       2 4.27e-7 9.25e-4   0.944 roc_auc binary  0.841     5\n 5     4   559    39       2 7.47e-3 5.95e+0   0.410 accura… binary  0.616     5\n 6     4   559    39       2 7.47e-3 5.95e+0   0.410 roc_auc binary  0.5       5\n 7    18  1107     3       3 3.83e-3 1.10e-4   0.492 accura… binary  0.811     5\n 8    18  1107     3       3 3.83e-3 1.10e-4   0.492 roc_auc binary  0.867     5\n 9    13   655    10       3 1.32e-8 3.12e-4   0.523 accura… binary  0.786     5\n10    13   655    10       3 1.32e-8 3.12e-4   0.523 roc_auc binary  0.834     5\n# … with 50 more rows, 2 more variables: std_err <dbl>, .config <chr>, and\n#   abbreviated variable names ¹​tree_depth, ²​learn_rate, ³​loss_reduction,\n#   ⁴​sample_size, ⁵​.estimator\n```\n:::\n\n```{.r .cell-code}\nxgb_tuning_result %>%\n  collect_metrics() %>%\n  filter(.metric == \"roc_auc\") %>%\n  select(mean, mtry:sample_size) %>%\n  pivot_longer(mtry:sample_size,\n               values_to = \"value\",\n               names_to = \"parameter\"\n  ) %>%\n  ggplot(aes(value, mean, color = parameter)) +\n  geom_point(alpha = 0.8, show.legend = FALSE) +\n  facet_wrap(~parameter, scales = \"free_x\") +\n  labs(x = NULL, y = \"AUC\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n#### XGB Best Parameters then Finalise Workflow\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshow_best(xgb_tuning_result, \"roc_auc\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 13\n   mtry trees min_n tree_d…¹ learn…² loss_…³ sampl…⁴ .metric .esti…⁵  mean     n\n  <int> <int> <int>    <int>   <dbl>   <dbl>   <dbl> <chr>   <chr>   <dbl> <int>\n1    18  1107     3        3 3.83e-3 1.10e-4   0.492 roc_auc binary  0.867     5\n2    12  1039    16        4 1.63e-2 2.34e-2   0.986 roc_auc binary  0.859     5\n3     3  1814     5        6 5.67e-6 3.81e-6   0.913 roc_auc binary  0.846     5\n4     4   840     7       11 3.22e-8 1.94e-1   0.775 roc_auc binary  0.841     5\n5     6  1202     4        2 4.27e-7 9.25e-4   0.944 roc_auc binary  0.841     5\n# … with 2 more variables: std_err <dbl>, .config <chr>, and abbreviated\n#   variable names ¹​tree_depth, ²​learn_rate, ³​loss_reduction, ⁴​sample_size,\n#   ⁵​.estimator\n```\n:::\n\n```{.r .cell-code}\nxgb_best_params <- select_best(xgb_tuning_result, \"roc_auc\")\nxgb_best_params\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 8\n   mtry trees min_n tree_depth learn_rate loss_reduction sample_size .config    \n  <int> <int> <int>      <int>      <dbl>          <dbl>       <dbl> <chr>      \n1    18  1107     3          3    0.00383       0.000110       0.492 Preprocess…\n```\n:::\n\n```{.r .cell-code}\nxgb_final_wflow <- finalize_workflow(\n  xgb_wflow,\n  xgb_best_params\n)\n\nxgb_final_wflow\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: boost_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = 18\n  trees = 1107\n  min_n = 3\n  tree_depth = 3\n  learn_rate = 0.0038298863779315\n  loss_reduction = 0.00011029830522072\n  sample_size = 0.492113380425144\n\nComputational engine: xgboost \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nxgb_final_wflow %>%\n  fit(data = training(train_split)) %>%\n  extract_fit_parsnip() %>%\n  vip(geom = \"point\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n### XGB Performance on Training Test Set\n\n#### XGB Accuracy Measured on Test Set\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxgb_final_res <- last_fit(xgb_final_wflow, train_split)\nxgb_final_res\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits            id               .metrics .notes   .predictions .workflow \n  <list>            <chr>            <list>   <list>   <list>       <list>    \n1 <split [667/224]> train/test split <tibble> <tibble> <tibble>     <workflow>\n```\n:::\n\n```{.r .cell-code}\nxgb_final_metrics <- collect_metrics(xgb_final_res)\nxgb_final_metrics\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.808 Preprocessor1_Model1\n2 roc_auc  binary         0.860 Preprocessor1_Model1\n```\n:::\n:::\n\n\n#### XGB AUC on Test Set (within train)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxgb_final_res %>%\n  collect_predictions() %>%\n  roc_curve( truth = survived,.pred_1, event_level = \"second\") %>%\n  ggplot(aes(x = 1-specificity, y = sensitivity)) +\n  geom_line(size = 1.5, color = \"midnightblue\") +\n  geom_abline(\n    lty = 2, alpha = 0.5,\n    color = \"gray50\",\n    size = 1.2\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nxgb_test_predictions <- collect_predictions(xgb_final_res)\nhead(xgb_test_predictions)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 7\n  id               .pred_0 .pred_1  .row .pred_class survived .config           \n  <chr>              <dbl>   <dbl> <int> <fct>       <fct>    <chr>             \n1 train/test split  0.0636   0.936     2 1           1        Preprocessor1_Mod…\n2 train/test split  0.866    0.134     5 0           0        Preprocessor1_Mod…\n3 train/test split  0.823    0.177     7 0           0        Preprocessor1_Mod…\n4 train/test split  0.887    0.113    13 0           0        Preprocessor1_Mod…\n5 train/test split  0.788    0.212    14 0           0        Preprocessor1_Mod…\n6 train/test split  0.483    0.517    20 1           1        Preprocessor1_Mod…\n```\n:::\n:::\n\n\n### XGB Confusion Matrix\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxgb_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n## Neural Net\n\n### NN Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnnet_model <- \n   mlp(hidden_units = tune(), penalty = tune(), epochs = tune()) %>% \n   set_engine(\"nnet\", MaxNWts = 2600) %>% \n   set_mode(\"classification\")\n\nnnet_model %>% translate()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle Layer Neural Network Model Specification (classification)\n\nMain Arguments:\n  hidden_units = tune()\n  penalty = tune()\n  epochs = tune()\n\nEngine-Specific Arguments:\n  MaxNWts = 2600\n\nComputational engine: nnet \n\nModel fit template:\nnnet::nnet(formula = missing_arg(), data = missing_arg(), size = tune(), \n    decay = tune(), maxit = tune(), MaxNWts = 2600, trace = FALSE, \n    linout = FALSE)\n```\n:::\n:::\n\n\n### NN Workflow\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnnet_wflow <- workflow() %>% \n  add_model(nnet_model) %>% \n  add_recipe(recipe_base)\n```\n:::\n\n\n### NN Parameters\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnnet_grid <- grid_latin_hypercube(\n  hidden_units(),\n  penalty (),\n  epochs ()\n)\n\nhead(nnet_grid) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 3\n  hidden_units  penalty epochs\n         <int>    <dbl>  <int>\n1            6 2.86e- 3    610\n2            3 2.68e-10    887\n3            8 1.95e- 6     78\n```\n:::\n:::\n\n\n### NN Hyper-Parameter Tuning\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnnet_folds <- vfold_cv(training(train_split), strata = survived)\nnnet_folds\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#  10-fold cross-validation using stratification \n# A tibble: 10 × 2\n   splits           id    \n   <list>           <chr> \n 1 <split [599/68]> Fold01\n 2 <split [600/67]> Fold02\n 3 <split [600/67]> Fold03\n 4 <split [600/67]> Fold04\n 5 <split [600/67]> Fold05\n 6 <split [600/67]> Fold06\n 7 <split [601/66]> Fold07\n 8 <split [601/66]> Fold08\n 9 <split [601/66]> Fold09\n10 <split [601/66]> Fold10\n```\n:::\n\n```{.r .cell-code}\ndoParallel::registerDoParallel(cores = cores)\n\nset.seed(234)\nnnet_tuning_result <- tune_grid(\n  nnet_wflow,\n  resamples = folds,\n  grid      = nnet_grid,\n  control   = control_grid(save_pred = TRUE,save_workflow = TRUE)\n)\nnnet_tuning_result\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Tuning results\n# 5-fold cross-validation using stratification \n# A tibble: 5 × 5\n  splits            id    .metrics         .notes           .predictions      \n  <list>            <chr> <list>           <list>           <list>            \n1 <split [532/135]> Fold1 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [405 × 9]>\n2 <split [534/133]> Fold2 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [399 × 9]>\n3 <split [534/133]> Fold3 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [399 × 9]>\n4 <split [534/133]> Fold4 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [399 × 9]>\n5 <split [534/133]> Fold5 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [399 × 9]>\n```\n:::\n:::\n\n\n### NN Best Parameters and Finalise Workflow\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshow_best(nnet_tuning_result, \"accuracy\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 9\n  hidden_units  penalty epochs .metric  .estimator  mean     n std_err .config  \n         <int>    <dbl>  <int> <chr>    <chr>      <dbl> <int>   <dbl> <chr>    \n1            6 2.86e- 3    610 accuracy binary     0.798     5 0.0201  Preproce…\n2            3 2.68e-10    887 accuracy binary     0.790     5 0.00910 Preproce…\n3            8 1.95e- 6     78 accuracy binary     0.790     5 0.0124  Preproce…\n```\n:::\n\n```{.r .cell-code}\nnn_best_params <- select_best(nnet_tuning_result, \"accuracy\")\n\nnnet_best_auc <- select_best(xgb_tuning_result, \"accuracy\")\nnnet_best_auc\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 8\n   mtry trees min_n tree_depth learn_rate loss_reduction sample_size .config    \n  <int> <int> <int>      <int>      <dbl>          <dbl>       <dbl> <chr>      \n1    18  1107     3          3    0.00383       0.000110       0.492 Preprocess…\n```\n:::\n\n```{.r .cell-code}\nnnet_final_wflow <- finalize_workflow(\n  nnet_wflow,\n  nn_best_params\n)\n\nnnet_final_wflow\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: mlp()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nSingle Layer Neural Network Model Specification (classification)\n\nMain Arguments:\n  hidden_units = 6\n  penalty = 0.00285607605888812\n  epochs = 610\n\nEngine-Specific Arguments:\n  MaxNWts = 2600\n\nComputational engine: nnet \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnnet_final_wflow %>%\n  fit(data = training(train_split)) %>%\n  extract_fit_parsnip() %>%\n  vip(geom = \"point\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/nn_final_train-1.png){width=672}\n:::\n:::\n\n\n### NN Accuracy - Train/Test Set\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnnet_tuning_metrics <- collect_metrics(nnet_tuning_result)\nnnet_tuning_metrics\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 9\n  hidden_units  penalty epochs .metric  .estimator  mean     n std_err .config  \n         <int>    <dbl>  <int> <chr>    <chr>      <dbl> <int>   <dbl> <chr>    \n1            6 2.86e- 3    610 accuracy binary     0.798     5 0.0201  Preproce…\n2            6 2.86e- 3    610 roc_auc  binary     0.829     5 0.0180  Preproce…\n3            3 2.68e-10    887 accuracy binary     0.790     5 0.00910 Preproce…\n4            3 2.68e-10    887 roc_auc  binary     0.813     5 0.0185  Preproce…\n5            8 1.95e- 6     78 accuracy binary     0.790     5 0.0124  Preproce…\n6            8 1.95e- 6     78 roc_auc  binary     0.839     5 0.0156  Preproce…\n```\n:::\n\n```{.r .cell-code}\nnnet_final_res <- last_fit(nnet_final_wflow, train_split)\nnnet_final_res\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits            id               .metrics .notes   .predictions .workflow \n  <list>            <chr>            <list>   <list>   <list>       <list>    \n1 <split [667/224]> train/test split <tibble> <tibble> <tibble>     <workflow>\n```\n:::\n\n```{.r .cell-code}\nnnet_final_metrics <- collect_metrics(nnet_final_res)\nnnet_final_metrics\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.790 Preprocessor1_Model1\n2 roc_auc  binary         0.771 Preprocessor1_Model1\n```\n:::\n:::\n\n\n### NN AUC\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnnet_final_res %>%\n  collect_predictions() %>%\n  roc_curve( truth = survived,.pred_1, event_level = \"second\") %>%\n  ggplot(aes(x = 1-specificity, y = sensitivity)) +\n  geom_line(size = 1.5, color = \"midnightblue\") +\n  geom_abline(\n    lty = 2, alpha = 0.5,\n    color = \"gray50\",\n    size = 1.2\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n### NN Predictions on Train/Test Set\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnnet_test_predictions <- nnet_final_res %>%\n  collect_predictions() \nhead(nnet_test_predictions)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 7\n  id               .pred_0 .pred_1  .row .pred_class survived .config           \n  <chr>              <dbl>   <dbl> <int> <fct>       <fct>    <chr>             \n1 train/test split   0.274   0.726     2 1           1        Preprocessor1_Mod…\n2 train/test split   0.645   0.355     5 0           0        Preprocessor1_Mod…\n3 train/test split   0.269   0.731     7 1           0        Preprocessor1_Mod…\n4 train/test split   0.728   0.272    13 0           0        Preprocessor1_Mod…\n5 train/test split   0.698   0.302    14 0           0        Preprocessor1_Mod…\n6 train/test split   0.271   0.729    20 1           1        Preprocessor1_Mod…\n```\n:::\n:::\n\n\n### NN Confusion Matrix\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnnet_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/NN_confusion_matrix-1.png){width=672}\n:::\n:::\n\n\n## Stack Models - not working\n\n### Stack Recipe\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrecipe_stack <- \n  recipe(survived ~ ., data = training(train_split)) %>% \n  update_role(passenger_id, name,surname,ticket,cabin,new_role = \"ID\") %>% \n  step_impute_knn(all_numeric_predictors()) %>% \n  step_dummy(all_nominal_predictors()) %>%\n  step_factor2string(all_nominal_predictors()) %>% \n  step_zv(all_predictors()) %>% \n  step_pca()\nrecipe_stack\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRecipe\n\nInputs:\n\n      role #variables\n        ID          5\n   outcome          1\n predictor         13\n\nOperations:\n\nK-nearest neighbor imputation for all_numeric_predictors()\nDummy variables from all_nominal_predictors()\nCharacter variables from all_nominal_predictors()\nZero variance filter on all_predictors()\nPCA extraction with <none>\n```\n:::\n\n```{.r .cell-code}\nrecipe_stack_trained <- prep(recipe_base)\nrecipe_stack_trained\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRecipe\n\nInputs:\n\n      role #variables\n        ID          5\n   outcome          1\n predictor         13\n\nTraining data contained 667 data points and 510 incomplete rows. \n\nOperations:\n\nK-nearest neighbor imputation for age, sib_sp, parch, fare [trained]\nDummy variables from pclass, sex, embarked, train_test, pax_type, cabin_prefac... [trained]\nCharacter variables from <none> [trained]\nZero variance filter removed train_test_test, pax_type_F_titled [trained]\nNo PCA components were extracted from <none> [trained]\n```\n:::\n:::\n\n\n### Stack Controls\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstack_ctrl <- control_resamples(save_pred = TRUE, save_workflow = TRUE)\n#stack_folds <- vfold_cv(training(train_split), v=10,strata = \"survived\")\n\nlibrary(stacks)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'stacks' was built under R version 4.2.1\n```\n:::\n\n```{.r .cell-code}\nmodel_stack <-\n  stacks() %>%\n  #add_candidates(lr_wflow) %>%\n  #add_candidates(rf_wflow) %>%\n  add_candidates(nnet_tuning_result) %>%\n  add_candidates(rlr_tuning_result) %>% \n  add_candidates(xgb_tuning_result)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Predictions from 7 candidates were identical to those from existing\ncandidates and were removed from the data stack.\n```\n:::\n:::\n\n\n### Stack LR\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstack_lr_wflow <- \n  workflow() %>% \n  add_model(lr_spec) %>% \n  add_recipe(recipe_stack)\nlr_wflow\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n```\n:::\n\n```{.r .cell-code}\nstack_lr_res <- \n  lr_wflow %>% \n  tune_grid(folds,control = stack_ctrl)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: No tuning parameters have been detected, performance will be evaluated\nusing the resamples with no tuning. Did you want to [tune()] parameters?\n```\n:::\n\n```{.r .cell-code}\nstack_lr_res\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Tuning results\n# 5-fold cross-validation using stratification \n# A tibble: 5 × 5\n  splits            id    .metrics         .notes           .predictions      \n  <list>            <chr> <list>           <list>           <list>            \n1 <split [532/135]> Fold1 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [135 × 6]>\n2 <split [534/133]> Fold2 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [133 × 6]>\n3 <split [534/133]> Fold3 <tibble [2 × 4]> <tibble [1 × 3]> <tibble [133 × 6]>\n4 <split [534/133]> Fold4 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [133 × 6]>\n5 <split [534/133]> Fold5 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [133 × 6]>\n\nThere were issues with some computations:\n\n  - Warning(s) x1: prediction from a rank-deficient fit may be misleading\n\nRun `show_notes(.Last.tune.result)` for more information.\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# autoplot(stack_lr_res) + \n#   scale_color_viridis_d(direction = -1) + \n#   theme(legend.position = \"top\")\n```\n:::\n\n\n\n### Stack RLR\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# stack_rlr_wflow <- \n#   workflow() %>% \n#   add_model(rlr_model) %>% \n#   add_recipe(recipe_stack)\n# stack_rlr_wflow\n# \n# stack_rlr_res <- \n#   stack_rlr_wflow %>% \n#   fit_resamples(folds,control = stack_ctrl)\n# stack_rlr_res\n```\n:::\n\n\n### Initialise Stack\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstack_models <-\n  stacks()\nstack_models\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A data stack with 0 model definitions and 0 candidate members.\n```\n:::\n\n```{.r .cell-code}\nstack_models %>% \nadd_candidates(stack_lr_res)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: The inputted `candidates` argument `stack_lr_res` generated notes\nduring tuning/resampling. Model stacking may fail due to these issues; see `?\ncollect_notes` if so.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A data stack with 1 model definition and 1 candidate member:\n#   stack_lr_res: 1 model configuration\n# Outcome: survived (factor)\n```\n:::\n:::\n\n\n## Join Model Prediction Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nall_predictions <- \n  lr_test_predictions %>% mutate(model = \"LR\") %>% \n  bind_rows(nnet_test_predictions %>% mutate(model = \"NNet\")) %>% \n  bind_rows(rlr_test_predictions %>% mutate(model = \"Reg_LR\")) %>% \n  bind_rows(rf_test_predictions %>% mutate(model = \"RF\")) %>% \n  bind_rows(xgb_test_predictions %>% mutate(model = \"xgb\")) %>% \n  bind_rows(xgb_usemodel_test_predictions %>% mutate(model = \"xgb_usemodel\")) \n  \nhead(all_predictions)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 8\n  id               .pred_0 .pred_1  .row .pred_class survived .config      model\n  <chr>              <dbl>   <dbl> <int> <fct>       <fct>    <chr>        <chr>\n1 train/test split  0.0518 0.948       2 1           1        Preprocesso… LR   \n2 train/test split  0.929  0.0709      5 0           0        Preprocesso… LR   \n3 train/test split  0.465  0.535       7 1           0        Preprocesso… LR   \n4 train/test split  0.914  0.0863     13 0           0        Preprocesso… LR   \n5 train/test split  0.997  0.00329    14 0           0        Preprocesso… LR   \n6 train/test split  0.131  0.869      20 1           1        Preprocesso… LR   \n```\n:::\n:::\n\n\n## All Metrics\n\nOrdered by descending ROC\n\n\n::: {.cell}\n\n```{.r .cell-code}\nall_metrics <- \n  lr_final_metrics %>% mutate(model = \"LR\") %>% \n  bind_rows(nnet_final_metrics %>% mutate(model = \"NNet\")) %>% \n  bind_rows(rlr_final_metrics %>% mutate(model = \"Reg_LR\")) %>% \n  bind_rows(rf_final_metrics %>% mutate(model = \"RF\")) %>% \n  bind_rows(xgb_final_metrics %>% mutate(model = \"xgb\")) %>% \n  bind_rows(xgb_usemodel_final_metrics %>% mutate(model = \"xgb-usemodel\")) \n\nall_metrics_table <- all_metrics %>% \n   pivot_wider(names_from = .metric,values_from = .estimate) %>% \n   arrange(desc(roc_auc))\n  \nall_metrics_table\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 5\n  .estimator .config              model        accuracy roc_auc\n  <chr>      <chr>                <chr>           <dbl>   <dbl>\n1 binary     Preprocessor1_Model1 RF              0.821   0.862\n2 binary     Preprocessor1_Model1 xgb             0.808   0.860\n3 binary     Preprocessor1_Model1 Reg_LR          0.830   0.857\n4 binary     Preprocessor1_Model1 xgb-usemodel    0.786   0.836\n5 binary     Preprocessor1_Model1 LR              0.830   0.819\n6 binary     Preprocessor1_Model1 NNet            0.790   0.771\n```\n:::\n:::\n\n\nand a graph:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nall_metrics %>% \n  filter(.metric == \"roc_auc\") %>% \n  select(model, roc = .estimate) %>% \n  ggplot(aes(model, roc)) +\n  geom_col()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/graph_all_metrics-1.png){width=672}\n:::\n:::\n\n\n## Ensemble - Workflow Sets - not working\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# no_pre_proc <- \n#    workflow_set(\n#       preproc = list(base = recipe_base), \n#       models = list(RF             = lr_model, \n#                     Regularised_LR = rlr_model, \n#                     Rand_Forest    = rf_model, \n#                     boosting       = xgb_model),\n#       cross = TRUE\n#    )\n# no_pre_proc\n# \n# add_cand\n```\n:::\n\n\n# Final Submission\n\n## Predict on Test set\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_test_preds <- \n  nnet_final_wflow %>% \n  fit(train_proc_adj_tbl) %>% \n  predict(new_data=testing(train_split)) %>% \n  bind_cols(testing(train_split)) %>% \n  select(PassengerID = passenger_id,Survived = .pred_class)\n\n#colnames(test_2)\n```\n:::\n\n\n## Write Submission File\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#write_csv(final_test_preds,\"titanic_sumission.csv\")\n```\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}