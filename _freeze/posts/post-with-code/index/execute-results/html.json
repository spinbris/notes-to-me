{
  "hash": "9a62aad6dee1400b6e261dccabc60db2",
  "result": {
    "markdown": "---\ntitle: \"Titanic from Kaggle\"\nauthor: \"Stephen Parton\"\ndate: \"2022-09-01\"\ncategories: [code, analysis,titanic]\nwebsite:\n  sidebar:\n    style: \"docked\"\n    search: true\n    contents:\n      - section: \"Data Exploration\"\n      - index.qmd\nformat: \n  html: \n    toc: true\n    toc-title: Contents\n    number-sections: true\n    number-depth: 3\n    code-fold: true\nexecute: \n  warning: false\n  error: false\n  freeze: true\n---\n\n\n![](thumbnail.jpg){width=\"215\"}\n\n## Summary \n\nThis is just a first test with code in a blog using the new Quarto framework! Guess what I am using..yep Titanic, Kaggle version..\n\nIt is not very well structured as it is pretty much in the order I did it following all instructions, books and blogs from the expert TidyModels and Quarto teams at RStudio/Posit . All errors belong to me!\n\n\n\n\n\n## Final Kaggle Scores\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkaggle <- tibble(\n  Model = c(\"Logistic Regression\",\n            \"Regularised Logistic Regression\",\n            \"Random Forest-final\",\n            \"Random Forest-initial\",\n            \"XG Boost\",\n            \"Neural Net\",\n            \"Ensemble\"), \n  Score = c(.76555,.77033,.77751,.78229,.77272,.76794,.77751)\n  )\n\nkaggle %>% knitr::kable()\n```\n\n::: {.cell-output-display}\n|Model                           |   Score|\n|:-------------------------------|-------:|\n|Logistic Regression             | 0.76555|\n|Regularised Logistic Regression | 0.77033|\n|Random Forest-final             | 0.77751|\n|Random Forest-initial           | 0.78229|\n|XG Boost                        | 0.77272|\n|Neural Net                      | 0.76794|\n|Ensemble                        | 0.77751|\n:::\n:::\n\n\nWhich when all submitted gave me a ranking of 1,872 out of 13,000 or so teams, so no grand-master!\n\nSeems like the value mainly comes from the feature engineering and selection process (as the experts all seem to say) given the similarity in above model scores.\n\n## Review Data\n\n### Load Some Kaggle Data\n\nNot the...? Yes, the Titanic again....\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain <- read_csv(\"data_raw/train.csv\",show_col_types = FALSE) %>% clean_names() %>% mutate(train_test = \"train\")\ntest <- read_csv(\"data_raw/test.csv\",show_col_types = FALSE) %>% clean_names() %>% \n  mutate(train_test = \"test\")\nall <- train %>% bind_rows(test)\n\n# colnames(data)\n# cwd()\n```\n:::\n\n\n### Some Initial EDA\n\nA quick look.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain %>% skim() \n```\n\n::: {.cell-output-display}\nTable: Data summary\n\n|                         |           |\n|:------------------------|:----------|\n|Name                     |Piped data |\n|Number of rows           |891        |\n|Number of columns        |13         |\n|_______________________  |           |\n|Column type frequency:   |           |\n|character                |6          |\n|numeric                  |7          |\n|________________________ |           |\n|Group variables          |None       |\n\n\n**Variable type: character**\n\n|skim_variable | n_missing| complete_rate| min| max| empty| n_unique| whitespace|\n|:-------------|---------:|-------------:|---:|---:|-----:|--------:|----------:|\n|name          |         0|          1.00|  12|  82|     0|      891|          0|\n|sex           |         0|          1.00|   4|   6|     0|        2|          0|\n|ticket        |         0|          1.00|   3|  18|     0|      681|          0|\n|cabin         |       687|          0.23|   1|  15|     0|      147|          0|\n|embarked      |         2|          1.00|   1|   1|     0|        3|          0|\n|train_test    |         0|          1.00|   5|   5|     0|        1|          0|\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate|   mean|     sd|   p0|    p25|    p50|   p75|   p100|hist  |\n|:-------------|---------:|-------------:|------:|------:|----:|------:|------:|-----:|------:|:-----|\n|passenger_id  |         0|           1.0| 446.00| 257.35| 1.00| 223.50| 446.00| 668.5| 891.00|▇▇▇▇▇ |\n|survived      |         0|           1.0|   0.38|   0.49| 0.00|   0.00|   0.00|   1.0|   1.00|▇▁▁▁▅ |\n|pclass        |         0|           1.0|   2.31|   0.84| 1.00|   2.00|   3.00|   3.0|   3.00|▃▁▃▁▇ |\n|age           |       177|           0.8|  29.70|  14.53| 0.42|  20.12|  28.00|  38.0|  80.00|▂▇▅▂▁ |\n|sib_sp        |         0|           1.0|   0.52|   1.10| 0.00|   0.00|   0.00|   1.0|   8.00|▇▁▁▁▁ |\n|parch         |         0|           1.0|   0.38|   0.81| 0.00|   0.00|   0.00|   0.0|   6.00|▇▁▁▁▁ |\n|fare          |         0|           1.0|  32.20|  49.69| 0.00|   7.91|  14.45|  31.0| 512.33|▇▁▁▁▁ |\n:::\n:::\n\n\n### Some Initial Wrangling\n\n\n::: {.cell}\n\n```{.r .cell-code}\nall_proc <- all %>% \n  mutate(title = str_extract(name,\"(\\\\w)([a-z]+)(\\\\.)\")) %>% \n  mutate(pax_type = case_when(\n    title %in% c(\"Miss.\",\"Ms.\",\"Mlle.\")         ~ \"F_unmarried\",\n    title %in% c(\"Mme.\",\"Mrs.\")                 ~ \"F_married\",\n    title %in% c(\"Countess.\",\"Lady.\",\"Dona.\")   ~ \"F_titled\",\n    title %in% c(\"Capt.\",\"Col.\",\"Major.\")       ~ \"Military\",\n    title %in% c(\"Dr.\",\"Rev.\")                  ~ \"M_Professional\",\n    title %in% c(\"Don.\",\"Jonkheer.\",\"Sir.\")     ~ \"M_titled\",\n    TRUE ~ title\n  ),\n  surname        = str_extract(name,\"(\\\\w+)(\\\\,)\"),\n  survival       = ifelse(survived==0,\"No\",\"Yes\"),\n  ticket_preface = str_extract(ticket,\"([:graph:]+)(\\\\s)\"),\n  ticket_preface = ifelse(is.na(ticket_preface),\"none\",ticket_preface),\n  cabin_preface  = ifelse(is.na(cabin),\"nk\",\n                    substr(cabin,1,1)),\n  embarked       = ifelse(is.na(embarked),\"S\",embarked)\n  ) %>% \n  group_by(pax_type,pclass) %>% \n  mutate(age     = ifelse(is.na(age),median(age,na.rm = T), age)) %>% \n  ungroup() %>% \n  add_count(ticket,name = \"ticket_group\") %>% \n  mutate(ticket_group = case_when(\n    ticket_group == 1 ~ \"single\",\n    ticket_group == 2 ~ \"couple\",\n    TRUE              ~ \"group\"\n  ),\n    family_group = as.numeric(sib_sp)+as.numeric(parch)+1\n  ) %>% \n  mutate(family_group = factor(\n    case_when(\n        family_group < 2  ~ \"single\",\n        family_group < 3  ~ \"couple\",\n        TRUE              ~ \"family\"\n        ),\n    ordered = TRUE)\n  ) %>% \n  mutate(age_group = factor(case_when(\n    age < 13      ~ \"child\",\n    age < 20      ~ \"teen\",\n    age < 30      ~ \"20s\",\n    age < 40      ~ \"30s\",\n    age < 50      ~ \"40s\",\n    age < 60      ~ \"50s\",\n    TRUE          ~ \"60+\"\n    \n  ),\n  ordered = TRUE)\n  ) %>% \n  mutate(across(where(is.character),as_factor)) %>% \n  mutate(pclass = factor(pclass,levels = c(\"1\",\"2\",\"3\")),\n         survived = factor(survived)\n         ) %>% \nselect(-c(title,ticket_preface))\n  \n#all_proc %>% glimpse() \n```\n:::\n\n\n### A bit more EDA\n\n\n::: {.cell}\n\n```{.r .cell-code}\nall_proc %>% \n  select(-c(name,ticket,cabin,surname,train_test)) %>% \n  DataExplorer::plot_bar()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/EDA_1-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/EDA_1-2.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nall_proc %>% DataExplorer::plot_histogram(ggtheme = theme_light() )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/data_explorer1-1.png){width=672}\n:::\n:::\n\n\n### Eyeballing Survival Graphs on Training Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nno_f <- all_proc %>%\n  filter(train_test == \"train\") %>% \n  select(passenger_id,pclass,sex,embarked,pax_type,ticket_group,family_group,age_group,cabin_preface,survival) %>% \n  droplevels() %>%\n  mutate(across(where(is.factor),~ factor(.x,ordered = FALSE))) %>%\n  pivot_longer(cols = c(pclass:cabin_preface)) \n\n\ng_l <- no_f %>% \n  split(.$name) %>% \n  map(~ ggplot(.,aes(y=value,fill=survival)) +\n                geom_bar() +\n              ggtitle(.$name) +\n        theme_bw() +\n        labs(x=NULL,y=NULL)+\n        scale_fill_viridis_d(option = \"cividis\")\n      \n            ) \n\nlibrary(patchwork)\nwrap_plots(g_l, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/eye_ball_survival-1.png){width=672}\n:::\n:::\n\n\n### Split Data back to Train/Test/Validation\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_proc_adj_tbl <- all_proc %>% \n  filter(train_test ==\"train\") %>% \n  select(-c(survival))\n\n\n  \ntrain_split <- initial_split(train_proc_adj_tbl,strata = survived)\n\ntrain_train <- training(train_split)\ntrain_test <- testing(train_split)\n```\n:::\n\n\n## Recipe-Base\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrecipe_base <- \n  recipe(survived ~ ., data = train_train) %>% \n  update_role(passenger_id, name,surname,ticket,cabin,new_role = \"ID\") %>%\n  step_impute_knn(all_numeric_predictors()) %>% \n  step_dummy(all_nominal_predictors()) %>%\n  step_factor2string(all_nominal_predictors()) %>% \n  step_zv(all_predictors()) %>% \n  step_pca()\nrecipe_base\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRecipe\n\nInputs:\n\n      role #variables\n        ID          5\n   outcome          1\n predictor         13\n\nOperations:\n\nK-nearest neighbor imputation for all_numeric_predictors()\nDummy variables from all_nominal_predictors()\nCharacter variables from all_nominal_predictors()\nZero variance filter on all_predictors()\nPCA extraction with <none>\n```\n:::\n:::\n\n\n### Save Files\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(all_proc,\"artifacts/all_proc.rds\")\nwrite_rds(train_split,\"artifacts/train_split.rds\")\nwrite_rds(recipe_base,\"artifacts/recipe_base.rds\")\n# \n# all_proc <- read_rds(\"artifacts/all_proc.rds\")\n# train_split <- read_rds(\"artifacts/train_split.rds\")\n# recipe_base <- read_rds(\"artifacts/recipe_base.rds\")\n```\n:::\n\n\n## Models\n\n### Logistic Regression\n\n#### LR Model Spec\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlr_spec <-  \n  logistic_reg() %>% \n  set_engine(\"glm\")\n\nlr_spec\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n```\n:::\n:::\n\n\n#### LR Workflow\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlr_wflow <- \n  workflow() %>% \n  add_model(lr_spec) %>% \n  add_recipe(recipe_base)\n\nlr_wflow\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n```\n:::\n:::\n\n\n#### LR Fit Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlr_fit <- \n  lr_wflow %>% \n  last_fit(train_split)\n\n#lr_fit\n\nlr_final_metrics <- lr_fit %>% collect_metrics()\nlr_final_metrics \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.790 Preprocessor1_Model1\n2 roc_auc  binary         0.791 Preprocessor1_Model1\n```\n:::\n\n```{.r .cell-code}\n#show_notes(.Last.tune.result)\n```\n:::\n\n\n#### LR Predict\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlr_test_predictions <- lr_fit %>% collect_predictions() %>% \n  rename(survived_pred = survived) %>% \n  bind_cols(train_test)\nlr_test_predictions\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 224 × 26\n   id       .pred_0 .pred_1  .row .pred…¹ survi…² .config passe…³ survi…⁴ pclass\n   <chr>      <dbl>   <dbl> <int> <fct>   <fct>   <chr>     <dbl> <fct>   <fct> \n 1 train/t…  0.0487  0.951      4 1       1       Prepro…       4 1       1     \n 2 train/t…  0.829   0.171     21 0       0       Prepro…      21 0       2     \n 3 train/t…  0.191   0.809     23 1       1       Prepro…      23 1       3     \n 4 train/t…  0.801   0.199     24 0       1       Prepro…      24 1       1     \n 5 train/t…  0.714   0.286     25 0       0       Prepro…      25 0       3     \n 6 train/t…  0.931   0.0687    28 0       0       Prepro…      28 0       1     \n 7 train/t…  0.270   0.730     31 1       0       Prepro…      31 0       1     \n 8 train/t…  0.904   0.0963    37 0       1       Prepro…      37 1       3     \n 9 train/t…  0.159   0.841     42 1       0       Prepro…      42 0       2     \n10 train/t…  0.904   0.0962    43 0       0       Prepro…      43 0       3     \n# … with 214 more rows, 16 more variables: name <fct>, sex <fct>, age <dbl>,\n#   sib_sp <dbl>, parch <dbl>, ticket <fct>, fare <dbl>, cabin <fct>,\n#   embarked <fct>, train_test <fct>, pax_type <fct>, surname <fct>,\n#   cabin_preface <fct>, ticket_group <fct>, family_group <ord>,\n#   age_group <ord>, and abbreviated variable names ¹​.pred_class,\n#   ²​survived_pred, ³​passenger_id, ⁴​survived\n```\n:::\n:::\n\n\n#### LR Performance on validation set\n\n##### AUC Curve\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlr_test_predictions %>% \n  roc_curve(truth = survived,.pred_1,event_level=\"second\") %>% \n  autoplot()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/LR_auc-1.png){width=672}\n:::\n:::\n\n\n##### Confusion Matrix\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlr_test_predictions %>% \n  conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/LR_confuse-1.png){width=672}\n:::\n:::\n\n\n#### LR Resampling\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfolds <- vfold_cv(train_train, strata = survived, v=5)\n#folds\n\ncontrol <- control_resamples(save_pred = TRUE,save_workflow = TRUE)\n\ncores <- parallel::detectCores()\ncl <- parallel::makePSOCKcluster(cores - 1)\n\n# doParallel::registerDoParallel(cores = cores)\nset.seed(1234)\nlr_fit_cv <- \n  lr_wflow %>% \n  fit_resamples(folds, control = control)\n\n#show_best(lr_fit_cv,metric= \"accuracy\")\n\n#lr_fit_cv\nlr_metrics_resample <- collect_metrics(lr_fit_cv)\nlr_metrics_resample\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy binary     0.832     5  0.0170 Preprocessor1_Model1\n2 roc_auc  binary     0.875     5  0.0171 Preprocessor1_Model1\n```\n:::\n\n```{.r .cell-code}\nparallel::stopCluster(cl)\n```\n:::\n\n\nFollowing still to be fixed!\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#lr_param <- extract_parameter_set_dials(lr_spec)\n\nlr_resample_test_predictions <- collect_predictions(lr_fit_cv) %>% \n  rename(survived_pred = survived) \n#  bind_cols(testing(train_split))\nlr_resample_test_predictions\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 667 × 7\n   id    .pred_0 .pred_1  .row .pred_class survived_pred .config             \n   <chr>   <dbl>   <dbl> <int> <fct>       <fct>         <chr>               \n 1 Fold1   0.944  0.0563     2 0           0             Preprocessor1_Model1\n 2 Fold1   0.447  0.553      5 1           0             Preprocessor1_Model1\n 3 Fold1   0.827  0.173     14 0           0             Preprocessor1_Model1\n 4 Fold1   0.479  0.521     18 1           0             Preprocessor1_Model1\n 5 Fold1   0.935  0.0651    22 0           0             Preprocessor1_Model1\n 6 Fold1   0.914  0.0862    24 0           0             Preprocessor1_Model1\n 7 Fold1   0.876  0.124     25 0           0             Preprocessor1_Model1\n 8 Fold1   0.603  0.397     28 0           0             Preprocessor1_Model1\n 9 Fold1   0.956  0.0442    32 0           0             Preprocessor1_Model1\n10 Fold1   0.953  0.0468    39 0           0             Preprocessor1_Model1\n# … with 657 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncl <- parallel::makePSOCKcluster(cores - 1)\n\nset.seed(1234)\nlm_fit <- lr_wflow %>% fit(data = train_proc_adj_tbl)\nextract_recipe(lm_fit, estimated = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRecipe\n\nInputs:\n\n      role #variables\n        ID          5\n   outcome          1\n predictor         13\n\nTraining data contained 891 data points and 687 incomplete rows. \n\nOperations:\n\nK-nearest neighbor imputation for age, sib_sp, parch, fare [trained]\nDummy variables from pclass, sex, embarked, train_test, pax_type, cabin_prefac... [trained]\nCharacter variables from <none> [trained]\nZero variance filter removed train_test_test [trained]\nNo PCA components were extracted from <none> [trained]\n```\n:::\n\n```{.r .cell-code}\nparallel::stopCluster(cl)\n```\n:::\n\n\n## Regularised Logistic Regression - GLMNET\n\n### RLR Model Spec\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrlr_model <- \n  logistic_reg(penalty = tune(), mixture = tune()) %>% \n  set_engine(\"glmnet\")\nrlr_model\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = tune()\n\nComputational engine: glmnet \n```\n:::\n:::\n\n\n### RLR Parameter Tuning\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrlr_param <- extract_parameter_set_dials(rlr_model)\n\nrlr_grid <- grid_latin_hypercube(\n  penalty(),\n  mixture(),\n  size = 30\n)\nhead(rlr_grid) %>% knitr::kable(digits =3)\n```\n\n::: {.cell-output-display}\n| penalty| mixture|\n|-------:|-------:|\n|   0.116|   0.866|\n|   0.095|   0.736|\n|   0.000|   0.141|\n|   0.000|   0.458|\n|   0.025|   0.983|\n|   0.484|   0.109|\n:::\n:::\n\n\n### RLR Workflow\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrlr_wflow <- \n  workflow() %>% \n  add_model(rlr_model) %>% \n  add_recipe(recipe_base)\nrlr_wflow\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = tune()\n\nComputational engine: glmnet \n```\n:::\n:::\n\n\n### RLR Hyper-parameter Tuning\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# rlr_folds <- vfold_cv(training(train_split), strata = survived, v=10,repeats = 5)\n# rlr_folds %>% tidy()\n\n#doParallel::registerDoParallel(cores = cores)\ncl <- parallel::makePSOCKcluster(cores - 1)\n\nset.seed(234)\nrlr_tuning_result <- tune_grid(\n  rlr_wflow,\n  resamples = folds,\n  grid      = rlr_grid,\n  control   = control_grid(save_pred = TRUE, save_workflow = TRUE)\n)\n\nrlr_tuning_metrics <- collect_metrics(rlr_tuning_result)\nhead(rlr_tuning_metrics) %>% knitr::kable(digits = 3)\n```\n\n::: {.cell-output-display}\n| penalty| mixture|.metric  |.estimator |  mean|  n| std_err|.config               |\n|-------:|-------:|:--------|:----------|-----:|--:|-------:|:---------------------|\n|   0.016|   0.018|accuracy |binary     | 0.834|  5|   0.018|Preprocessor1_Model01 |\n|   0.016|   0.018|roc_auc  |binary     | 0.879|  5|   0.014|Preprocessor1_Model01 |\n|   0.000|   0.066|accuracy |binary     | 0.834|  5|   0.016|Preprocessor1_Model02 |\n|   0.000|   0.066|roc_auc  |binary     | 0.875|  5|   0.017|Preprocessor1_Model02 |\n|   0.000|   0.070|accuracy |binary     | 0.834|  5|   0.016|Preprocessor1_Model03 |\n|   0.000|   0.070|roc_auc  |binary     | 0.875|  5|   0.017|Preprocessor1_Model03 |\n:::\n\n```{.r .cell-code}\nparallel::stopCluster(cl)\n```\n:::\n\n\nReview hyper-parameter tuning results and select best\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrlr_tuning_result %>%\n  collect_metrics() %>%\n  filter(.metric == \"accuracy\") %>%\n  select(mean, penalty,mixture) %>%\n  pivot_longer(penalty:mixture,\n               values_to = \"value\",\n               names_to = \"parameter\"\n  ) %>%\n  ggplot(aes(value, mean, color = parameter)) +\n  geom_point(alpha = 0.8, show.legend = FALSE) +\n  facet_wrap(~parameter, scales = \"free_x\") +\n  labs(x = NULL, y = \"AUC\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/rlr_tune-1.png){width=672}\n:::\n\n```{.r .cell-code}\nshow_best(rlr_tuning_result, \"accuracy\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 8\n   penalty mixture .metric  .estimator  mean     n std_err .config              \n     <dbl>   <dbl> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n1 0.00886    0.923 accuracy binary     0.843     5  0.0126 Preprocessor1_Model28\n2 0.00193    0.946 accuracy binary     0.838     5  0.0166 Preprocessor1_Model29\n3 0.00349    0.598 accuracy binary     0.835     5  0.0177 Preprocessor1_Model18\n4 0.000475   0.368 accuracy binary     0.835     5  0.0165 Preprocessor1_Model12\n5 0.000269   0.558 accuracy binary     0.835     5  0.0165 Preprocessor1_Model17\n```\n:::\n\n```{.r .cell-code}\nbest_rlr_auc <- select_best(rlr_tuning_result, \"accuracy\")\nbest_rlr_auc\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  penalty mixture .config              \n    <dbl>   <dbl> <chr>                \n1 0.00886   0.923 Preprocessor1_Model28\n```\n:::\n:::\n\n\n### RLR Predict\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrlr_final_wflow <- finalize_workflow(\n  rlr_wflow,\n  best_rlr_auc\n)\n\nrlr_final_wflow\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = 0.00885574773491923\n  mixture = 0.923322001239285\n\nComputational engine: glmnet \n```\n:::\n\n```{.r .cell-code}\nrlr_final_wflow %>%\n  last_fit(train_split) %>%\n  extract_fit_parsnip() %>%\n  vip(geom = \"col\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/rlr_predict1-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrlr_final_fit <- rlr_final_wflow %>%\n  last_fit(train_split)\n\nrlr_final_metrics <- collect_metrics(rlr_final_fit)\nrlr_final_metrics %>% knitr::kable()\n```\n\n::: {.cell-output-display}\n|.metric  |.estimator | .estimate|.config              |\n|:--------|:----------|---------:|:--------------------|\n|accuracy |binary     | 0.8080357|Preprocessor1_Model1 |\n|roc_auc  |binary     | 0.8128160|Preprocessor1_Model1 |\n:::\n\n```{.r .cell-code}\nrlr_test_predictions <- rlr_final_fit %>% collect_predictions()\nrlr_test_predictions_all <- rlr_test_predictions %>% \n  bind_cols(train_test %>% select(-survived)) \n\n\n\nglimpse(rlr_test_predictions_all)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 224\nColumns: 25\n$ id            <chr> \"train/test split\", \"train/test split\", \"train/test spli…\n$ .pred_0       <dbl> 0.1041824, 0.8021418, 0.2841632, 0.7752333, 0.6520484, 0…\n$ .pred_1       <dbl> 0.89581765, 0.19785816, 0.71583682, 0.22476672, 0.347951…\n$ .row          <int> 4, 21, 23, 24, 25, 28, 31, 37, 42, 43, 44, 49, 50, 59, 6…\n$ .pred_class   <fct> 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,…\n$ survived      <fct> 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,…\n$ .config       <chr> \"Preprocessor1_Model1\", \"Preprocessor1_Model1\", \"Preproc…\n$ passenger_id  <dbl> 4, 21, 23, 24, 25, 28, 31, 37, 42, 43, 44, 49, 50, 59, 6…\n$ pclass        <fct> 1, 2, 3, 1, 3, 1, 1, 3, 2, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3,…\n$ name          <fct> \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\", \"Fynney,…\n$ sex           <fct> female, male, female, male, female, male, male, male, fe…\n$ age           <dbl> 35.00, 35.00, 15.00, 28.00, 8.00, 19.00, 40.00, 26.00, 2…\n$ sib_sp        <dbl> 1, 0, 0, 0, 3, 3, 0, 0, 1, 0, 1, 2, 1, 1, 0, 1, 0, 0, 0,…\n$ parch         <dbl> 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0,…\n$ ticket        <fct> 113803, 239865, 330923, 113788, 349909, 19950, PC 17601,…\n$ fare          <dbl> 53.1000, 26.0000, 8.0292, 35.5000, 21.0750, 263.0000, 27…\n$ cabin         <fct> C123, NA, NA, A6, NA, C23 C25 C27, NA, NA, NA, NA, NA, N…\n$ embarked      <fct> S, S, Q, S, S, S, C, C, S, C, C, C, S, S, S, C, S, S, S,…\n$ train_test    <fct> train, train, train, train, train, train, train, train, …\n$ pax_type      <fct> F_married, Mr., F_unmarried, Mr., F_unmarried, Mr., M_ti…\n$ surname       <fct> \"Futrelle,\", \"Fynney,\", \"McGowan,\", \"Sloper,\", \"Palsson,…\n$ cabin_preface <fct> C, nk, nk, A, nk, C, nk, nk, nk, nk, nk, nk, nk, nk, nk,…\n$ ticket_group  <fct> couple, couple, single, single, group, group, single, si…\n$ family_group  <ord> couple, single, single, single, family, family, single, …\n$ age_group     <ord> 30s, 30s, teen, 20s, child, teen, 40s, 20s, 20s, 20s, ch…\n```\n:::\n\n```{.r .cell-code}\n# rlr_pred <- predict(rlr_final_fit,train_2 )%>% \n#   bind_cols(predict(rlr_final_fit, train_2,type=\"prob\")) %>% \n#   bind_cols(train_2 %>% select(survived))\n# \n# rlr_pred %>% \n#   roc_auc(truth = survived, .pred_1, event_level = \"second\")\n# \n# rlr_pred %>% \n#   roc_curve(truth = survived, .pred_1,event_level=\"second\") %>% \n#   autoplot()\n# \n# \n# rlr_metrics <- rlr_pred %>% \n# metrics(truth = survived, estimate = .pred_class) %>% \n#   filter(.metric == \"accuracy\")\n# rlr_metrics\n# survive_rlr_pred <- \n#   augment(survive_lr_fit, train_2)\n# survive_rlr_pred\n```\n:::\n\n\n### RLR Confusion Matrix\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrlr_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/rlr_confusion_matrix-1.png){width=672}\n:::\n:::\n\n\n## Random Forest\n\n### RF Model Spec - Ranger\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_model <- \n  rand_forest(\n    trees = 1000,\n    mtry  = tune(),\n    min_n = tune()\n    ) %>% \n  set_engine(\"ranger\",importance = \"permutation\") %>% \n  set_mode(\"classification\")\n```\n:::\n\n\n### RF Workflow\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_wflow <- \n  workflow() %>% \n  add_model(rf_model) %>% \n  add_recipe(recipe_base)\n```\n:::\n\n\n### RF Tuning - Initial\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncl <- parallel::makePSOCKcluster(cores - 1)\n\nset.seed(1234)\nrf_tuning_result <- tune_grid(\n  rf_wflow,\n  resamples = folds,\n  grid = 20\n)\nparallel::stopCluster(cl)\n\nrf_tuning_result\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Tuning results\n# 5-fold cross-validation using stratification \n# A tibble: 5 × 4\n  splits            id    .metrics          .notes          \n  <list>            <chr> <list>            <list>          \n1 <split [532/135]> Fold1 <tibble [40 × 6]> <tibble [0 × 3]>\n2 <split [534/133]> Fold2 <tibble [40 × 6]> <tibble [0 × 3]>\n3 <split [534/133]> Fold3 <tibble [40 × 6]> <tibble [0 × 3]>\n4 <split [534/133]> Fold4 <tibble [40 × 6]> <tibble [0 × 3]>\n5 <split [534/133]> Fold5 <tibble [40 × 6]> <tibble [0 × 3]>\n```\n:::\n\n```{.r .cell-code}\nrf_tuning_result %>% \n  collect_metrics() %>% \n  filter(.metric == \"accuracy\") %>% \n  select(mean,min_n,mtry) %>% \n  pivot_longer(min_n:mtry) %>% \n  ggplot(aes(value, mean, color = name)) +\n  geom_point(show.legend = FALSE) +\n  facet_wrap(~name, scales = \"free_x\") +\n  labs(x = NULL, y = \"Accuracy\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/rf_tuning-1.png){width=672}\n:::\n:::\n\n\nBit hard to make much of it, but say min_n between 10 and 40 and mtry between 10 and 30?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_grid <- grid_regular(\n  mtry(range = c(5, 40)),\n  min_n(range = c(5, 30)),\n  levels = 5\n)\n\nrf_grid\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 25 × 2\n    mtry min_n\n   <int> <int>\n 1     5     5\n 2    13     5\n 3    22     5\n 4    31     5\n 5    40     5\n 6     5    11\n 7    13    11\n 8    22    11\n 9    31    11\n10    40    11\n# … with 15 more rows\n```\n:::\n:::\n\n\n### RF Graph Results\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncl <- parallel::makePSOCKcluster(cores - 1)\n\n\nset.seed(1234)\nrf_grid_tune <- tune_grid(\n  rf_wflow,\n  resamples = folds,\n  grid = rf_grid\n)\nrf_grid_tune\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Tuning results\n# 5-fold cross-validation using stratification \n# A tibble: 5 × 4\n  splits            id    .metrics          .notes          \n  <list>            <chr> <list>            <list>          \n1 <split [532/135]> Fold1 <tibble [50 × 6]> <tibble [5 × 3]>\n2 <split [534/133]> Fold2 <tibble [50 × 6]> <tibble [5 × 3]>\n3 <split [534/133]> Fold3 <tibble [50 × 6]> <tibble [5 × 3]>\n4 <split [534/133]> Fold4 <tibble [50 × 6]> <tibble [5 × 3]>\n5 <split [534/133]> Fold5 <tibble [50 × 6]> <tibble [5 × 3]>\n\nThere were issues with some computations:\n\n  - Warning(s) x5: 40 columns were requested but there were 33 predictors in the dat...   - Warning(s) x20: 40 columns were requested but there were 33 predictors in the dat...\n\nRun `show_notes(.Last.tune.result)` for more information.\n```\n:::\n\n```{.r .cell-code}\nparallel::stopCluster(cl)\n\nrf_grid_tune %>%\n  collect_metrics() %>%\n  filter(.metric == \"accuracy\") %>%\n  mutate(min_n = factor(min_n)) %>%\n  ggplot(aes(mtry, mean, color = min_n)) +\n  geom_line(alpha = 0.5, size = 1.5) +\n  geom_point() +\n  labs(y = \"Accuracy\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nWell that's interesting, lets see what tune thinks is best\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_best_params <- select_best(rf_grid_tune,\"accuracy\")\nrf_best_params %>% knitr::kable()\n```\n\n::: {.cell-output-display}\n| mtry| min_n|.config               |\n|----:|-----:|:---------------------|\n|    5|    17|Preprocessor1_Model11 |\n:::\n:::\n\n\n### RF Final Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_final_model <- finalize_model(\n  rf_model,\n  rf_best_params\n)\nrf_final_model\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = 5\n  trees = 1000\n  min_n = 17\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger \n```\n:::\n:::\n\n\n### RF Final Workflow\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_final_wflow <- finalize_workflow(\n  rf_wflow,\n  rf_best_params\n)\n\nrf_final_wflow\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = 5\n  trees = 1000\n  min_n = 17\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger \n```\n:::\n:::\n\n\n### RF Parameter Importance\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_final_wflow %>%\n  fit(data = train_proc_adj_tbl) %>%\n  extract_fit_parsnip() %>%\n  vip(geom = \"point\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/rf_vip-1.png){width=672}\n:::\n:::\n\n\n### RF Final Fit\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_final_fit <- \n  rf_final_wflow %>% \n  last_fit(train_split)\n\nrf_final_metrics <- collect_metrics(rf_final_fit)\nrf_final_metrics\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.804 Preprocessor1_Model1\n2 roc_auc  binary         0.801 Preprocessor1_Model1\n```\n:::\n:::\n\n\n### RF Predict\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# rf_final_fit <- rf_wflow %>% fit(train_test)\n# class(rf_final_fit)\n\n rf_test_predictions <- \n   collect_predictions(rf_final_fit)\n   # fit(rf_final_wflow,train_train) %>% \n   # predict(rf_final_wflow, new_data = train_test) %>% \n   #bind_cols(predict(rf_final_wflow, train_test,type = \"prob\")) %>% \n   #bind_cols(train_test %>% select(survived))\n\n \n head(rf_test_predictions)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 7\n  id               .pred_0 .pred_1  .row .pred_class survived .config           \n  <chr>              <dbl>   <dbl> <int> <fct>       <fct>    <chr>             \n1 train/test split  0.0440   0.956     4 1           1        Preprocessor1_Mod…\n2 train/test split  0.855    0.145    21 0           0        Preprocessor1_Mod…\n3 train/test split  0.224    0.776    23 1           1        Preprocessor1_Mod…\n4 train/test split  0.809    0.191    24 0           1        Preprocessor1_Mod…\n5 train/test split  0.699    0.301    25 0           0        Preprocessor1_Mod…\n6 train/test split  0.754    0.246    28 0           0        Preprocessor1_Mod…\n```\n:::\n:::\n\n\n### RF Performance on Test Set\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# rf_test_predictions %>% \n#   roc_auc(truth = survived, .pred_1,event_level = \"second\")\n\nrf_metrics_accuracy <- rf_test_predictions %>% \n  metrics(truth = survived, estimate = .pred_class) %>% \n  filter(.metric == \"accuracy\")\nrf_metrics_accuracy\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.804\n```\n:::\n\n```{.r .cell-code}\nrf_test_predictions %>% \n  roc_curve(truth = survived, .pred_1,event_level = \"second\") %>% \n  autoplot()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/rf_perf-1.png){width=672}\n:::\n:::\n\n\n### RF Confusion Matrix\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/rf_confusion_matrix-1.png){width=672}\n:::\n:::\n\n\n## XG Boost - Usemodel\n\n### XGB - Usemodel Library specs\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(usemodels)\n\nuse_xgboost(survived ~ .,\n            data=train_train,\n            verbose = TRUE\n  \n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nxgboost_recipe <- \n  recipe(formula = survived ~ ., data = train_train) %>% \n  step_novel(all_nominal_predictors()) %>% \n  ## This model requires the predictors to be numeric. The most common \n  ## method to convert qualitative predictors to numeric is to create \n  ## binary indicator variables (aka dummy variables) from these \n  ## predictors. However, for this model, binary indicator variables can be \n  ## made for each of the levels of the factors (known as 'one-hot \n  ## encoding'). \n  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>% \n  step_zv(all_predictors()) \n\nxgboost_spec <- \n  boost_tree(trees = tune(), min_n = tune(), tree_depth = tune(), learn_rate = tune(), \n    loss_reduction = tune(), sample_size = tune()) %>% \n  set_mode(\"classification\") %>% \n  set_engine(\"xgboost\") \n\nxgboost_workflow <- \n  workflow() %>% \n  add_recipe(xgboost_recipe) %>% \n  add_model(xgboost_spec) \n\nset.seed(19336)\nxgboost_tune <-\n  tune_grid(xgboost_workflow, resamples = stop(\"add your rsample object\"), grid = stop(\"add number of candidate points\"))\n```\n:::\n:::\n\n\n### XGB - Parameters\n\nThis grid is used for both versions of XG Boost.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxgb_grid <- grid_latin_hypercube(\n  tree_depth(),\n  min_n(),\n  trees(),\n  loss_reduction(),\n  sample_size = sample_prop(),\n  finalize(mtry(), train_train),\n  learn_rate(),\n  size = 30\n)\n\nhead(xgb_grid)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 7\n  tree_depth min_n trees loss_reduction sample_size  mtry    learn_rate\n       <int> <int> <int>          <dbl>       <dbl> <int>         <dbl>\n1         14    30  1603   0.0230             0.806    13 0.00985      \n2         11     9    22   0.0000361          0.983     3 0.0000469    \n3          1    17   848   0.00581            0.539    11 0.00559      \n4         10     8  1097   0.00000104         0.652     8 0.00000000128\n5         11    19  1422   1.00               0.283     6 0.00124      \n6         15    32  1007   0.0000000318       0.919    15 0.00000608   \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nxgboost_usemodel_recipe <- \n  recipe(formula = survived ~ ., data = train_train) %>% \n  step_novel(all_nominal_predictors()) %>% \n  ## This model requires the predictors to be numeric. The most common \n  ## method to convert qualitative predictors to numeric is to create \n  ## binary indicator variables (aka dummy variables) from these \n  ## predictors. However, for this model, binary indicator variables can be \n  ## made for each of the levels of the factors (known as 'one-hot \n  ## encoding'). \n  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>% \n  step_zv(all_predictors()) \n\nxgboost_usemodel_model <- \n  boost_tree(trees = tune(), mtry = tune(),min_n = tune(), tree_depth = tune(), learn_rate = tune(), \n    loss_reduction = tune(), sample_size = tune()) %>% \n  set_mode(\"classification\") %>% \n  set_engine(\"xgboost\") \n\nxgboost_usemodel_wflow <- \n  workflow() %>% \n  add_recipe(xgboost_usemodel_recipe) %>% \n  add_model(xgboost_usemodel_model) \n\n#doParallel::registerDoParallel(cores = cores)\ncl <- parallel::makePSOCKcluster(cores - 1)\n\nset.seed(1234)\nxgboost_usemodel_tune <-\n  tune_grid(xgboost_usemodel_wflow, resamples = folds, grid = xgb_grid)\n\nparallel::stopCluster(cl)\n```\n:::\n\n\n### XGB - Usemodel Best Parameter Settings\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxgb_tuning_metrics_usemodel <- collect_metrics(xgboost_usemodel_tune)\nxgb_tuning_metrics_usemodel\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 60 × 13\n    mtry trees min_n tree_depth learn_r…¹ loss_r…² sampl…³ .metric .esti…⁴  mean\n   <int> <int> <int>      <int>     <dbl>    <dbl>   <dbl> <chr>   <chr>   <dbl>\n 1    11   848    17          1   5.59e-3 5.81e- 3   0.539 accura… binary  0.702\n 2    11   848    17          1   5.59e-3 5.81e- 3   0.539 roc_auc binary  0.833\n 3     9  1145    10          2   5.20e-8 1.60e- 1   0.866 accura… binary  0.703\n 4     9  1145    10          2   5.20e-8 1.60e- 1   0.866 roc_auc binary  0.831\n 5    17   740    15          2   8.39e-2 6.64e- 9   0.252 accura… binary  0.753\n 6    17   740    15          2   8.39e-2 6.64e- 9   0.252 roc_auc binary  0.789\n 7    12   690    38          2   3.89e-9 5.16e-10   0.146 accura… binary  0.616\n 8    12   690    38          2   3.89e-9 5.16e-10   0.146 roc_auc binary  0.5  \n 9    10  1314    11          3   1.72e-5 1.25e- 1   0.163 accura… binary  0.616\n10    10  1314    11          3   1.72e-5 1.25e- 1   0.163 roc_auc binary  0.779\n# … with 50 more rows, 3 more variables: n <int>, std_err <dbl>, .config <chr>,\n#   and abbreviated variable names ¹​learn_rate, ²​loss_reduction, ³​sample_size,\n#   ⁴​.estimator\n```\n:::\n\n```{.r .cell-code}\nxgboost_usemodel_tune %>%\n  collect_metrics() %>%\n  filter(.metric == \"accuracy\") %>%\n  select(mean, mtry:sample_size) %>%\n  pivot_longer(mtry:sample_size,\n               values_to = \"value\",\n               names_to = \"parameter\"\n  ) %>%\n  ggplot(aes(value, mean, color = parameter)) +\n  geom_point(alpha = 0.8, show.legend = FALSE) +\n  facet_wrap(~parameter, scales = \"free_x\") +\n  labs(x = NULL, y = \"Accuracy\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/xgb_usemodel_para_sel-1.png){width=672}\n:::\n:::\n\n\nNow select best from above\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshow_best(xgboost_usemodel_tune, \"accuracy\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 13\n   mtry trees min_n tree_d…¹ learn…² loss_…³ sampl…⁴ .metric .esti…⁵  mean     n\n  <int> <int> <int>    <int>   <dbl>   <dbl>   <dbl> <chr>   <chr>   <dbl> <int>\n1     4  1982     4       15 4.01e-2 5.53e-8   0.393 accura… binary  0.777     5\n2    13  1603    30       14 9.85e-3 2.30e-2   0.806 accura… binary  0.771     5\n3    17   740    15        2 8.39e-2 6.64e-9   0.252 accura… binary  0.753     5\n4     9  1145    10        2 5.20e-8 1.60e-1   0.866 accura… binary  0.703     5\n5    16  1549     6        7 1.36e-4 4.92e-4   0.463 accura… binary  0.703     5\n# … with 2 more variables: std_err <dbl>, .config <chr>, and abbreviated\n#   variable names ¹​tree_depth, ²​learn_rate, ³​loss_reduction, ⁴​sample_size,\n#   ⁵​.estimator\n```\n:::\n\n```{.r .cell-code}\nxgb_usemodel_best_params <- select_best(xgboost_usemodel_tune, \"accuracy\")\nxgb_usemodel_best_params\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 8\n   mtry trees min_n tree_depth learn_rate loss_reduction sample_size .config    \n  <int> <int> <int>      <int>      <dbl>          <dbl>       <dbl> <chr>      \n1     4  1982     4         15     0.0401   0.0000000553       0.393 Preprocess…\n```\n:::\n\n```{.r .cell-code}\nxgb_usemodel_final_wflow <- finalize_workflow(\n  xgboost_usemodel_wflow,\n  xgb_usemodel_best_params\n)\n\nxgb_usemodel_final_wflow\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: boost_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_novel()\n• step_dummy()\n• step_zv()\n\n── Model ───────────────────────────────────────────────────────────────────────\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = 4\n  trees = 1982\n  min_n = 4\n  tree_depth = 15\n  learn_rate = 0.0400670375292599\n  loss_reduction = 5.52655767061452e-08\n  sample_size = 0.392634701682255\n\nComputational engine: xgboost \n```\n:::\n:::\n\n\n### XGB - Usemodel Parameter Ranking - VIP\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxgb_usemodel_final_wflow %>%\n  fit(data = train_train) %>%\n  extract_fit_parsnip() %>%\n  vip(geom = \"point\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/xgb_usemodel_vip-1.png){width=672}\n:::\n:::\n\n\n### XGB - Usemodel Performance\n\n#### XGB - Usemodel Accuracy Measured on Test Set\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncl <- parallel::makePSOCKcluster(cores - 1)\n\nset.seed(1234)\nxgb_usemodel_final_res <- last_fit(xgb_usemodel_final_wflow, train_split)\nxgb_usemodel_final_res\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits            id               .metrics .notes   .predictions .workflow \n  <list>            <chr>            <list>   <list>   <list>       <list>    \n1 <split [667/224]> train/test split <tibble> <tibble> <tibble>     <workflow>\n\nThere were issues with some computations:\n\n  - Warning(s) x2: There are new levels in a factor: NA\n\nRun `show_notes(.Last.tune.result)` for more information.\n```\n:::\n\n```{.r .cell-code}\nxgb_usemodel_final_metrics <- collect_metrics(xgb_usemodel_final_res)\nxgb_usemodel_final_metrics\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.710 Preprocessor1_Model1\n2 roc_auc  binary         0.758 Preprocessor1_Model1\n```\n:::\n\n```{.r .cell-code}\nparallel::stopCluster(cl)\n```\n:::\n\n\n#### XGB - Usemodel AUC on Test Set (within train)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxgb_usemodel_final_res %>%\n  collect_predictions() %>%\n  roc_curve( truth = survived,.pred_1, event_level = \"second\") %>%\n  ggplot(aes(x = 1-specificity, y = sensitivity)) +\n  geom_line(size = 1.5, color = \"midnightblue\") +\n  geom_abline(\n    lty = 2, alpha = 0.5,\n    color = \"gray50\",\n    size = 1.2\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/xgb_usemodel_auc-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nxgb_usemodel_test_predictions <- collect_predictions(xgb_usemodel_final_res)\nhead(xgb_usemodel_test_predictions)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 7\n  id               .pred_0 .pred_1  .row .pred_class survived .config           \n  <chr>              <dbl>   <dbl> <int> <fct>       <fct>    <chr>             \n1 train/test split   0.181   0.819     4 1           1        Preprocessor1_Mod…\n2 train/test split   0.739   0.261    21 0           0        Preprocessor1_Mod…\n3 train/test split   0.606   0.394    23 0           1        Preprocessor1_Mod…\n4 train/test split   0.509   0.491    24 0           1        Preprocessor1_Mod…\n5 train/test split   0.516   0.484    25 0           0        Preprocessor1_Mod…\n6 train/test split   0.409   0.591    28 1           0        Preprocessor1_Mod…\n```\n:::\n:::\n\n\n### XGB - Usemodel Confusion Matrix\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxgb_usemodel_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n## XG Boost - Base Recipe\n\n### XGB Model Spec\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxgb_model <- \n  boost_tree(\n    trees = tune(),\n    tree_depth = tune(),\n    min_n = tune(),\n    loss_reduction = tune(),\n    sample_size = tune(),\n    mtry = tune(),\n    learn_rate = tune()) %>% \n  set_engine(\"xgboost\") %>% \n  set_mode(\"classification\")\n\nxgb_model\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = tune()\n  min_n = tune()\n  tree_depth = tune()\n  learn_rate = tune()\n  loss_reduction = tune()\n  sample_size = tune()\n\nComputational engine: xgboost \n```\n:::\n:::\n\n\n### XGB Workflow\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxgb_wflow <- \n  workflow() %>% \n  add_model(xgb_model) %>% \n  add_recipe(recipe_base)\n```\n:::\n\n\n### XGB Hyper-Parameter Tuning\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# xgb_folds <- vfold_cv(training(train_split), strata = survived)\n# xgb_folds\n\n\n#doParallel::registerDoParallel(cores = cores)\n\nset.seed(1234)\ncl <- parallel::makePSOCKcluster(cores - 1)\n\nxgb_tuning_result <- tune_grid(\n  xgb_wflow,\n  resamples = folds,\n  grid      = xgb_grid,\n  control  = control_grid(save_pred = TRUE,save_workflow = TRUE)\n)\nxgb_tuning_result\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Tuning results\n# 5-fold cross-validation using stratification \n# A tibble: 5 × 5\n  splits            id    .metrics           .notes           .predictions\n  <list>            <chr> <list>             <list>           <list>      \n1 <split [532/135]> Fold1 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n2 <split [534/133]> Fold2 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n3 <split [534/133]> Fold3 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n4 <split [534/133]> Fold4 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n5 <split [534/133]> Fold5 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n```\n:::\n\n```{.r .cell-code}\nparallel::stopCluster(cl)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nxgb_tuning_metrics <- collect_metrics(xgb_tuning_result)\nxgb_tuning_metrics\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 60 × 13\n    mtry trees min_n tree_depth learn_r…¹ loss_r…² sampl…³ .metric .esti…⁴  mean\n   <int> <int> <int>      <int>     <dbl>    <dbl>   <dbl> <chr>   <chr>   <dbl>\n 1    11   848    17          1   5.59e-3 5.81e- 3   0.539 accura… binary  0.793\n 2    11   848    17          1   5.59e-3 5.81e- 3   0.539 roc_auc binary  0.854\n 3     9  1145    10          2   5.20e-8 1.60e- 1   0.866 accura… binary  0.799\n 4     9  1145    10          2   5.20e-8 1.60e- 1   0.866 roc_auc binary  0.859\n 5    17   740    15          2   8.39e-2 6.64e- 9   0.252 accura… binary  0.706\n 6    17   740    15          2   8.39e-2 6.64e- 9   0.252 roc_auc binary  0.757\n 7    12   690    38          2   3.89e-9 5.16e-10   0.146 accura… binary  0.616\n 8    12   690    38          2   3.89e-9 5.16e-10   0.146 roc_auc binary  0.5  \n 9    10  1314    11          3   1.72e-5 1.25e- 1   0.163 accura… binary  0.616\n10    10  1314    11          3   1.72e-5 1.25e- 1   0.163 roc_auc binary  0.728\n# … with 50 more rows, 3 more variables: n <int>, std_err <dbl>, .config <chr>,\n#   and abbreviated variable names ¹​learn_rate, ²​loss_reduction, ³​sample_size,\n#   ⁴​.estimator\n```\n:::\n\n```{.r .cell-code}\nxgb_tuning_result %>%\n  collect_metrics() %>%\n  filter(.metric == \"accuracy\") %>%\n  select(mean, mtry:sample_size) %>%\n  pivot_longer(mtry:sample_size,\n               values_to = \"value\",\n               names_to = \"parameter\"\n  ) %>%\n  ggplot(aes(value, mean, color = parameter)) +\n  geom_point(alpha = 0.8, show.legend = FALSE) +\n  facet_wrap(~parameter, scales = \"free_x\") +\n  labs(x = NULL, y = \"AUC\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n#### XGB Best Parameters then Finalise Workflow\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshow_best(xgb_tuning_result, \"accuracy\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 13\n   mtry trees min_n tree_d…¹ learn…² loss_…³ sampl…⁴ .metric .esti…⁵  mean     n\n  <int> <int> <int>    <int>   <dbl>   <dbl>   <dbl> <chr>   <chr>   <dbl> <int>\n1     4  1982     4       15 4.01e-2 5.53e-8   0.393 accura… binary  0.853     5\n2    13  1603    30       14 9.85e-3 2.30e-2   0.806 accura… binary  0.808     5\n3     9  1145    10        2 5.20e-8 1.60e-1   0.866 accura… binary  0.799     5\n4    19   259    16        9 6.05e-7 1.64e-4   0.735 accura… binary  0.799     5\n5    16  1549     6        7 1.36e-4 4.92e-4   0.463 accura… binary  0.798     5\n# … with 2 more variables: std_err <dbl>, .config <chr>, and abbreviated\n#   variable names ¹​tree_depth, ²​learn_rate, ³​loss_reduction, ⁴​sample_size,\n#   ⁵​.estimator\n```\n:::\n\n```{.r .cell-code}\nxgb_best_params <- select_best(xgb_tuning_result, \"accuracy\")\nxgb_best_params\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 8\n   mtry trees min_n tree_depth learn_rate loss_reduction sample_size .config    \n  <int> <int> <int>      <int>      <dbl>          <dbl>       <dbl> <chr>      \n1     4  1982     4         15     0.0401   0.0000000553       0.393 Preprocess…\n```\n:::\n\n```{.r .cell-code}\nxgb_final_wflow <- finalize_workflow(\n  xgb_wflow,\n  xgb_best_params\n)\n\nxgb_final_wflow\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: boost_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = 4\n  trees = 1982\n  min_n = 4\n  tree_depth = 15\n  learn_rate = 0.0400670375292599\n  loss_reduction = 5.52655767061452e-08\n  sample_size = 0.392634701682255\n\nComputational engine: xgboost \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nxgb_final_wflow %>%\n  fit(data = train_train) %>%\n  extract_fit_parsnip() %>%\n  vip(geom = \"point\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n### XGB Performance on Training Test Set\n\n#### XGB Accuracy Measured on Test Set\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxgb_final_res <- last_fit(xgb_final_wflow, train_split)\nxgb_final_res\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits            id               .metrics .notes   .predictions .workflow \n  <list>            <chr>            <list>   <list>   <list>       <list>    \n1 <split [667/224]> train/test split <tibble> <tibble> <tibble>     <workflow>\n```\n:::\n\n```{.r .cell-code}\nxgb_final_metrics <- collect_metrics(xgb_final_res)\nxgb_final_metrics\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.799 Preprocessor1_Model1\n2 roc_auc  binary         0.805 Preprocessor1_Model1\n```\n:::\n:::\n\n\n#### XGB AUC on Test Set (within train)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxgb_final_res %>%\n  collect_predictions() %>%\n  roc_curve( truth = survived,.pred_1, event_level = \"second\") %>%\n  ggplot(aes(x = 1-specificity, y = sensitivity)) +\n  geom_line(size = 1.5, color = \"midnightblue\") +\n  geom_abline(\n    lty = 2, alpha = 0.5,\n    color = \"gray50\",\n    size = 1.2\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nxgb_test_predictions <- collect_predictions(xgb_final_res)\nhead(xgb_test_predictions)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 7\n  id               .pred_0 .pred_1  .row .pred_class survived .config           \n  <chr>              <dbl>   <dbl> <int> <fct>       <fct>    <chr>             \n1 train/test split 0.00416  0.996      4 1           1        Preprocessor1_Mod…\n2 train/test split 0.780    0.220     21 0           0        Preprocessor1_Mod…\n3 train/test split 0.101    0.899     23 1           1        Preprocessor1_Mod…\n4 train/test split 0.770    0.230     24 0           1        Preprocessor1_Mod…\n5 train/test split 0.615    0.385     25 0           0        Preprocessor1_Mod…\n6 train/test split 0.916    0.0843    28 0           0        Preprocessor1_Mod…\n```\n:::\n:::\n\n\n### XGB Confusion Matrix\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxgb_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n## Neural Net\n\n### NN Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnnet_model <- \n   mlp(hidden_units = tune(), penalty = tune(), epochs = tune()) %>% \n   set_engine(\"nnet\", MaxNWts = 2600) %>% \n   set_mode(\"classification\")\n\nnnet_model %>% translate()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle Layer Neural Network Model Specification (classification)\n\nMain Arguments:\n  hidden_units = tune()\n  penalty = tune()\n  epochs = tune()\n\nEngine-Specific Arguments:\n  MaxNWts = 2600\n\nComputational engine: nnet \n\nModel fit template:\nnnet::nnet(formula = missing_arg(), data = missing_arg(), size = tune(), \n    decay = tune(), maxit = tune(), MaxNWts = 2600, trace = FALSE, \n    linout = FALSE)\n```\n:::\n:::\n\n\n### NN Workflow\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnnet_wflow <- workflow() %>% \n  add_model(nnet_model) %>% \n  add_recipe(recipe_base)\n```\n:::\n\n\n### NN Parameters\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnnet_grid <- grid_latin_hypercube(\n  hidden_units(),\n  penalty (),\n  epochs ()\n)\n\nhead(nnet_grid) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 3\n  hidden_units  penalty epochs\n         <int>    <dbl>  <int>\n1            8 3.93e- 5    339\n2            2 7.19e- 1    761\n3            5 3.32e-10    514\n```\n:::\n:::\n\n\n### NN Hyper-Parameter Tuning\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# nnet_folds <- vfold_cv(train_train, strata = survived)\n# nnet_folds\n\n\n# doParallel::registerDoParallel(cores = cores)\ncl <- parallel::makePSOCKcluster(cores - 1)\n\nset.seed(1234)\nnnet_tuning_result <- tune_grid(\n  nnet_wflow,\n  resamples = folds,\n  grid      = nnet_grid,\n  control   = control_grid(save_pred = TRUE,save_workflow = TRUE)\n)\nnnet_tuning_result\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Tuning results\n# 5-fold cross-validation using stratification \n# A tibble: 5 × 5\n  splits            id    .metrics         .notes           .predictions      \n  <list>            <chr> <list>           <list>           <list>            \n1 <split [532/135]> Fold1 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [405 × 9]>\n2 <split [534/133]> Fold2 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [399 × 9]>\n3 <split [534/133]> Fold3 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [399 × 9]>\n4 <split [534/133]> Fold4 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [399 × 9]>\n5 <split [534/133]> Fold5 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [399 × 9]>\n```\n:::\n\n```{.r .cell-code}\nparallel::stopCluster(cl)\n```\n:::\n\n\n### NN Best Parameters and Finalise Workflow\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshow_best(nnet_tuning_result, \"accuracy\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 9\n  hidden_units  penalty epochs .metric  .estimator  mean     n std_err .config  \n         <int>    <dbl>  <int> <chr>    <chr>      <dbl> <int>   <dbl> <chr>    \n1            2 7.19e- 1    761 accuracy binary     0.834     5 0.00706 Preproce…\n2            5 3.32e-10    514 accuracy binary     0.810     5 0.0127  Preproce…\n3            8 3.93e- 5    339 accuracy binary     0.793     5 0.0114  Preproce…\n```\n:::\n\n```{.r .cell-code}\nnn_best_params <- select_best(nnet_tuning_result, \"accuracy\")\n\nnnet_best_auc <- select_best(xgb_tuning_result, \"accuracy\")\nnnet_best_auc\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 8\n   mtry trees min_n tree_depth learn_rate loss_reduction sample_size .config    \n  <int> <int> <int>      <int>      <dbl>          <dbl>       <dbl> <chr>      \n1     4  1982     4         15     0.0401   0.0000000553       0.393 Preprocess…\n```\n:::\n\n```{.r .cell-code}\nnnet_final_wflow <- finalize_workflow(\n  nnet_wflow,\n  nn_best_params\n)\n\nnnet_final_wflow\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: mlp()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nSingle Layer Neural Network Model Specification (classification)\n\nMain Arguments:\n  hidden_units = 2\n  penalty = 0.719258269343031\n  epochs = 761\n\nEngine-Specific Arguments:\n  MaxNWts = 2600\n\nComputational engine: nnet \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnnet_final_wflow %>%\n  fit(data = train_train) %>%\n  extract_fit_parsnip() %>%\n  vip(geom = \"point\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/nn_final_train-1.png){width=672}\n:::\n:::\n\n\n### NN Accuracy - Train/Test Set\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnnet_tuning_metrics <- collect_metrics(nnet_tuning_result)\nnnet_tuning_metrics\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 9\n  hidden_units  penalty epochs .metric  .estimator  mean     n std_err .config  \n         <int>    <dbl>  <int> <chr>    <chr>      <dbl> <int>   <dbl> <chr>    \n1            8 3.93e- 5    339 accuracy binary     0.793     5 0.0114  Preproce…\n2            8 3.93e- 5    339 roc_auc  binary     0.840     5 0.0185  Preproce…\n3            2 7.19e- 1    761 accuracy binary     0.834     5 0.00706 Preproce…\n4            2 7.19e- 1    761 roc_auc  binary     0.893     5 0.00912 Preproce…\n5            5 3.32e-10    514 accuracy binary     0.810     5 0.0127  Preproce…\n6            5 3.32e-10    514 roc_auc  binary     0.854     5 0.0165  Preproce…\n```\n:::\n\n```{.r .cell-code}\nnnet_final_res <- last_fit(nnet_final_wflow, train_split)\nnnet_final_res\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits            id               .metrics .notes   .predictions .workflow \n  <list>            <chr>            <list>   <list>   <list>       <list>    \n1 <split [667/224]> train/test split <tibble> <tibble> <tibble>     <workflow>\n```\n:::\n\n```{.r .cell-code}\nnnet_final_metrics <- collect_metrics(nnet_final_res)\nnnet_final_metrics\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.799 Preprocessor1_Model1\n2 roc_auc  binary         0.806 Preprocessor1_Model1\n```\n:::\n:::\n\n\n### NN AUC\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnnet_final_res %>%\n  collect_predictions() %>%\n  roc_curve( truth = survived,.pred_1, event_level = \"second\") %>%\n  ggplot(aes(x = 1-specificity, y = sensitivity)) +\n  geom_line(size = 1.5, color = \"midnightblue\") +\n  geom_abline(\n    lty = 2, alpha = 0.5,\n    color = \"gray50\",\n    size = 1.2\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n### NN Predictions on Train/Test Set\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnnet_test_predictions <- nnet_final_res %>%\n  collect_predictions() \nhead(nnet_test_predictions)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 7\n  id               .pred_0 .pred_1  .row .pred_class survived .config           \n  <chr>              <dbl>   <dbl> <int> <fct>       <fct>    <chr>             \n1 train/test split   0.295   0.705     4 1           1        Preprocessor1_Mod…\n2 train/test split   0.633   0.367    21 0           0        Preprocessor1_Mod…\n3 train/test split   0.346   0.654    23 1           1        Preprocessor1_Mod…\n4 train/test split   0.574   0.426    24 0           1        Preprocessor1_Mod…\n5 train/test split   0.584   0.416    25 0           0        Preprocessor1_Mod…\n6 train/test split   0.574   0.426    28 0           0        Preprocessor1_Mod…\n```\n:::\n:::\n\n\n### NN Confusion Matrix\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnnet_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/NN_confusion_matrix-1.png){width=672}\n:::\n:::\n\n\n## Stack Models\n\n### Stack Recipe\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrecipe_stack <- \n  recipe(survived ~ ., data = train_train) %>% \n  update_role(passenger_id, name,surname,ticket,cabin,new_role = \"ID\") %>% \n  step_impute_knn(all_numeric_predictors()) %>% \n  step_dummy(all_nominal_predictors()) %>%\n  step_factor2string(all_nominal_predictors()) %>% \n  step_zv(all_predictors()) %>% \n  step_pca()\nrecipe_stack\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRecipe\n\nInputs:\n\n      role #variables\n        ID          5\n   outcome          1\n predictor         13\n\nOperations:\n\nK-nearest neighbor imputation for all_numeric_predictors()\nDummy variables from all_nominal_predictors()\nCharacter variables from all_nominal_predictors()\nZero variance filter on all_predictors()\nPCA extraction with <none>\n```\n:::\n\n```{.r .cell-code}\nrecipe_stack_trained <- prep(recipe_base)\nrecipe_stack_trained\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRecipe\n\nInputs:\n\n      role #variables\n        ID          5\n   outcome          1\n predictor         13\n\nTraining data contained 667 data points and 509 incomplete rows. \n\nOperations:\n\nK-nearest neighbor imputation for age, sib_sp, parch, fare [trained]\nDummy variables from pclass, sex, embarked, train_test, pax_type, cabin_prefac... [trained]\nCharacter variables from <none> [trained]\nZero variance filter removed train_test_test [trained]\nNo PCA components were extracted from <none> [trained]\n```\n:::\n:::\n\n\n### Stack Controls\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstack_ctrl <- control_resamples(save_pred = TRUE, save_workflow = TRUE)\n#stack_folds <- vfold_cv(training(train_split), v=10,strata = \"survived\")\n\nlibrary(stacks)\n\nmodel_stack <-\n  stacks() %>%\n  #add_candidates(lr_wflow) %>%\n  #add_candidates(rf_wflow) %>%\n  add_candidates(nnet_tuning_result) %>%\n  add_candidates(rlr_tuning_result) %>% \n  add_candidates(xgb_tuning_result)\n```\n:::\n\n\n### Stack Blend\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncl <- parallel::makePSOCKcluster(cores - 1)\n\nset.seed(1234)\nensemble <- blend_predictions(model_stack,penalty = 10^seq(-2, -0.5, length = 20))\nautoplot(ensemble)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n\n```{.r .cell-code}\nparallel::stopCluster(cl)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nensemble \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 3\n  member                         type         weight\n  <chr>                          <chr>         <dbl>\n1 .pred_1_xgb_tuning_result_1_29 boost_tree     2.17\n2 .pred_1_nnet_tuning_result_1_2 mlp            2.05\n3 .pred_1_rlr_tuning_result_1_28 logistic_reg   1.07\n```\n:::\n:::\n\n\n### Stack Weights\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(ensemble, \"weights\") +\n  geom_text(aes(x = weight + 0.01, label = model), hjust = 0) + \n  theme(legend.position = \"none\") \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n### Fit Member Models\n\n\n::: {.cell}\n\n```{.r .cell-code}\nensemble <- fit_members(ensemble)\ncollect_parameters(ensemble,\"xgb_tuning_result\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 27 × 10\n   member          mtry trees min_n tree_…¹ learn…² loss_r…³ sampl…⁴ terms  coef\n   <chr>          <int> <int> <int>   <int>   <dbl>    <dbl>   <dbl> <chr> <dbl>\n 1 xgb_tuning_re…    11   848    17       1 5.59e-3 5.81e- 3   0.539 .pre…     0\n 2 xgb_tuning_re…     9  1145    10       2 5.20e-8 1.60e- 1   0.866 .pre…     0\n 3 xgb_tuning_re…    17   740    15       2 8.39e-2 6.64e- 9   0.252 .pre…     0\n 4 xgb_tuning_re…    10  1314    11       3 1.72e-5 1.25e- 1   0.163 .pre…     0\n 5 xgb_tuning_re…    18  1475    25       3 1.50e-6 2.46e- 9   0.328 .pre…     0\n 6 xgb_tuning_re…     6    98    23       4 4.07e-4 1.02e- 3   0.897 .pre…     0\n 7 xgb_tuning_re…     7   923    13       5 1.66e-3 1.78e- 5   0.352 .pre…     0\n 8 xgb_tuning_re…    16   610    26       5 1.14e-5 1.88e-10   0.211 .pre…     0\n 9 xgb_tuning_re…    16  1549     6       7 1.36e-4 4.92e- 4   0.463 .pre…     0\n10 xgb_tuning_re…    14  1900    22       7 2.14e-7 3.46e- 6   0.447 .pre…     0\n# … with 17 more rows, and abbreviated variable names ¹​tree_depth, ²​learn_rate,\n#   ³​loss_reduction, ⁴​sample_size\n```\n:::\n:::\n\n\n### Stack Predict\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#ensemble_metrics <- metric_set(roc_auc,accuracy)\n\nensemble_test_predictions <- \n  predict(ensemble,train_test) %>% \n  bind_cols(train_test) \n\n\n# ensemble_test_predictions <- ensemble_test_predictions %>% \n#   mutate(.pred_class=as.numeric(.pred_class)) %>% \n#    mutate(survived =as.numeric(survived)) \n# \n# ensemble_test_predictions <- ensemble_test_predictions %>% \n#   mutate(roc = roc_auc(truth=survived, estimate = .pred_class))\n\n\n\nglimpse(ensemble_test_predictions)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 224\nColumns: 20\n$ .pred_class   <fct> 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,…\n$ passenger_id  <dbl> 4, 21, 23, 24, 25, 28, 31, 37, 42, 43, 44, 49, 50, 59, 6…\n$ survived      <fct> 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,…\n$ pclass        <fct> 1, 2, 3, 1, 3, 1, 1, 3, 2, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3,…\n$ name          <fct> \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\", \"Fynney,…\n$ sex           <fct> female, male, female, male, female, male, male, male, fe…\n$ age           <dbl> 35.00, 35.00, 15.00, 28.00, 8.00, 19.00, 40.00, 26.00, 2…\n$ sib_sp        <dbl> 1, 0, 0, 0, 3, 3, 0, 0, 1, 0, 1, 2, 1, 1, 0, 1, 0, 0, 0,…\n$ parch         <dbl> 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0,…\n$ ticket        <fct> 113803, 239865, 330923, 113788, 349909, 19950, PC 17601,…\n$ fare          <dbl> 53.1000, 26.0000, 8.0292, 35.5000, 21.0750, 263.0000, 27…\n$ cabin         <fct> C123, NA, NA, A6, NA, C23 C25 C27, NA, NA, NA, NA, NA, N…\n$ embarked      <fct> S, S, Q, S, S, S, C, C, S, C, C, C, S, S, S, C, S, S, S,…\n$ train_test    <fct> train, train, train, train, train, train, train, train, …\n$ pax_type      <fct> F_married, Mr., F_unmarried, Mr., F_unmarried, Mr., M_ti…\n$ surname       <fct> \"Futrelle,\", \"Fynney,\", \"McGowan,\", \"Sloper,\", \"Palsson,…\n$ cabin_preface <fct> C, nk, nk, A, nk, C, nk, nk, nk, nk, nk, nk, nk, nk, nk,…\n$ ticket_group  <fct> couple, couple, single, single, group, group, single, si…\n$ family_group  <ord> couple, single, single, single, family, family, single, …\n$ age_group     <ord> 30s, 30s, teen, 20s, child, teen, 40s, 20s, 20s, 20s, ch…\n```\n:::\n:::\n\n\n## Join Model Prediction Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nall_predictions <- \n  lr_test_predictions %>% mutate(model = \"LR\") %>% \n  bind_rows(nnet_test_predictions %>% mutate(model = \"NNet\")) %>% \n  bind_rows(rlr_test_predictions %>% mutate(model = \"Reg_LR\")) %>% \n  bind_rows(rf_test_predictions %>% mutate(model = \"RF\")) %>% \n  bind_rows(xgb_test_predictions %>% mutate(model = \"xgb\")) %>% \n  bind_rows(xgb_usemodel_test_predictions %>% mutate(model = \"xgb_usemodel\")) %>% \n  bind_rows(ensemble_test_predictions %>% mutate(model = \"ensemble\"))\n  \nall_predictions %>% head() %>% knitr::kable()\n```\n\n::: {.cell-output-display}\n|id               |   .pred_0|   .pred_1| .row|.pred_class |survived_pred |.config              | passenger_id|survived |pclass |name                                         |sex    | age| sib_sp| parch|ticket |     fare|cabin       |embarked |train_test |pax_type    |surname   |cabin_preface |ticket_group |family_group |age_group |model |\n|:----------------|---------:|---------:|----:|:-----------|:-------------|:--------------------|------------:|:--------|:------|:--------------------------------------------|:------|---:|------:|-----:|:------|--------:|:-----------|:--------|:----------|:-----------|:---------|:-------------|:------------|:------------|:---------|:-----|\n|train/test split | 0.0487129| 0.9512871|    4|1           |1             |Preprocessor1_Model1 |            4|1        |1      |Futrelle, Mrs. Jacques Heath (Lily May Peel) |female |  35|      1|     0|113803 |  53.1000|C123        |S        |train      |F_married   |Futrelle, |C             |couple       |couple       |30s       |LR    |\n|train/test split | 0.8291704| 0.1708296|   21|0           |0             |Preprocessor1_Model1 |           21|0        |2      |Fynney, Mr. Joseph J                         |male   |  35|      0|     0|239865 |  26.0000|NA          |S        |train      |Mr.         |Fynney,   |nk            |couple       |single       |30s       |LR    |\n|train/test split | 0.1906593| 0.8093407|   23|1           |1             |Preprocessor1_Model1 |           23|1        |3      |McGowan, Miss. Anna \"Annie\"                  |female |  15|      0|     0|330923 |   8.0292|NA          |Q        |train      |F_unmarried |McGowan,  |nk            |single       |single       |teen      |LR    |\n|train/test split | 0.8012471| 0.1987529|   24|0           |1             |Preprocessor1_Model1 |           24|1        |1      |Sloper, Mr. William Thompson                 |male   |  28|      0|     0|113788 |  35.5000|A6          |S        |train      |Mr.         |Sloper,   |A             |single       |single       |20s       |LR    |\n|train/test split | 0.7142250| 0.2857750|   25|0           |0             |Preprocessor1_Model1 |           25|0        |3      |Palsson, Miss. Torborg Danira                |female |   8|      3|     1|349909 |  21.0750|NA          |S        |train      |F_unmarried |Palsson,  |nk            |group        |family       |child     |LR    |\n|train/test split | 0.9312528| 0.0687472|   28|0           |0             |Preprocessor1_Model1 |           28|0        |1      |Fortune, Mr. Charles Alexander               |male   |  19|      3|     2|19950  | 263.0000|C23 C25 C27 |S        |train      |Mr.         |Fortune,  |C             |group        |family       |teen      |LR    |\n:::\n:::\n\n\n## All Metrics\n\nOrdered by descending Accuracy metric\n\n\n::: {.cell}\n\n```{.r .cell-code}\nall_metrics <- \n  lr_final_metrics %>% mutate(model = \"LR\") %>% \n  bind_rows(nnet_final_metrics %>% mutate(model = \"NNet\")) %>% \n  bind_rows(rlr_final_metrics %>% mutate(model = \"Reg_LR\")) %>% \n  bind_rows(rf_final_metrics %>% mutate(model = \"RF\")) %>% \n  bind_rows(xgb_final_metrics %>% mutate(model = \"xgb\")) %>% \n  bind_rows(xgb_usemodel_final_metrics %>% mutate(model = \"xgb-usemodel\")) \n\nall_metrics_table <- all_metrics %>% \n   pivot_wider(names_from = .metric,values_from = .estimate) %>% \n   arrange(desc(accuracy))\n  \nwrite_rds(all_metrics,\"artifacts/all_metrics.rds\")\n\nall_metrics_table %>% knitr::kable(digits=3)\n```\n\n::: {.cell-output-display}\n|.estimator |.config              |model        | accuracy| roc_auc|\n|:----------|:--------------------|:------------|--------:|-------:|\n|binary     |Preprocessor1_Model1 |Reg_LR       |    0.808|   0.813|\n|binary     |Preprocessor1_Model1 |RF           |    0.804|   0.801|\n|binary     |Preprocessor1_Model1 |NNet         |    0.799|   0.806|\n|binary     |Preprocessor1_Model1 |xgb          |    0.799|   0.805|\n|binary     |Preprocessor1_Model1 |LR           |    0.790|   0.791|\n|binary     |Preprocessor1_Model1 |xgb-usemodel |    0.710|   0.758|\n:::\n:::\n\n\nand a graph:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nall_metrics %>% \n  filter(.metric == \"accuracy\") %>% \n  select(model, accuracy = .estimate) %>% \n  ggplot(aes(model, accuracy)) +\n  geom_col()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/graph_all_metrics-1.png){width=672}\n:::\n:::\n\n\n# Final Submission\n\n## \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# all_predictions %>% \n# distinct(model)\n\n\n\ntest_proc <- all_proc %>% \n  filter(train_test==\"test\")\n\n# LR ----\nfinal_test_pred_LR <- \n  lr_wflow %>% \n  fit(train_proc_adj_tbl) %>% \n  predict(new_data=test_proc) %>% \n  bind_cols(test_proc)\n\nsubmission_LR <- final_test_pred_LR %>% \n  select(PassengerID = passenger_id,Survived = .pred_class)\n\nwrite_csv(submission_LR,\"titanic_submission_LR.csv\") \n\n\n# RLR ----\nfinal_test_pred_RLR <- \n  rlr_final_wflow %>% \n  fit(train_proc_adj_tbl) %>% \n  predict(new_data=test_proc) %>% \n  bind_cols(test_proc)\n\nsubmission_RLR <- final_test_pred_RLR %>% \n  select(PassengerID = passenger_id,Survived = .pred_class)\n\nwrite_csv(submission_RLR,\"titanic_submission_RLR.csv\") \n\n# RF ----\nfinal_test_pred_RF <- \n  rf_final_wflow %>% \n  fit(train_proc_adj_tbl) %>% \n  predict(new_data=test_proc) %>% \n  bind_cols(test_proc)\n\nsubmission_RF <- final_test_pred_RF %>% \n  select(PassengerID = passenger_id,Survived = .pred_class)\n\nwrite_csv(submission_RF,\"titanic_submission_RF.csv\") \n\n# NN ----\nfinal_test_pred_NN <- \n  nnet_final_wflow %>% \n  fit(train_proc_adj_tbl) %>% \n  predict(new_data=test_proc) %>% \n  bind_cols(test_proc)\n\nsubmission_NN <- final_test_pred_NN %>% \n  select(PassengerID = passenger_id,Survived = .pred_class)\n\nwrite_csv(submission_NN,\"titanic_submission_NN.csv\") \n\n\n# XGB -----\nfinal_test_pred_xgb <-\n  xgb_final_wflow %>% \n  fit(train_proc_adj_tbl) %>% \n  predict(new_data=test_proc) %>% \n  bind_cols(test_proc)\n\nsubmission_xgb <- final_test_pred_xgb %>% \n  select(PassengerID = passenger_id,Survived = .pred_class)\n\nwrite_csv(submission_xgb,\"titanic_submission_xgb.csv\")\n\n\n# ensemble -----\nfinal_test_pred_ens <-\n  ensemble %>% \n  #fit(train_proc_adj_tbl) %>% \n  predict(new_data=test_proc) %>% \n  bind_cols(test_proc)\n\nsubmission_ens <- final_test_pred_ens %>% \n  select(PassengerID = passenger_id,Survived = .pred_class)\n\nwrite_csv(submission_ens,\"titanic_submission_ens.csv\")\n```\n:::\n\n\n## \n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}