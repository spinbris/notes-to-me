[
  {
    "objectID": "posts/forecasting_with_h20/index.html",
    "href": "posts/forecasting_with_h20/index.html",
    "title": "Forecasting Flight Passengers using H20",
    "section": "",
    "text": "This analyses is one part of a multi-part set of posts looking at forecasting on domestic Australian flight volumes by route in the period prior to when covid largely shut the industry down. Its intention is just to provide me with examples over the main models to save time on future projects.It is split into:\n\nSome pre analysis (basic EDA analysis is not covered as already included in previous posts)\n‘Sequence’ style models - ARIMA etc\nML style models - XGBoost etc including nesting and ensembling\nDeep learning models (GLuonTS etc)\nSummary of conclusions\n\nThis post is in relation to the part 4 - focussing on H20, usimg the modeltime package to connect. This post is actually using ML models, but will be expanded to include deep learning approaches\nit uses the modeltime H20 documentation"
  },
  {
    "objectID": "posts/forecasting_with_h20/index.html#load-libraries",
    "href": "posts/forecasting_with_h20/index.html#load-libraries",
    "title": "Forecasting Flight Passengers using H20",
    "section": "2 Load Libraries",
    "text": "2 Load Libraries\n\n\nCode\nlibrary(tidymodels)\nlibrary(modeltime.h2o)\nlibrary(tidyverse)\nlibrary(timetk)"
  },
  {
    "objectID": "posts/forecasting_with_h20/index.html#load-data",
    "href": "posts/forecasting_with_h20/index.html#load-data",
    "title": "Forecasting Flight Passengers using H20",
    "section": "3 Load Data",
    "text": "3 Load Data\nAll data is loaded, except Brisbane-Emerald route is excluded as it caused problems, probably due to lack of data.\nThe top 10 routes are shown in order of overall patronage\n\n\nCode\ntop_x   <- 10\nstart   <- \"2001-01-01\"\nend     <- \"2019-07-01\"\nhorizon <-  \"1 year\"\n\ntop_routes_prep_df <- read_rds(\"./artifacts/top_routes_prep_df.rds\") %>%  \n  filter(route != \"BRISBANE-EMERALD\") %>% #dodgy for some reason\n  #rowid_to_column(var = \"id\") %>% \n  select(date,route,passenger_trips)\n\ntopx <- top_routes_prep_df %>% \n  group_by(route) %>% \n  summarise(passenger_trips = sum(passenger_trips)) %>% \n  ungroup() %>% \n  slice_max(passenger_trips, n=top_x) %>% \n  arrange(desc(passenger_trips)) %>% \n  select(route) %>% \n  pull() %>% \n  as.character()\n\ntopx %>% knitr::kable()\n\n\n\n\n\nx\n\n\n\n\nMELBOURNE-SYDNEY\n\n\nBRISBANE-SYDNEY\n\n\nBRISBANE-MELBOURNE\n\n\nGOLD COAST-SYDNEY\n\n\nADELAIDE-MELBOURNE\n\n\nADELAIDE-SYDNEY\n\n\nMELBOURNE-PERTH\n\n\nPERTH-SYDNEY\n\n\nMELBOURNE-GOLD COAST\n\n\nBRISBANE-CAIRNS"
  },
  {
    "objectID": "posts/forecasting_with_h20/index.html#graph-plots-for-top-routes-to-save-space",
    "href": "posts/forecasting_with_h20/index.html#graph-plots-for-top-routes-to-save-space",
    "title": "Forecasting Flight Passengers using H20",
    "section": "4 Graph Plots for top routes (to save space)",
    "text": "4 Graph Plots for top routes (to save space)\nThese graphs include full history. Covid period will be excluded for future analysis (bit hard to predict that little black swan).\n\n\nCode\ntop_routes_prep_df %>% \n  filter(route %in% topx) %>%\n  group_by(route) %>% \n  plot_time_series(\n    .date_var    = date,\n    .value       = passenger_trips/1000,\n    .facet_ncol  = 2,\n    .smooth      = F,\n    .interactive = F,\n    .title       = \"Passenger Trips(000) by Route\"\n  )"
  },
  {
    "objectID": "posts/forecasting_with_h20/index.html#split-data",
    "href": "posts/forecasting_with_h20/index.html#split-data",
    "title": "Forecasting Flight Passengers using H20",
    "section": "5 Split data",
    "text": "5 Split data\nData filtered to targetted period and then is split into trainig and test sets. Test set is 12 months.\n\n\nCode\ndata_tbl <- top_routes_prep_df %>% \n  filter(date %>% between_time(start,end))\n  \n\nsplits <- time_series_split(data_tbl, assess = horizon, cumulative = TRUE)\n\nrecipe_spec <- recipe(passenger_trips ~ ., data = training(splits)) %>%\n    step_timeseries_signature(date) \n\ntrain_tbl <- training(splits) %>% bake(prep(recipe_spec), .)\ntest_tbl  <- testing(splits)  %>% bake(prep(recipe_spec), .)\n\n#min(test_tbl$date)\nsplits\n\n\n<Analysis/Assess/Total>\n<12751/828/13579>"
  },
  {
    "objectID": "posts/forecasting_with_h20/index.html#connect-to-h20",
    "href": "posts/forecasting_with_h20/index.html#connect-to-h20",
    "title": "Forecasting Flight Passengers using H20",
    "section": "6 Connect to H20",
    "text": "6 Connect to H20\n\n\nCode\n# Initialize H2O\nh2o.init(\n    nthreads = -1,\n    ip       = 'localhost',\n    port     = 54321\n)\n\n\n Connection successful!\n\nR is connected to the H2O cluster: \n    H2O cluster uptime:         2 hours 52 minutes \n    H2O cluster timezone:       Australia/Brisbane \n    H2O data parsing timezone:  UTC \n    H2O cluster version:        3.38.0.3 \n    H2O cluster version age:    1 month and 7 days  \n    H2O cluster name:           H2O_started_from_R_spinb_yru550 \n    H2O cluster total nodes:    1 \n    H2O cluster total memory:   3.75 GB \n    H2O cluster total cores:    8 \n    H2O cluster allowed cores:  8 \n    H2O cluster healthy:        TRUE \n    H2O Connection ip:          localhost \n    H2O Connection port:        54321 \n    H2O Connection proxy:       NA \n    H2O Internal Security:      FALSE \n    R Version:                  R version 4.2.2 (2022-10-31 ucrt) \n\n\nCode\n# Optional - Set H2O No Progress to remove progress bars\nh2o.no_progress()"
  },
  {
    "objectID": "posts/forecasting_with_h20/index.html#set-up-model-specification",
    "href": "posts/forecasting_with_h20/index.html#set-up-model-specification",
    "title": "Forecasting Flight Passengers using H20",
    "section": "7 Set up Model Specification",
    "text": "7 Set up Model Specification\n\n\nCode\nmodel_spec <- automl_reg(mode = 'regression') %>%\n    set_engine(\n         engine                     = 'h2o',\n         max_runtime_secs           = 60*60, \n         max_runtime_secs_per_model = 60,\n         max_models                 = 10,\n         nfolds                     = 5,\n         #exclude_algos              = c(\"DeepLearning\"),\n         verbosity                  = NULL,\n         seed                       = 786\n    ) \n\nmodel_spec\n\n\nH2O AutoML Model Specification (regression)\n\nEngine-Specific Arguments:\n  max_runtime_secs = 60 * 60\n  max_runtime_secs_per_model = 60\n  max_models = 10\n  nfolds = 5\n  verbosity = NULL\n  seed = 786\n\nComputational engine: h2o"
  },
  {
    "objectID": "posts/forecasting_with_h20/index.html#train-and-fit",
    "href": "posts/forecasting_with_h20/index.html#train-and-fit",
    "title": "Forecasting Flight Passengers using H20",
    "section": "8 Train and Fit",
    "text": "8 Train and Fit\n\n\nCode\nmodel_fitted <- model_spec %>%\n    fit(passenger_trips ~ ., data = train_tbl)\n\n\n                                                 model_id     rmse      mse\n1    StackedEnsemble_AllModels_1_AutoML_4_20221230_153853 4623.464 21376415\n2 StackedEnsemble_BestOfFamily_1_AutoML_4_20221230_153853 4736.108 22430716\n3                          GBM_5_AutoML_4_20221230_153853 4738.926 22457424\n4                          GBM_3_AutoML_4_20221230_153853 5017.286 25173157\n5                          GBM_4_AutoML_4_20221230_153853 5085.078 25858014\n6                          GBM_1_AutoML_4_20221230_153853 5603.475 31398934\n       mae rmsle mean_residual_deviance\n1 2625.410   NaN               21376415\n2 2789.898   NaN               22430716\n3 2787.829   NaN               22457424\n4 2800.649   NaN               25173157\n5 2843.318   NaN               25858014\n6 2889.674   NaN               31398934\n\n[12 rows x 6 columns] \n\n\nCode\nmodel_fitted \n\n\nparsnip model object\n\n\nH2O AutoML - Stackedensemble\n--------\nModel: Model Details:\n==============\n\nH2ORegressionModel: stackedensemble\nModel ID:  StackedEnsemble_AllModels_1_AutoML_4_20221230_153853 \nNumber of Base Models: 10\n\nBase Models (count by algorithm type):\n\ndeeplearning          drf          gbm          glm \n           1            2            6            1 \n\nMetalearner:\n\nMetalearner algorithm: glm\nMetalearner cross-validation fold assignment:\n  Fold assignment scheme: AUTO\n  Number of folds: 5\n  Fold column: NULL\nMetalearner hyperparameters: \n\n\nH2ORegressionMetrics: stackedensemble\n** Reported on training data. **\n\nMSE:  3217224\nRMSE:  1793.662\nMAE:  1164.881\nRMSLE:  NaN\nMean Residual Deviance :  3217224\n\n\n\nH2ORegressionMetrics: stackedensemble\n** Reported on cross-validation data. **\n** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **\n\nMSE:  21376415\nRMSE:  4623.464\nMAE:  2625.41\nRMSLE:  NaN\nMean Residual Deviance :  21376415\n\n\nCross-Validation Metrics Summary: \n                                        mean                   sd\nmae                              2620.668000            54.265266\nmean_residual_deviance       21332104.000000       1110405.600000\nmse                          21332104.000000       1110405.600000\nnull_deviance          24041516000000.000000 1477628900000.000000\nr2                                  0.997734             0.000133\nresidual_deviance         54455750000.000000    4141945600.000000\nrmse                             4617.392000           121.426810\nrmsle                                     NA             0.000000\n                                  cv_1_valid            cv_2_valid\nmae                              2665.413000           2617.336000\nmean_residual_deviance       22474568.000000       21760620.000000\nmse                          22474568.000000       21760620.000000\nnull_deviance          24430357000000.000000 22966381000000.000000\nr2                                  0.997614              0.997571\nresidual_deviance         58299027000.000000    55772467000.000000\nrmse                             4740.735000           4664.828000\nrmsle                                     NA                    NA\n                                  cv_3_valid            cv_4_valid\nmae                              2647.775100           2644.215000\nmean_residual_deviance       21071190.000000       21798888.000000\nmse                          21071190.000000       21798888.000000\nnull_deviance          25562297000000.000000 25167888000000.000000\nr2                                  0.997853              0.997777\nresidual_deviance         54869380000.000000    55935947000.000000\nrmse                             4590.336400           4668.927700\nrmsle                                     NA                    NA\n                                  cv_5_valid\nmae                              2528.600600\nmean_residual_deviance       19555256.000000\nmse                          19555256.000000\nnull_deviance          22080662000000.000000\nr2                                  0.997853\nresidual_deviance         47401940000.000000\nrmse                             4422.132300\nrmsle                                     NA"
  },
  {
    "objectID": "posts/forecasting_with_h20/index.html#leaderboard",
    "href": "posts/forecasting_with_h20/index.html#leaderboard",
    "title": "Forecasting Flight Passengers using H20",
    "section": "9 Leaderboard",
    "text": "9 Leaderboard\n\n\nCode\nleaderboard_tbl <- automl_leaderboard(model_fitted) \n\nleaderboard_tbl %>% knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\nmodel_id\nrmse\nmse\nmae\nrmsle\nmean_residual_deviance\n\n\n\n\nStackedEnsemble_AllModels_1_AutoML_4_20221230_153853\n4623.464\n21376415\n2625.410\nNA\n21376415\n\n\nStackedEnsemble_BestOfFamily_1_AutoML_4_20221230_153853\n4736.108\n22430716\n2789.898\nNA\n22430716\n\n\nGBM_5_AutoML_4_20221230_153853\n4738.926\n22457424\n2787.829\nNA\n22457424\n\n\nGBM_3_AutoML_4_20221230_153853\n5017.286\n25173157\n2800.649\nNA\n25173157\n\n\nGBM_4_AutoML_4_20221230_153853\n5085.078\n25858014\n2843.318\nNA\n25858014\n\n\nGBM_1_AutoML_4_20221230_153853\n5603.475\n31398934\n2889.674\nNA\n31398934\n\n\nGBM_2_AutoML_4_20221230_153853\n5633.260\n31733613\n2944.514\nNA\n31733613\n\n\nGBM_grid_1_AutoML_4_20221230_153853_model_1\n6170.972\n38080898\n3323.607\nNA\n38080898\n\n\nDeepLearning_1_AutoML_4_20221230_153853\n15622.131\n244050990\n11268.303\nNA\n244050990\n\n\nDRF_1_AutoML_4_20221230_153853\n23504.606\n552466523\n12546.398\n2.691383\n552466523\n\n\nXRT_1_AutoML_4_20221230_153853\n82152.863\n6749092971\n48764.480\n3.175682\n6749092971\n\n\nGLM_1_AutoML_4_20221230_153853\n97131.095\n9434449699\n56375.288\n3.267512\n9434449699\n\n\n\n\n\nSo AutoML and stacked ensembles thereof lead the way, deep learning approaches not really ranking!\nNow,\n\n\nCode\nmodeltime_tbl <- modeltime_table(\n    model_fitted\n) \n\nmodeltime_tbl\n\n\n# Modeltime Table\n# A tibble: 1 × 3\n  .model_id .model   .model_desc                 \n      <int> <list>   <chr>                       \n1         1 <fit[+]> H2O AUTOML - STACKEDENSEMBLE"
  },
  {
    "objectID": "posts/forecasting_with_h20/index.html#calibrate---test-data",
    "href": "posts/forecasting_with_h20/index.html#calibrate---test-data",
    "title": "Forecasting Flight Passengers using H20",
    "section": "10 Calibrate - test data",
    "text": "10 Calibrate - test data\n\n\nCode\ncalibration_tbl <- modeltime_tbl %>%\n  modeltime_calibrate(\n    new_data = test_tbl,\n    id      = \"route\")\n\nforecast_test_tbl <- calibration_tbl %>% \n    modeltime_forecast(\n        new_data    = test_tbl,\n        actual_data = data_tbl,\n        keep_data   = TRUE,\n        conf_by_id  = T\n    ) %>%\n    group_by(route)\n\n#calibration_tbl"
  },
  {
    "objectID": "posts/forecasting_with_h20/index.html#graph-forecast---top-10-routes",
    "href": "posts/forecasting_with_h20/index.html#graph-forecast---top-10-routes",
    "title": "Forecasting Flight Passengers using H20",
    "section": "11 Graph Forecast - Top 10 Routes",
    "text": "11 Graph Forecast - Top 10 Routes\nUsing the top model in the leaderboard- Auto_ML Stacked Ensemble\n\n\nCode\nforecast_test_tbl %>%\n  filter(route %in% topx,\n         lubridate::year(date)> 2015) %>% \n    plot_modeltime_forecast(\n        .facet_ncol = 2, \n        .interactive = T,\n        .title = \"Forecast v Test Data - top 10 Routes\"\n    )\n\n\n\n\n\n\nSo forecasts look pretty good…"
  },
  {
    "objectID": "posts/forecasting_with_h20/index.html#accuracy",
    "href": "posts/forecasting_with_h20/index.html#accuracy",
    "title": "Forecasting Flight Passengers using H20",
    "section": "12 Accuracy",
    "text": "12 Accuracy\nAnother look at accuracy measures of top model only.\n\n\nCode\ncalibration_tbl %>% \n  modeltime_accuracy(metric_set = extended_forecast_accuracy_metric_set()) %>% \n  knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n.model_id\n.model_desc\n.type\nmae\nmape\nmaape\nmase\nsmape\nrmse\nrsq\n\n\n\n\n1\nH2O AUTOML - STACKEDENSEMBLE\nTest\n2277.27\nInf\n15.97232\n0.02854\n19.08186\n3768.153\n0.9988767"
  },
  {
    "objectID": "posts/forecasting_with_h20/index.html#refit-to-full-dataset",
    "href": "posts/forecasting_with_h20/index.html#refit-to-full-dataset",
    "title": "Forecasting Flight Passengers using H20",
    "section": "13 Refit to full Dataset",
    "text": "13 Refit to full Dataset\nBefore doing any predictions, we need to refit model to full dataset (train and test), so that prediction is based on most recent data!\n\n\nCode\ndata_prepared_tbl <- bind_rows(train_tbl, test_tbl)\n\nfuture_tbl <- data_prepared_tbl %>%\n    group_by(route) %>%\n    future_frame(.date_var   = date,\n                 .length_out = \"1 year\") %>%\n    ungroup()\n\nfuture_prepared_tbl <- bake(prep(recipe_spec), future_tbl)\n\nrefit_tbl <- calibration_tbl %>%\n    modeltime_refit(data_prepared_tbl)\n\n\n                                                 model_id     rmse      mse\n1    StackedEnsemble_AllModels_1_AutoML_5_20221230_154413 4478.597 20057827\n2 StackedEnsemble_BestOfFamily_1_AutoML_5_20221230_154413 4653.480 21654877\n3                          GBM_5_AutoML_5_20221230_154413 4663.906 21752021\n4                          GBM_3_AutoML_5_20221230_154413 4874.181 23757643\n5                          GBM_4_AutoML_5_20221230_154413 5018.797 25188324\n6                          GBM_1_AutoML_5_20221230_154413 5148.774 26509875\n       mae rmsle mean_residual_deviance\n1 2525.244   NaN               20057827\n2 2708.357   NaN               21654877\n3 2704.795   NaN               21752021\n4 2737.018   NaN               23757643\n5 2806.473   NaN               25188324\n6 2758.185   NaN               26509875\n\n[12 rows x 6 columns]"
  },
  {
    "objectID": "posts/forecasting_with_h20/index.html#prediction",
    "href": "posts/forecasting_with_h20/index.html#prediction",
    "title": "Forecasting Flight Passengers using H20",
    "section": "14 Prediction",
    "text": "14 Prediction\n\n\nCode\nprediction <- refit_tbl %>%\n    modeltime_forecast(\n        new_data    = future_prepared_tbl,\n        actual_data = data_prepared_tbl,\n        keep_data   = TRUE,\n        conf_by_id  = T\n    ) %>%\n    group_by(route) \n\nprediction %>% \n  filter(route %in% topx,\n         lubridate::year(date)> 2015) %>% \n  plot_modeltime_forecast(\n        .facet_ncol  = 2,\n        .interactive = T,\n        .title       = \"Passenger Trip Prediction - top 10 Routes\"\n        \n    )"
  },
  {
    "objectID": "posts/forecasting_with_h20/index.html#save-model-and-close-h2o-connection",
    "href": "posts/forecasting_with_h20/index.html#save-model-and-close-h2o-connection",
    "title": "Forecasting Flight Passengers using H20",
    "section": "15 Save Model and Close H2o connection",
    "text": "15 Save Model and Close H2o connection\n\n\nCode\nmodel_fitted %>% \n  save_h2o_model(path = \"./artifacts/h20_model1\", overwrite = TRUE)\n\n#model_h2o <- load_h2o_model(path = \"./artifacts/h20_model1\")\n\n#h2o.shutdown(prompt = FALSE)"
  },
  {
    "objectID": "posts/aust_domestic_flights/index.html#introduction",
    "href": "posts/aust_domestic_flights/index.html#introduction",
    "title": "Australian Domestic Flights",
    "section": "1 Introduction",
    "text": "1 Introduction\nThis analysis summarises Australian domestic flight volumes and on-time performance (OTP) issues by airline over time.\nIt has been prepared mainly to get more used to Quarto, and comprises:\n\nInitial data load and preprocessing - not shown\nDomestic Flight Analysis - This document\nGlobal Flight Analysis - Next document\nForecasting - to come\n\n\n\nCode\nlibrary(tidyverse)\n\n\nlibrary(scales)\n\nlibrary(leaflet)\nlibrary(leaflet.minicharts)\n\n\nlibrary(janitor)\nlibrary(plotly)\nlibrary(gganimate)\n\nlibrary(dygraphs)\n\n\noptions(scipen = 999)"
  },
  {
    "objectID": "posts/aust_domestic_flights/index.html#data-sources",
    "href": "posts/aust_domestic_flights/index.html#data-sources",
    "title": "Australian Domestic Flights",
    "section": "2 Data Sources",
    "text": "2 Data Sources\nData is sourced from https://data.gov.au/ site, specific datasets used being:\n\nTop routes\nIndustry Totals\nOn-Time-Performance - Domestic\n\n(need to add notes/refs)\n\n\nCode\ntop_routes_prep_df <- read_rds(\"./artifacts/top_routes_prep_df.rds\")\nind_totals_prep_df <- read_rds(\"./artifacts/ind_totals_prep_df.rds\")\ndom_cargo_prep_df  <- read_rds(\"./artifacts/dom_cargo_prep_df.rds\")\notp_prep_df        <- read_rds(\"./artifacts/otp_prep_df.rds\")\n\nlatest_date        <- max(top_routes_prep_df$date)\n\n\notp_prep_df <- otp_prep_df %>% \n  mutate(across(airline,str_replace,'QantasLink','Qantas')) %>% \n  mutate(across(airline,str_replace,\"Virgin Australia - Atr/F100 Operations\",\"Virgin Australia\")) %>% \n  mutate(across(airline,str_replace,\"Virgin Australia Regional Airlines\",\"Virgin Australia\"))"
  },
  {
    "objectID": "posts/aust_domestic_flights/index.html#exploratory-data-analysis",
    "href": "posts/aust_domestic_flights/index.html#exploratory-data-analysis",
    "title": "Australian Domestic Flights",
    "section": "3 Exploratory Data Analysis",
    "text": "3 Exploratory Data Analysis\n\n3.1 All Major Routes - Total Monthly Pax\nTotal monthly passenger numbers :\n\n\nCode\ng <- ind_totals_prep_df %>% \n  #filter(year>2010) %>% \n  ggplot(aes(x=date,y=passenger_trips))+\n  geom_line()+\n  scale_y_continuous(labels=scales::comma)+\n  scale_x_date(date_breaks = \"2 year\",date_labels = \"%y\")+\n  labs(title = \"Australian Domestic Flight History\", x=\"Year\", y = \"Passenger Numbers (monthly)\")+\n  theme_bw()\nggplotly(g)\n\n\n\n\n\n\nKey “points of interest”:\n\n1987 pilot strike\n2000 Olympic Games\nCOVID!!!!\n\nSeasonality and trend both also clearly show, at least until covid.\nWe can break this down by top 10 routes (only tracked 2-way):\n\n\n3.2 Top 10 Routes - Monthly Pax by O/D City Pairs\n\n\nCode\n## * Top routes ----\ntop_routes <- top_routes_prep_df %>% \n  group_by(route,date=max(date)) %>% \n  summarise(passenger_trips = sum(passenger_trips)) %>% \n  ungroup() %>%\n  slice_max(passenger_trips, n=10) %>% \n  select(route) %>% \n  pull() %>% \n  as.character()\n  \n\ng1 <- top_routes_prep_df %>% \n  filter(route %in% top_routes) %>%\n  mutate(route = factor(route,levels=top_routes)) %>% \n  ggplot(aes(date,passenger_trips,colour =route))+\n  geom_line()+\n  scale_y_continuous(labels=scales::comma)+\n  scale_x_date(date_breaks = \"2 year\",date_labels = \"%y\")+\n  scale_colour_discrete(name  =\"Route - 2way\")+\n  labs(title = \"Australian Domestic Flight History - Top10 (2-way) Routes\", x=\"by Month\", y = \"Passenger Numbers (monthly)\")+\n  #theme_bw() +\n  theme(legend.position=\"bottom\")\nggplotly(g1)\n\n\n\n\n\n\n\n\n3.3 All Routes - Total Monthly Pax - Mapped\nFollowing map shows all routes in 2019 (precovid), thickness of line representiing pax volumes for the year (in this case with a moving monthly timeline to show impact of covid - but does not really work that well). As width of line signifies volumes of passenger trips, Sydney-Melbourne route clearly has thickest line!\n\n\nCode\n## * Routes Mapped - Leaflet ----\n\ntop_routes_short <- top_routes_prep_df %>%\n  filter(year>2019) \n  # group_by(year,city1,city2,city1_lng,city1_lat,city2_lng,city2_lat) %>% \n  # summarise(passenger_trips = sum(passenger_trips))\n\n  leaflet() %>% \n    addProviderTiles(providers$OpenTopoMap) %>% \n    addTiles() %>%\n    #addProviderTiles(providers$Esri.WorldStreetMap) %>% \n  addFlows(\n    top_routes_short$city1_lng, \n    top_routes_short$city1_lat, \n    top_routes_short$city2_lng, \n    top_routes_short$city2_lat,\n    flow = top_routes_short$passenger_trips,\n    time = top_routes_short$date,\n    dir = 0,\n    minThickness = .1,\n    maxThickness = 5,\n    popupOptions = list(closeOnClick = FALSE, autoClose = FALSE)\n  )\n\n\n\n\n\n\n\n\n3.4 On Time Performance (OTP) - All Domestic Routes\nPerformance Metric: OTP_issues_pct = (delayed arrivals + cancelled flights)/ Total Sectors Scheduled.\nAs this metric is based on arrival delays and canellations as a percentage of scheduled services, the higher the number, then the worse the performance!\n\n\nCode\notp_issues_all <- otp_prep_df %>% \n  filter(airline == \"All Airlines\") %>% \n  group_by(date) %>% \n  summarise(sectors_scheduled = sum(sectors_scheduled),\n            arrivals_delayed = sum(arrivals_delayed),\n            cancellations = sum(cancellations),\n            otp_issues_num = sum(otp_issues_num)\n            ) %>% \n  mutate(otp_issues_pct = (arrivals_delayed+cancellations)/sectors_scheduled)\n\ng_opt <- otp_issues_all %>% \n  ggplot(aes(date,otp_issues_pct))+\n  geom_line()+\n  geom_smooth(method=\"loess\")+\n  scale_y_continuous(labels=scales::percent)+\n  theme_bw()\n\nggplotly(g_opt)\n\n\n\n\n\n\nWhile the ‘loess’ smoother indicates a continual worsening of performance, most recent reporting perhaps indicates the airlines are starting to address OTP issues.\n\n\n3.5 OTP - By Airline over Time\nThis graph just focuses on the main 3 domestic carriers.\n\n\nCode\notp_issues_airline <- otp_prep_df %>% \n  filter(airline %in% c(\"Jetstar\",\"Qantas\",\"Virgin Australia\"),\n         year > 2019\n         ) %>%\n  \n  mutate(airline = str_to_title(airline)) %>% \n  group_by(date,airline) %>% \n  summarise(sectors_scheduled = sum(sectors_scheduled),\n            arrivals_delayed  = sum(arrivals_delayed),\n            cancellations     = sum(cancellations),\n            otp_issues_num    = sum(otp_issues_num)\n            ) %>% \n  mutate(arrivals_delayed_pct = arrivals_delayed/sectors_scheduled,\n         cacellations_pct     = cancellations/sectors_scheduled,\n         otp_issues_total_pct = (arrivals_delayed+cancellations)/sectors_scheduled ) %>% \n  select(date,airline,ends_with(\"pct\")) %>% \n  pivot_longer(cols = ends_with(\"pct\"), names_to = \"otp_metric\",values_to = \"pct_issues\")\n\ng_otp_issues_airline <- otp_issues_airline %>% \n  ggplot(aes(date,pct_issues,colour = airline))+\n  geom_line()+\n  #geom_smooth(method=\"loess\")+\n  scale_x_date(date_breaks = \"3 month\",date_labels = \"%m/%y\")+\n  scale_y_continuous(labels=scales::percent)+\n  xlab(\"Month\")+\n  ylab(\"Pct of Monthly Scheduled Services\") +\n  theme_bw()+\n  theme(legend.position =  \"bottom\")+\n  facet_wrap(~otp_metric,ncol=1)\n\n\nggplotly(g_otp_issues_airline)\n\n\n\n\n\n\nNote:\n\ncancellations in initial covid period\nUpswing in OTP issues (mainly non-cancellations) in more recent days\nJetstar worst performer, although all 3 airlines guilty of worsening performance.\nSigns of improvement in most recent reports.\n\nTo highlight the y-o-y changes:\n\n\nCode\nyear_select <- 2016\n\notp_issues_airline2 <- otp_prep_df %>% \n  filter(airline != \"All Airlines\",\n         year > year_select\n         ) %>%\n  mutate(airline = str_to_title(airline)) %>% \n  group_by(year,airline) %>% \n  summarise(sectors_scheduled = sum(sectors_scheduled),\n            arrivals_delayed = sum(arrivals_delayed),\n            cancellations = sum(cancellations),\n            otp_issues_num = sum(otp_issues_num)\n            ) %>% \n  mutate(otp_issues_pct = (arrivals_delayed+cancellations)/sectors_scheduled ) %>% \n  mutate(airline = fct_reorder(airline,otp_issues_pct))\n\n\ng_otp_issues_airline_2 <- otp_issues_airline2 %>% \n  filter(airline %in%c(\"Jetstar\",\"Virgin Australia\", \"Qantas\")) %>% \n  ggplot(aes(year,otp_issues_pct,fill = year))+\n  geom_col()+\n  geom_text(aes(label = percent(otp_issues_pct,accuracy = .1)),\n            hjust = 1,\n            colour = \"white\")+\n  #coord_flip()+\n  scale_y_continuous(labels=scales::percent)+\n  #scale_x_discrete(breaks = 0)+\n  ylab(\"OTP Issues/Scheduled Services\")+\n  xlab(\"\")+\n  labs(title=\"On-Time Performance Issues by Year\",\n       subtitle = \"as pct of Scheduled Services\")+\n  theme_bw()+\n  \n  coord_flip()+\n  facet_wrap(vars(airline),dir = \"v\")\n\ng_otp_issues_airline_2\n\n\n\n\n\nCode\n#ggplotly(g_otp_issues_airline_2)"
  },
  {
    "objectID": "posts/aust_international_flights/index.html#introduction",
    "href": "posts/aust_international_flights/index.html#introduction",
    "title": "Australian International Flights",
    "section": "1 Introduction",
    "text": "1 Introduction\nThis analysis summarises Australian international flight volumes over time.\nIt has been prepared mainly to get more used to Quarto, and comprises:\n\nInitial data load and preprocessing - not shown\nDomestic Flight Analysis - previous post\nGlobal Flight Analysis - this document\nForecasting - to come\n\nThis is a pretty brief look - might try it in Shiny where it will probably come together better. The biggest challenge was the great circle mapping, the solution to which was pretty much right in front of me on ‘the R Graph Gallery’…"
  },
  {
    "objectID": "posts/aust_international_flights/index.html#packages-and-data",
    "href": "posts/aust_international_flights/index.html#packages-and-data",
    "title": "Australian International Flights",
    "section": "2 Packages and Data",
    "text": "2 Packages and Data\nLoad packages:\n\n\nCode\n#| echo: false\n#| message: false\n#| warning: false\n\nlibrary(tidyverse)\nlibrary(scales)\n\nlibrary(maps)\nlibrary(geosphere)\n\nlibrary(janitor)\nlibrary(plotly)\nlibrary(gganimate)\n\n\nLoad pre-processed data:\n\n\nCode\n#| echo: false\n\nintl_flights_seats_prep_df <- read_rds(\"./artifacts/intl_flights_seats_prep_df.rds\")\nintl_flights_city_pairs_prep_df <- read_rds(\"./artifacts/intl_flights_city_pairs_prep_df.rds\")\nintl_country_of_port_prep_df <- read_rds(\"./artifacts/intl_country_of_port_prep_df.rds\")"
  },
  {
    "objectID": "posts/aust_international_flights/index.html#exploratory-data-analysis",
    "href": "posts/aust_international_flights/index.html#exploratory-data-analysis",
    "title": "Australian International Flights",
    "section": "3 Exploratory Data Analysis",
    "text": "3 Exploratory Data Analysis\n\n3.1 All Major Routes - Total Monthly Pax\nTotal monthly passenger numbers , which shows the cliff it went off, but also some solid signs of rebound:\n\n\nCode\n## * Industry Volumes by Time ----\ncity_pair_totals <- intl_flights_city_pairs_prep_df %>% \n  group_by(date) %>% \n  summarise(passengers_total =sum(passengers_total))\n  \ng <- city_pair_totals %>% \n  #filter(year>2010) %>% \n  ggplot(aes(x=date,y=passengers_total))+\n  geom_line()+\n  scale_y_continuous(labels=scales::comma)+\n  scale_x_date(date_breaks = \"2 year\",date_labels = \"%y\")+\n  labs(title = \"Australian Global Flight History\", x=\"Year\", y = \"Passenger Numbers (monthly)\")+\n  theme_bw()\nggplotly(g)"
  },
  {
    "objectID": "posts/aust_international_flights/index.html#top-routes",
    "href": "posts/aust_international_flights/index.html#top-routes",
    "title": "Australian International Flights",
    "section": "4 Top Routes",
    "text": "4 Top Routes\nYep, that will hurt:\n\n\nCode\ntop_totals <- intl_flights_city_pairs_prep_df %>% \n  filter(year ==2019) %>% \n  group_by(year, route) %>% \n  summarise(passengers_total =sum(passengers_total)) %>% \n  ungroup() %>%\n  slice_max(passengers_total, n=20) %>% \n  select(route) %>% \n  pull() %>% \n  as.character()\n\ng1 <- intl_flights_city_pairs_prep_df %>% \n  filter(route %in% top_totals,year > 2014) %>%\n  mutate(route = factor(route,levels=top_totals)) %>% \n  ggplot(aes(date,passengers_total,colour =route))+\n  geom_line()+\n  scale_y_continuous(labels=scales::comma)+\n  scale_x_date(date_breaks = \"2 year\",date_labels = \"%y\")+\n  scale_colour_discrete(name  =\"Route - 2way\")+\n  labs(title = \"Australian International Flight History - Top (2-way) Routes\", x=\"by Month\", y = \"Passenger Numbers (monthly)\")+\n  theme_bw()\n  \nggplotly(g1)"
  },
  {
    "objectID": "posts/aust_international_flights/index.html#top-destinations",
    "href": "posts/aust_international_flights/index.html#top-destinations",
    "title": "Australian International Flights",
    "section": "5 Top Destinations",
    "text": "5 Top Destinations\nWhich tells the same story all over again!\n\n\nCode\ndestination_df <- intl_flights_city_pairs_prep_df %>% \n  group_by(intl_city_country,international_city,year) %>% \n  summarise(\n    passengers_total = sum(passengers_total),\n    freight_total_tonnes = sum(freight_total_tonnes),\n    mail_total_tonnes = sum(mail_total_tonnes)\n    ) %>% \n  ungroup()\n\ntop_dest_unique <- destination_df %>%\n  group_by(international_city) %>% \n  summarise(passengers_total = sum(passengers_total)) %>% \n  ungroup() %>% \n  slice_max(passengers_total, n=10) %>% \n  select(international_city) %>% \n  unique() %>% \n  pull() %>% \n  as.character()\n\n\ng2 <- destination_df %>% \n  filter(international_city %in% top_dest_unique ,year > 2016) %>%\n  ggplot(aes(international_city,passengers_total))+\n  geom_col()+\n  scale_y_continuous(labels=scales::comma)+\n  scale_colour_discrete(name  =\"Route - 2way\")+\n  labs(title = \"Australian International Flight History - Top Destinations\", x=\"\", y = \"Passenger Numbers pa\")+\n  theme_bw() +\n  facet_wrap(~year,ncol = 1,dir = \"v\",scales = \"free_y\") +\n  coord_flip()\n\ng2"
  },
  {
    "objectID": "posts/aust_international_flights/index.html#mapping---aust-international-routes-2019",
    "href": "posts/aust_international_flights/index.html#mapping---aust-international-routes-2019",
    "title": "Australian International Flights",
    "section": "6 Mapping - Aust International Routes 2019",
    "text": "6 Mapping - Aust International Routes 2019\nUsing 2019, just because it is pre-covid. Could use later years and will in a more dynamic environment.\nSetting up required code:\n\n\nCode\ntop_routes <- intl_flights_city_pairs_prep_df %>% \n  filter(year ==2019) %>% \n  group_by(route) %>% \n  summarise(passengers_total = sum(passengers_total)) %>% \n  ungroup() %>%\n  slice_max(passengers_total, n=150) %>% \n  select(route) %>% \n  pull() %>% \n  as.character()\n\nroutes <- intl_flights_city_pairs_prep_df %>% \n  filter(route %in% top_routes) %>% \n  select(route,australian_city, international_city,\n         aust_city_lat,aust_city_lng,\n         intl_city_lat,intl_city_lng) %>% \n  unique()\n\n\nAnd the resulting map:\n\n\nCode\n# A function to plot routes\nplot_routes=function( dep_lon, dep_lat, arr_lon, arr_lat, ...){\n  inter <- gcIntermediate(c(dep_lon, dep_lat), c(arr_lon, arr_lat), n=50, addStartEnd=TRUE, breakAtDateLine=F)             \n  inter=data.frame(inter)\n  diff_of_lon=abs(dep_lon) + abs(arr_lon)\n  if(diff_of_lon > 180){\n    lines(subset(inter, lon>=0), ...)\n    lines(subset(inter, lon<0), ...)\n  }else{\n    lines(inter, ...)\n  }\n}\n\n# background map\npar(mar=c(0,0,0,0))\nmap('world',col=\"gray\", fill=TRUE, bg=\"white\", \n    lwd=0.05,border=0, mar=rep(0,4),ylim=c(-75,75) )\ntitle(\"International Flight Routes - Australia 2019\")\n\n# add all selected routes:\nfor(i in 1:nrow(routes)){\n  plot_routes(routes$aust_city_lng[i], \n              routes$aust_city_lat[i], \n              routes$intl_city_lng[i], \n              routes$intl_city_lat[i], \n              col=\"blue\", lwd=1)\n}\n\n# add points and names of cities\npoints(x=routes$intl_city_lng, \n       y=routes$intl_city_lat, col=\"slateblue\", cex=2, pch=20)\n\n\n\n\n\nThe above map is a bit(!) overloaded, because I left all routes in (to pick up London, New York etc). We can play with that in a more dynamic environment, probably Shiny (or even Power Bi)\nAs mentioned, the great circle mapping was a bit of a pain to do, but actually quite simple once you find the correct approach. I will improve this as time permits!"
  },
  {
    "objectID": "posts/post-with-code/index.html#summary",
    "href": "posts/post-with-code/index.html#summary",
    "title": "Titanic from Kaggle",
    "section": "0.1 Summary",
    "text": "0.1 Summary\nThis is just a first test with code in a blog using the new Quarto framework! Guess what I am using..yep Titanic, Kaggle version..\nIt is not very well structured as it is pretty much in the order I did it following all instructions, books and blogs from the expert TidyModels and Quarto teams at RStudio/Posit . All errors belong to me!"
  },
  {
    "objectID": "posts/post-with-code/index.html#final-kaggle-scores",
    "href": "posts/post-with-code/index.html#final-kaggle-scores",
    "title": "Titanic from Kaggle",
    "section": "0.2 Final Kaggle Scores",
    "text": "0.2 Final Kaggle Scores\n\n\nCode\nkaggle <- tibble(\n  Model = c(\"Logistic Regression\",\n            \"Regularised Logistic Regression\",\n            \"Random Forest-final\",\n            \"Random Forest-initial\",\n            \"XG Boost\",\n            \"Neural Net\",\n            \"Ensemble\"), \n  Score = c(.76555,.77033,.77751,.78229,.77272,.76794,.77751)\n  )\n\nkaggle %>% knitr::kable()\n\n\n\n\n\nModel\nScore\n\n\n\n\nLogistic Regression\n0.76555\n\n\nRegularised Logistic Regression\n0.77033\n\n\nRandom Forest-final\n0.77751\n\n\nRandom Forest-initial\n0.78229\n\n\nXG Boost\n0.77272\n\n\nNeural Net\n0.76794\n\n\nEnsemble\n0.77751\n\n\n\n\n\nWhich when all submitted gave me a ranking of 1,872 out of 13,000 or so teams, so no grand-master!\nSeems like the value mainly comes from the feature engineering and selection process (as the experts all seem to say) given the similarity in above model scores."
  },
  {
    "objectID": "posts/post-with-code/index.html#review-data",
    "href": "posts/post-with-code/index.html#review-data",
    "title": "Titanic from Kaggle",
    "section": "0.3 Review Data",
    "text": "0.3 Review Data\n\n0.3.1 Load Some Kaggle Data\nNot the…? Yes, the Titanic again….\n\n\nCode\ntrain <- read_csv(\"data_raw/train.csv\",show_col_types = FALSE) %>% clean_names() %>% mutate(train_test = \"train\")\ntest <- read_csv(\"data_raw/test.csv\",show_col_types = FALSE) %>% clean_names() %>% \n  mutate(train_test = \"test\")\nall <- train %>% bind_rows(test)\n\n# colnames(data)\n# cwd()\n\n\n\n\n0.3.2 Some Initial EDA\nA quick look.\n\n\nCode\ntrain %>% skim() \n\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n891\n\n\nNumber of columns\n13\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nname\n0\n1.00\n12\n82\n0\n891\n0\n\n\nsex\n0\n1.00\n4\n6\n0\n2\n0\n\n\nticket\n0\n1.00\n3\n18\n0\n681\n0\n\n\ncabin\n687\n0.23\n1\n15\n0\n147\n0\n\n\nembarked\n2\n1.00\n1\n1\n0\n3\n0\n\n\ntrain_test\n0\n1.00\n5\n5\n0\n1\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\npassenger_id\n0\n1.0\n446.00\n257.35\n1.00\n223.50\n446.00\n668.5\n891.00\n▇▇▇▇▇\n\n\nsurvived\n0\n1.0\n0.38\n0.49\n0.00\n0.00\n0.00\n1.0\n1.00\n▇▁▁▁▅\n\n\npclass\n0\n1.0\n2.31\n0.84\n1.00\n2.00\n3.00\n3.0\n3.00\n▃▁▃▁▇\n\n\nage\n177\n0.8\n29.70\n14.53\n0.42\n20.12\n28.00\n38.0\n80.00\n▂▇▅▂▁\n\n\nsib_sp\n0\n1.0\n0.52\n1.10\n0.00\n0.00\n0.00\n1.0\n8.00\n▇▁▁▁▁\n\n\nparch\n0\n1.0\n0.38\n0.81\n0.00\n0.00\n0.00\n0.0\n6.00\n▇▁▁▁▁\n\n\nfare\n0\n1.0\n32.20\n49.69\n0.00\n7.91\n14.45\n31.0\n512.33\n▇▁▁▁▁\n\n\n\n\n\n\n\n0.3.3 Some Initial Wrangling\n\n\nCode\nall_proc <- all %>% \n  mutate(title = str_extract(name,\"(\\\\w)([a-z]+)(\\\\.)\")) %>% \n  mutate(pax_type = case_when(\n    title %in% c(\"Miss.\",\"Ms.\",\"Mlle.\")         ~ \"F_unmarried\",\n    title %in% c(\"Mme.\",\"Mrs.\")                 ~ \"F_married\",\n    title %in% c(\"Countess.\",\"Lady.\",\"Dona.\")   ~ \"F_titled\",\n    title %in% c(\"Capt.\",\"Col.\",\"Major.\")       ~ \"Military\",\n    title %in% c(\"Dr.\",\"Rev.\")                  ~ \"M_Professional\",\n    title %in% c(\"Don.\",\"Jonkheer.\",\"Sir.\")     ~ \"M_titled\",\n    TRUE ~ title\n  ),\n  surname        = str_extract(name,\"(\\\\w+)(\\\\,)\"),\n  survival       = ifelse(survived==0,\"No\",\"Yes\"),\n  ticket_preface = str_extract(ticket,\"([:graph:]+)(\\\\s)\"),\n  ticket_preface = ifelse(is.na(ticket_preface),\"none\",ticket_preface),\n  cabin_preface  = ifelse(is.na(cabin),\"nk\",\n                    substr(cabin,1,1)),\n  embarked       = ifelse(is.na(embarked),\"S\",embarked)\n  ) %>% \n  group_by(pax_type,pclass) %>% \n  mutate(age     = ifelse(is.na(age),median(age,na.rm = T), age)) %>% \n  ungroup() %>% \n  add_count(ticket,name = \"ticket_group\") %>% \n  mutate(ticket_group = case_when(\n    ticket_group == 1 ~ \"single\",\n    ticket_group == 2 ~ \"couple\",\n    TRUE              ~ \"group\"\n  ),\n    family_group = as.numeric(sib_sp)+as.numeric(parch)+1\n  ) %>% \n  mutate(family_group = factor(\n    case_when(\n        family_group < 2  ~ \"single\",\n        family_group < 3  ~ \"couple\",\n        TRUE              ~ \"family\"\n        ),\n    ordered = TRUE)\n  ) %>% \n  mutate(age_group = factor(case_when(\n    age < 13      ~ \"child\",\n    age < 20      ~ \"teen\",\n    age < 30      ~ \"20s\",\n    age < 40      ~ \"30s\",\n    age < 50      ~ \"40s\",\n    age < 60      ~ \"50s\",\n    TRUE          ~ \"60+\"\n    \n  ),\n  ordered = TRUE)\n  ) %>% \n  mutate(across(where(is.character),as_factor)) %>% \n  mutate(pclass = factor(pclass,levels = c(\"1\",\"2\",\"3\")),\n         survived = factor(survived)\n         ) %>% \nselect(-c(title,ticket_preface))\n  \n#all_proc %>% glimpse() \n\n\n\n\n0.3.4 A bit more EDA\n\n\nCode\nall_proc %>% \n  select(-c(name,ticket,cabin,surname,train_test)) %>% \n  DataExplorer::plot_bar()\n\n\n\n\n\n\n\n\n\n\nCode\nall_proc %>% DataExplorer::plot_histogram(ggtheme = theme_light() )\n\n\n\n\n\n\n\n0.3.5 Eyeballing Survival Graphs on Training Data\n\n\nCode\nno_f <- all_proc %>%\n  filter(train_test == \"train\") %>% \n  select(passenger_id,pclass,sex,embarked,pax_type,ticket_group,family_group,age_group,cabin_preface,survival) %>% \n  droplevels() %>%\n  mutate(across(where(is.factor),~ factor(.x,ordered = FALSE))) %>%\n  pivot_longer(cols = c(pclass:cabin_preface)) \n\n\ng_l <- no_f %>% \n  split(.$name) %>% \n  map(~ ggplot(.,aes(y=value,fill=survival)) +\n                geom_bar() +\n              ggtitle(.$name) +\n        theme_bw() +\n        labs(x=NULL,y=NULL)+\n        scale_fill_viridis_d(option = \"cividis\")\n      \n            ) \n\nlibrary(patchwork)\nwrap_plots(g_l, ncol = 2)\n\n\n\n\n\n\n\n0.3.6 Split Data back to Train/Test/Validation\n\n\nCode\ntrain_proc_adj_tbl <- all_proc %>% \n  filter(train_test ==\"train\") %>% \n  select(-c(survival))\n\n\n  \ntrain_split <- initial_split(train_proc_adj_tbl,strata = survived)\n\ntrain_train <- training(train_split)\ntrain_test <- testing(train_split)"
  },
  {
    "objectID": "posts/post-with-code/index.html#recipe-base",
    "href": "posts/post-with-code/index.html#recipe-base",
    "title": "Titanic from Kaggle",
    "section": "0.4 Recipe-Base",
    "text": "0.4 Recipe-Base\n\n\nCode\nrecipe_base <- \n  recipe(survived ~ ., data = train_train) %>% \n  update_role(passenger_id, name,surname,ticket,cabin,new_role = \"ID\") %>%\n  step_impute_knn(all_numeric_predictors()) %>% \n  step_dummy(all_nominal_predictors()) %>%\n  step_factor2string(all_nominal_predictors()) %>% \n  step_zv(all_predictors()) %>% \n  step_pca()\nrecipe_base\n\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          5\n   outcome          1\n predictor         13\n\nOperations:\n\nK-nearest neighbor imputation for all_numeric_predictors()\nDummy variables from all_nominal_predictors()\nCharacter variables from all_nominal_predictors()\nZero variance filter on all_predictors()\nPCA extraction with <none>\n\n\n\n0.4.1 Save Files\n\n\nCode\nwrite_rds(all_proc,\"artifacts/all_proc.rds\")\nwrite_rds(train_split,\"artifacts/train_split.rds\")\nwrite_rds(recipe_base,\"artifacts/recipe_base.rds\")\n# \n# all_proc <- read_rds(\"artifacts/all_proc.rds\")\n# train_split <- read_rds(\"artifacts/train_split.rds\")\n# recipe_base <- read_rds(\"artifacts/recipe_base.rds\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#models",
    "href": "posts/post-with-code/index.html#models",
    "title": "Titanic from Kaggle",
    "section": "0.5 Models",
    "text": "0.5 Models\n\n0.5.1 Logistic Regression\n\nLR Model Spec\n\n\nCode\nlr_spec <-  \n  logistic_reg() %>% \n  set_engine(\"glm\")\n\nlr_spec\n\n\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\n\nLR Workflow\n\n\nCode\nlr_wflow <- \n  workflow() %>% \n  add_model(lr_spec) %>% \n  add_recipe(recipe_base)\n\nlr_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\n\nLR Fit Model\n\n\nCode\nlr_fit <- \n  lr_wflow %>% \n  last_fit(train_split)\n\n#lr_fit\n\nlr_final_metrics <- lr_fit %>% collect_metrics()\nlr_final_metrics \n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.799 Preprocessor1_Model1\n2 roc_auc  binary         0.822 Preprocessor1_Model1\n\n\nCode\n#show_notes(.Last.tune.result)\n\n\n\n\nLR Predict\n\n\nCode\nlr_test_predictions <- lr_fit %>% collect_predictions() %>% \n  rename(survived_pred = survived) %>% \n  bind_cols(train_test)\nlr_test_predictions\n\n\n# A tibble: 224 × 26\n   id       .pred_0 .pred_1  .row .pred…¹ survi…² .config passe…³ survi…⁴ pclass\n   <chr>      <dbl>   <dbl> <int> <fct>   <fct>   <chr>     <dbl> <fct>   <fct> \n 1 train/t…  0.0948 9.05e-1    10 1       1       Prepro…      10 1       2     \n 2 train/t…  1.00   2.63e-7    11 0       1       Prepro…      11 1       3     \n 3 train/t…  0.996  4.01e-3    14 0       0       Prepro…      14 0       3     \n 4 train/t…  0.749  2.51e-1    18 0       1       Prepro…      18 1       2     \n 5 train/t…  0.122  8.78e-1    20 1       1       Prepro…      20 1       3     \n 6 train/t…  0.309  6.91e-1    23 1       1       Prepro…      23 1       3     \n 7 train/t…  0.887  1.13e-1    28 0       0       Prepro…      28 0       1     \n 8 train/t…  0.473  5.27e-1    40 1       1       Prepro…      40 1       3     \n 9 train/t…  0.468  5.32e-1    41 1       0       Prepro…      41 0       3     \n10 train/t…  0.862  1.38e-1    51 0       0       Prepro…      51 0       3     \n# … with 214 more rows, 16 more variables: name <fct>, sex <fct>, age <dbl>,\n#   sib_sp <dbl>, parch <dbl>, ticket <fct>, fare <dbl>, cabin <fct>,\n#   embarked <fct>, train_test <fct>, pax_type <fct>, surname <fct>,\n#   cabin_preface <fct>, ticket_group <fct>, family_group <ord>,\n#   age_group <ord>, and abbreviated variable names ¹​.pred_class,\n#   ²​survived_pred, ³​passenger_id, ⁴​survived\n\n\n\n\nLR Performance on validation set\n\nAUC Curve\n\n\nCode\nlr_test_predictions %>% \n  roc_curve(truth = survived,.pred_1,event_level=\"second\") %>% \n  autoplot()\n\n\n\n\n\n\n\nConfusion Matrix\n\n\nCode\nlr_test_predictions %>% \n  conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")\n\n\n\n\n\n\n\n\nLR Resampling\n\n\nCode\nfolds <- vfold_cv(train_train, strata = survived, v=5)\n#folds\n\ncontrol <- control_resamples(save_pred = TRUE,save_workflow = TRUE)\n\ncores <- parallel::detectCores()\ncl <- parallel::makePSOCKcluster(cores - 1)\n\n# doParallel::registerDoParallel(cores = cores)\nset.seed(1234)\nlr_fit_cv <- \n  lr_wflow %>% \n  fit_resamples(folds, control = control)\n\n#show_best(lr_fit_cv,metric= \"accuracy\")\n\n#lr_fit_cv\nlr_metrics_resample <- collect_metrics(lr_fit_cv)\nlr_metrics_resample\n\n\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy binary     0.823     5 0.0124  Preprocessor1_Model1\n2 roc_auc  binary     0.856     5 0.00839 Preprocessor1_Model1\n\n\nCode\nparallel::stopCluster(cl)\n\n\nFollowing still to be fixed!\n\n\nCode\n#lr_param <- extract_parameter_set_dials(lr_spec)\n\nlr_resample_test_predictions <- collect_predictions(lr_fit_cv) %>% \n  rename(survived_pred = survived) \n#  bind_cols(testing(train_split))\nlr_resample_test_predictions\n\n\n# A tibble: 667 × 7\n   id    .pred_0 .pred_1  .row .pred_class survived_pred .config             \n   <chr>   <dbl>   <dbl> <int> <fct>       <fct>         <chr>               \n 1 Fold1   0.888 0.112       2 0           0             Preprocessor1_Model1\n 2 Fold1   0.756 0.244      10 0           0             Preprocessor1_Model1\n 3 Fold1   0.932 0.0677     15 0           0             Preprocessor1_Model1\n 4 Fold1   0.187 0.813      20 1           0             Preprocessor1_Model1\n 5 Fold1   0.919 0.0810     26 0           0             Preprocessor1_Model1\n 6 Fold1   0.978 0.0219     29 0           0             Preprocessor1_Model1\n 7 Fold1   0.974 0.0265     34 0           0             Preprocessor1_Model1\n 8 Fold1   0.993 0.00666    36 0           0             Preprocessor1_Model1\n 9 Fold1   0.921 0.0793     43 0           0             Preprocessor1_Model1\n10 Fold1   0.924 0.0763     44 0           0             Preprocessor1_Model1\n# … with 657 more rows\n\n\n\n\nCode\ncl <- parallel::makePSOCKcluster(cores - 1)\n\nset.seed(1234)\nlm_fit <- lr_wflow %>% fit(data = train_proc_adj_tbl)\nextract_recipe(lm_fit, estimated = TRUE)\n\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          5\n   outcome          1\n predictor         13\n\nTraining data contained 891 data points and 687 incomplete rows. \n\nOperations:\n\nK-nearest neighbor imputation for age, sib_sp, parch, fare [trained]\nDummy variables from pclass, sex, embarked, train_test, pax_type, cabin_prefac... [trained]\nCharacter variables from <none> [trained]\nZero variance filter removed train_test_test [trained]\nNo PCA components were extracted from <none> [trained]\n\n\nCode\nparallel::stopCluster(cl)"
  },
  {
    "objectID": "posts/post-with-code/index.html#regularised-logistic-regression---glmnet",
    "href": "posts/post-with-code/index.html#regularised-logistic-regression---glmnet",
    "title": "Titanic from Kaggle",
    "section": "0.6 Regularised Logistic Regression - GLMNET",
    "text": "0.6 Regularised Logistic Regression - GLMNET\n\n0.6.1 RLR Model Spec\n\n\nCode\nrlr_model <- \n  logistic_reg(penalty = tune(), mixture = tune()) %>% \n  set_engine(\"glmnet\")\nrlr_model\n\n\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = tune()\n\nComputational engine: glmnet \n\n\n\n\n0.6.2 RLR Parameter Tuning\n\n\nCode\nrlr_param <- extract_parameter_set_dials(rlr_model)\n\nrlr_grid <- grid_latin_hypercube(\n  penalty(),\n  mixture(),\n  size = 30\n)\nhead(rlr_grid) %>% knitr::kable(digits =3)\n\n\n\n\n\npenalty\nmixture\n\n\n\n\n0.116\n0.866\n\n\n0.095\n0.736\n\n\n0.000\n0.141\n\n\n0.000\n0.458\n\n\n0.025\n0.983\n\n\n0.484\n0.109\n\n\n\n\n\n\n\n0.6.3 RLR Workflow\n\n\nCode\nrlr_wflow <- \n  workflow() %>% \n  add_model(rlr_model) %>% \n  add_recipe(recipe_base)\nrlr_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = tune()\n\nComputational engine: glmnet \n\n\n\n\n0.6.4 RLR Hyper-parameter Tuning\n\n\nCode\n# rlr_folds <- vfold_cv(training(train_split), strata = survived, v=10,repeats = 5)\n# rlr_folds %>% tidy()\n\n#doParallel::registerDoParallel(cores = cores)\ncl <- parallel::makePSOCKcluster(cores - 1)\n\nset.seed(234)\nrlr_tuning_result <- tune_grid(\n  rlr_wflow,\n  resamples = folds,\n  grid      = rlr_grid,\n  control   = control_grid(save_pred = TRUE, save_workflow = TRUE)\n)\n\nrlr_tuning_metrics <- collect_metrics(rlr_tuning_result)\nhead(rlr_tuning_metrics) %>% knitr::kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npenalty\nmixture\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n0.016\n0.018\naccuracy\nbinary\n0.821\n5\n0.016\nPreprocessor1_Model01\n\n\n0.016\n0.018\nroc_auc\nbinary\n0.865\n5\n0.009\nPreprocessor1_Model01\n\n\n0.000\n0.066\naccuracy\nbinary\n0.825\n5\n0.015\nPreprocessor1_Model02\n\n\n0.000\n0.066\nroc_auc\nbinary\n0.857\n5\n0.008\nPreprocessor1_Model02\n\n\n0.000\n0.070\naccuracy\nbinary\n0.825\n5\n0.015\nPreprocessor1_Model03\n\n\n0.000\n0.070\nroc_auc\nbinary\n0.857\n5\n0.008\nPreprocessor1_Model03\n\n\n\n\n\nCode\nparallel::stopCluster(cl)\n\n\nReview hyper-parameter tuning results and select best\n\n\nCode\nrlr_tuning_result %>%\n  collect_metrics() %>%\n  filter(.metric == \"accuracy\") %>%\n  select(mean, penalty,mixture) %>%\n  pivot_longer(penalty:mixture,\n               values_to = \"value\",\n               names_to = \"parameter\"\n  ) %>%\n  ggplot(aes(value, mean, color = parameter)) +\n  geom_point(alpha = 0.8, show.legend = FALSE) +\n  facet_wrap(~parameter, scales = \"free_x\") +\n  labs(x = NULL, y = \"AUC\")\n\n\n\n\n\nCode\nshow_best(rlr_tuning_result, \"accuracy\")\n\n\n# A tibble: 5 × 8\n   penalty mixture .metric  .estimator  mean     n std_err .config              \n     <dbl>   <dbl> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n1 8.86e- 3   0.923 accuracy binary     0.829     5  0.0169 Preprocessor1_Model28\n2 1.36e- 9   0.141 accuracy binary     0.826     5  0.0137 Preprocessor1_Model05\n3 1.30e-10   0.182 accuracy binary     0.826     5  0.0137 Preprocessor1_Model06\n4 5.43e- 9   0.211 accuracy binary     0.826     5  0.0137 Preprocessor1_Model07\n5 2.52e- 8   0.241 accuracy binary     0.826     5  0.0137 Preprocessor1_Model08\n\n\nCode\nbest_rlr_auc <- select_best(rlr_tuning_result, \"accuracy\")\nbest_rlr_auc\n\n\n# A tibble: 1 × 3\n  penalty mixture .config              \n    <dbl>   <dbl> <chr>                \n1 0.00886   0.923 Preprocessor1_Model28\n\n\n\n\n0.6.5 RLR Predict\n\n\nCode\nrlr_final_wflow <- finalize_workflow(\n  rlr_wflow,\n  best_rlr_auc\n)\n\nrlr_final_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = 0.00885574773491923\n  mixture = 0.923322001239285\n\nComputational engine: glmnet \n\n\nCode\nrlr_final_wflow %>%\n  last_fit(train_split) %>%\n  extract_fit_parsnip() %>%\n  vip(geom = \"col\")\n\n\n\n\n\n\n\nCode\nrlr_final_fit <- rlr_final_wflow %>%\n  last_fit(train_split)\n\nrlr_final_metrics <- collect_metrics(rlr_final_fit)\nrlr_final_metrics %>% knitr::kable()\n\n\n\n\n\n.metric\n.estimator\n.estimate\n.config\n\n\n\n\naccuracy\nbinary\n0.8080357\nPreprocessor1_Model1\n\n\nroc_auc\nbinary\n0.8424756\nPreprocessor1_Model1\n\n\n\n\n\nCode\nrlr_test_predictions <- rlr_final_fit %>% collect_predictions()\nrlr_test_predictions_all <- rlr_test_predictions %>% \n  bind_cols(train_test %>% select(-survived)) \n\n\n\nglimpse(rlr_test_predictions_all)\n\n\nRows: 224\nColumns: 25\n$ id            <chr> \"train/test split\", \"train/test split\", \"train/test spli…\n$ .pred_0       <dbl> 0.1216896, 0.8658490, 0.9641622, 0.7243443, 0.2225635, 0…\n$ .pred_1       <dbl> 0.87831041, 0.13415097, 0.03583775, 0.27565575, 0.777436…\n$ .row          <int> 10, 11, 14, 18, 20, 23, 28, 40, 41, 51, 54, 57, 61, 66, …\n$ .pred_class   <fct> 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0,…\n$ survived      <fct> 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1,…\n$ .config       <chr> \"Preprocessor1_Model1\", \"Preprocessor1_Model1\", \"Preproc…\n$ passenger_id  <dbl> 10, 11, 14, 18, 20, 23, 28, 40, 41, 51, 54, 57, 61, 66, …\n$ pclass        <fct> 2, 3, 3, 2, 3, 3, 1, 3, 3, 3, 2, 2, 3, 3, 2, 3, 3, 2, 3,…\n$ name          <fct> \"Nasser, Mrs. Nicholas (Adele Achem)\", \"Sandstrom, Miss.…\n$ sex           <fct> female, female, male, male, female, female, male, female…\n$ age           <dbl> 14, 4, 39, 30, 31, 15, 19, 14, 40, 7, 29, 21, 22, 6, 21,…\n$ sib_sp        <dbl> 1, 1, 1, 0, 0, 0, 3, 1, 1, 4, 1, 0, 0, 1, 0, 0, 0, 0, 3,…\n$ parch         <dbl> 0, 1, 5, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,…\n$ ticket        <fct> 237736, PP 9549, 347082, 244373, 2649, 330923, 19950, 26…\n$ fare          <dbl> 30.0708, 16.7000, 31.2750, 13.0000, 7.2250, 8.0292, 263.…\n$ cabin         <fct> NA, G6, NA, NA, NA, NA, C23 C25 C27, NA, NA, NA, NA, NA,…\n$ embarked      <fct> C, S, S, S, C, Q, S, C, S, S, S, S, C, C, S, S, Q, S, S,…\n$ train_test    <fct> train, train, train, train, train, train, train, train, …\n$ pax_type      <fct> F_married, F_unmarried, Mr., Mr., F_married, F_unmarried…\n$ surname       <fct> \"Nasser,\", \"Sandstrom,\", \"Andersson,\", \"Williams,\", \"Mas…\n$ cabin_preface <fct> nk, G, nk, nk, nk, nk, C, nk, nk, nk, nk, nk, nk, nk, nk…\n$ ticket_group  <fct> couple, group, group, single, single, single, group, cou…\n$ family_group  <ord> couple, family, family, single, single, single, family, …\n$ age_group     <ord> teen, child, 30s, 30s, 30s, teen, teen, teen, 40s, child…\n\n\nCode\n# rlr_pred <- predict(rlr_final_fit,train_2 )%>% \n#   bind_cols(predict(rlr_final_fit, train_2,type=\"prob\")) %>% \n#   bind_cols(train_2 %>% select(survived))\n# \n# rlr_pred %>% \n#   roc_auc(truth = survived, .pred_1, event_level = \"second\")\n# \n# rlr_pred %>% \n#   roc_curve(truth = survived, .pred_1,event_level=\"second\") %>% \n#   autoplot()\n# \n# \n# rlr_metrics <- rlr_pred %>% \n# metrics(truth = survived, estimate = .pred_class) %>% \n#   filter(.metric == \"accuracy\")\n# rlr_metrics\n# survive_rlr_pred <- \n#   augment(survive_lr_fit, train_2)\n# survive_rlr_pred\n\n\n\n\n0.6.6 RLR Confusion Matrix\n\n\nCode\nrlr_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#random-forest",
    "href": "posts/post-with-code/index.html#random-forest",
    "title": "Titanic from Kaggle",
    "section": "0.7 Random Forest",
    "text": "0.7 Random Forest\n\n0.7.1 RF Model Spec - Ranger\n\n\nCode\nrf_model <- \n  rand_forest(\n    trees = 1000,\n    mtry  = tune(),\n    min_n = tune()\n    ) %>% \n  set_engine(\"ranger\",importance = \"permutation\") %>% \n  set_mode(\"classification\")\n\n\n\n\n0.7.2 RF Workflow\n\n\nCode\nrf_wflow <- \n  workflow() %>% \n  add_model(rf_model) %>% \n  add_recipe(recipe_base)\n\n\n\n\n0.7.3 RF Tuning - Initial\n\n\nCode\ncl <- parallel::makePSOCKcluster(cores - 1)\n\nset.seed(1234)\nrf_tuning_result <- tune_grid(\n  rf_wflow,\n  resamples = folds,\n  grid = 20\n)\nparallel::stopCluster(cl)\n\nrf_tuning_result\n\n\n# Tuning results\n# 5-fold cross-validation using stratification \n# A tibble: 5 × 4\n  splits            id    .metrics          .notes          \n  <list>            <chr> <list>            <list>          \n1 <split [532/135]> Fold1 <tibble [40 × 6]> <tibble [0 × 3]>\n2 <split [534/133]> Fold2 <tibble [40 × 6]> <tibble [0 × 3]>\n3 <split [534/133]> Fold3 <tibble [40 × 6]> <tibble [0 × 3]>\n4 <split [534/133]> Fold4 <tibble [40 × 6]> <tibble [0 × 3]>\n5 <split [534/133]> Fold5 <tibble [40 × 6]> <tibble [0 × 3]>\n\n\nCode\nrf_tuning_result %>% \n  collect_metrics() %>% \n  filter(.metric == \"accuracy\") %>% \n  select(mean,min_n,mtry) %>% \n  pivot_longer(min_n:mtry) %>% \n  ggplot(aes(value, mean, color = name)) +\n  geom_point(show.legend = FALSE) +\n  facet_wrap(~name, scales = \"free_x\") +\n  labs(x = NULL, y = \"Accuracy\")\n\n\n\n\n\nBit hard to make much of it, but say min_n between 10 and 40 and mtry between 10 and 30?\n\n\nCode\nrf_grid <- grid_regular(\n  mtry(range = c(5, 40)),\n  min_n(range = c(5, 30)),\n  levels = 5\n)\n\nrf_grid\n\n\n# A tibble: 25 × 2\n    mtry min_n\n   <int> <int>\n 1     5     5\n 2    13     5\n 3    22     5\n 4    31     5\n 5    40     5\n 6     5    11\n 7    13    11\n 8    22    11\n 9    31    11\n10    40    11\n# … with 15 more rows\n\n\n\n\n0.7.4 RF Graph Results\n\n\nCode\ncl <- parallel::makePSOCKcluster(cores - 1)\n\n\nset.seed(1234)\nrf_grid_tune <- tune_grid(\n  rf_wflow,\n  resamples = folds,\n  grid = rf_grid\n)\nrf_grid_tune\n\n\n# Tuning results\n# 5-fold cross-validation using stratification \n# A tibble: 5 × 4\n  splits            id    .metrics          .notes          \n  <list>            <chr> <list>            <list>          \n1 <split [532/135]> Fold1 <tibble [50 × 6]> <tibble [5 × 3]>\n2 <split [534/133]> Fold2 <tibble [50 × 6]> <tibble [5 × 3]>\n3 <split [534/133]> Fold3 <tibble [50 × 6]> <tibble [5 × 3]>\n4 <split [534/133]> Fold4 <tibble [50 × 6]> <tibble [5 × 3]>\n5 <split [534/133]> Fold5 <tibble [50 × 6]> <tibble [5 × 3]>\n\nThere were issues with some computations:\n\n  - Warning(s) x10: 40 columns were requested but there were 33 predictors in the dat...   - Warning(s) x15: 40 columns were requested but there were 33 predictors in the dat...\n\nRun `show_notes(.Last.tune.result)` for more information.\n\n\nCode\nparallel::stopCluster(cl)\n\nrf_grid_tune %>%\n  collect_metrics() %>%\n  filter(.metric == \"accuracy\") %>%\n  mutate(min_n = factor(min_n)) %>%\n  ggplot(aes(mtry, mean, color = min_n)) +\n  geom_line(alpha = 0.5, size = 1.5) +\n  geom_point() +\n  labs(y = \"Accuracy\")\n\n\n\n\n\nWell that’s interesting, lets see what tune thinks is best\n\n\nCode\nrf_best_params <- select_best(rf_grid_tune,\"accuracy\")\nrf_best_params %>% knitr::kable()\n\n\n\n\n\nmtry\nmin_n\n.config\n\n\n\n\n31\n17\nPreprocessor1_Model14\n\n\n\n\n\n\n\n0.7.5 RF Final Model\n\n\nCode\nrf_final_model <- finalize_model(\n  rf_model,\n  rf_best_params\n)\nrf_final_model\n\n\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = 31\n  trees = 1000\n  min_n = 17\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger \n\n\n\n\n0.7.6 RF Final Workflow\n\n\nCode\nrf_final_wflow <- finalize_workflow(\n  rf_wflow,\n  rf_best_params\n)\n\nrf_final_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = 31\n  trees = 1000\n  min_n = 17\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger \n\n\n\n\n0.7.7 RF Parameter Importance\n\n\nCode\nrf_final_wflow %>%\n  fit(data = train_proc_adj_tbl) %>%\n  extract_fit_parsnip() %>%\n  vip(geom = \"point\")\n\n\n\n\n\n\n\n0.7.8 RF Final Fit\n\n\nCode\nrf_final_fit <- \n  rf_final_wflow %>% \n  last_fit(train_split)\n\nrf_final_metrics <- collect_metrics(rf_final_fit)\nrf_final_metrics\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.821 Preprocessor1_Model1\n2 roc_auc  binary         0.874 Preprocessor1_Model1\n\n\n\n\n0.7.9 RF Predict\n\n\nCode\n# rf_final_fit <- rf_wflow %>% fit(train_test)\n# class(rf_final_fit)\n\n rf_test_predictions <- \n   collect_predictions(rf_final_fit)\n   # fit(rf_final_wflow,train_train) %>% \n   # predict(rf_final_wflow, new_data = train_test) %>% \n   #bind_cols(predict(rf_final_wflow, train_test,type = \"prob\")) %>% \n   #bind_cols(train_test %>% select(survived))\n\n \n head(rf_test_predictions)\n\n\n# A tibble: 6 × 7\n  id               .pred_0 .pred_1  .row .pred_class survived .config           \n  <chr>              <dbl>   <dbl> <int> <fct>       <fct>    <chr>             \n1 train/test split  0.0101   0.990    10 1           1        Preprocessor1_Mod…\n2 train/test split  0.386    0.614    11 1           1        Preprocessor1_Mod…\n3 train/test split  0.703    0.297    14 0           0        Preprocessor1_Mod…\n4 train/test split  0.884    0.116    18 0           1        Preprocessor1_Mod…\n5 train/test split  0.370    0.630    20 1           1        Preprocessor1_Mod…\n6 train/test split  0.598    0.402    23 0           1        Preprocessor1_Mod…\n\n\n\n\n0.7.10 RF Performance on Test Set\n\n\nCode\n# rf_test_predictions %>% \n#   roc_auc(truth = survived, .pred_1,event_level = \"second\")\n\nrf_metrics_accuracy <- rf_test_predictions %>% \n  metrics(truth = survived, estimate = .pred_class) %>% \n  filter(.metric == \"accuracy\")\nrf_metrics_accuracy\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.821\n\n\nCode\nrf_test_predictions %>% \n  roc_curve(truth = survived, .pred_1,event_level = \"second\") %>% \n  autoplot()\n\n\n\n\n\n\n\n0.7.11 RF Confusion Matrix\n\n\nCode\nrf_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#xg-boost---usemodel",
    "href": "posts/post-with-code/index.html#xg-boost---usemodel",
    "title": "Titanic from Kaggle",
    "section": "0.8 XG Boost - Usemodel",
    "text": "0.8 XG Boost - Usemodel\n\n0.8.1 XGB - Usemodel Library specs\n\n\nCode\nlibrary(usemodels)\n\nuse_xgboost(survived ~ .,\n            data=train_train,\n            verbose = TRUE\n  \n)\n\n\nxgboost_recipe <- \n  recipe(formula = survived ~ ., data = train_train) %>% \n  step_novel(all_nominal_predictors()) %>% \n  ## This model requires the predictors to be numeric. The most common \n  ## method to convert qualitative predictors to numeric is to create \n  ## binary indicator variables (aka dummy variables) from these \n  ## predictors. However, for this model, binary indicator variables can be \n  ## made for each of the levels of the factors (known as 'one-hot \n  ## encoding'). \n  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>% \n  step_zv(all_predictors()) \n\nxgboost_spec <- \n  boost_tree(trees = tune(), min_n = tune(), tree_depth = tune(), learn_rate = tune(), \n    loss_reduction = tune(), sample_size = tune()) %>% \n  set_mode(\"classification\") %>% \n  set_engine(\"xgboost\") \n\nxgboost_workflow <- \n  workflow() %>% \n  add_recipe(xgboost_recipe) %>% \n  add_model(xgboost_spec) \n\nset.seed(19336)\nxgboost_tune <-\n  tune_grid(xgboost_workflow, resamples = stop(\"add your rsample object\"), grid = stop(\"add number of candidate points\"))\n\n\n\n\n0.8.2 XGB - Parameters\nThis grid is used for both versions of XG Boost.\n\n\nCode\nxgb_grid <- grid_latin_hypercube(\n  tree_depth(),\n  min_n(),\n  trees(),\n  loss_reduction(),\n  sample_size = sample_prop(),\n  finalize(mtry(), train_train),\n  learn_rate(),\n  size = 30\n)\n\nhead(xgb_grid)\n\n\n# A tibble: 6 × 7\n  tree_depth min_n trees loss_reduction sample_size  mtry    learn_rate\n       <int> <int> <int>          <dbl>       <dbl> <int>         <dbl>\n1         14    30  1603   0.0230             0.806    13 0.00985      \n2         11     9    22   0.0000361          0.983     3 0.0000469    \n3          1    17   848   0.00581            0.539    11 0.00559      \n4         10     8  1097   0.00000104         0.652     8 0.00000000128\n5         11    19  1422   1.00               0.283     6 0.00124      \n6         15    32  1007   0.0000000318       0.919    15 0.00000608   \n\n\n\n\nCode\nxgboost_usemodel_recipe <- \n  recipe(formula = survived ~ ., data = train_train) %>% \n  step_novel(all_nominal_predictors()) %>% \n  ## This model requires the predictors to be numeric. The most common \n  ## method to convert qualitative predictors to numeric is to create \n  ## binary indicator variables (aka dummy variables) from these \n  ## predictors. However, for this model, binary indicator variables can be \n  ## made for each of the levels of the factors (known as 'one-hot \n  ## encoding'). \n  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>% \n  step_zv(all_predictors()) \n\nxgboost_usemodel_model <- \n  boost_tree(trees = tune(), mtry = tune(),min_n = tune(), tree_depth = tune(), learn_rate = tune(), \n    loss_reduction = tune(), sample_size = tune()) %>% \n  set_mode(\"classification\") %>% \n  set_engine(\"xgboost\") \n\nxgboost_usemodel_wflow <- \n  workflow() %>% \n  add_recipe(xgboost_usemodel_recipe) %>% \n  add_model(xgboost_usemodel_model) \n\n#doParallel::registerDoParallel(cores = cores)\ncl <- parallel::makePSOCKcluster(cores - 1)\n\nset.seed(1234)\nxgboost_usemodel_tune <-\n  tune_grid(xgboost_usemodel_wflow, resamples = folds, grid = xgb_grid)\n\nparallel::stopCluster(cl)\n\n\n\n\n0.8.3 XGB - Usemodel Best Parameter Settings\n\n\nCode\nxgb_tuning_metrics_usemodel <- collect_metrics(xgboost_usemodel_tune)\nxgb_tuning_metrics_usemodel\n\n\n# A tibble: 60 × 13\n    mtry trees min_n tree_depth learn_r…¹ loss_r…² sampl…³ .metric .esti…⁴  mean\n   <int> <int> <int>      <int>     <dbl>    <dbl>   <dbl> <chr>   <chr>   <dbl>\n 1    11   848    17          1   5.59e-3 5.81e- 3   0.539 accura… binary  0.708\n 2    11   848    17          1   5.59e-3 5.81e- 3   0.539 roc_auc binary  0.823\n 3     9  1145    10          2   5.20e-8 1.60e- 1   0.866 accura… binary  0.702\n 4     9  1145    10          2   5.20e-8 1.60e- 1   0.866 roc_auc binary  0.821\n 5    17   740    15          2   8.39e-2 6.64e- 9   0.252 accura… binary  0.743\n 6    17   740    15          2   8.39e-2 6.64e- 9   0.252 roc_auc binary  0.776\n 7    12   690    38          2   3.89e-9 5.16e-10   0.146 accura… binary  0.616\n 8    12   690    38          2   3.89e-9 5.16e-10   0.146 roc_auc binary  0.5  \n 9    10  1314    11          3   1.72e-5 1.25e- 1   0.163 accura… binary  0.616\n10    10  1314    11          3   1.72e-5 1.25e- 1   0.163 roc_auc binary  0.757\n# … with 50 more rows, 3 more variables: n <int>, std_err <dbl>, .config <chr>,\n#   and abbreviated variable names ¹​learn_rate, ²​loss_reduction, ³​sample_size,\n#   ⁴​.estimator\n\n\nCode\nxgboost_usemodel_tune %>%\n  collect_metrics() %>%\n  filter(.metric == \"accuracy\") %>%\n  select(mean, mtry:sample_size) %>%\n  pivot_longer(mtry:sample_size,\n               values_to = \"value\",\n               names_to = \"parameter\"\n  ) %>%\n  ggplot(aes(value, mean, color = parameter)) +\n  geom_point(alpha = 0.8, show.legend = FALSE) +\n  facet_wrap(~parameter, scales = \"free_x\") +\n  labs(x = NULL, y = \"Accuracy\")\n\n\n\n\n\nNow select best from above\n\n\nCode\nshow_best(xgboost_usemodel_tune, \"accuracy\")\n\n\n# A tibble: 5 × 13\n   mtry trees min_n tree_d…¹ learn…² loss_…³ sampl…⁴ .metric .esti…⁵  mean     n\n  <int> <int> <int>    <int>   <dbl>   <dbl>   <dbl> <chr>   <chr>   <dbl> <int>\n1    13  1603    30       14 9.85e-3 2.30e-2   0.806 accura… binary  0.766     5\n2     4  1982     4       15 4.01e-2 5.53e-8   0.393 accura… binary  0.754     5\n3    17   740    15        2 8.39e-2 6.64e-9   0.252 accura… binary  0.743     5\n4    11   848    17        1 5.59e-3 5.81e-3   0.539 accura… binary  0.708     5\n5     9  1145    10        2 5.20e-8 1.60e-1   0.866 accura… binary  0.702     5\n# … with 2 more variables: std_err <dbl>, .config <chr>, and abbreviated\n#   variable names ¹​tree_depth, ²​learn_rate, ³​loss_reduction, ⁴​sample_size,\n#   ⁵​.estimator\n\n\nCode\nxgb_usemodel_best_params <- select_best(xgboost_usemodel_tune, \"accuracy\")\nxgb_usemodel_best_params\n\n\n# A tibble: 1 × 8\n   mtry trees min_n tree_depth learn_rate loss_reduction sample_size .config    \n  <int> <int> <int>      <int>      <dbl>          <dbl>       <dbl> <chr>      \n1    13  1603    30         14    0.00985         0.0230       0.806 Preprocess…\n\n\nCode\nxgb_usemodel_final_wflow <- finalize_workflow(\n  xgboost_usemodel_wflow,\n  xgb_usemodel_best_params\n)\n\nxgb_usemodel_final_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: boost_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_novel()\n• step_dummy()\n• step_zv()\n\n── Model ───────────────────────────────────────────────────────────────────────\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = 13\n  trees = 1603\n  min_n = 30\n  tree_depth = 14\n  learn_rate = 0.00985014124434902\n  loss_reduction = 0.0230337047700143\n  sample_size = 0.80635308077326\n\nComputational engine: xgboost \n\n\n\n\n0.8.4 XGB - Usemodel Parameter Ranking - VIP\n\n\nCode\nxgb_usemodel_final_wflow %>%\n  fit(data = train_train) %>%\n  extract_fit_parsnip() %>%\n  vip(geom = \"point\")\n\n\n\n\n\n\n\n0.8.5 XGB - Usemodel Performance\n\nXGB - Usemodel Accuracy Measured on Test Set\n\n\nCode\ncl <- parallel::makePSOCKcluster(cores - 1)\n\nset.seed(1234)\nxgb_usemodel_final_res <- last_fit(xgb_usemodel_final_wflow, train_split)\nxgb_usemodel_final_res\n\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits            id               .metrics .notes   .predictions .workflow \n  <list>            <chr>            <list>   <list>   <list>       <list>    \n1 <split [667/224]> train/test split <tibble> <tibble> <tibble>     <workflow>\n\nThere were issues with some computations:\n\n  - Warning(s) x2: There are new levels in a factor: NA\n\nRun `show_notes(.Last.tune.result)` for more information.\n\n\nCode\nxgb_usemodel_final_metrics <- collect_metrics(xgb_usemodel_final_res)\nxgb_usemodel_final_metrics\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.670 Preprocessor1_Model1\n2 roc_auc  binary         0.797 Preprocessor1_Model1\n\n\nCode\nparallel::stopCluster(cl)\n\n\n\n\nXGB - Usemodel AUC on Test Set (within train)\n\n\nCode\nxgb_usemodel_final_res %>%\n  collect_predictions() %>%\n  roc_curve( truth = survived,.pred_1, event_level = \"second\") %>%\n  ggplot(aes(x = 1-specificity, y = sensitivity)) +\n  geom_line(size = 1.5, color = \"midnightblue\") +\n  geom_abline(\n    lty = 2, alpha = 0.5,\n    color = \"gray50\",\n    size = 1.2\n  )\n\n\n\n\n\n\n\nCode\nxgb_usemodel_test_predictions <- collect_predictions(xgb_usemodel_final_res)\nhead(xgb_usemodel_test_predictions)\n\n\n# A tibble: 6 × 7\n  id               .pred_0 .pred_1  .row .pred_class survived .config           \n  <chr>              <dbl>   <dbl> <int> <fct>       <fct>    <chr>             \n1 train/test split   0.534   0.466    10 0           1        Preprocessor1_Mod…\n2 train/test split   0.291   0.709    11 1           1        Preprocessor1_Mod…\n3 train/test split   0.733   0.267    14 0           0        Preprocessor1_Mod…\n4 train/test split   0.736   0.264    18 0           1        Preprocessor1_Mod…\n5 train/test split   0.640   0.360    20 0           1        Preprocessor1_Mod…\n6 train/test split   0.625   0.375    23 0           1        Preprocessor1_Mod…\n\n\n\n\n\n0.8.6 XGB - Usemodel Confusion Matrix\n\n\nCode\nxgb_usemodel_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#xg-boost---base-recipe",
    "href": "posts/post-with-code/index.html#xg-boost---base-recipe",
    "title": "Titanic from Kaggle",
    "section": "0.9 XG Boost - Base Recipe",
    "text": "0.9 XG Boost - Base Recipe\n\n0.9.1 XGB Model Spec\n\n\nCode\nxgb_model <- \n  boost_tree(\n    trees = tune(),\n    tree_depth = tune(),\n    min_n = tune(),\n    loss_reduction = tune(),\n    sample_size = tune(),\n    mtry = tune(),\n    learn_rate = tune()) %>% \n  set_engine(\"xgboost\") %>% \n  set_mode(\"classification\")\n\nxgb_model\n\n\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = tune()\n  min_n = tune()\n  tree_depth = tune()\n  learn_rate = tune()\n  loss_reduction = tune()\n  sample_size = tune()\n\nComputational engine: xgboost \n\n\n\n\n0.9.2 XGB Workflow\n\n\nCode\nxgb_wflow <- \n  workflow() %>% \n  add_model(xgb_model) %>% \n  add_recipe(recipe_base)\n\n\n\n\n0.9.3 XGB Hyper-Parameter Tuning\n\n\nCode\n# xgb_folds <- vfold_cv(training(train_split), strata = survived)\n# xgb_folds\n\n\n#doParallel::registerDoParallel(cores = cores)\n\nset.seed(1234)\ncl <- parallel::makePSOCKcluster(cores - 1)\n\nxgb_tuning_result <- tune_grid(\n  xgb_wflow,\n  resamples = folds,\n  grid      = xgb_grid,\n  control  = control_grid(save_pred = TRUE,save_workflow = TRUE)\n)\nxgb_tuning_result\n\n\n# Tuning results\n# 5-fold cross-validation using stratification \n# A tibble: 5 × 5\n  splits            id    .metrics           .notes           .predictions\n  <list>            <chr> <list>             <list>           <list>      \n1 <split [532/135]> Fold1 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n2 <split [534/133]> Fold2 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n3 <split [534/133]> Fold3 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n4 <split [534/133]> Fold4 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n5 <split [534/133]> Fold5 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n\n\nCode\nparallel::stopCluster(cl)\n\n\n\n\nCode\nxgb_tuning_metrics <- collect_metrics(xgb_tuning_result)\nxgb_tuning_metrics\n\n\n# A tibble: 60 × 13\n    mtry trees min_n tree_depth learn_r…¹ loss_r…² sampl…³ .metric .esti…⁴  mean\n   <int> <int> <int>      <int>     <dbl>    <dbl>   <dbl> <chr>   <chr>   <dbl>\n 1    11   848    17          1   5.59e-3 5.81e- 3   0.539 accura… binary  0.775\n 2    11   848    17          1   5.59e-3 5.81e- 3   0.539 roc_auc binary  0.844\n 3     9  1145    10          2   5.20e-8 1.60e- 1   0.866 accura… binary  0.775\n 4     9  1145    10          2   5.20e-8 1.60e- 1   0.866 roc_auc binary  0.842\n 5    17   740    15          2   8.39e-2 6.64e- 9   0.252 accura… binary  0.718\n 6    17   740    15          2   8.39e-2 6.64e- 9   0.252 roc_auc binary  0.753\n 7    12   690    38          2   3.89e-9 5.16e-10   0.146 accura… binary  0.616\n 8    12   690    38          2   3.89e-9 5.16e-10   0.146 roc_auc binary  0.5  \n 9    10  1314    11          3   1.72e-5 1.25e- 1   0.163 accura… binary  0.616\n10    10  1314    11          3   1.72e-5 1.25e- 1   0.163 roc_auc binary  0.721\n# … with 50 more rows, 3 more variables: n <int>, std_err <dbl>, .config <chr>,\n#   and abbreviated variable names ¹​learn_rate, ²​loss_reduction, ³​sample_size,\n#   ⁴​.estimator\n\n\nCode\nxgb_tuning_result %>%\n  collect_metrics() %>%\n  filter(.metric == \"accuracy\") %>%\n  select(mean, mtry:sample_size) %>%\n  pivot_longer(mtry:sample_size,\n               values_to = \"value\",\n               names_to = \"parameter\"\n  ) %>%\n  ggplot(aes(value, mean, color = parameter)) +\n  geom_point(alpha = 0.8, show.legend = FALSE) +\n  facet_wrap(~parameter, scales = \"free_x\") +\n  labs(x = NULL, y = \"AUC\")\n\n\n\n\n\n\nXGB Best Parameters then Finalise Workflow\n\n\nCode\nshow_best(xgb_tuning_result, \"accuracy\")\n\n\n# A tibble: 5 × 13\n   mtry trees min_n tree_d…¹ learn…² loss_…³ sampl…⁴ .metric .esti…⁵  mean     n\n  <int> <int> <int>    <int>   <dbl>   <dbl>   <dbl> <chr>   <chr>   <dbl> <int>\n1     4  1982     4       15 4.01e-2 5.53e-8   0.393 accura… binary  0.814     5\n2    15  1689     7       13 2.02e-9 5.67e-6   0.958 accura… binary  0.784     5\n3    16  1549     6        7 1.36e-4 4.92e-4   0.463 accura… binary  0.783     5\n4    19   259    16        9 6.05e-7 1.64e-4   0.735 accura… binary  0.781     5\n5    13  1603    30       14 9.85e-3 2.30e-2   0.806 accura… binary  0.780     5\n# … with 2 more variables: std_err <dbl>, .config <chr>, and abbreviated\n#   variable names ¹​tree_depth, ²​learn_rate, ³​loss_reduction, ⁴​sample_size,\n#   ⁵​.estimator\n\n\nCode\nxgb_best_params <- select_best(xgb_tuning_result, \"accuracy\")\nxgb_best_params\n\n\n# A tibble: 1 × 8\n   mtry trees min_n tree_depth learn_rate loss_reduction sample_size .config    \n  <int> <int> <int>      <int>      <dbl>          <dbl>       <dbl> <chr>      \n1     4  1982     4         15     0.0401   0.0000000553       0.393 Preprocess…\n\n\nCode\nxgb_final_wflow <- finalize_workflow(\n  xgb_wflow,\n  xgb_best_params\n)\n\nxgb_final_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: boost_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = 4\n  trees = 1982\n  min_n = 4\n  tree_depth = 15\n  learn_rate = 0.0400670375292599\n  loss_reduction = 5.52655767061452e-08\n  sample_size = 0.392634701682255\n\nComputational engine: xgboost \n\n\n\n\nCode\nxgb_final_wflow %>%\n  fit(data = train_train) %>%\n  extract_fit_parsnip() %>%\n  vip(geom = \"point\")\n\n\n\n\n\n\n\n\n0.9.4 XGB Performance on Training Test Set\n\nXGB Accuracy Measured on Test Set\n\n\nCode\nxgb_final_res <- last_fit(xgb_final_wflow, train_split)\nxgb_final_res\n\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits            id               .metrics .notes   .predictions .workflow \n  <list>            <chr>            <list>   <list>   <list>       <list>    \n1 <split [667/224]> train/test split <tibble> <tibble> <tibble>     <workflow>\n\n\nCode\nxgb_final_metrics <- collect_metrics(xgb_final_res)\nxgb_final_metrics\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.839 Preprocessor1_Model1\n2 roc_auc  binary         0.870 Preprocessor1_Model1\n\n\n\n\nXGB AUC on Test Set (within train)\n\n\nCode\nxgb_final_res %>%\n  collect_predictions() %>%\n  roc_curve( truth = survived,.pred_1, event_level = \"second\") %>%\n  ggplot(aes(x = 1-specificity, y = sensitivity)) +\n  geom_line(size = 1.5, color = \"midnightblue\") +\n  geom_abline(\n    lty = 2, alpha = 0.5,\n    color = \"gray50\",\n    size = 1.2\n  )\n\n\n\n\n\n\n\nCode\nxgb_test_predictions <- collect_predictions(xgb_final_res)\nhead(xgb_test_predictions)\n\n\n# A tibble: 6 × 7\n  id               .pred_0 .pred_1  .row .pred_class survived .config           \n  <chr>              <dbl>   <dbl> <int> <fct>       <fct>    <chr>             \n1 train/test split  0.0609  0.939     10 1           1        Preprocessor1_Mod…\n2 train/test split  0.346   0.654     11 1           1        Preprocessor1_Mod…\n3 train/test split  0.968   0.0321    14 0           0        Preprocessor1_Mod…\n4 train/test split  0.845   0.155     18 0           1        Preprocessor1_Mod…\n5 train/test split  0.385   0.615     20 1           1        Preprocessor1_Mod…\n6 train/test split  0.319   0.681     23 1           1        Preprocessor1_Mod…\n\n\n\n\n\n0.9.5 XGB Confusion Matrix\n\n\nCode\nxgb_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#neural-net",
    "href": "posts/post-with-code/index.html#neural-net",
    "title": "Titanic from Kaggle",
    "section": "0.10 Neural Net",
    "text": "0.10 Neural Net\n\n0.10.1 NN Model\n\n\nCode\nnnet_model <- \n   mlp(hidden_units = tune(), penalty = tune(), epochs = tune()) %>% \n   set_engine(\"nnet\", MaxNWts = 2600) %>% \n   set_mode(\"classification\")\n\nnnet_model %>% translate()\n\n\nSingle Layer Neural Network Model Specification (classification)\n\nMain Arguments:\n  hidden_units = tune()\n  penalty = tune()\n  epochs = tune()\n\nEngine-Specific Arguments:\n  MaxNWts = 2600\n\nComputational engine: nnet \n\nModel fit template:\nnnet::nnet(formula = missing_arg(), data = missing_arg(), size = tune(), \n    decay = tune(), maxit = tune(), MaxNWts = 2600, trace = FALSE, \n    linout = FALSE)\n\n\n\n\n0.10.2 NN Workflow\n\n\nCode\nnnet_wflow <- workflow() %>% \n  add_model(nnet_model) %>% \n  add_recipe(recipe_base)\n\n\n\n\n0.10.3 NN Parameters\n\n\nCode\nnnet_grid <- grid_latin_hypercube(\n  hidden_units(),\n  penalty (),\n  epochs ()\n)\n\nhead(nnet_grid) \n\n\n# A tibble: 3 × 3\n  hidden_units  penalty epochs\n         <int>    <dbl>  <int>\n1            7 7.66e- 5    944\n2            6 6.36e-10    524\n3            2 1.80e- 3    146\n\n\n\n\n0.10.4 NN Hyper-Parameter Tuning\n\n\nCode\n# nnet_folds <- vfold_cv(train_train, strata = survived)\n# nnet_folds\n\n\n# doParallel::registerDoParallel(cores = cores)\ncl <- parallel::makePSOCKcluster(cores - 1)\n\nset.seed(1234)\nnnet_tuning_result <- tune_grid(\n  nnet_wflow,\n  resamples = folds,\n  grid      = nnet_grid,\n  control   = control_grid(save_pred = TRUE,save_workflow = TRUE)\n)\nnnet_tuning_result\n\n\n# Tuning results\n# 5-fold cross-validation using stratification \n# A tibble: 5 × 5\n  splits            id    .metrics         .notes           .predictions      \n  <list>            <chr> <list>           <list>           <list>            \n1 <split [532/135]> Fold1 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [405 × 9]>\n2 <split [534/133]> Fold2 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [399 × 9]>\n3 <split [534/133]> Fold3 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [399 × 9]>\n4 <split [534/133]> Fold4 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [399 × 9]>\n5 <split [534/133]> Fold5 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [399 × 9]>\n\n\nCode\nparallel::stopCluster(cl)\n\n\n\n\n0.10.5 NN Best Parameters and Finalise Workflow\n\n\nCode\nshow_best(nnet_tuning_result, \"accuracy\")\n\n\n# A tibble: 3 × 9\n  hidden_units  penalty epochs .metric  .estimator  mean     n std_err .config  \n         <int>    <dbl>  <int> <chr>    <chr>      <dbl> <int>   <dbl> <chr>    \n1            2 1.80e- 3    146 accuracy binary     0.820     5  0.0161 Preproce…\n2            7 7.66e- 5    944 accuracy binary     0.776     5  0.0372 Preproce…\n3            6 6.36e-10    524 accuracy binary     0.766     5  0.0334 Preproce…\n\n\nCode\nnn_best_params <- select_best(nnet_tuning_result, \"accuracy\")\n\nnnet_best_auc <- select_best(xgb_tuning_result, \"accuracy\")\nnnet_best_auc\n\n\n# A tibble: 1 × 8\n   mtry trees min_n tree_depth learn_rate loss_reduction sample_size .config    \n  <int> <int> <int>      <int>      <dbl>          <dbl>       <dbl> <chr>      \n1     4  1982     4         15     0.0401   0.0000000553       0.393 Preprocess…\n\n\nCode\nnnet_final_wflow <- finalize_workflow(\n  nnet_wflow,\n  nn_best_params\n)\n\nnnet_final_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: mlp()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nSingle Layer Neural Network Model Specification (classification)\n\nMain Arguments:\n  hidden_units = 2\n  penalty = 0.00180188446786651\n  epochs = 146\n\nEngine-Specific Arguments:\n  MaxNWts = 2600\n\nComputational engine: nnet \n\n\n\n\nCode\nnnet_final_wflow %>%\n  fit(data = train_train) %>%\n  extract_fit_parsnip() %>%\n  vip(geom = \"point\")\n\n\n\n\n\n\n\n0.10.6 NN Accuracy - Train/Test Set\n\n\nCode\nnnet_tuning_metrics <- collect_metrics(nnet_tuning_result)\nnnet_tuning_metrics\n\n\n# A tibble: 6 × 9\n  hidden_units  penalty epochs .metric  .estimator  mean     n std_err .config  \n         <int>    <dbl>  <int> <chr>    <chr>      <dbl> <int>   <dbl> <chr>    \n1            7 7.66e- 5    944 accuracy binary     0.776     5  0.0372 Preproce…\n2            7 7.66e- 5    944 roc_auc  binary     0.788     5  0.0395 Preproce…\n3            6 6.36e-10    524 accuracy binary     0.766     5  0.0334 Preproce…\n4            6 6.36e-10    524 roc_auc  binary     0.779     5  0.0421 Preproce…\n5            2 1.80e- 3    146 accuracy binary     0.820     5  0.0161 Preproce…\n6            2 1.80e- 3    146 roc_auc  binary     0.865     5  0.0153 Preproce…\n\n\nCode\nnnet_final_res <- last_fit(nnet_final_wflow, train_split)\nnnet_final_res\n\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits            id               .metrics .notes   .predictions .workflow \n  <list>            <chr>            <list>   <list>   <list>       <list>    \n1 <split [667/224]> train/test split <tibble> <tibble> <tibble>     <workflow>\n\n\nCode\nnnet_final_metrics <- collect_metrics(nnet_final_res)\nnnet_final_metrics\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.786 Preprocessor1_Model1\n2 roc_auc  binary         0.824 Preprocessor1_Model1\n\n\n\n\n0.10.7 NN AUC\n\n\nCode\nnnet_final_res %>%\n  collect_predictions() %>%\n  roc_curve( truth = survived,.pred_1, event_level = \"second\") %>%\n  ggplot(aes(x = 1-specificity, y = sensitivity)) +\n  geom_line(size = 1.5, color = \"midnightblue\") +\n  geom_abline(\n    lty = 2, alpha = 0.5,\n    color = \"gray50\",\n    size = 1.2\n  )\n\n\n\n\n\n\n\n0.10.8 NN Predictions on Train/Test Set\n\n\nCode\nnnet_test_predictions <- nnet_final_res %>%\n  collect_predictions() \nhead(nnet_test_predictions)\n\n\n# A tibble: 6 × 7\n  id               .pred_0 .pred_1  .row .pred_class survived .config           \n  <chr>              <dbl>   <dbl> <int> <fct>       <fct>    <chr>             \n1 train/test split   0.363   0.637    10 1           1        Preprocessor1_Mod…\n2 train/test split   0.603   0.397    11 0           1        Preprocessor1_Mod…\n3 train/test split   0.701   0.299    14 0           0        Preprocessor1_Mod…\n4 train/test split   0.680   0.320    18 0           1        Preprocessor1_Mod…\n5 train/test split   0.363   0.637    20 1           1        Preprocessor1_Mod…\n6 train/test split   0.363   0.637    23 1           1        Preprocessor1_Mod…\n\n\n\n\n0.10.9 NN Confusion Matrix\n\n\nCode\nnnet_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#stack-models",
    "href": "posts/post-with-code/index.html#stack-models",
    "title": "Titanic from Kaggle",
    "section": "0.11 Stack Models",
    "text": "0.11 Stack Models\n\n0.11.1 Stack Recipe\n\n\nCode\nrecipe_stack <- \n  recipe(survived ~ ., data = train_train) %>% \n  update_role(passenger_id, name,surname,ticket,cabin,new_role = \"ID\") %>% \n  step_impute_knn(all_numeric_predictors()) %>% \n  step_dummy(all_nominal_predictors()) %>%\n  step_factor2string(all_nominal_predictors()) %>% \n  step_zv(all_predictors()) %>% \n  step_pca()\nrecipe_stack\n\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          5\n   outcome          1\n predictor         13\n\nOperations:\n\nK-nearest neighbor imputation for all_numeric_predictors()\nDummy variables from all_nominal_predictors()\nCharacter variables from all_nominal_predictors()\nZero variance filter on all_predictors()\nPCA extraction with <none>\n\n\nCode\nrecipe_stack_trained <- prep(recipe_base)\nrecipe_stack_trained\n\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          5\n   outcome          1\n predictor         13\n\nTraining data contained 667 data points and 514 incomplete rows. \n\nOperations:\n\nK-nearest neighbor imputation for age, sib_sp, parch, fare [trained]\nDummy variables from pclass, sex, embarked, train_test, pax_type, cabin_prefac... [trained]\nCharacter variables from <none> [trained]\nZero variance filter removed train_test_test [trained]\nNo PCA components were extracted from <none> [trained]\n\n\n\n\n0.11.2 Stack Controls\n\n\nCode\nstack_ctrl <- control_resamples(save_pred = TRUE, save_workflow = TRUE)\n#stack_folds <- vfold_cv(training(train_split), v=10,strata = \"survived\")\n\nlibrary(stacks)\n\nmodel_stack <-\n  stacks() %>%\n  #add_candidates(lr_wflow) %>%\n  #add_candidates(rf_wflow) %>%\n  add_candidates(nnet_tuning_result) %>%\n  add_candidates(rlr_tuning_result) %>% \n  add_candidates(xgb_tuning_result)\n\n\n\n\n0.11.3 Stack Blend\n\n\nCode\ncl <- parallel::makePSOCKcluster(cores - 1)\n\nset.seed(1234)\nensemble <- blend_predictions(model_stack,penalty = 10^seq(-2, -0.5, length = 20))\nautoplot(ensemble)\n\n\n\n\n\nCode\nparallel::stopCluster(cl)\n\n\n\n\nCode\nensemble \n\n\n# A tibble: 4 × 3\n  member                         type         weight\n  <chr>                          <chr>         <dbl>\n1 .pred_1_nnet_tuning_result_1_3 mlp           2.25 \n2 .pred_1_rlr_tuning_result_1_30 logistic_reg  1.11 \n3 .pred_1_rlr_tuning_result_1_28 logistic_reg  1.09 \n4 .pred_1_xgb_tuning_result_1_29 boost_tree    0.658\n\n\n\n\n0.11.4 Stack Weights\n\n\nCode\nautoplot(ensemble, \"weights\") +\n  geom_text(aes(x = weight + 0.01, label = model), hjust = 0) + \n  theme(legend.position = \"none\") \n\n\n\n\n\n\n\n0.11.5 Fit Member Models\n\n\nCode\nensemble <- fit_members(ensemble)\ncollect_parameters(ensemble,\"xgb_tuning_result\")\n\n\n# A tibble: 27 × 10\n   member          mtry trees min_n tree_…¹ learn…² loss_r…³ sampl…⁴ terms  coef\n   <chr>          <int> <int> <int>   <int>   <dbl>    <dbl>   <dbl> <chr> <dbl>\n 1 xgb_tuning_re…    11   848    17       1 5.59e-3 5.81e- 3   0.539 .pre…     0\n 2 xgb_tuning_re…     9  1145    10       2 5.20e-8 1.60e- 1   0.866 .pre…     0\n 3 xgb_tuning_re…    17   740    15       2 8.39e-2 6.64e- 9   0.252 .pre…     0\n 4 xgb_tuning_re…    10  1314    11       3 1.72e-5 1.25e- 1   0.163 .pre…     0\n 5 xgb_tuning_re…    18  1475    25       3 1.50e-6 2.46e- 9   0.328 .pre…     0\n 6 xgb_tuning_re…     6    98    23       4 4.07e-4 1.02e- 3   0.897 .pre…     0\n 7 xgb_tuning_re…     7   923    13       5 1.66e-3 1.78e- 5   0.352 .pre…     0\n 8 xgb_tuning_re…    16   610    26       5 1.14e-5 1.88e-10   0.211 .pre…     0\n 9 xgb_tuning_re…    16  1549     6       7 1.36e-4 4.92e- 4   0.463 .pre…     0\n10 xgb_tuning_re…    14  1900    22       7 2.14e-7 3.46e- 6   0.447 .pre…     0\n# … with 17 more rows, and abbreviated variable names ¹​tree_depth, ²​learn_rate,\n#   ³​loss_reduction, ⁴​sample_size\n\n\n\n\n0.11.6 Stack Predict\n\n\nCode\n#ensemble_metrics <- metric_set(roc_auc,accuracy)\n\nensemble_test_predictions <- \n  predict(ensemble,train_test) %>% \n  bind_cols(train_test) \n\n\n# ensemble_test_predictions <- ensemble_test_predictions %>% \n#   mutate(.pred_class=as.numeric(.pred_class)) %>% \n#    mutate(survived =as.numeric(survived)) \n# \n# ensemble_test_predictions <- ensemble_test_predictions %>% \n#   mutate(roc = roc_auc(truth=survived, estimate = .pred_class))\n\n\n\nglimpse(ensemble_test_predictions)\n\n\nRows: 224\nColumns: 20\n$ .pred_class   <fct> 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0,…\n$ passenger_id  <dbl> 10, 11, 14, 18, 20, 23, 28, 40, 41, 51, 54, 57, 61, 66, …\n$ survived      <fct> 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1,…\n$ pclass        <fct> 2, 3, 3, 2, 3, 3, 1, 3, 3, 3, 2, 2, 3, 3, 2, 3, 3, 2, 3,…\n$ name          <fct> \"Nasser, Mrs. Nicholas (Adele Achem)\", \"Sandstrom, Miss.…\n$ sex           <fct> female, female, male, male, female, female, male, female…\n$ age           <dbl> 14, 4, 39, 30, 31, 15, 19, 14, 40, 7, 29, 21, 22, 6, 21,…\n$ sib_sp        <dbl> 1, 1, 1, 0, 0, 0, 3, 1, 1, 4, 1, 0, 0, 1, 0, 0, 0, 0, 3,…\n$ parch         <dbl> 0, 1, 5, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,…\n$ ticket        <fct> 237736, PP 9549, 347082, 244373, 2649, 330923, 19950, 26…\n$ fare          <dbl> 30.0708, 16.7000, 31.2750, 13.0000, 7.2250, 8.0292, 263.…\n$ cabin         <fct> NA, G6, NA, NA, NA, NA, C23 C25 C27, NA, NA, NA, NA, NA,…\n$ embarked      <fct> C, S, S, S, C, Q, S, C, S, S, S, S, C, C, S, S, Q, S, S,…\n$ train_test    <fct> train, train, train, train, train, train, train, train, …\n$ pax_type      <fct> F_married, F_unmarried, Mr., Mr., F_married, F_unmarried…\n$ surname       <fct> \"Nasser,\", \"Sandstrom,\", \"Andersson,\", \"Williams,\", \"Mas…\n$ cabin_preface <fct> nk, G, nk, nk, nk, nk, C, nk, nk, nk, nk, nk, nk, nk, nk…\n$ ticket_group  <fct> couple, group, group, single, single, single, group, cou…\n$ family_group  <ord> couple, family, family, single, single, single, family, …\n$ age_group     <ord> teen, child, 30s, 30s, 30s, teen, teen, teen, 40s, child…"
  },
  {
    "objectID": "posts/post-with-code/index.html#join-model-prediction-data",
    "href": "posts/post-with-code/index.html#join-model-prediction-data",
    "title": "Titanic from Kaggle",
    "section": "0.12 Join Model Prediction Data",
    "text": "0.12 Join Model Prediction Data\n\n\nCode\nall_predictions <- \n  lr_test_predictions %>% mutate(model = \"LR\") %>% \n  bind_rows(nnet_test_predictions %>% mutate(model = \"NNet\")) %>% \n  bind_rows(rlr_test_predictions %>% mutate(model = \"Reg_LR\")) %>% \n  bind_rows(rf_test_predictions %>% mutate(model = \"RF\")) %>% \n  bind_rows(xgb_test_predictions %>% mutate(model = \"xgb\")) %>% \n  bind_rows(xgb_usemodel_test_predictions %>% mutate(model = \"xgb_usemodel\")) %>% \n  bind_rows(ensemble_test_predictions %>% mutate(model = \"ensemble\"))\n  \nall_predictions %>% head() %>% knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\n.pred_0\n.pred_1\n.row\n.pred_class\nsurvived_pred\n.config\npassenger_id\nsurvived\npclass\nname\nsex\nage\nsib_sp\nparch\nticket\nfare\ncabin\nembarked\ntrain_test\npax_type\nsurname\ncabin_preface\nticket_group\nfamily_group\nage_group\nmodel\n\n\n\n\ntrain/test split\n0.0947816\n0.9052184\n10\n1\n1\nPreprocessor1_Model1\n10\n1\n2\nNasser, Mrs. Nicholas (Adele Achem)\nfemale\n14\n1\n0\n237736\n30.0708\nNA\nC\ntrain\nF_married\nNasser,\nnk\ncouple\ncouple\nteen\nLR\n\n\ntrain/test split\n0.9999997\n0.0000003\n11\n0\n1\nPreprocessor1_Model1\n11\n1\n3\nSandstrom, Miss. Marguerite Rut\nfemale\n4\n1\n1\nPP 9549\n16.7000\nG6\nS\ntrain\nF_unmarried\nSandstrom,\nG\ngroup\nfamily\nchild\nLR\n\n\ntrain/test split\n0.9959939\n0.0040061\n14\n0\n0\nPreprocessor1_Model1\n14\n0\n3\nAndersson, Mr. Anders Johan\nmale\n39\n1\n5\n347082\n31.2750\nNA\nS\ntrain\nMr.\nAndersson,\nnk\ngroup\nfamily\n30s\nLR\n\n\ntrain/test split\n0.7485089\n0.2514911\n18\n0\n1\nPreprocessor1_Model1\n18\n1\n2\nWilliams, Mr. Charles Eugene\nmale\n30\n0\n0\n244373\n13.0000\nNA\nS\ntrain\nMr.\nWilliams,\nnk\nsingle\nsingle\n30s\nLR\n\n\ntrain/test split\n0.1223361\n0.8776639\n20\n1\n1\nPreprocessor1_Model1\n20\n1\n3\nMasselmani, Mrs. Fatima\nfemale\n31\n0\n0\n2649\n7.2250\nNA\nC\ntrain\nF_married\nMasselmani,\nnk\nsingle\nsingle\n30s\nLR\n\n\ntrain/test split\n0.3091538\n0.6908462\n23\n1\n1\nPreprocessor1_Model1\n23\n1\n3\nMcGowan, Miss. Anna “Annie”\nfemale\n15\n0\n0\n330923\n8.0292\nNA\nQ\ntrain\nF_unmarried\nMcGowan,\nnk\nsingle\nsingle\nteen\nLR"
  },
  {
    "objectID": "posts/post-with-code/index.html#all-metrics",
    "href": "posts/post-with-code/index.html#all-metrics",
    "title": "Titanic from Kaggle",
    "section": "0.13 All Metrics",
    "text": "0.13 All Metrics\nOrdered by descending Accuracy metric\n\n\nCode\nall_metrics <- \n  lr_final_metrics %>% mutate(model = \"LR\") %>% \n  bind_rows(nnet_final_metrics %>% mutate(model = \"NNet\")) %>% \n  bind_rows(rlr_final_metrics %>% mutate(model = \"Reg_LR\")) %>% \n  bind_rows(rf_final_metrics %>% mutate(model = \"RF\")) %>% \n  bind_rows(xgb_final_metrics %>% mutate(model = \"xgb\")) %>% \n  bind_rows(xgb_usemodel_final_metrics %>% mutate(model = \"xgb-usemodel\")) \n\nall_metrics_table <- all_metrics %>% \n   pivot_wider(names_from = .metric,values_from = .estimate) %>% \n   arrange(desc(accuracy))\n  \nwrite_rds(all_metrics,\"artifacts/all_metrics.rds\")\n\nall_metrics_table %>% knitr::kable(digits=3)\n\n\n\n\n\n.estimator\n.config\nmodel\naccuracy\nroc_auc\n\n\n\n\nbinary\nPreprocessor1_Model1\nxgb\n0.839\n0.870\n\n\nbinary\nPreprocessor1_Model1\nRF\n0.821\n0.874\n\n\nbinary\nPreprocessor1_Model1\nReg_LR\n0.808\n0.842\n\n\nbinary\nPreprocessor1_Model1\nLR\n0.799\n0.822\n\n\nbinary\nPreprocessor1_Model1\nNNet\n0.786\n0.824\n\n\nbinary\nPreprocessor1_Model1\nxgb-usemodel\n0.670\n0.797\n\n\n\n\n\nand a graph:\n\n\nCode\nall_metrics %>% \n  filter(.metric == \"accuracy\") %>% \n  select(model, accuracy = .estimate) %>% \n  ggplot(aes(model, accuracy)) +\n  geom_col()"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "What is this for?",
    "section": "",
    "text": "This is my public notebook created in Quarto after seeing all the recent webinars from the amazing people at RStudio.\nIt is intended that it will contain public ‘Notes to Myself’ on some of my interests which professionally are likely to centre on things like:\n\nR Programming\nPython Programming\nML analytics in R and Python\nFinance and data analytics (my day job)\nOther analytics and notes collected from wherever\n\nNot sure that it will be much use to anyone else, but feel free to wander through."
  }
]