[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Notes Index",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\ncode\n\n\nanalytics\n\n\nflights\n\n\nmaps\n\n\n\n\n\n\n\n\n\n\n\nOct 20, 2022\n\n\nStephen J Parton\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\ntitanic\n\n\n\n\n\n\n\n\n\n\n\nSep 1, 2022\n\n\nStephen Parton\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nAug 29, 2022\n\n\nStephen Parton\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/model-01-logistic_regression/index.html#summary",
    "href": "posts/model-01-logistic_regression/index.html#summary",
    "title": "Titanic Logistic Regression",
    "section": "Summary",
    "text": "Summary\nThis analysis looks at the previously processed Titanic analysis, using logistic regression."
  },
  {
    "objectID": "posts/model-01-logistic_regression/index.html#load-some-pre-prepared-kaggle-data",
    "href": "posts/model-01-logistic_regression/index.html#load-some-pre-prepared-kaggle-data",
    "title": "Titanic Logistic Regression",
    "section": "Load Some Pre-prepared Kaggle Data",
    "text": "Load Some Pre-prepared Kaggle Data\n\n\nCode\n#getwd()\n\nall_proc <- read_rds(\"../../posts/post-with-code/artifacts/all_proc.rds\")\ntrain_split <- read_rds(\"../../posts/post-with-code/artifacts/train_split.rds\")\nrecipe_base <- read_rds(\"../../posts/post-with-code/artifacts/recipe_base.rds\")"
  },
  {
    "objectID": "posts/model-01-logistic_regression/index.html#models",
    "href": "posts/model-01-logistic_regression/index.html#models",
    "title": "Titanic Logistic Regression",
    "section": "Models",
    "text": "Models\n\nLogistic Regression- GLM\n\nLR Model Spec\n\n\nCode\nlr_spec <-  \n  logistic_reg() %>% \n  set_engine(\"glm\")\n\nlr_spec\n\n\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\n\nLR Workflow\n\n\nCode\nlr_wflow <- \n  workflow() %>% \n  add_model(lr_spec) %>% \n  add_recipe(recipe_base)\n\nlr_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\n\nLR Fit Model\n\n\nCode\nlr_fit <- \n  lr_wflow %>% \n  last_fit(train_split)\n\n#lr_fit\n\nlr_final_metrics <- lr_fit %>% collect_metrics()\nlr_final_metrics \n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.835 Preprocessor1_Model1\n2 roc_auc  binary         0.867 Preprocessor1_Model1\n\n\nCode\n#show_notes(.Last.tune.result)\n\n\n\n\nLR Predict\n\n\nCode\nlr_test_predictions <- lr_fit %>% collect_predictions()\nlr_test_predictions\n\n\n# A tibble: 224 × 7\n   id               .pred_0 .pred_1  .row .pred_class survived .config          \n   <chr>              <dbl>   <dbl> <int> <fct>       <fct>    <chr>            \n 1 train/test split  0.346   0.654      3 1           1        Preprocessor1_Mo…\n 2 train/test split  0.0685  0.931      4 1           1        Preprocessor1_Mo…\n 3 train/test split  0.920   0.0802     5 0           0        Preprocessor1_Mo…\n 4 train/test split  0.569   0.431     11 0           1        Preprocessor1_Mo…\n 5 train/test split  0.622   0.378     31 0           0        Preprocessor1_Mo…\n 6 train/test split  0.277   0.723     33 1           1        Preprocessor1_Mo…\n 7 train/test split  0.670   0.330     35 0           0        Preprocessor1_Mo…\n 8 train/test split  0.811   0.189     36 0           0        Preprocessor1_Mo…\n 9 train/test split  0.902   0.0975    37 0           1        Preprocessor1_Mo…\n10 train/test split  0.554   0.446     39 0           0        Preprocessor1_Mo…\n# … with 214 more rows\n\n\n\n\nLR Performance on validation set\n\nAUC Curve\n\n\nCode\nlr_test_predictions %>% \n  roc_curve(truth = survived,.pred_1,event_level=\"second\") %>% \n  autoplot()\n\n\n\n\n\n\n\nConfusion Matrix\n\n\nCode\nlr_test_predictions %>% \n  conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")\n\n\n\n\n\n\n\n\nLR Resampling\n\n\nCode\nfolds <- vfold_cv(training(train_split), strata = survived, v=10)\n#folds\n\ncontrol <- control_resamples(save_pred = TRUE)\n\nlr_fit_cv <- \n  lr_wflow %>% \n  fit_resamples(folds, control = control)\n\n#show_best(lr_fit_cv,metric= \"accuracy\")\n\n#lr_fit_cv\nlr_metrics_resample <- collect_metrics(lr_fit_cv)\nlr_metrics_resample\n\n\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy binary     0.811    10  0.0130 Preprocessor1_Model1\n2 roc_auc  binary     0.854    10  0.0125 Preprocessor1_Model1"
  },
  {
    "objectID": "posts/post-with-code/index.html#summary",
    "href": "posts/post-with-code/index.html#summary",
    "title": "Titanic from Kaggle",
    "section": "0.1 Summary",
    "text": "0.1 Summary\nThis is just a first test with code in a blog using the new Quarto framework! Guess what I am using..yep Titanic, Kaggle version..\nIt is not very well structured as it is pretty much in the order I did it following all instructions, books and blogs from the expert TidyModels and Quarto teams at RStudio/Posit . All errors belong to me!"
  },
  {
    "objectID": "posts/post-with-code/index.html#load-some-kaggle-data",
    "href": "posts/post-with-code/index.html#load-some-kaggle-data",
    "title": "Titanic from Kaggle",
    "section": "2 Load Some Kaggle Data",
    "text": "2 Load Some Kaggle Data\nNot the…? Yes, the Titanic again….\n\n\nCode\ntrain <- read_csv(\"data_raw/train.csv\",show_col_types = FALSE) %>% clean_names() %>% mutate(train_test = \"train\")\ntest <- read_csv(\"data_raw/test.csv\",show_col_types = FALSE) %>% clean_names() %>% \n  mutate(train_test = \"test\")\nall <- train %>% bind_rows(test)\n\n# colnames(data)\n# cwd()"
  },
  {
    "objectID": "posts/post-with-code/index.html#some-initial-eda",
    "href": "posts/post-with-code/index.html#some-initial-eda",
    "title": "Titanic from Kaggle",
    "section": "3 Some Initial EDA",
    "text": "3 Some Initial EDA\nA quick look.\n\n\nCode\ntrain %>% skim() \n\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n891\n\n\nNumber of columns\n13\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nname\n0\n1.00\n12\n82\n0\n891\n0\n\n\nsex\n0\n1.00\n4\n6\n0\n2\n0\n\n\nticket\n0\n1.00\n3\n18\n0\n681\n0\n\n\ncabin\n687\n0.23\n1\n15\n0\n147\n0\n\n\nembarked\n2\n1.00\n1\n1\n0\n3\n0\n\n\ntrain_test\n0\n1.00\n5\n5\n0\n1\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\npassenger_id\n0\n1.0\n446.00\n257.35\n1.00\n223.50\n446.00\n668.5\n891.00\n▇▇▇▇▇\n\n\nsurvived\n0\n1.0\n0.38\n0.49\n0.00\n0.00\n0.00\n1.0\n1.00\n▇▁▁▁▅\n\n\npclass\n0\n1.0\n2.31\n0.84\n1.00\n2.00\n3.00\n3.0\n3.00\n▃▁▃▁▇\n\n\nage\n177\n0.8\n29.70\n14.53\n0.42\n20.12\n28.00\n38.0\n80.00\n▂▇▅▂▁\n\n\nsib_sp\n0\n1.0\n0.52\n1.10\n0.00\n0.00\n0.00\n1.0\n8.00\n▇▁▁▁▁\n\n\nparch\n0\n1.0\n0.38\n0.81\n0.00\n0.00\n0.00\n0.0\n6.00\n▇▁▁▁▁\n\n\nfare\n0\n1.0\n32.20\n49.69\n0.00\n7.91\n14.45\n31.0\n512.33\n▇▁▁▁▁"
  },
  {
    "objectID": "posts/post-with-code/index.html#some-initial-wrangling",
    "href": "posts/post-with-code/index.html#some-initial-wrangling",
    "title": "Titanic from Kaggle",
    "section": "4 Some Initial Wrangling",
    "text": "4 Some Initial Wrangling\n\n\nCode\nall_proc <- all %>% \n  mutate(title = str_extract(name,\"(\\\\w)([a-z]+)(\\\\.)\")) %>% \n  mutate(pax_type = case_when(\n    title %in% c(\"Miss.\",\"Ms.\",\"Mlle.\")         ~ \"F_unmarried\",\n    title %in% c(\"Mme.\",\"Mrs.\")                 ~ \"F_married\",\n    title %in% c(\"Countess.\",\"Lady.\",\"Dona.\")   ~ \"F_titled\",\n    title %in% c(\"Capt.\",\"Col.\",\"Major.\")       ~ \"Military\",\n    title %in% c(\"Dr.\",\"Rev.\")                  ~ \"M_Professional\",\n    title %in% c(\"Don.\",\"Jonkheer.\",\"Sir.\")     ~ \"M_titled\",\n    TRUE ~ title\n  ),\n  surname        = str_extract(name,\"(\\\\w+)(\\\\,)\"),\n  survival       = ifelse(survived==0,\"No\",\"Yes\"),\n  ticket_preface = str_extract(ticket,\"([:graph:]+)(\\\\s)\"),\n  ticket_preface = ifelse(is.na(ticket_preface),\"none\",ticket_preface),\n  cabin_preface  = ifelse(is.na(cabin),\"nk\",\n                    substr(cabin,1,1)),\n  embarked       = ifelse(is.na(embarked),\"S\",embarked)\n  ) %>% \n  group_by(pax_type,pclass) %>% \n  mutate(age     = ifelse(is.na(age),median(age,na.rm = T), age)) %>% \n  ungroup() %>% \n  add_count(ticket,name = \"ticket_group\") %>% \n  mutate(ticket_group = case_when(\n    ticket_group == 1 ~ \"single\",\n    ticket_group == 2 ~ \"couple\",\n    TRUE              ~ \"group\"\n  ),\n    family_group = as.numeric(sib_sp)+as.numeric(parch)+1\n  ) %>% \n  mutate(family_group = factor(\n    case_when(\n        family_group < 2  ~ \"single\",\n        family_group < 3  ~ \"couple\",\n        TRUE              ~ \"family\"\n        ),\n    ordered = TRUE)\n  ) %>% \n  mutate(age_group = factor(case_when(\n    age < 13      ~ \"child\",\n    age < 20      ~ \"teen\",\n    age < 30      ~ \"20s\",\n    age < 40      ~ \"30s\",\n    age < 50      ~ \"40s\",\n    age < 60      ~ \"50s\",\n    TRUE          ~ \"60+\"\n    \n  ),\n  ordered = TRUE)\n  ) %>% \n  mutate(across(where(is.character),as_factor)) %>% \n  mutate(pclass = factor(pclass,levels = c(\"1\",\"2\",\"3\")),\n         survived = factor(survived)\n         ) %>% \nselect(-c(title,ticket_preface))\n  \n#all_proc %>% glimpse()"
  },
  {
    "objectID": "posts/post-with-code/index.html#a-bit-more-eda",
    "href": "posts/post-with-code/index.html#a-bit-more-eda",
    "title": "Titanic from Kaggle",
    "section": "5 A bit more EDA",
    "text": "5 A bit more EDA\n\n\nCode\nall_proc %>% \n  select(-c(name,ticket,cabin,surname,train_test)) %>% \n  DataExplorer::plot_bar()\n\n\n\n\n\n\n\n\n\n\nCode\nall_proc %>% DataExplorer::plot_histogram(ggtheme = theme_light() )"
  },
  {
    "objectID": "posts/post-with-code/index.html#eyeballing-survival-graphs-on-training-data",
    "href": "posts/post-with-code/index.html#eyeballing-survival-graphs-on-training-data",
    "title": "Titanic from Kaggle",
    "section": "6 Eyeballing Survival Graphs on Training Data",
    "text": "6 Eyeballing Survival Graphs on Training Data\n\n\nCode\nno_f <- all_proc %>%\n  filter(train_test == \"train\") %>% \n  select(passenger_id,pclass,sex,embarked,pax_type,ticket_group,family_group,age_group,cabin_preface,survival) %>% \n  droplevels() %>%\n  mutate(across(where(is.factor),~ factor(.x,ordered = FALSE))) %>%\n  pivot_longer(cols = c(pclass:cabin_preface)) \n\n\ng_l <- no_f %>% \n  split(.$name) %>% \n  map(~ ggplot(.,aes(y=value,fill=survival)) +\n                geom_bar() +\n              ggtitle(.$name) +\n        theme_bw() +\n        labs(x=NULL,y=NULL)+\n        scale_fill_viridis_d(option = \"cividis\")\n      \n            ) \n\nlibrary(patchwork)\nwrap_plots(g_l, ncol = 2)"
  },
  {
    "objectID": "posts/post-with-code/index.html#split-data-back-to-traintestvalidation",
    "href": "posts/post-with-code/index.html#split-data-back-to-traintestvalidation",
    "title": "Titanic from Kaggle",
    "section": "7 Split Data back to Train/Test/Validation",
    "text": "7 Split Data back to Train/Test/Validation\n\n\nCode\ntrain_proc_adj_tbl <- all_proc %>% \n  filter(train_test ==\"train\") %>% \n  select(-c(survival))\n  \ntrain_split <- initial_split(train_proc_adj_tbl,strata = survived)"
  },
  {
    "objectID": "posts/post-with-code/index.html#recipe-base",
    "href": "posts/post-with-code/index.html#recipe-base",
    "title": "Titanic from Kaggle",
    "section": "0.4 Recipe-Base",
    "text": "0.4 Recipe-Base\n\n\nCode\nrecipe_base <- \n  recipe(survived ~ ., data = train_train) %>% \n  update_role(passenger_id, name,surname,ticket,cabin,new_role = \"ID\") %>%\n  step_impute_knn(all_numeric_predictors()) %>% \n  step_dummy(all_nominal_predictors()) %>%\n  step_factor2string(all_nominal_predictors()) %>% \n  step_zv(all_predictors()) %>% \n  step_pca()\nrecipe_base\n\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          5\n   outcome          1\n predictor         13\n\nOperations:\n\nK-nearest neighbor imputation for all_numeric_predictors()\nDummy variables from all_nominal_predictors()\nCharacter variables from all_nominal_predictors()\nZero variance filter on all_predictors()\nPCA extraction with <none>\n\n\n\n0.4.1 Save Files\n\n\nCode\nwrite_rds(all_proc,\"artifacts/all_proc.rds\")\nwrite_rds(train_split,\"artifacts/train_split.rds\")\nwrite_rds(recipe_base,\"artifacts/recipe_base.rds\")\n# \n# all_proc <- read_rds(\"artifacts/all_proc.rds\")\n# train_split <- read_rds(\"artifacts/train_split.rds\")\n# recipe_base <- read_rds(\"artifacts/recipe_base.rds\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#save-files",
    "href": "posts/post-with-code/index.html#save-files",
    "title": "Titanic from Kaggle",
    "section": "9 Save Files",
    "text": "9 Save Files\n\n\nCode\nwrite_rds(all_proc,\"artifacts/all_proc.rds\")\nwrite_rds(train_split,\"artifacts/train_split.rds\")\nwrite_rds(recipe_base,\"artifacts/recipe_base.rds\")\n\nall_proc <- read_rds(\"artifacts/all_proc.rds\")\ntrain_split <- read_rds(\"artifacts/train_split.rds\")\nrecipe_base <- read_rds(\"artifacts/recipe_base.rds\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#models",
    "href": "posts/post-with-code/index.html#models",
    "title": "Titanic from Kaggle",
    "section": "0.5 Models",
    "text": "0.5 Models\n\n0.5.1 Logistic Regression\n\nLR Model Spec\n\n\nCode\nlr_spec <-  \n  logistic_reg() %>% \n  set_engine(\"glm\")\n\nlr_spec\n\n\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\n\nLR Workflow\n\n\nCode\nlr_wflow <- \n  workflow() %>% \n  add_model(lr_spec) %>% \n  add_recipe(recipe_base)\n\nlr_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\n\nLR Fit Model\n\n\nCode\nlr_fit <- \n  lr_wflow %>% \n  last_fit(train_split)\n\n#lr_fit\n\nlr_final_metrics <- lr_fit %>% collect_metrics()\nlr_final_metrics \n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.799 Preprocessor1_Model1\n2 roc_auc  binary         0.822 Preprocessor1_Model1\n\n\nCode\n#show_notes(.Last.tune.result)\n\n\n\n\nLR Predict\n\n\nCode\nlr_test_predictions <- lr_fit %>% collect_predictions() %>% \n  rename(survived_pred = survived) %>% \n  bind_cols(train_test)\nlr_test_predictions\n\n\n# A tibble: 224 × 26\n   id       .pred_0 .pred_1  .row .pred…¹ survi…² .config passe…³ survi…⁴ pclass\n   <chr>      <dbl>   <dbl> <int> <fct>   <fct>   <chr>     <dbl> <fct>   <fct> \n 1 train/t…  0.0948 9.05e-1    10 1       1       Prepro…      10 1       2     \n 2 train/t…  1.00   2.63e-7    11 0       1       Prepro…      11 1       3     \n 3 train/t…  0.996  4.01e-3    14 0       0       Prepro…      14 0       3     \n 4 train/t…  0.749  2.51e-1    18 0       1       Prepro…      18 1       2     \n 5 train/t…  0.122  8.78e-1    20 1       1       Prepro…      20 1       3     \n 6 train/t…  0.309  6.91e-1    23 1       1       Prepro…      23 1       3     \n 7 train/t…  0.887  1.13e-1    28 0       0       Prepro…      28 0       1     \n 8 train/t…  0.473  5.27e-1    40 1       1       Prepro…      40 1       3     \n 9 train/t…  0.468  5.32e-1    41 1       0       Prepro…      41 0       3     \n10 train/t…  0.862  1.38e-1    51 0       0       Prepro…      51 0       3     \n# … with 214 more rows, 16 more variables: name <fct>, sex <fct>, age <dbl>,\n#   sib_sp <dbl>, parch <dbl>, ticket <fct>, fare <dbl>, cabin <fct>,\n#   embarked <fct>, train_test <fct>, pax_type <fct>, surname <fct>,\n#   cabin_preface <fct>, ticket_group <fct>, family_group <ord>,\n#   age_group <ord>, and abbreviated variable names ¹​.pred_class,\n#   ²​survived_pred, ³​passenger_id, ⁴​survived\n\n\n\n\nLR Performance on validation set\n\nAUC Curve\n\n\nCode\nlr_test_predictions %>% \n  roc_curve(truth = survived,.pred_1,event_level=\"second\") %>% \n  autoplot()\n\n\n\n\n\n\n\nConfusion Matrix\n\n\nCode\nlr_test_predictions %>% \n  conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")\n\n\n\n\n\n\n\n\nLR Resampling\n\n\nCode\nfolds <- vfold_cv(train_train, strata = survived, v=5)\n#folds\n\ncontrol <- control_resamples(save_pred = TRUE,save_workflow = TRUE)\n\ncores <- parallel::detectCores()\ncl <- parallel::makePSOCKcluster(cores - 1)\n\n# doParallel::registerDoParallel(cores = cores)\nset.seed(1234)\nlr_fit_cv <- \n  lr_wflow %>% \n  fit_resamples(folds, control = control)\n\n#show_best(lr_fit_cv,metric= \"accuracy\")\n\n#lr_fit_cv\nlr_metrics_resample <- collect_metrics(lr_fit_cv)\nlr_metrics_resample\n\n\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy binary     0.823     5 0.0124  Preprocessor1_Model1\n2 roc_auc  binary     0.856     5 0.00839 Preprocessor1_Model1\n\n\nCode\nparallel::stopCluster(cl)\n\n\nFollowing still to be fixed!\n\n\nCode\n#lr_param <- extract_parameter_set_dials(lr_spec)\n\nlr_resample_test_predictions <- collect_predictions(lr_fit_cv) %>% \n  rename(survived_pred = survived) \n#  bind_cols(testing(train_split))\nlr_resample_test_predictions\n\n\n# A tibble: 667 × 7\n   id    .pred_0 .pred_1  .row .pred_class survived_pred .config             \n   <chr>   <dbl>   <dbl> <int> <fct>       <fct>         <chr>               \n 1 Fold1   0.888 0.112       2 0           0             Preprocessor1_Model1\n 2 Fold1   0.756 0.244      10 0           0             Preprocessor1_Model1\n 3 Fold1   0.932 0.0677     15 0           0             Preprocessor1_Model1\n 4 Fold1   0.187 0.813      20 1           0             Preprocessor1_Model1\n 5 Fold1   0.919 0.0810     26 0           0             Preprocessor1_Model1\n 6 Fold1   0.978 0.0219     29 0           0             Preprocessor1_Model1\n 7 Fold1   0.974 0.0265     34 0           0             Preprocessor1_Model1\n 8 Fold1   0.993 0.00666    36 0           0             Preprocessor1_Model1\n 9 Fold1   0.921 0.0793     43 0           0             Preprocessor1_Model1\n10 Fold1   0.924 0.0763     44 0           0             Preprocessor1_Model1\n# … with 657 more rows\n\n\n\n\nCode\ncl <- parallel::makePSOCKcluster(cores - 1)\n\nset.seed(1234)\nlm_fit <- lr_wflow %>% fit(data = train_proc_adj_tbl)\nextract_recipe(lm_fit, estimated = TRUE)\n\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          5\n   outcome          1\n predictor         13\n\nTraining data contained 891 data points and 687 incomplete rows. \n\nOperations:\n\nK-nearest neighbor imputation for age, sib_sp, parch, fare [trained]\nDummy variables from pclass, sex, embarked, train_test, pax_type, cabin_prefac... [trained]\nCharacter variables from <none> [trained]\nZero variance filter removed train_test_test [trained]\nNo PCA components were extracted from <none> [trained]\n\n\nCode\nparallel::stopCluster(cl)"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "What is this for?",
    "section": "",
    "text": "This is my public notebook created in Quarto after seeing all the recent webinars from the amazing people at RStudio.\nIt is intended that it will contain public ‘Notes to Myself’ on some of my interests which professionally are likely to centre on things like:\n\nR Programming\nPython Programming\nML analytics in R and Python\nFinance and data analytics (my day job)\nOther analytics and notes collected from wherever\n\nNot sure that it will be much use to anyone else, but feel free to wander through."
  },
  {
    "objectID": "posts/post-with-code/index.html#review-data",
    "href": "posts/post-with-code/index.html#review-data",
    "title": "Titanic from Kaggle",
    "section": "0.3 Review Data",
    "text": "0.3 Review Data\n\n0.3.1 Load Some Kaggle Data\nNot the…? Yes, the Titanic again….\n\n\nCode\ntrain <- read_csv(\"data_raw/train.csv\",show_col_types = FALSE) %>% clean_names() %>% mutate(train_test = \"train\")\ntest <- read_csv(\"data_raw/test.csv\",show_col_types = FALSE) %>% clean_names() %>% \n  mutate(train_test = \"test\")\nall <- train %>% bind_rows(test)\n\n# colnames(data)\n# cwd()\n\n\n\n\n0.3.2 Some Initial EDA\nA quick look.\n\n\nCode\ntrain %>% skim() \n\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n891\n\n\nNumber of columns\n13\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nname\n0\n1.00\n12\n82\n0\n891\n0\n\n\nsex\n0\n1.00\n4\n6\n0\n2\n0\n\n\nticket\n0\n1.00\n3\n18\n0\n681\n0\n\n\ncabin\n687\n0.23\n1\n15\n0\n147\n0\n\n\nembarked\n2\n1.00\n1\n1\n0\n3\n0\n\n\ntrain_test\n0\n1.00\n5\n5\n0\n1\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\npassenger_id\n0\n1.0\n446.00\n257.35\n1.00\n223.50\n446.00\n668.5\n891.00\n▇▇▇▇▇\n\n\nsurvived\n0\n1.0\n0.38\n0.49\n0.00\n0.00\n0.00\n1.0\n1.00\n▇▁▁▁▅\n\n\npclass\n0\n1.0\n2.31\n0.84\n1.00\n2.00\n3.00\n3.0\n3.00\n▃▁▃▁▇\n\n\nage\n177\n0.8\n29.70\n14.53\n0.42\n20.12\n28.00\n38.0\n80.00\n▂▇▅▂▁\n\n\nsib_sp\n0\n1.0\n0.52\n1.10\n0.00\n0.00\n0.00\n1.0\n8.00\n▇▁▁▁▁\n\n\nparch\n0\n1.0\n0.38\n0.81\n0.00\n0.00\n0.00\n0.0\n6.00\n▇▁▁▁▁\n\n\nfare\n0\n1.0\n32.20\n49.69\n0.00\n7.91\n14.45\n31.0\n512.33\n▇▁▁▁▁\n\n\n\n\n\n\n\n0.3.3 Some Initial Wrangling\n\n\nCode\nall_proc <- all %>% \n  mutate(title = str_extract(name,\"(\\\\w)([a-z]+)(\\\\.)\")) %>% \n  mutate(pax_type = case_when(\n    title %in% c(\"Miss.\",\"Ms.\",\"Mlle.\")         ~ \"F_unmarried\",\n    title %in% c(\"Mme.\",\"Mrs.\")                 ~ \"F_married\",\n    title %in% c(\"Countess.\",\"Lady.\",\"Dona.\")   ~ \"F_titled\",\n    title %in% c(\"Capt.\",\"Col.\",\"Major.\")       ~ \"Military\",\n    title %in% c(\"Dr.\",\"Rev.\")                  ~ \"M_Professional\",\n    title %in% c(\"Don.\",\"Jonkheer.\",\"Sir.\")     ~ \"M_titled\",\n    TRUE ~ title\n  ),\n  surname        = str_extract(name,\"(\\\\w+)(\\\\,)\"),\n  survival       = ifelse(survived==0,\"No\",\"Yes\"),\n  ticket_preface = str_extract(ticket,\"([:graph:]+)(\\\\s)\"),\n  ticket_preface = ifelse(is.na(ticket_preface),\"none\",ticket_preface),\n  cabin_preface  = ifelse(is.na(cabin),\"nk\",\n                    substr(cabin,1,1)),\n  embarked       = ifelse(is.na(embarked),\"S\",embarked)\n  ) %>% \n  group_by(pax_type,pclass) %>% \n  mutate(age     = ifelse(is.na(age),median(age,na.rm = T), age)) %>% \n  ungroup() %>% \n  add_count(ticket,name = \"ticket_group\") %>% \n  mutate(ticket_group = case_when(\n    ticket_group == 1 ~ \"single\",\n    ticket_group == 2 ~ \"couple\",\n    TRUE              ~ \"group\"\n  ),\n    family_group = as.numeric(sib_sp)+as.numeric(parch)+1\n  ) %>% \n  mutate(family_group = factor(\n    case_when(\n        family_group < 2  ~ \"single\",\n        family_group < 3  ~ \"couple\",\n        TRUE              ~ \"family\"\n        ),\n    ordered = TRUE)\n  ) %>% \n  mutate(age_group = factor(case_when(\n    age < 13      ~ \"child\",\n    age < 20      ~ \"teen\",\n    age < 30      ~ \"20s\",\n    age < 40      ~ \"30s\",\n    age < 50      ~ \"40s\",\n    age < 60      ~ \"50s\",\n    TRUE          ~ \"60+\"\n    \n  ),\n  ordered = TRUE)\n  ) %>% \n  mutate(across(where(is.character),as_factor)) %>% \n  mutate(pclass = factor(pclass,levels = c(\"1\",\"2\",\"3\")),\n         survived = factor(survived)\n         ) %>% \nselect(-c(title,ticket_preface))\n  \n#all_proc %>% glimpse() \n\n\n\n\n0.3.4 A bit more EDA\n\n\nCode\nall_proc %>% \n  select(-c(name,ticket,cabin,surname,train_test)) %>% \n  DataExplorer::plot_bar()\n\n\n\n\n\n\n\n\n\n\nCode\nall_proc %>% DataExplorer::plot_histogram(ggtheme = theme_light() )\n\n\n\n\n\n\n\n0.3.5 Eyeballing Survival Graphs on Training Data\n\n\nCode\nno_f <- all_proc %>%\n  filter(train_test == \"train\") %>% \n  select(passenger_id,pclass,sex,embarked,pax_type,ticket_group,family_group,age_group,cabin_preface,survival) %>% \n  droplevels() %>%\n  mutate(across(where(is.factor),~ factor(.x,ordered = FALSE))) %>%\n  pivot_longer(cols = c(pclass:cabin_preface)) \n\n\ng_l <- no_f %>% \n  split(.$name) %>% \n  map(~ ggplot(.,aes(y=value,fill=survival)) +\n                geom_bar() +\n              ggtitle(.$name) +\n        theme_bw() +\n        labs(x=NULL,y=NULL)+\n        scale_fill_viridis_d(option = \"cividis\")\n      \n            ) \n\nlibrary(patchwork)\nwrap_plots(g_l, ncol = 2)\n\n\n\n\n\n\n\n0.3.6 Split Data back to Train/Test/Validation\n\n\nCode\ntrain_proc_adj_tbl <- all_proc %>% \n  filter(train_test ==\"train\") %>% \n  select(-c(survival))\n\n\n  \ntrain_split <- initial_split(train_proc_adj_tbl,strata = survived)\n\ntrain_train <- training(train_split)\ntrain_test <- testing(train_split)"
  },
  {
    "objectID": "posts/post-with-code/index.html#regularised-logistic-regression---glmnet",
    "href": "posts/post-with-code/index.html#regularised-logistic-regression---glmnet",
    "title": "Titanic from Kaggle",
    "section": "0.6 Regularised Logistic Regression - GLMNET",
    "text": "0.6 Regularised Logistic Regression - GLMNET\n\n0.6.1 RLR Model Spec\n\n\nCode\nrlr_model <- \n  logistic_reg(penalty = tune(), mixture = tune()) %>% \n  set_engine(\"glmnet\")\nrlr_model\n\n\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = tune()\n\nComputational engine: glmnet \n\n\n\n\n0.6.2 RLR Parameter Tuning\n\n\nCode\nrlr_param <- extract_parameter_set_dials(rlr_model)\n\nrlr_grid <- grid_latin_hypercube(\n  penalty(),\n  mixture(),\n  size = 30\n)\nhead(rlr_grid) %>% knitr::kable(digits =3)\n\n\n\n\n\npenalty\nmixture\n\n\n\n\n0.116\n0.866\n\n\n0.095\n0.736\n\n\n0.000\n0.141\n\n\n0.000\n0.458\n\n\n0.025\n0.983\n\n\n0.484\n0.109\n\n\n\n\n\n\n\n0.6.3 RLR Workflow\n\n\nCode\nrlr_wflow <- \n  workflow() %>% \n  add_model(rlr_model) %>% \n  add_recipe(recipe_base)\nrlr_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = tune()\n\nComputational engine: glmnet \n\n\n\n\n0.6.4 RLR Hyper-parameter Tuning\n\n\nCode\n# rlr_folds <- vfold_cv(training(train_split), strata = survived, v=10,repeats = 5)\n# rlr_folds %>% tidy()\n\n#doParallel::registerDoParallel(cores = cores)\ncl <- parallel::makePSOCKcluster(cores - 1)\n\nset.seed(234)\nrlr_tuning_result <- tune_grid(\n  rlr_wflow,\n  resamples = folds,\n  grid      = rlr_grid,\n  control   = control_grid(save_pred = TRUE, save_workflow = TRUE)\n)\n\nrlr_tuning_metrics <- collect_metrics(rlr_tuning_result)\nhead(rlr_tuning_metrics) %>% knitr::kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npenalty\nmixture\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n0.016\n0.018\naccuracy\nbinary\n0.821\n5\n0.016\nPreprocessor1_Model01\n\n\n0.016\n0.018\nroc_auc\nbinary\n0.865\n5\n0.009\nPreprocessor1_Model01\n\n\n0.000\n0.066\naccuracy\nbinary\n0.825\n5\n0.015\nPreprocessor1_Model02\n\n\n0.000\n0.066\nroc_auc\nbinary\n0.857\n5\n0.008\nPreprocessor1_Model02\n\n\n0.000\n0.070\naccuracy\nbinary\n0.825\n5\n0.015\nPreprocessor1_Model03\n\n\n0.000\n0.070\nroc_auc\nbinary\n0.857\n5\n0.008\nPreprocessor1_Model03\n\n\n\n\n\nCode\nparallel::stopCluster(cl)\n\n\nReview hyper-parameter tuning results and select best\n\n\nCode\nrlr_tuning_result %>%\n  collect_metrics() %>%\n  filter(.metric == \"accuracy\") %>%\n  select(mean, penalty,mixture) %>%\n  pivot_longer(penalty:mixture,\n               values_to = \"value\",\n               names_to = \"parameter\"\n  ) %>%\n  ggplot(aes(value, mean, color = parameter)) +\n  geom_point(alpha = 0.8, show.legend = FALSE) +\n  facet_wrap(~parameter, scales = \"free_x\") +\n  labs(x = NULL, y = \"AUC\")\n\n\n\n\n\nCode\nshow_best(rlr_tuning_result, \"accuracy\")\n\n\n# A tibble: 5 × 8\n   penalty mixture .metric  .estimator  mean     n std_err .config              \n     <dbl>   <dbl> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n1 8.86e- 3   0.923 accuracy binary     0.829     5  0.0169 Preprocessor1_Model28\n2 1.36e- 9   0.141 accuracy binary     0.826     5  0.0137 Preprocessor1_Model05\n3 1.30e-10   0.182 accuracy binary     0.826     5  0.0137 Preprocessor1_Model06\n4 5.43e- 9   0.211 accuracy binary     0.826     5  0.0137 Preprocessor1_Model07\n5 2.52e- 8   0.241 accuracy binary     0.826     5  0.0137 Preprocessor1_Model08\n\n\nCode\nbest_rlr_auc <- select_best(rlr_tuning_result, \"accuracy\")\nbest_rlr_auc\n\n\n# A tibble: 1 × 3\n  penalty mixture .config              \n    <dbl>   <dbl> <chr>                \n1 0.00886   0.923 Preprocessor1_Model28\n\n\n\n\n0.6.5 RLR Predict\n\n\nCode\nrlr_final_wflow <- finalize_workflow(\n  rlr_wflow,\n  best_rlr_auc\n)\n\nrlr_final_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = 0.00885574773491923\n  mixture = 0.923322001239285\n\nComputational engine: glmnet \n\n\nCode\nrlr_final_wflow %>%\n  last_fit(train_split) %>%\n  extract_fit_parsnip() %>%\n  vip(geom = \"col\")\n\n\n\n\n\n\n\nCode\nrlr_final_fit <- rlr_final_wflow %>%\n  last_fit(train_split)\n\nrlr_final_metrics <- collect_metrics(rlr_final_fit)\nrlr_final_metrics %>% knitr::kable()\n\n\n\n\n\n.metric\n.estimator\n.estimate\n.config\n\n\n\n\naccuracy\nbinary\n0.8080357\nPreprocessor1_Model1\n\n\nroc_auc\nbinary\n0.8424756\nPreprocessor1_Model1\n\n\n\n\n\nCode\nrlr_test_predictions <- rlr_final_fit %>% collect_predictions()\nrlr_test_predictions_all <- rlr_test_predictions %>% \n  bind_cols(train_test %>% select(-survived)) \n\n\n\nglimpse(rlr_test_predictions_all)\n\n\nRows: 224\nColumns: 25\n$ id            <chr> \"train/test split\", \"train/test split\", \"train/test spli…\n$ .pred_0       <dbl> 0.1216896, 0.8658490, 0.9641622, 0.7243443, 0.2225635, 0…\n$ .pred_1       <dbl> 0.87831041, 0.13415097, 0.03583775, 0.27565575, 0.777436…\n$ .row          <int> 10, 11, 14, 18, 20, 23, 28, 40, 41, 51, 54, 57, 61, 66, …\n$ .pred_class   <fct> 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0,…\n$ survived      <fct> 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1,…\n$ .config       <chr> \"Preprocessor1_Model1\", \"Preprocessor1_Model1\", \"Preproc…\n$ passenger_id  <dbl> 10, 11, 14, 18, 20, 23, 28, 40, 41, 51, 54, 57, 61, 66, …\n$ pclass        <fct> 2, 3, 3, 2, 3, 3, 1, 3, 3, 3, 2, 2, 3, 3, 2, 3, 3, 2, 3,…\n$ name          <fct> \"Nasser, Mrs. Nicholas (Adele Achem)\", \"Sandstrom, Miss.…\n$ sex           <fct> female, female, male, male, female, female, male, female…\n$ age           <dbl> 14, 4, 39, 30, 31, 15, 19, 14, 40, 7, 29, 21, 22, 6, 21,…\n$ sib_sp        <dbl> 1, 1, 1, 0, 0, 0, 3, 1, 1, 4, 1, 0, 0, 1, 0, 0, 0, 0, 3,…\n$ parch         <dbl> 0, 1, 5, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,…\n$ ticket        <fct> 237736, PP 9549, 347082, 244373, 2649, 330923, 19950, 26…\n$ fare          <dbl> 30.0708, 16.7000, 31.2750, 13.0000, 7.2250, 8.0292, 263.…\n$ cabin         <fct> NA, G6, NA, NA, NA, NA, C23 C25 C27, NA, NA, NA, NA, NA,…\n$ embarked      <fct> C, S, S, S, C, Q, S, C, S, S, S, S, C, C, S, S, Q, S, S,…\n$ train_test    <fct> train, train, train, train, train, train, train, train, …\n$ pax_type      <fct> F_married, F_unmarried, Mr., Mr., F_married, F_unmarried…\n$ surname       <fct> \"Nasser,\", \"Sandstrom,\", \"Andersson,\", \"Williams,\", \"Mas…\n$ cabin_preface <fct> nk, G, nk, nk, nk, nk, C, nk, nk, nk, nk, nk, nk, nk, nk…\n$ ticket_group  <fct> couple, group, group, single, single, single, group, cou…\n$ family_group  <ord> couple, family, family, single, single, single, family, …\n$ age_group     <ord> teen, child, 30s, 30s, 30s, teen, teen, teen, 40s, child…\n\n\nCode\n# rlr_pred <- predict(rlr_final_fit,train_2 )%>% \n#   bind_cols(predict(rlr_final_fit, train_2,type=\"prob\")) %>% \n#   bind_cols(train_2 %>% select(survived))\n# \n# rlr_pred %>% \n#   roc_auc(truth = survived, .pred_1, event_level = \"second\")\n# \n# rlr_pred %>% \n#   roc_curve(truth = survived, .pred_1,event_level=\"second\") %>% \n#   autoplot()\n# \n# \n# rlr_metrics <- rlr_pred %>% \n# metrics(truth = survived, estimate = .pred_class) %>% \n#   filter(.metric == \"accuracy\")\n# rlr_metrics\n# survive_rlr_pred <- \n#   augment(survive_lr_fit, train_2)\n# survive_rlr_pred\n\n\n\n\n0.6.6 RLR Confusion Matrix\n\n\nCode\nrlr_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#random-forest",
    "href": "posts/post-with-code/index.html#random-forest",
    "title": "Titanic from Kaggle",
    "section": "0.7 Random Forest",
    "text": "0.7 Random Forest\n\n0.7.1 RF Model Spec - Ranger\n\n\nCode\nrf_model <- \n  rand_forest(\n    trees = 1000,\n    mtry  = tune(),\n    min_n = tune()\n    ) %>% \n  set_engine(\"ranger\",importance = \"permutation\") %>% \n  set_mode(\"classification\")\n\n\n\n\n0.7.2 RF Workflow\n\n\nCode\nrf_wflow <- \n  workflow() %>% \n  add_model(rf_model) %>% \n  add_recipe(recipe_base)\n\n\n\n\n0.7.3 RF Tuning - Initial\n\n\nCode\ncl <- parallel::makePSOCKcluster(cores - 1)\n\nset.seed(1234)\nrf_tuning_result <- tune_grid(\n  rf_wflow,\n  resamples = folds,\n  grid = 20\n)\nparallel::stopCluster(cl)\n\nrf_tuning_result\n\n\n# Tuning results\n# 5-fold cross-validation using stratification \n# A tibble: 5 × 4\n  splits            id    .metrics          .notes          \n  <list>            <chr> <list>            <list>          \n1 <split [532/135]> Fold1 <tibble [40 × 6]> <tibble [0 × 3]>\n2 <split [534/133]> Fold2 <tibble [40 × 6]> <tibble [0 × 3]>\n3 <split [534/133]> Fold3 <tibble [40 × 6]> <tibble [0 × 3]>\n4 <split [534/133]> Fold4 <tibble [40 × 6]> <tibble [0 × 3]>\n5 <split [534/133]> Fold5 <tibble [40 × 6]> <tibble [0 × 3]>\n\n\nCode\nrf_tuning_result %>% \n  collect_metrics() %>% \n  filter(.metric == \"accuracy\") %>% \n  select(mean,min_n,mtry) %>% \n  pivot_longer(min_n:mtry) %>% \n  ggplot(aes(value, mean, color = name)) +\n  geom_point(show.legend = FALSE) +\n  facet_wrap(~name, scales = \"free_x\") +\n  labs(x = NULL, y = \"Accuracy\")\n\n\n\n\n\nBit hard to make much of it, but say min_n between 10 and 40 and mtry between 10 and 30?\n\n\nCode\nrf_grid <- grid_regular(\n  mtry(range = c(5, 40)),\n  min_n(range = c(5, 30)),\n  levels = 5\n)\n\nrf_grid\n\n\n# A tibble: 25 × 2\n    mtry min_n\n   <int> <int>\n 1     5     5\n 2    13     5\n 3    22     5\n 4    31     5\n 5    40     5\n 6     5    11\n 7    13    11\n 8    22    11\n 9    31    11\n10    40    11\n# … with 15 more rows\n\n\n\n\n0.7.4 RF Graph Results\n\n\nCode\ncl <- parallel::makePSOCKcluster(cores - 1)\n\n\nset.seed(1234)\nrf_grid_tune <- tune_grid(\n  rf_wflow,\n  resamples = folds,\n  grid = rf_grid\n)\nrf_grid_tune\n\n\n# Tuning results\n# 5-fold cross-validation using stratification \n# A tibble: 5 × 4\n  splits            id    .metrics          .notes          \n  <list>            <chr> <list>            <list>          \n1 <split [532/135]> Fold1 <tibble [50 × 6]> <tibble [5 × 3]>\n2 <split [534/133]> Fold2 <tibble [50 × 6]> <tibble [5 × 3]>\n3 <split [534/133]> Fold3 <tibble [50 × 6]> <tibble [5 × 3]>\n4 <split [534/133]> Fold4 <tibble [50 × 6]> <tibble [5 × 3]>\n5 <split [534/133]> Fold5 <tibble [50 × 6]> <tibble [5 × 3]>\n\nThere were issues with some computations:\n\n  - Warning(s) x10: 40 columns were requested but there were 33 predictors in the dat...   - Warning(s) x15: 40 columns were requested but there were 33 predictors in the dat...\n\nRun `show_notes(.Last.tune.result)` for more information.\n\n\nCode\nparallel::stopCluster(cl)\n\nrf_grid_tune %>%\n  collect_metrics() %>%\n  filter(.metric == \"accuracy\") %>%\n  mutate(min_n = factor(min_n)) %>%\n  ggplot(aes(mtry, mean, color = min_n)) +\n  geom_line(alpha = 0.5, size = 1.5) +\n  geom_point() +\n  labs(y = \"Accuracy\")\n\n\n\n\n\nWell that’s interesting, lets see what tune thinks is best\n\n\nCode\nrf_best_params <- select_best(rf_grid_tune,\"accuracy\")\nrf_best_params %>% knitr::kable()\n\n\n\n\n\nmtry\nmin_n\n.config\n\n\n\n\n31\n17\nPreprocessor1_Model14\n\n\n\n\n\n\n\n0.7.5 RF Final Model\n\n\nCode\nrf_final_model <- finalize_model(\n  rf_model,\n  rf_best_params\n)\nrf_final_model\n\n\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = 31\n  trees = 1000\n  min_n = 17\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger \n\n\n\n\n0.7.6 RF Final Workflow\n\n\nCode\nrf_final_wflow <- finalize_workflow(\n  rf_wflow,\n  rf_best_params\n)\n\nrf_final_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = 31\n  trees = 1000\n  min_n = 17\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger \n\n\n\n\n0.7.7 RF Parameter Importance\n\n\nCode\nrf_final_wflow %>%\n  fit(data = train_proc_adj_tbl) %>%\n  extract_fit_parsnip() %>%\n  vip(geom = \"point\")\n\n\n\n\n\n\n\n0.7.8 RF Final Fit\n\n\nCode\nrf_final_fit <- \n  rf_final_wflow %>% \n  last_fit(train_split)\n\nrf_final_metrics <- collect_metrics(rf_final_fit)\nrf_final_metrics\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.821 Preprocessor1_Model1\n2 roc_auc  binary         0.874 Preprocessor1_Model1\n\n\n\n\n0.7.9 RF Predict\n\n\nCode\n# rf_final_fit <- rf_wflow %>% fit(train_test)\n# class(rf_final_fit)\n\n rf_test_predictions <- \n   collect_predictions(rf_final_fit)\n   # fit(rf_final_wflow,train_train) %>% \n   # predict(rf_final_wflow, new_data = train_test) %>% \n   #bind_cols(predict(rf_final_wflow, train_test,type = \"prob\")) %>% \n   #bind_cols(train_test %>% select(survived))\n\n \n head(rf_test_predictions)\n\n\n# A tibble: 6 × 7\n  id               .pred_0 .pred_1  .row .pred_class survived .config           \n  <chr>              <dbl>   <dbl> <int> <fct>       <fct>    <chr>             \n1 train/test split  0.0101   0.990    10 1           1        Preprocessor1_Mod…\n2 train/test split  0.386    0.614    11 1           1        Preprocessor1_Mod…\n3 train/test split  0.703    0.297    14 0           0        Preprocessor1_Mod…\n4 train/test split  0.884    0.116    18 0           1        Preprocessor1_Mod…\n5 train/test split  0.370    0.630    20 1           1        Preprocessor1_Mod…\n6 train/test split  0.598    0.402    23 0           1        Preprocessor1_Mod…\n\n\n\n\n0.7.10 RF Performance on Test Set\n\n\nCode\n# rf_test_predictions %>% \n#   roc_auc(truth = survived, .pred_1,event_level = \"second\")\n\nrf_metrics_accuracy <- rf_test_predictions %>% \n  metrics(truth = survived, estimate = .pred_class) %>% \n  filter(.metric == \"accuracy\")\nrf_metrics_accuracy\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.821\n\n\nCode\nrf_test_predictions %>% \n  roc_curve(truth = survived, .pred_1,event_level = \"second\") %>% \n  autoplot()\n\n\n\n\n\n\n\n0.7.11 RF Confusion Matrix\n\n\nCode\nrf_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#xg-boost---usemodel",
    "href": "posts/post-with-code/index.html#xg-boost---usemodel",
    "title": "Titanic from Kaggle",
    "section": "0.8 XG Boost - Usemodel",
    "text": "0.8 XG Boost - Usemodel\n\n0.8.1 XGB - Usemodel Library specs\n\n\nCode\nlibrary(usemodels)\n\nuse_xgboost(survived ~ .,\n            data=train_train,\n            verbose = TRUE\n  \n)\n\n\nxgboost_recipe <- \n  recipe(formula = survived ~ ., data = train_train) %>% \n  step_novel(all_nominal_predictors()) %>% \n  ## This model requires the predictors to be numeric. The most common \n  ## method to convert qualitative predictors to numeric is to create \n  ## binary indicator variables (aka dummy variables) from these \n  ## predictors. However, for this model, binary indicator variables can be \n  ## made for each of the levels of the factors (known as 'one-hot \n  ## encoding'). \n  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>% \n  step_zv(all_predictors()) \n\nxgboost_spec <- \n  boost_tree(trees = tune(), min_n = tune(), tree_depth = tune(), learn_rate = tune(), \n    loss_reduction = tune(), sample_size = tune()) %>% \n  set_mode(\"classification\") %>% \n  set_engine(\"xgboost\") \n\nxgboost_workflow <- \n  workflow() %>% \n  add_recipe(xgboost_recipe) %>% \n  add_model(xgboost_spec) \n\nset.seed(19336)\nxgboost_tune <-\n  tune_grid(xgboost_workflow, resamples = stop(\"add your rsample object\"), grid = stop(\"add number of candidate points\"))\n\n\n\n\n0.8.2 XGB - Parameters\nThis grid is used for both versions of XG Boost.\n\n\nCode\nxgb_grid <- grid_latin_hypercube(\n  tree_depth(),\n  min_n(),\n  trees(),\n  loss_reduction(),\n  sample_size = sample_prop(),\n  finalize(mtry(), train_train),\n  learn_rate(),\n  size = 30\n)\n\nhead(xgb_grid)\n\n\n# A tibble: 6 × 7\n  tree_depth min_n trees loss_reduction sample_size  mtry    learn_rate\n       <int> <int> <int>          <dbl>       <dbl> <int>         <dbl>\n1         14    30  1603   0.0230             0.806    13 0.00985      \n2         11     9    22   0.0000361          0.983     3 0.0000469    \n3          1    17   848   0.00581            0.539    11 0.00559      \n4         10     8  1097   0.00000104         0.652     8 0.00000000128\n5         11    19  1422   1.00               0.283     6 0.00124      \n6         15    32  1007   0.0000000318       0.919    15 0.00000608   \n\n\n\n\nCode\nxgboost_usemodel_recipe <- \n  recipe(formula = survived ~ ., data = train_train) %>% \n  step_novel(all_nominal_predictors()) %>% \n  ## This model requires the predictors to be numeric. The most common \n  ## method to convert qualitative predictors to numeric is to create \n  ## binary indicator variables (aka dummy variables) from these \n  ## predictors. However, for this model, binary indicator variables can be \n  ## made for each of the levels of the factors (known as 'one-hot \n  ## encoding'). \n  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>% \n  step_zv(all_predictors()) \n\nxgboost_usemodel_model <- \n  boost_tree(trees = tune(), mtry = tune(),min_n = tune(), tree_depth = tune(), learn_rate = tune(), \n    loss_reduction = tune(), sample_size = tune()) %>% \n  set_mode(\"classification\") %>% \n  set_engine(\"xgboost\") \n\nxgboost_usemodel_wflow <- \n  workflow() %>% \n  add_recipe(xgboost_usemodel_recipe) %>% \n  add_model(xgboost_usemodel_model) \n\n#doParallel::registerDoParallel(cores = cores)\ncl <- parallel::makePSOCKcluster(cores - 1)\n\nset.seed(1234)\nxgboost_usemodel_tune <-\n  tune_grid(xgboost_usemodel_wflow, resamples = folds, grid = xgb_grid)\n\nparallel::stopCluster(cl)\n\n\n\n\n0.8.3 XGB - Usemodel Best Parameter Settings\n\n\nCode\nxgb_tuning_metrics_usemodel <- collect_metrics(xgboost_usemodel_tune)\nxgb_tuning_metrics_usemodel\n\n\n# A tibble: 60 × 13\n    mtry trees min_n tree_depth learn_r…¹ loss_r…² sampl…³ .metric .esti…⁴  mean\n   <int> <int> <int>      <int>     <dbl>    <dbl>   <dbl> <chr>   <chr>   <dbl>\n 1    11   848    17          1   5.59e-3 5.81e- 3   0.539 accura… binary  0.708\n 2    11   848    17          1   5.59e-3 5.81e- 3   0.539 roc_auc binary  0.823\n 3     9  1145    10          2   5.20e-8 1.60e- 1   0.866 accura… binary  0.702\n 4     9  1145    10          2   5.20e-8 1.60e- 1   0.866 roc_auc binary  0.821\n 5    17   740    15          2   8.39e-2 6.64e- 9   0.252 accura… binary  0.743\n 6    17   740    15          2   8.39e-2 6.64e- 9   0.252 roc_auc binary  0.776\n 7    12   690    38          2   3.89e-9 5.16e-10   0.146 accura… binary  0.616\n 8    12   690    38          2   3.89e-9 5.16e-10   0.146 roc_auc binary  0.5  \n 9    10  1314    11          3   1.72e-5 1.25e- 1   0.163 accura… binary  0.616\n10    10  1314    11          3   1.72e-5 1.25e- 1   0.163 roc_auc binary  0.757\n# … with 50 more rows, 3 more variables: n <int>, std_err <dbl>, .config <chr>,\n#   and abbreviated variable names ¹​learn_rate, ²​loss_reduction, ³​sample_size,\n#   ⁴​.estimator\n\n\nCode\nxgboost_usemodel_tune %>%\n  collect_metrics() %>%\n  filter(.metric == \"accuracy\") %>%\n  select(mean, mtry:sample_size) %>%\n  pivot_longer(mtry:sample_size,\n               values_to = \"value\",\n               names_to = \"parameter\"\n  ) %>%\n  ggplot(aes(value, mean, color = parameter)) +\n  geom_point(alpha = 0.8, show.legend = FALSE) +\n  facet_wrap(~parameter, scales = \"free_x\") +\n  labs(x = NULL, y = \"Accuracy\")\n\n\n\n\n\nNow select best from above\n\n\nCode\nshow_best(xgboost_usemodel_tune, \"accuracy\")\n\n\n# A tibble: 5 × 13\n   mtry trees min_n tree_d…¹ learn…² loss_…³ sampl…⁴ .metric .esti…⁵  mean     n\n  <int> <int> <int>    <int>   <dbl>   <dbl>   <dbl> <chr>   <chr>   <dbl> <int>\n1    13  1603    30       14 9.85e-3 2.30e-2   0.806 accura… binary  0.766     5\n2     4  1982     4       15 4.01e-2 5.53e-8   0.393 accura… binary  0.754     5\n3    17   740    15        2 8.39e-2 6.64e-9   0.252 accura… binary  0.743     5\n4    11   848    17        1 5.59e-3 5.81e-3   0.539 accura… binary  0.708     5\n5     9  1145    10        2 5.20e-8 1.60e-1   0.866 accura… binary  0.702     5\n# … with 2 more variables: std_err <dbl>, .config <chr>, and abbreviated\n#   variable names ¹​tree_depth, ²​learn_rate, ³​loss_reduction, ⁴​sample_size,\n#   ⁵​.estimator\n\n\nCode\nxgb_usemodel_best_params <- select_best(xgboost_usemodel_tune, \"accuracy\")\nxgb_usemodel_best_params\n\n\n# A tibble: 1 × 8\n   mtry trees min_n tree_depth learn_rate loss_reduction sample_size .config    \n  <int> <int> <int>      <int>      <dbl>          <dbl>       <dbl> <chr>      \n1    13  1603    30         14    0.00985         0.0230       0.806 Preprocess…\n\n\nCode\nxgb_usemodel_final_wflow <- finalize_workflow(\n  xgboost_usemodel_wflow,\n  xgb_usemodel_best_params\n)\n\nxgb_usemodel_final_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: boost_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_novel()\n• step_dummy()\n• step_zv()\n\n── Model ───────────────────────────────────────────────────────────────────────\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = 13\n  trees = 1603\n  min_n = 30\n  tree_depth = 14\n  learn_rate = 0.00985014124434902\n  loss_reduction = 0.0230337047700143\n  sample_size = 0.80635308077326\n\nComputational engine: xgboost \n\n\n\n\n0.8.4 XGB - Usemodel Parameter Ranking - VIP\n\n\nCode\nxgb_usemodel_final_wflow %>%\n  fit(data = train_train) %>%\n  extract_fit_parsnip() %>%\n  vip(geom = \"point\")\n\n\n\n\n\n\n\n0.8.5 XGB - Usemodel Performance\n\nXGB - Usemodel Accuracy Measured on Test Set\n\n\nCode\ncl <- parallel::makePSOCKcluster(cores - 1)\n\nset.seed(1234)\nxgb_usemodel_final_res <- last_fit(xgb_usemodel_final_wflow, train_split)\nxgb_usemodel_final_res\n\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits            id               .metrics .notes   .predictions .workflow \n  <list>            <chr>            <list>   <list>   <list>       <list>    \n1 <split [667/224]> train/test split <tibble> <tibble> <tibble>     <workflow>\n\nThere were issues with some computations:\n\n  - Warning(s) x2: There are new levels in a factor: NA\n\nRun `show_notes(.Last.tune.result)` for more information.\n\n\nCode\nxgb_usemodel_final_metrics <- collect_metrics(xgb_usemodel_final_res)\nxgb_usemodel_final_metrics\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.670 Preprocessor1_Model1\n2 roc_auc  binary         0.797 Preprocessor1_Model1\n\n\nCode\nparallel::stopCluster(cl)\n\n\n\n\nXGB - Usemodel AUC on Test Set (within train)\n\n\nCode\nxgb_usemodel_final_res %>%\n  collect_predictions() %>%\n  roc_curve( truth = survived,.pred_1, event_level = \"second\") %>%\n  ggplot(aes(x = 1-specificity, y = sensitivity)) +\n  geom_line(size = 1.5, color = \"midnightblue\") +\n  geom_abline(\n    lty = 2, alpha = 0.5,\n    color = \"gray50\",\n    size = 1.2\n  )\n\n\n\n\n\n\n\nCode\nxgb_usemodel_test_predictions <- collect_predictions(xgb_usemodel_final_res)\nhead(xgb_usemodel_test_predictions)\n\n\n# A tibble: 6 × 7\n  id               .pred_0 .pred_1  .row .pred_class survived .config           \n  <chr>              <dbl>   <dbl> <int> <fct>       <fct>    <chr>             \n1 train/test split   0.534   0.466    10 0           1        Preprocessor1_Mod…\n2 train/test split   0.291   0.709    11 1           1        Preprocessor1_Mod…\n3 train/test split   0.733   0.267    14 0           0        Preprocessor1_Mod…\n4 train/test split   0.736   0.264    18 0           1        Preprocessor1_Mod…\n5 train/test split   0.640   0.360    20 0           1        Preprocessor1_Mod…\n6 train/test split   0.625   0.375    23 0           1        Preprocessor1_Mod…\n\n\n\n\n\n0.8.6 XGB - Usemodel Confusion Matrix\n\n\nCode\nxgb_usemodel_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#xg-boost---base-recipe",
    "href": "posts/post-with-code/index.html#xg-boost---base-recipe",
    "title": "Titanic from Kaggle",
    "section": "0.9 XG Boost - Base Recipe",
    "text": "0.9 XG Boost - Base Recipe\n\n0.9.1 XGB Model Spec\n\n\nCode\nxgb_model <- \n  boost_tree(\n    trees = tune(),\n    tree_depth = tune(),\n    min_n = tune(),\n    loss_reduction = tune(),\n    sample_size = tune(),\n    mtry = tune(),\n    learn_rate = tune()) %>% \n  set_engine(\"xgboost\") %>% \n  set_mode(\"classification\")\n\nxgb_model\n\n\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = tune()\n  min_n = tune()\n  tree_depth = tune()\n  learn_rate = tune()\n  loss_reduction = tune()\n  sample_size = tune()\n\nComputational engine: xgboost \n\n\n\n\n0.9.2 XGB Workflow\n\n\nCode\nxgb_wflow <- \n  workflow() %>% \n  add_model(xgb_model) %>% \n  add_recipe(recipe_base)\n\n\n\n\n0.9.3 XGB Hyper-Parameter Tuning\n\n\nCode\n# xgb_folds <- vfold_cv(training(train_split), strata = survived)\n# xgb_folds\n\n\n#doParallel::registerDoParallel(cores = cores)\n\nset.seed(1234)\ncl <- parallel::makePSOCKcluster(cores - 1)\n\nxgb_tuning_result <- tune_grid(\n  xgb_wflow,\n  resamples = folds,\n  grid      = xgb_grid,\n  control  = control_grid(save_pred = TRUE,save_workflow = TRUE)\n)\nxgb_tuning_result\n\n\n# Tuning results\n# 5-fold cross-validation using stratification \n# A tibble: 5 × 5\n  splits            id    .metrics           .notes           .predictions\n  <list>            <chr> <list>             <list>           <list>      \n1 <split [532/135]> Fold1 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n2 <split [534/133]> Fold2 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n3 <split [534/133]> Fold3 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n4 <split [534/133]> Fold4 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n5 <split [534/133]> Fold5 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n\n\nCode\nparallel::stopCluster(cl)\n\n\n\n\nCode\nxgb_tuning_metrics <- collect_metrics(xgb_tuning_result)\nxgb_tuning_metrics\n\n\n# A tibble: 60 × 13\n    mtry trees min_n tree_depth learn_r…¹ loss_r…² sampl…³ .metric .esti…⁴  mean\n   <int> <int> <int>      <int>     <dbl>    <dbl>   <dbl> <chr>   <chr>   <dbl>\n 1    11   848    17          1   5.59e-3 5.81e- 3   0.539 accura… binary  0.775\n 2    11   848    17          1   5.59e-3 5.81e- 3   0.539 roc_auc binary  0.844\n 3     9  1145    10          2   5.20e-8 1.60e- 1   0.866 accura… binary  0.775\n 4     9  1145    10          2   5.20e-8 1.60e- 1   0.866 roc_auc binary  0.842\n 5    17   740    15          2   8.39e-2 6.64e- 9   0.252 accura… binary  0.718\n 6    17   740    15          2   8.39e-2 6.64e- 9   0.252 roc_auc binary  0.753\n 7    12   690    38          2   3.89e-9 5.16e-10   0.146 accura… binary  0.616\n 8    12   690    38          2   3.89e-9 5.16e-10   0.146 roc_auc binary  0.5  \n 9    10  1314    11          3   1.72e-5 1.25e- 1   0.163 accura… binary  0.616\n10    10  1314    11          3   1.72e-5 1.25e- 1   0.163 roc_auc binary  0.721\n# … with 50 more rows, 3 more variables: n <int>, std_err <dbl>, .config <chr>,\n#   and abbreviated variable names ¹​learn_rate, ²​loss_reduction, ³​sample_size,\n#   ⁴​.estimator\n\n\nCode\nxgb_tuning_result %>%\n  collect_metrics() %>%\n  filter(.metric == \"accuracy\") %>%\n  select(mean, mtry:sample_size) %>%\n  pivot_longer(mtry:sample_size,\n               values_to = \"value\",\n               names_to = \"parameter\"\n  ) %>%\n  ggplot(aes(value, mean, color = parameter)) +\n  geom_point(alpha = 0.8, show.legend = FALSE) +\n  facet_wrap(~parameter, scales = \"free_x\") +\n  labs(x = NULL, y = \"AUC\")\n\n\n\n\n\n\nXGB Best Parameters then Finalise Workflow\n\n\nCode\nshow_best(xgb_tuning_result, \"accuracy\")\n\n\n# A tibble: 5 × 13\n   mtry trees min_n tree_d…¹ learn…² loss_…³ sampl…⁴ .metric .esti…⁵  mean     n\n  <int> <int> <int>    <int>   <dbl>   <dbl>   <dbl> <chr>   <chr>   <dbl> <int>\n1     4  1982     4       15 4.01e-2 5.53e-8   0.393 accura… binary  0.814     5\n2    15  1689     7       13 2.02e-9 5.67e-6   0.958 accura… binary  0.784     5\n3    16  1549     6        7 1.36e-4 4.92e-4   0.463 accura… binary  0.783     5\n4    19   259    16        9 6.05e-7 1.64e-4   0.735 accura… binary  0.781     5\n5    13  1603    30       14 9.85e-3 2.30e-2   0.806 accura… binary  0.780     5\n# … with 2 more variables: std_err <dbl>, .config <chr>, and abbreviated\n#   variable names ¹​tree_depth, ²​learn_rate, ³​loss_reduction, ⁴​sample_size,\n#   ⁵​.estimator\n\n\nCode\nxgb_best_params <- select_best(xgb_tuning_result, \"accuracy\")\nxgb_best_params\n\n\n# A tibble: 1 × 8\n   mtry trees min_n tree_depth learn_rate loss_reduction sample_size .config    \n  <int> <int> <int>      <int>      <dbl>          <dbl>       <dbl> <chr>      \n1     4  1982     4         15     0.0401   0.0000000553       0.393 Preprocess…\n\n\nCode\nxgb_final_wflow <- finalize_workflow(\n  xgb_wflow,\n  xgb_best_params\n)\n\nxgb_final_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: boost_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = 4\n  trees = 1982\n  min_n = 4\n  tree_depth = 15\n  learn_rate = 0.0400670375292599\n  loss_reduction = 5.52655767061452e-08\n  sample_size = 0.392634701682255\n\nComputational engine: xgboost \n\n\n\n\nCode\nxgb_final_wflow %>%\n  fit(data = train_train) %>%\n  extract_fit_parsnip() %>%\n  vip(geom = \"point\")\n\n\n\n\n\n\n\n\n0.9.4 XGB Performance on Training Test Set\n\nXGB Accuracy Measured on Test Set\n\n\nCode\nxgb_final_res <- last_fit(xgb_final_wflow, train_split)\nxgb_final_res\n\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits            id               .metrics .notes   .predictions .workflow \n  <list>            <chr>            <list>   <list>   <list>       <list>    \n1 <split [667/224]> train/test split <tibble> <tibble> <tibble>     <workflow>\n\n\nCode\nxgb_final_metrics <- collect_metrics(xgb_final_res)\nxgb_final_metrics\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.839 Preprocessor1_Model1\n2 roc_auc  binary         0.870 Preprocessor1_Model1\n\n\n\n\nXGB AUC on Test Set (within train)\n\n\nCode\nxgb_final_res %>%\n  collect_predictions() %>%\n  roc_curve( truth = survived,.pred_1, event_level = \"second\") %>%\n  ggplot(aes(x = 1-specificity, y = sensitivity)) +\n  geom_line(size = 1.5, color = \"midnightblue\") +\n  geom_abline(\n    lty = 2, alpha = 0.5,\n    color = \"gray50\",\n    size = 1.2\n  )\n\n\n\n\n\n\n\nCode\nxgb_test_predictions <- collect_predictions(xgb_final_res)\nhead(xgb_test_predictions)\n\n\n# A tibble: 6 × 7\n  id               .pred_0 .pred_1  .row .pred_class survived .config           \n  <chr>              <dbl>   <dbl> <int> <fct>       <fct>    <chr>             \n1 train/test split  0.0609  0.939     10 1           1        Preprocessor1_Mod…\n2 train/test split  0.346   0.654     11 1           1        Preprocessor1_Mod…\n3 train/test split  0.968   0.0321    14 0           0        Preprocessor1_Mod…\n4 train/test split  0.845   0.155     18 0           1        Preprocessor1_Mod…\n5 train/test split  0.385   0.615     20 1           1        Preprocessor1_Mod…\n6 train/test split  0.319   0.681     23 1           1        Preprocessor1_Mod…\n\n\n\n\n\n0.9.5 XGB Confusion Matrix\n\n\nCode\nxgb_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#neural-net",
    "href": "posts/post-with-code/index.html#neural-net",
    "title": "Titanic from Kaggle",
    "section": "0.10 Neural Net",
    "text": "0.10 Neural Net\n\n0.10.1 NN Model\n\n\nCode\nnnet_model <- \n   mlp(hidden_units = tune(), penalty = tune(), epochs = tune()) %>% \n   set_engine(\"nnet\", MaxNWts = 2600) %>% \n   set_mode(\"classification\")\n\nnnet_model %>% translate()\n\n\nSingle Layer Neural Network Model Specification (classification)\n\nMain Arguments:\n  hidden_units = tune()\n  penalty = tune()\n  epochs = tune()\n\nEngine-Specific Arguments:\n  MaxNWts = 2600\n\nComputational engine: nnet \n\nModel fit template:\nnnet::nnet(formula = missing_arg(), data = missing_arg(), size = tune(), \n    decay = tune(), maxit = tune(), MaxNWts = 2600, trace = FALSE, \n    linout = FALSE)\n\n\n\n\n0.10.2 NN Workflow\n\n\nCode\nnnet_wflow <- workflow() %>% \n  add_model(nnet_model) %>% \n  add_recipe(recipe_base)\n\n\n\n\n0.10.3 NN Parameters\n\n\nCode\nnnet_grid <- grid_latin_hypercube(\n  hidden_units(),\n  penalty (),\n  epochs ()\n)\n\nhead(nnet_grid) \n\n\n# A tibble: 3 × 3\n  hidden_units  penalty epochs\n         <int>    <dbl>  <int>\n1            7 7.66e- 5    944\n2            6 6.36e-10    524\n3            2 1.80e- 3    146\n\n\n\n\n0.10.4 NN Hyper-Parameter Tuning\n\n\nCode\n# nnet_folds <- vfold_cv(train_train, strata = survived)\n# nnet_folds\n\n\n# doParallel::registerDoParallel(cores = cores)\ncl <- parallel::makePSOCKcluster(cores - 1)\n\nset.seed(1234)\nnnet_tuning_result <- tune_grid(\n  nnet_wflow,\n  resamples = folds,\n  grid      = nnet_grid,\n  control   = control_grid(save_pred = TRUE,save_workflow = TRUE)\n)\nnnet_tuning_result\n\n\n# Tuning results\n# 5-fold cross-validation using stratification \n# A tibble: 5 × 5\n  splits            id    .metrics         .notes           .predictions      \n  <list>            <chr> <list>           <list>           <list>            \n1 <split [532/135]> Fold1 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [405 × 9]>\n2 <split [534/133]> Fold2 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [399 × 9]>\n3 <split [534/133]> Fold3 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [399 × 9]>\n4 <split [534/133]> Fold4 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [399 × 9]>\n5 <split [534/133]> Fold5 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [399 × 9]>\n\n\nCode\nparallel::stopCluster(cl)\n\n\n\n\n0.10.5 NN Best Parameters and Finalise Workflow\n\n\nCode\nshow_best(nnet_tuning_result, \"accuracy\")\n\n\n# A tibble: 3 × 9\n  hidden_units  penalty epochs .metric  .estimator  mean     n std_err .config  \n         <int>    <dbl>  <int> <chr>    <chr>      <dbl> <int>   <dbl> <chr>    \n1            2 1.80e- 3    146 accuracy binary     0.820     5  0.0161 Preproce…\n2            7 7.66e- 5    944 accuracy binary     0.776     5  0.0372 Preproce…\n3            6 6.36e-10    524 accuracy binary     0.766     5  0.0334 Preproce…\n\n\nCode\nnn_best_params <- select_best(nnet_tuning_result, \"accuracy\")\n\nnnet_best_auc <- select_best(xgb_tuning_result, \"accuracy\")\nnnet_best_auc\n\n\n# A tibble: 1 × 8\n   mtry trees min_n tree_depth learn_rate loss_reduction sample_size .config    \n  <int> <int> <int>      <int>      <dbl>          <dbl>       <dbl> <chr>      \n1     4  1982     4         15     0.0401   0.0000000553       0.393 Preprocess…\n\n\nCode\nnnet_final_wflow <- finalize_workflow(\n  nnet_wflow,\n  nn_best_params\n)\n\nnnet_final_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: mlp()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nSingle Layer Neural Network Model Specification (classification)\n\nMain Arguments:\n  hidden_units = 2\n  penalty = 0.00180188446786651\n  epochs = 146\n\nEngine-Specific Arguments:\n  MaxNWts = 2600\n\nComputational engine: nnet \n\n\n\n\nCode\nnnet_final_wflow %>%\n  fit(data = train_train) %>%\n  extract_fit_parsnip() %>%\n  vip(geom = \"point\")\n\n\n\n\n\n\n\n0.10.6 NN Accuracy - Train/Test Set\n\n\nCode\nnnet_tuning_metrics <- collect_metrics(nnet_tuning_result)\nnnet_tuning_metrics\n\n\n# A tibble: 6 × 9\n  hidden_units  penalty epochs .metric  .estimator  mean     n std_err .config  \n         <int>    <dbl>  <int> <chr>    <chr>      <dbl> <int>   <dbl> <chr>    \n1            7 7.66e- 5    944 accuracy binary     0.776     5  0.0372 Preproce…\n2            7 7.66e- 5    944 roc_auc  binary     0.788     5  0.0395 Preproce…\n3            6 6.36e-10    524 accuracy binary     0.766     5  0.0334 Preproce…\n4            6 6.36e-10    524 roc_auc  binary     0.779     5  0.0421 Preproce…\n5            2 1.80e- 3    146 accuracy binary     0.820     5  0.0161 Preproce…\n6            2 1.80e- 3    146 roc_auc  binary     0.865     5  0.0153 Preproce…\n\n\nCode\nnnet_final_res <- last_fit(nnet_final_wflow, train_split)\nnnet_final_res\n\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits            id               .metrics .notes   .predictions .workflow \n  <list>            <chr>            <list>   <list>   <list>       <list>    \n1 <split [667/224]> train/test split <tibble> <tibble> <tibble>     <workflow>\n\n\nCode\nnnet_final_metrics <- collect_metrics(nnet_final_res)\nnnet_final_metrics\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.786 Preprocessor1_Model1\n2 roc_auc  binary         0.824 Preprocessor1_Model1\n\n\n\n\n0.10.7 NN AUC\n\n\nCode\nnnet_final_res %>%\n  collect_predictions() %>%\n  roc_curve( truth = survived,.pred_1, event_level = \"second\") %>%\n  ggplot(aes(x = 1-specificity, y = sensitivity)) +\n  geom_line(size = 1.5, color = \"midnightblue\") +\n  geom_abline(\n    lty = 2, alpha = 0.5,\n    color = \"gray50\",\n    size = 1.2\n  )\n\n\n\n\n\n\n\n0.10.8 NN Predictions on Train/Test Set\n\n\nCode\nnnet_test_predictions <- nnet_final_res %>%\n  collect_predictions() \nhead(nnet_test_predictions)\n\n\n# A tibble: 6 × 7\n  id               .pred_0 .pred_1  .row .pred_class survived .config           \n  <chr>              <dbl>   <dbl> <int> <fct>       <fct>    <chr>             \n1 train/test split   0.363   0.637    10 1           1        Preprocessor1_Mod…\n2 train/test split   0.603   0.397    11 0           1        Preprocessor1_Mod…\n3 train/test split   0.701   0.299    14 0           0        Preprocessor1_Mod…\n4 train/test split   0.680   0.320    18 0           1        Preprocessor1_Mod…\n5 train/test split   0.363   0.637    20 1           1        Preprocessor1_Mod…\n6 train/test split   0.363   0.637    23 1           1        Preprocessor1_Mod…\n\n\n\n\n0.10.9 NN Confusion Matrix\n\n\nCode\nnnet_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#stack-models---not-working",
    "href": "posts/post-with-code/index.html#stack-models---not-working",
    "title": "Titanic from Kaggle",
    "section": "0.10 Stack Models - not working",
    "text": "0.10 Stack Models - not working\n\n0.10.1 Stack Recipe\n\n\nCode\nrecipe_stack <- \n  recipe(survived ~ ., data = training(train_split)) %>% \n  update_role(passenger_id, name,surname,ticket,cabin,new_role = \"ID\") %>% \n  step_impute_knn(all_numeric_predictors()) %>% \n  step_dummy(all_nominal_predictors()) %>%\n  step_factor2string(all_nominal_predictors()) %>% \n  step_zv(all_predictors()) %>% \n  step_pca()\nrecipe_stack\n\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          5\n   outcome          1\n predictor         13\n\nOperations:\n\nK-nearest neighbor imputation for all_numeric_predictors()\nDummy variables from all_nominal_predictors()\nCharacter variables from all_nominal_predictors()\nZero variance filter on all_predictors()\nPCA extraction with <none>\n\n\nCode\nrecipe_stack_trained <- prep(recipe_base)\nrecipe_stack_trained\n\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          5\n   outcome          1\n predictor         13\n\nTraining data contained 667 data points and 510 incomplete rows. \n\nOperations:\n\nK-nearest neighbor imputation for age, sib_sp, parch, fare [trained]\nDummy variables from pclass, sex, embarked, train_test, pax_type, cabin_prefac... [trained]\nCharacter variables from <none> [trained]\nZero variance filter removed train_test_test, pax_type_F_titled [trained]\nNo PCA components were extracted from <none> [trained]\n\n\n\n\n0.10.2 Stack Controls\n\n\nCode\nstack_ctrl <- control_resamples(save_pred = TRUE, save_workflow = TRUE)\n#stack_folds <- vfold_cv(training(train_split), v=10,strata = \"survived\")\n\nlibrary(stacks)\n\n\nWarning: package 'stacks' was built under R version 4.2.1\n\n\nCode\nmodel_stack <-\n  stacks() %>%\n  #add_candidates(lr_wflow) %>%\n  #add_candidates(rf_wflow) %>%\n  add_candidates(nnet_tuning_result) %>%\n  add_candidates(rlr_tuning_result) %>% \n  add_candidates(xgb_tuning_result)\n\n\nWarning: Predictions from 7 candidates were identical to those from existing\ncandidates and were removed from the data stack.\n\n\n\n\n0.10.3 Stack LR\n\n\nCode\nstack_lr_wflow <- \n  workflow() %>% \n  add_model(lr_spec) %>% \n  add_recipe(recipe_stack)\nlr_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\nCode\nstack_lr_res <- \n  lr_wflow %>% \n  tune_grid(folds,control = stack_ctrl)\n\n\nWarning: No tuning parameters have been detected, performance will be evaluated\nusing the resamples with no tuning. Did you want to [tune()] parameters?\n\n\nCode\nstack_lr_res\n\n\n# Tuning results\n# 5-fold cross-validation using stratification \n# A tibble: 5 × 5\n  splits            id    .metrics         .notes           .predictions      \n  <list>            <chr> <list>           <list>           <list>            \n1 <split [532/135]> Fold1 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [135 × 6]>\n2 <split [534/133]> Fold2 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [133 × 6]>\n3 <split [534/133]> Fold3 <tibble [2 × 4]> <tibble [1 × 3]> <tibble [133 × 6]>\n4 <split [534/133]> Fold4 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [133 × 6]>\n5 <split [534/133]> Fold5 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [133 × 6]>\n\nThere were issues with some computations:\n\n  - Warning(s) x1: prediction from a rank-deficient fit may be misleading\n\nRun `show_notes(.Last.tune.result)` for more information.\n\n\n\n\nCode\n# autoplot(stack_lr_res) + \n#   scale_color_viridis_d(direction = -1) + \n#   theme(legend.position = \"top\")\n\n\n\n\n0.10.4 Stack RLR\n\n\nCode\n# stack_rlr_wflow <- \n#   workflow() %>% \n#   add_model(rlr_model) %>% \n#   add_recipe(recipe_stack)\n# stack_rlr_wflow\n# \n# stack_rlr_res <- \n#   stack_rlr_wflow %>% \n#   fit_resamples(folds,control = stack_ctrl)\n# stack_rlr_res\n\n\n\n\n0.10.5 Initialise Stack\n\n\nCode\nstack_models <-\n  stacks()\nstack_models\n\n\n# A data stack with 0 model definitions and 0 candidate members.\n\n\nCode\nstack_models %>% \nadd_candidates(stack_lr_res)\n\n\nWarning: The inputted `candidates` argument `stack_lr_res` generated notes\nduring tuning/resampling. Model stacking may fail due to these issues; see `?\ncollect_notes` if so.\n\n\n# A data stack with 1 model definition and 1 candidate member:\n#   stack_lr_res: 1 model configuration\n# Outcome: survived (factor)"
  },
  {
    "objectID": "posts/post-with-code/index.html#join-model-prediction-data",
    "href": "posts/post-with-code/index.html#join-model-prediction-data",
    "title": "Titanic from Kaggle",
    "section": "0.12 Join Model Prediction Data",
    "text": "0.12 Join Model Prediction Data\n\n\nCode\nall_predictions <- \n  lr_test_predictions %>% mutate(model = \"LR\") %>% \n  bind_rows(nnet_test_predictions %>% mutate(model = \"NNet\")) %>% \n  bind_rows(rlr_test_predictions %>% mutate(model = \"Reg_LR\")) %>% \n  bind_rows(rf_test_predictions %>% mutate(model = \"RF\")) %>% \n  bind_rows(xgb_test_predictions %>% mutate(model = \"xgb\")) %>% \n  bind_rows(xgb_usemodel_test_predictions %>% mutate(model = \"xgb_usemodel\")) %>% \n  bind_rows(ensemble_test_predictions %>% mutate(model = \"ensemble\"))\n  \nall_predictions %>% head() %>% knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\n.pred_0\n.pred_1\n.row\n.pred_class\nsurvived_pred\n.config\npassenger_id\nsurvived\npclass\nname\nsex\nage\nsib_sp\nparch\nticket\nfare\ncabin\nembarked\ntrain_test\npax_type\nsurname\ncabin_preface\nticket_group\nfamily_group\nage_group\nmodel\n\n\n\n\ntrain/test split\n0.0947816\n0.9052184\n10\n1\n1\nPreprocessor1_Model1\n10\n1\n2\nNasser, Mrs. Nicholas (Adele Achem)\nfemale\n14\n1\n0\n237736\n30.0708\nNA\nC\ntrain\nF_married\nNasser,\nnk\ncouple\ncouple\nteen\nLR\n\n\ntrain/test split\n0.9999997\n0.0000003\n11\n0\n1\nPreprocessor1_Model1\n11\n1\n3\nSandstrom, Miss. Marguerite Rut\nfemale\n4\n1\n1\nPP 9549\n16.7000\nG6\nS\ntrain\nF_unmarried\nSandstrom,\nG\ngroup\nfamily\nchild\nLR\n\n\ntrain/test split\n0.9959939\n0.0040061\n14\n0\n0\nPreprocessor1_Model1\n14\n0\n3\nAndersson, Mr. Anders Johan\nmale\n39\n1\n5\n347082\n31.2750\nNA\nS\ntrain\nMr.\nAndersson,\nnk\ngroup\nfamily\n30s\nLR\n\n\ntrain/test split\n0.7485089\n0.2514911\n18\n0\n1\nPreprocessor1_Model1\n18\n1\n2\nWilliams, Mr. Charles Eugene\nmale\n30\n0\n0\n244373\n13.0000\nNA\nS\ntrain\nMr.\nWilliams,\nnk\nsingle\nsingle\n30s\nLR\n\n\ntrain/test split\n0.1223361\n0.8776639\n20\n1\n1\nPreprocessor1_Model1\n20\n1\n3\nMasselmani, Mrs. Fatima\nfemale\n31\n0\n0\n2649\n7.2250\nNA\nC\ntrain\nF_married\nMasselmani,\nnk\nsingle\nsingle\n30s\nLR\n\n\ntrain/test split\n0.3091538\n0.6908462\n23\n1\n1\nPreprocessor1_Model1\n23\n1\n3\nMcGowan, Miss. Anna “Annie”\nfemale\n15\n0\n0\n330923\n8.0292\nNA\nQ\ntrain\nF_unmarried\nMcGowan,\nnk\nsingle\nsingle\nteen\nLR"
  },
  {
    "objectID": "posts/post-with-code/index.html#all-metrics",
    "href": "posts/post-with-code/index.html#all-metrics",
    "title": "Titanic from Kaggle",
    "section": "0.13 All Metrics",
    "text": "0.13 All Metrics\nOrdered by descending Accuracy metric\n\n\nCode\nall_metrics <- \n  lr_final_metrics %>% mutate(model = \"LR\") %>% \n  bind_rows(nnet_final_metrics %>% mutate(model = \"NNet\")) %>% \n  bind_rows(rlr_final_metrics %>% mutate(model = \"Reg_LR\")) %>% \n  bind_rows(rf_final_metrics %>% mutate(model = \"RF\")) %>% \n  bind_rows(xgb_final_metrics %>% mutate(model = \"xgb\")) %>% \n  bind_rows(xgb_usemodel_final_metrics %>% mutate(model = \"xgb-usemodel\")) \n\nall_metrics_table <- all_metrics %>% \n   pivot_wider(names_from = .metric,values_from = .estimate) %>% \n   arrange(desc(accuracy))\n  \nwrite_rds(all_metrics,\"artifacts/all_metrics.rds\")\n\nall_metrics_table %>% knitr::kable(digits=3)\n\n\n\n\n\n.estimator\n.config\nmodel\naccuracy\nroc_auc\n\n\n\n\nbinary\nPreprocessor1_Model1\nxgb\n0.839\n0.870\n\n\nbinary\nPreprocessor1_Model1\nRF\n0.821\n0.874\n\n\nbinary\nPreprocessor1_Model1\nReg_LR\n0.808\n0.842\n\n\nbinary\nPreprocessor1_Model1\nLR\n0.799\n0.822\n\n\nbinary\nPreprocessor1_Model1\nNNet\n0.786\n0.824\n\n\nbinary\nPreprocessor1_Model1\nxgb-usemodel\n0.670\n0.797\n\n\n\n\n\nand a graph:\n\n\nCode\nall_metrics %>% \n  filter(.metric == \"accuracy\") %>% \n  select(model, accuracy = .estimate) %>% \n  ggplot(aes(model, accuracy)) +\n  geom_col()"
  },
  {
    "objectID": "posts/post-with-code/index.html#ensemble---workflow-sets---not-working",
    "href": "posts/post-with-code/index.html#ensemble---workflow-sets---not-working",
    "title": "Titanic from Kaggle",
    "section": "0.13 Ensemble - Workflow Sets - not working",
    "text": "0.13 Ensemble - Workflow Sets - not working\n\n\nCode\n# no_pre_proc <- \n#    workflow_set(\n#       preproc = list(base = recipe_base), \n#       models = list(RF             = lr_model, \n#                     Regularised_LR = rlr_model, \n#                     Rand_Forest    = rf_model, \n#                     boosting       = xgb_model),\n#       cross = TRUE\n#    )\n# no_pre_proc\n# \n# add_cand"
  },
  {
    "objectID": "posts/post-with-code/index.html#predict-on-test-set",
    "href": "posts/post-with-code/index.html#predict-on-test-set",
    "title": "Titanic from Kaggle",
    "section": "1.1 Predict on Test set",
    "text": "1.1 Predict on Test set\n\n\nCode\n# all_predictions %>% \n# distinct(model)\n\n\n\ntest_proc <- all_proc %>% \n  filter(train_test==\"test\")\n\n# LR ----\nfinal_test_pred_LR <- \n  lr_wflow %>% \n  fit(train_proc_adj_tbl) %>% \n  predict(new_data=test_proc) %>% \n  bind_cols(test_proc)\n\nsubmission_LR <- final_test_pred_LR %>% \n  select(PassengerID = passenger_id,Survived = .pred_class)\n\nwrite_csv(submission_LR,\"titanic_submission_LR.csv\") \n\n\n# RLR ----\nfinal_test_pred_RLR <- \n  rlr_final_wflow %>% \n  fit(train_proc_adj_tbl) %>% \n  predict(new_data=test_proc) %>% \n  bind_cols(test_proc)\n\nsubmission_RLR <- final_test_pred_RLR %>% \n  select(PassengerID = passenger_id,Survived = .pred_class)\n\nwrite_csv(submission_RLR,\"titanic_submission_RLR.csv\") \n\n# RF ----\nfinal_test_pred_RF <- \n  rf_final_wflow %>% \n  fit(train_proc_adj_tbl) %>% \n  predict(new_data=test_proc) %>% \n  bind_cols(test_proc)\n\nsubmission_RF <- final_test_pred_RF %>% \n  select(PassengerID = passenger_id,Survived = .pred_class)\n\nwrite_csv(submission_RF,\"titanic_submission_RF.csv\") \n\n# NN ----\nfinal_test_pred_NN <- \n  nnet_final_wflow %>% \n  fit(train_proc_adj_tbl) %>% \n  predict(new_data=test_proc) %>% \n  bind_cols(test_proc)\n\nsubmission_NN <- final_test_pred_NN %>% \n  select(PassengerID = passenger_id,Survived = .pred_class)\n\nwrite_csv(submission_NN,\"titanic_submission_NN.csv\") \n\n\n# XGB -----\nfinal_test_pred_xgb <-\n  xgb_final_wflow %>% \n  fit(train_proc_adj_tbl) %>% \n  predict(new_data=test_proc) %>% \n  bind_cols(test_proc)\n\nsubmission_xgb <- final_test_pred_xgb %>% \n  select(PassengerID = passenger_id,Survived = .pred_class)\n\nwrite_csv(submission_xgb,\"titanic_submission_xgb.csv\")\n\n\n# ensemble -----\nfinal_test_pred_ens <-\n  ensemble %>% \n  #fit(train_proc_adj_tbl) %>% \n  predict(new_data=test_proc) %>% \n  bind_cols(test_proc)\n\nsubmission_ens <- final_test_pred_ens %>% \n  select(PassengerID = passenger_id,Survived = .pred_class)\n\nwrite_csv(submission_ens,\"titanic_submission_ens.csv\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#write-submission-file",
    "href": "posts/post-with-code/index.html#write-submission-file",
    "title": "Titanic from Kaggle",
    "section": "1.2 Write Submission File",
    "text": "1.2 Write Submission File\n\n\nCode\nwrite_csv(test_predictions,\"titanic_submission_xgb.csv\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#stack-models",
    "href": "posts/post-with-code/index.html#stack-models",
    "title": "Titanic from Kaggle",
    "section": "0.11 Stack Models",
    "text": "0.11 Stack Models\n\n0.11.1 Stack Recipe\n\n\nCode\nrecipe_stack <- \n  recipe(survived ~ ., data = train_train) %>% \n  update_role(passenger_id, name,surname,ticket,cabin,new_role = \"ID\") %>% \n  step_impute_knn(all_numeric_predictors()) %>% \n  step_dummy(all_nominal_predictors()) %>%\n  step_factor2string(all_nominal_predictors()) %>% \n  step_zv(all_predictors()) %>% \n  step_pca()\nrecipe_stack\n\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          5\n   outcome          1\n predictor         13\n\nOperations:\n\nK-nearest neighbor imputation for all_numeric_predictors()\nDummy variables from all_nominal_predictors()\nCharacter variables from all_nominal_predictors()\nZero variance filter on all_predictors()\nPCA extraction with <none>\n\n\nCode\nrecipe_stack_trained <- prep(recipe_base)\nrecipe_stack_trained\n\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          5\n   outcome          1\n predictor         13\n\nTraining data contained 667 data points and 514 incomplete rows. \n\nOperations:\n\nK-nearest neighbor imputation for age, sib_sp, parch, fare [trained]\nDummy variables from pclass, sex, embarked, train_test, pax_type, cabin_prefac... [trained]\nCharacter variables from <none> [trained]\nZero variance filter removed train_test_test [trained]\nNo PCA components were extracted from <none> [trained]\n\n\n\n\n0.11.2 Stack Controls\n\n\nCode\nstack_ctrl <- control_resamples(save_pred = TRUE, save_workflow = TRUE)\n#stack_folds <- vfold_cv(training(train_split), v=10,strata = \"survived\")\n\nlibrary(stacks)\n\nmodel_stack <-\n  stacks() %>%\n  #add_candidates(lr_wflow) %>%\n  #add_candidates(rf_wflow) %>%\n  add_candidates(nnet_tuning_result) %>%\n  add_candidates(rlr_tuning_result) %>% \n  add_candidates(xgb_tuning_result)\n\n\n\n\n0.11.3 Stack Blend\n\n\nCode\ncl <- parallel::makePSOCKcluster(cores - 1)\n\nset.seed(1234)\nensemble <- blend_predictions(model_stack,penalty = 10^seq(-2, -0.5, length = 20))\nautoplot(ensemble)\n\n\n\n\n\nCode\nparallel::stopCluster(cl)\n\n\n\n\nCode\nensemble \n\n\n# A tibble: 4 × 3\n  member                         type         weight\n  <chr>                          <chr>         <dbl>\n1 .pred_1_nnet_tuning_result_1_3 mlp           2.25 \n2 .pred_1_rlr_tuning_result_1_30 logistic_reg  1.11 \n3 .pred_1_rlr_tuning_result_1_28 logistic_reg  1.09 \n4 .pred_1_xgb_tuning_result_1_29 boost_tree    0.658\n\n\n\n\n0.11.4 Stack Weights\n\n\nCode\nautoplot(ensemble, \"weights\") +\n  geom_text(aes(x = weight + 0.01, label = model), hjust = 0) + \n  theme(legend.position = \"none\") \n\n\n\n\n\n\n\n0.11.5 Fit Member Models\n\n\nCode\nensemble <- fit_members(ensemble)\ncollect_parameters(ensemble,\"xgb_tuning_result\")\n\n\n# A tibble: 27 × 10\n   member          mtry trees min_n tree_…¹ learn…² loss_r…³ sampl…⁴ terms  coef\n   <chr>          <int> <int> <int>   <int>   <dbl>    <dbl>   <dbl> <chr> <dbl>\n 1 xgb_tuning_re…    11   848    17       1 5.59e-3 5.81e- 3   0.539 .pre…     0\n 2 xgb_tuning_re…     9  1145    10       2 5.20e-8 1.60e- 1   0.866 .pre…     0\n 3 xgb_tuning_re…    17   740    15       2 8.39e-2 6.64e- 9   0.252 .pre…     0\n 4 xgb_tuning_re…    10  1314    11       3 1.72e-5 1.25e- 1   0.163 .pre…     0\n 5 xgb_tuning_re…    18  1475    25       3 1.50e-6 2.46e- 9   0.328 .pre…     0\n 6 xgb_tuning_re…     6    98    23       4 4.07e-4 1.02e- 3   0.897 .pre…     0\n 7 xgb_tuning_re…     7   923    13       5 1.66e-3 1.78e- 5   0.352 .pre…     0\n 8 xgb_tuning_re…    16   610    26       5 1.14e-5 1.88e-10   0.211 .pre…     0\n 9 xgb_tuning_re…    16  1549     6       7 1.36e-4 4.92e- 4   0.463 .pre…     0\n10 xgb_tuning_re…    14  1900    22       7 2.14e-7 3.46e- 6   0.447 .pre…     0\n# … with 17 more rows, and abbreviated variable names ¹​tree_depth, ²​learn_rate,\n#   ³​loss_reduction, ⁴​sample_size\n\n\n\n\n0.11.6 Stack Predict\n\n\nCode\n#ensemble_metrics <- metric_set(roc_auc,accuracy)\n\nensemble_test_predictions <- \n  predict(ensemble,train_test) %>% \n  bind_cols(train_test) \n\n\n# ensemble_test_predictions <- ensemble_test_predictions %>% \n#   mutate(.pred_class=as.numeric(.pred_class)) %>% \n#    mutate(survived =as.numeric(survived)) \n# \n# ensemble_test_predictions <- ensemble_test_predictions %>% \n#   mutate(roc = roc_auc(truth=survived, estimate = .pred_class))\n\n\n\nglimpse(ensemble_test_predictions)\n\n\nRows: 224\nColumns: 20\n$ .pred_class   <fct> 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0,…\n$ passenger_id  <dbl> 10, 11, 14, 18, 20, 23, 28, 40, 41, 51, 54, 57, 61, 66, …\n$ survived      <fct> 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1,…\n$ pclass        <fct> 2, 3, 3, 2, 3, 3, 1, 3, 3, 3, 2, 2, 3, 3, 2, 3, 3, 2, 3,…\n$ name          <fct> \"Nasser, Mrs. Nicholas (Adele Achem)\", \"Sandstrom, Miss.…\n$ sex           <fct> female, female, male, male, female, female, male, female…\n$ age           <dbl> 14, 4, 39, 30, 31, 15, 19, 14, 40, 7, 29, 21, 22, 6, 21,…\n$ sib_sp        <dbl> 1, 1, 1, 0, 0, 0, 3, 1, 1, 4, 1, 0, 0, 1, 0, 0, 0, 0, 3,…\n$ parch         <dbl> 0, 1, 5, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,…\n$ ticket        <fct> 237736, PP 9549, 347082, 244373, 2649, 330923, 19950, 26…\n$ fare          <dbl> 30.0708, 16.7000, 31.2750, 13.0000, 7.2250, 8.0292, 263.…\n$ cabin         <fct> NA, G6, NA, NA, NA, NA, C23 C25 C27, NA, NA, NA, NA, NA,…\n$ embarked      <fct> C, S, S, S, C, Q, S, C, S, S, S, S, C, C, S, S, Q, S, S,…\n$ train_test    <fct> train, train, train, train, train, train, train, train, …\n$ pax_type      <fct> F_married, F_unmarried, Mr., Mr., F_married, F_unmarried…\n$ surname       <fct> \"Nasser,\", \"Sandstrom,\", \"Andersson,\", \"Williams,\", \"Mas…\n$ cabin_preface <fct> nk, G, nk, nk, nk, nk, C, nk, nk, nk, nk, nk, nk, nk, nk…\n$ ticket_group  <fct> couple, group, group, single, single, single, group, cou…\n$ family_group  <ord> couple, family, family, single, single, single, family, …\n$ age_group     <ord> teen, child, 30s, 30s, 30s, teen, teen, teen, 40s, child…"
  },
  {
    "objectID": "posts/post-with-code/index.html#final-kaggle-scores",
    "href": "posts/post-with-code/index.html#final-kaggle-scores",
    "title": "Titanic from Kaggle",
    "section": "0.2 Final Kaggle Scores",
    "text": "0.2 Final Kaggle Scores\n\n\nCode\nkaggle <- tibble(\n  Model = c(\"Logistic Regression\",\n            \"Regularised Logistic Regression\",\n            \"Random Forest-final\",\n            \"Random Forest-initial\",\n            \"XG Boost\",\n            \"Neural Net\",\n            \"Ensemble\"), \n  Score = c(.76555,.77033,.77751,.78229,.77272,.76794,.77751)\n  )\n\nkaggle %>% knitr::kable()\n\n\n\n\n\nModel\nScore\n\n\n\n\nLogistic Regression\n0.76555\n\n\nRegularised Logistic Regression\n0.77033\n\n\nRandom Forest-final\n0.77751\n\n\nRandom Forest-initial\n0.78229\n\n\nXG Boost\n0.77272\n\n\nNeural Net\n0.76794\n\n\nEnsemble\n0.77751\n\n\n\n\n\nWhich when all submitted gave me a ranking of 1,872 out of 13,000 or so teams, so no grand-master!\nSeems like the value mainly comes from the feature engineering and selection process (as the experts all seem to say) given the similarity in above model scores."
  },
  {
    "objectID": "posts/post-with-code/index.html#section",
    "href": "posts/post-with-code/index.html#section",
    "title": "Titanic from Kaggle",
    "section": "1.1 ",
    "text": "1.1 \n\n\nCode\n# all_predictions %>% \n# distinct(model)\n\n\n\ntest_proc <- all_proc %>% \n  filter(train_test==\"test\")\n\n# LR ----\nfinal_test_pred_LR <- \n  lr_wflow %>% \n  fit(train_proc_adj_tbl) %>% \n  predict(new_data=test_proc) %>% \n  bind_cols(test_proc)\n\nsubmission_LR <- final_test_pred_LR %>% \n  select(PassengerID = passenger_id,Survived = .pred_class)\n\nwrite_csv(submission_LR,\"titanic_submission_LR.csv\") \n\n\n# RLR ----\nfinal_test_pred_RLR <- \n  rlr_final_wflow %>% \n  fit(train_proc_adj_tbl) %>% \n  predict(new_data=test_proc) %>% \n  bind_cols(test_proc)\n\nsubmission_RLR <- final_test_pred_RLR %>% \n  select(PassengerID = passenger_id,Survived = .pred_class)\n\nwrite_csv(submission_RLR,\"titanic_submission_RLR.csv\") \n\n# RF ----\nfinal_test_pred_RF <- \n  rf_final_wflow %>% \n  fit(train_proc_adj_tbl) %>% \n  predict(new_data=test_proc) %>% \n  bind_cols(test_proc)\n\nsubmission_RF <- final_test_pred_RF %>% \n  select(PassengerID = passenger_id,Survived = .pred_class)\n\nwrite_csv(submission_RF,\"titanic_submission_RF.csv\") \n\n# NN ----\nfinal_test_pred_NN <- \n  nnet_final_wflow %>% \n  fit(train_proc_adj_tbl) %>% \n  predict(new_data=test_proc) %>% \n  bind_cols(test_proc)\n\nsubmission_NN <- final_test_pred_NN %>% \n  select(PassengerID = passenger_id,Survived = .pred_class)\n\nwrite_csv(submission_NN,\"titanic_submission_NN.csv\") \n\n\n# XGB -----\nfinal_test_pred_xgb <-\n  xgb_final_wflow %>% \n  fit(train_proc_adj_tbl) %>% \n  predict(new_data=test_proc) %>% \n  bind_cols(test_proc)\n\nsubmission_xgb <- final_test_pred_xgb %>% \n  select(PassengerID = passenger_id,Survived = .pred_class)\n\nwrite_csv(submission_xgb,\"titanic_submission_xgb.csv\")\n\n\n# ensemble -----\nfinal_test_pred_ens <-\n  ensemble %>% \n  #fit(train_proc_adj_tbl) %>% \n  predict(new_data=test_proc) %>% \n  bind_cols(test_proc)\n\nsubmission_ens <- final_test_pred_ens %>% \n  select(PassengerID = passenger_id,Survived = .pred_class)\n\nwrite_csv(submission_ens,\"titanic_submission_ens.csv\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#section-1",
    "href": "posts/post-with-code/index.html#section-1",
    "title": "Titanic from Kaggle",
    "section": "1.2 ",
    "text": "1.2"
  },
  {
    "objectID": "posts/aust_domestic_flights/index.html",
    "href": "posts/aust_domestic_flights/index.html",
    "title": "Australian Domestic Flights",
    "section": "",
    "text": "This analysis summarises Australian domestic flight volumes and on-time performance (OTP) issues by airline over time.\nIt has been prepared mainly to get more used to Quarto, adn comprises:\n\nInitial data load and preprocessing - not shown\nDomestic Flight Analysis - This document\nGlobal Flight Analysis - Next document\nForecasting - to come"
  },
  {
    "objectID": "posts/aust_domestic_flights/index.html#data-sources",
    "href": "posts/aust_domestic_flights/index.html#data-sources",
    "title": "Australian Domestic Flights",
    "section": "2 Data Sources",
    "text": "2 Data Sources\nData is sourced from https://data.gov.au/ site, specific datasets used being:\n\nTop routes\nIndustry Totals\nOn-Time-Performance - Domestic\n\n(need to add notes/refs)\n\n\nCode\ntop_routes_prep_df <- read_rds(\"./artifacts/top_routes_prep_df.rds\")\nind_totals_prep_df <- read_rds(\"./artifacts/ind_totals_prep_df.rds\")\ndom_cargo_prep_df  <- read_rds(\"./artifacts/dom_cargo_prep_df.rds\")\notp_prep_df        <- read_rds(\"./artifacts/otp_prep_df.rds\")\n\nlatest_date        <- max(top_routes_prep_df$date)\n\n\notp_prep_df <- otp_prep_df %>% \n  mutate(across(airline,str_replace,'QantasLink','Qantas')) %>% \n  mutate(across(airline,str_replace,\"Virgin Australia - Atr/F100 Operations\",\"Virgin Australia\")) %>% \n  mutate(across(airline,str_replace,\"Virgin Australia Regional Airlines\",\"Virgin Australia\"))"
  },
  {
    "objectID": "posts/aust_domestic_flights/index.html#exploratory-data-analysis",
    "href": "posts/aust_domestic_flights/index.html#exploratory-data-analysis",
    "title": "Australian Domestic Flights",
    "section": "3 Exploratory Data Analysis",
    "text": "3 Exploratory Data Analysis\n\n3.1 All Major Routes - Total Monthly Pax\nTotal monthly passenger numbers :\n\n\nCode\ng <- ind_totals_prep_df %>% \n  #filter(year>2010) %>% \n  ggplot(aes(x=date,y=passenger_trips))+\n  geom_line()+\n  scale_y_continuous(labels=scales::comma)+\n  scale_x_date(date_breaks = \"2 year\",date_labels = \"%y\")+\n  labs(title = \"Australian Domestic Flight History\", x=\"Year\", y = \"Passenger Numbers (monthly)\")+\n  theme_bw()\nggplotly(g)\n\n\n\n\n\n\nKey “points of interest”:\n\n1987 pilot strike\n2000 Olympic Games\nCOVID!!!!\n\nSeasonality and trend both also clearly show, at least until covid.\nWe can break this down by top 10 routes (only tracked 2-way):\n\n\n3.2 Top 10 Routes - Monthly Pax by O/D City Pairs\n\n\nCode\n## * Top routes ----\ntop_routes <- top_routes_prep_df %>% \n  group_by(route,date=max(date)) %>% \n  summarise(passenger_trips = sum(passenger_trips)) %>% \n  ungroup() %>%\n  slice_max(passenger_trips, n=10) %>% \n  select(route) %>% \n  pull() %>% \n  as.character()\n  \n\ng1 <- top_routes_prep_df %>% \n  filter(route %in% top_routes) %>%\n  mutate(route = factor(route,levels=top_routes)) %>% \n  ggplot(aes(date,passenger_trips,colour =route))+\n  geom_line()+\n  scale_y_continuous(labels=scales::comma)+\n  scale_x_date(date_breaks = \"2 year\",date_labels = \"%y\")+\n  scale_colour_discrete(name  =\"Route - 2way\")+\n  labs(title = \"Australian Domestic Flight History - Top10 (2-way) Routes\", x=\"by Month\", y = \"Passenger Numbers (monthly)\")+\n  #theme_bw() +\n  theme(legend.position=\"bottom\")\nggplotly(g1)\n\n\n\n\n\n\n\n\n3.3 All Routes - Total Monthly Pax - Mapped\nFollowing map shows all routes in 2019 (precovid), thickness of line representiing pax volumes for the year (in this case with a moving monthly timeline to show impact of covid - but does not really work that well). As width of line signifies volumes of passenger trips, Sydney-Melbourne route clearly has thickest line!\n\n\nCode\n## * Routes Mapped - Leaflet ----\n\ntop_routes_short <- top_routes_prep_df %>%\n  filter(year>2019) \n  # group_by(year,city1,city2,city1_lng,city1_lat,city2_lng,city2_lat) %>% \n  # summarise(passenger_trips = sum(passenger_trips))\n\n  leaflet() %>% \n    addProviderTiles(providers$OpenTopoMap) %>% \n    addTiles() %>%\n    #addProviderTiles(providers$Esri.WorldStreetMap) %>% \n  addFlows(\n    top_routes_short$city1_lng, \n    top_routes_short$city1_lat, \n    top_routes_short$city2_lng, \n    top_routes_short$city2_lat,\n    flow = top_routes_short$passenger_trips,\n    time = top_routes_short$date,\n    dir = 0,\n    minThickness = .1,\n    maxThickness = 5,\n    popupOptions = list(closeOnClick = FALSE, autoClose = FALSE)\n  )\n\n\n\n\n\n\n\n\n3.4 On Time Performance (OTP) - All Domestic Routes\nPerformance Metric: OTP_issues_pct = (delayed arrivals + cancelled flights)/ Total Sectors Scheduled.\nAs this metric is based on arrival delays and canellations as a percentage of scheduled services, the higher the number, then the worse the performance!\n\n\nCode\notp_issues_all <- otp_prep_df %>% \n  filter(airline == \"All Airlines\") %>% \n  group_by(date) %>% \n  summarise(sectors_scheduled = sum(sectors_scheduled),\n            arrivals_delayed = sum(arrivals_delayed),\n            cancellations = sum(cancellations),\n            otp_issues_num = sum(otp_issues_num)\n            ) %>% \n  mutate(otp_issues_pct = (arrivals_delayed+cancellations)/sectors_scheduled)\n\ng_opt <- otp_issues_all %>% \n  ggplot(aes(date,otp_issues_pct))+\n  geom_line()+\n  geom_smooth(method=\"loess\")+\n  scale_y_continuous(labels=scales::percent)+\n  theme_bw()\n\nggplotly(g_opt)\n\n\n\n\n\n\nWhile the ‘loess’ smoother indicates a continual worsening of performance, most recent reporting perhaps indicates the airlines are starting to address OTP issues.\n\n\n3.5 OTP - By Airline over Time\nThis graph just focuses on the main 3 domestic carriers.\n\n\nCode\notp_issues_airline <- otp_prep_df %>% \n  filter(airline %in% c(\"Jetstar\",\"Qantas\",\"Virgin Australia\"),\n         year > 2019\n         ) %>%\n  \n  mutate(airline = str_to_title(airline)) %>% \n  group_by(date,airline) %>% \n  summarise(sectors_scheduled = sum(sectors_scheduled),\n            arrivals_delayed  = sum(arrivals_delayed),\n            cancellations     = sum(cancellations),\n            otp_issues_num    = sum(otp_issues_num)\n            ) %>% \n  mutate(arrivals_delayed_pct = arrivals_delayed/sectors_scheduled,\n         cacellations_pct     = cancellations/sectors_scheduled,\n         otp_issues_total_pct = (arrivals_delayed+cancellations)/sectors_scheduled ) %>% \n  select(date,airline,ends_with(\"pct\")) %>% \n  pivot_longer(cols = ends_with(\"pct\"), names_to = \"otp_metric\",values_to = \"pct_issues\")\n\ng_otp_issues_airline <- otp_issues_airline %>% \n  ggplot(aes(date,pct_issues,colour = airline))+\n  geom_line()+\n  #geom_smooth(method=\"loess\")+\n  scale_x_date(date_breaks = \"3 month\",date_labels = \"%m/%y\")+\n  scale_y_continuous(labels=scales::percent)+\n  xlab(\"Month\")+\n  ylab(\"Pct of Monthly Scheduled Services\") +\n  theme_bw()+\n  theme(legend.position =  \"bottom\")+\n  facet_wrap(~otp_metric,ncol=1)\n\n\nggplotly(g_otp_issues_airline)\n\n\n\n\n\n\nNote:\n\ncancellations in initial covid period\nUpswing in OTP issues (mainly non-cancellations) in more recent days\nJetstar worst performer, although all 3 airlines guilty of worsening performance.\nSigns of improvement in most recent reports."
  },
  {
    "objectID": "posts/aust_domestic_flights/index.knit.html",
    "href": "posts/aust_domestic_flights/index.knit.html",
    "title": "Australian Domestic Flights",
    "section": "",
    "text": "This analysis summarises Australian domestic flight volumes and on-time performance (OTP) issues by airline over time.\nIt has been prepared mainly to get more used to Quarto, adn comprises:\n\nInitial data load and preprocessing - not shown\nDomestic Flight Analysis - This document\nGlobal Flight Analysis - Next document\nForecasting - to come"
  },
  {
    "objectID": "posts/aust_domestic_flights/index.knit.html#data-sources",
    "href": "posts/aust_domestic_flights/index.knit.html#data-sources",
    "title": "Australian Domestic Flights",
    "section": "2 Data Sources",
    "text": "2 Data Sources\nData is sourced from https://data.gov.au/ site, specific datasets used being:\n\nTop routes\nIndustry Totals\nOn-Time-Performance - Domestic\n\n(need to add notes/refs)\n\n\nCode\ntop_routes_prep_df <- read_rds(\"./artifacts/top_routes_prep_df.rds\")\nind_totals_prep_df <- read_rds(\"./artifacts/ind_totals_prep_df.rds\")\ndom_cargo_prep_df  <- read_rds(\"./artifacts/dom_cargo_prep_df.rds\")\notp_prep_df        <- read_rds(\"./artifacts/otp_prep_df.rds\")\n\nlatest_date        <- max(top_routes_prep_df$date)\n\n\notp_prep_df <- otp_prep_df %>% \n  mutate(across(airline,str_replace,'QantasLink','Qantas')) %>% \n  mutate(across(airline,str_replace,\"Virgin Australia - Atr/F100 Operations\",\"Virgin Australia\")) %>% \n  mutate(across(airline,str_replace,\"Virgin Australia Regional Airlines\",\"Virgin Australia\"))"
  },
  {
    "objectID": "posts/aust_domestic_flights/index.knit.html#exploratory-data-analysis",
    "href": "posts/aust_domestic_flights/index.knit.html#exploratory-data-analysis",
    "title": "Australian Domestic Flights",
    "section": "3 Exploratory Data Analysis",
    "text": "3 Exploratory Data Analysis\n\n3.1 All Major Routes - Total Monthly Pax\nTotal monthly passenger numbers :\n\n\nCode\ng <- ind_totals_prep_df %>% \n  #filter(year>2010) %>% \n  ggplot(aes(x=date,y=passenger_trips))+\n  geom_line()+\n  scale_y_continuous(labels=scales::comma)+\n  scale_x_date(date_breaks = \"2 year\",date_labels = \"%y\")+\n  labs(title = \"Australian Domestic Flight History\", x=\"Year\", y = \"Passenger Numbers (monthly)\")+\n  theme_bw()\nggplotly(g)\n\n\n\n\n\n\nKey “points of interest”:\n\n1987 pilot strike\n2000 Olympic Games\nCOVID!!!!\n\nSeasonality and trend both also clearly show, at least until covid.\nWe can break this down by top 10 routes (only tracked 2-way):\n\n\n3.2 Top 10 Routes - Monthly Pax by O/D City Pairs\n\n\nCode\n## * Top routes ----\ntop_routes <- top_routes_prep_df %>% \n  group_by(route,date=max(date)) %>% \n  summarise(passenger_trips = sum(passenger_trips)) %>% \n  ungroup() %>%\n  slice_max(passenger_trips, n=10) %>% \n  select(route) %>% \n  pull() %>% \n  as.character()\n  \n\ng1 <- top_routes_prep_df %>% \n  filter(route %in% top_routes) %>%\n  mutate(route = factor(route,levels=top_routes)) %>% \n  ggplot(aes(date,passenger_trips,colour =route))+\n  geom_line()+\n  scale_y_continuous(labels=scales::comma)+\n  scale_x_date(date_breaks = \"2 year\",date_labels = \"%y\")+\n  scale_colour_discrete(name  =\"Route - 2way\")+\n  labs(title = \"Australian Domestic Flight History - Top10 (2-way) Routes\", x=\"by Month\", y = \"Passenger Numbers (monthly)\")+\n  #theme_bw() +\n  theme(legend.position=\"bottom\")\nggplotly(g1)\n\n\n\n\n\n\n\n\n3.3 All Routes - Total Monthly Pax - Mapped\nFollowing map shows all routes in 2019 (precovid), thickness of line representiing pax volumes for the year (in this case with a moving monthly timeline to show impact of covid - but does not really work that well). As width of line signifies volumes of passenger trips, Sydney-Melbourne route clearly has thickest line!\n\n\nCode\n## * Routes Mapped - Leaflet ----\n\ntop_routes_short <- top_routes_prep_df %>%\n  filter(year>2019) \n  # group_by(year,city1,city2,city1_lng,city1_lat,city2_lng,city2_lat) %>% \n  # summarise(passenger_trips = sum(passenger_trips))\n\n  leaflet() %>% \n    #addProviderTiles(providers$OpenTopoMap) %>% \n    addTiles() %>%\n    addProviderTiles(providers$Esri.WorldStreetMap) %>% \n  addFlows(\n    top_routes_short$city1_lng, \n    top_routes_short$city1_lat, \n    top_routes_short$city2_lng, \n    top_routes_short$city2_lat,\n    flow = top_routes_short$passenger_trips,\n    time = top_routes_short$date,\n    dir = 0,\n    minThickness = .1,\n    maxThickness = 5,\n    popupOptions = list(closeOnClick = FALSE, autoClose = FALSE)\n  )"
  },
  {
    "objectID": "posts/aust_domestic_flights/index.knit.html#introduction",
    "href": "posts/aust_domestic_flights/index.knit.html#introduction",
    "title": "Australian Domestic Flights",
    "section": "1 Introduction",
    "text": "1 Introduction\nThis analysis summarises Australian domestic flight volumes and on-time performance (OTP) issues by airline over time.\nIt has been prepared mainly to get more used to Quarto, and comprises:\n\nInitial data load and preprocessing - not shown\nDomestic Flight Analysis - This document\nGlobal Flight Analysis - Next document\nForecasting - to come\n\n\n\nCode\nlibrary(tidyverse)\n\n\nlibrary(scales)\n\nlibrary(leaflet)\nlibrary(leaflet.minicharts)\n\n\nlibrary(janitor)\nlibrary(plotly)\nlibrary(gganimate)\n\nlibrary(dygraphs)\n\n\noptions(scipen = 999)"
  },
  {
    "objectID": "posts/aust_domestic_flights/index.html#introduction",
    "href": "posts/aust_domestic_flights/index.html#introduction",
    "title": "Australian Domestic Flights",
    "section": "1 Introduction",
    "text": "1 Introduction\nThis analysis summarises Australian domestic flight volumes and on-time performance (OTP) issues by airline over time.\nIt has been prepared mainly to get more used to Quarto, and comprises:\n\nInitial data load and preprocessing - not shown\nDomestic Flight Analysis - This document\nGlobal Flight Analysis - Next document\nForecasting - to come\n\n\n\nCode\nlibrary(tidyverse)\n\n\nlibrary(scales)\n\nlibrary(leaflet)\nlibrary(leaflet.minicharts)\n\n\nlibrary(janitor)\nlibrary(plotly)\nlibrary(gganimate)\n\nlibrary(dygraphs)\n\n\noptions(scipen = 999)"
  }
]