[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Notes Index",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\ntitanic\n\n\n\n\n\n\n\n\n\n\n\nSep 1, 2022\n\n\nStephen Parton\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nAug 29, 2022\n\n\nStephen Parton\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/model-01-logistic_regression/index.html#summary",
    "href": "posts/model-01-logistic_regression/index.html#summary",
    "title": "Titanic Logistic Regression",
    "section": "Summary",
    "text": "Summary\nThis analysis looks at the previously processed Titanic analysis, using logistic regression."
  },
  {
    "objectID": "posts/model-01-logistic_regression/index.html#load-some-pre-prepared-kaggle-data",
    "href": "posts/model-01-logistic_regression/index.html#load-some-pre-prepared-kaggle-data",
    "title": "Titanic Logistic Regression",
    "section": "Load Some Pre-prepared Kaggle Data",
    "text": "Load Some Pre-prepared Kaggle Data\n\n\nCode\n#getwd()\n\nall_proc <- read_rds(\"../../posts/post-with-code/artifacts/all_proc.rds\")\ntrain_split <- read_rds(\"../../posts/post-with-code/artifacts/train_split.rds\")\nrecipe_base <- read_rds(\"../../posts/post-with-code/artifacts/recipe_base.rds\")"
  },
  {
    "objectID": "posts/model-01-logistic_regression/index.html#models",
    "href": "posts/model-01-logistic_regression/index.html#models",
    "title": "Titanic Logistic Regression",
    "section": "Models",
    "text": "Models\n\nLogistic Regression- GLM\n\nLR Model Spec\n\n\nCode\nlr_spec <-  \n  logistic_reg() %>% \n  set_engine(\"glm\")\n\nlr_spec\n\n\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\n\nLR Workflow\n\n\nCode\nlr_wflow <- \n  workflow() %>% \n  add_model(lr_spec) %>% \n  add_recipe(recipe_base)\n\nlr_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\n\nLR Fit Model\n\n\nCode\nlr_fit <- \n  lr_wflow %>% \n  last_fit(train_split)\n\n#lr_fit\n\nlr_final_metrics <- lr_fit %>% collect_metrics()\nlr_final_metrics \n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.835 Preprocessor1_Model1\n2 roc_auc  binary         0.867 Preprocessor1_Model1\n\n\nCode\n#show_notes(.Last.tune.result)\n\n\n\n\nLR Predict\n\n\nCode\nlr_test_predictions <- lr_fit %>% collect_predictions()\nlr_test_predictions\n\n\n# A tibble: 224 × 7\n   id               .pred_0 .pred_1  .row .pred_class survived .config          \n   <chr>              <dbl>   <dbl> <int> <fct>       <fct>    <chr>            \n 1 train/test split  0.346   0.654      3 1           1        Preprocessor1_Mo…\n 2 train/test split  0.0685  0.931      4 1           1        Preprocessor1_Mo…\n 3 train/test split  0.920   0.0802     5 0           0        Preprocessor1_Mo…\n 4 train/test split  0.569   0.431     11 0           1        Preprocessor1_Mo…\n 5 train/test split  0.622   0.378     31 0           0        Preprocessor1_Mo…\n 6 train/test split  0.277   0.723     33 1           1        Preprocessor1_Mo…\n 7 train/test split  0.670   0.330     35 0           0        Preprocessor1_Mo…\n 8 train/test split  0.811   0.189     36 0           0        Preprocessor1_Mo…\n 9 train/test split  0.902   0.0975    37 0           1        Preprocessor1_Mo…\n10 train/test split  0.554   0.446     39 0           0        Preprocessor1_Mo…\n# … with 214 more rows\n\n\n\n\nLR Performance on validation set\n\nAUC Curve\n\n\nCode\nlr_test_predictions %>% \n  roc_curve(truth = survived,.pred_1,event_level=\"second\") %>% \n  autoplot()\n\n\n\n\n\n\n\nConfusion Matrix\n\n\nCode\nlr_test_predictions %>% \n  conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")\n\n\n\n\n\n\n\n\nLR Resampling\n\n\nCode\nfolds <- vfold_cv(training(train_split), strata = survived, v=10)\n#folds\n\ncontrol <- control_resamples(save_pred = TRUE)\n\nlr_fit_cv <- \n  lr_wflow %>% \n  fit_resamples(folds, control = control)\n\n#show_best(lr_fit_cv,metric= \"accuracy\")\n\n#lr_fit_cv\nlr_metrics_resample <- collect_metrics(lr_fit_cv)\nlr_metrics_resample\n\n\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy binary     0.811    10  0.0130 Preprocessor1_Model1\n2 roc_auc  binary     0.854    10  0.0125 Preprocessor1_Model1"
  },
  {
    "objectID": "posts/post-with-code/index.html#summary",
    "href": "posts/post-with-code/index.html#summary",
    "title": "Titanic from Kaggle",
    "section": "0.1 Summary",
    "text": "0.1 Summary\nThis is just a first test with code in a blog using the new Quarto framework! Guess what I am using.."
  },
  {
    "objectID": "posts/post-with-code/index.html#load-some-kaggle-data",
    "href": "posts/post-with-code/index.html#load-some-kaggle-data",
    "title": "Titanic from Kaggle",
    "section": "2 Load Some Kaggle Data",
    "text": "2 Load Some Kaggle Data\nNot the…? Yes, the Titanic again….\n\n\nCode\ntrain <- read_csv(\"data_raw/train.csv\",show_col_types = FALSE) %>% clean_names() %>% mutate(train_test = \"train\")\ntest <- read_csv(\"data_raw/test.csv\",show_col_types = FALSE) %>% clean_names() %>% \n  mutate(train_test = \"test\")\nall <- train %>% bind_rows(test)\n\n# colnames(data)\n# cwd()"
  },
  {
    "objectID": "posts/post-with-code/index.html#some-initial-eda",
    "href": "posts/post-with-code/index.html#some-initial-eda",
    "title": "Titanic from Kaggle",
    "section": "3 Some Initial EDA",
    "text": "3 Some Initial EDA\nA quick look.\n\n\nCode\ntrain %>% skim() \n\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n891\n\n\nNumber of columns\n13\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nname\n0\n1.00\n12\n82\n0\n891\n0\n\n\nsex\n0\n1.00\n4\n6\n0\n2\n0\n\n\nticket\n0\n1.00\n3\n18\n0\n681\n0\n\n\ncabin\n687\n0.23\n1\n15\n0\n147\n0\n\n\nembarked\n2\n1.00\n1\n1\n0\n3\n0\n\n\ntrain_test\n0\n1.00\n5\n5\n0\n1\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\npassenger_id\n0\n1.0\n446.00\n257.35\n1.00\n223.50\n446.00\n668.5\n891.00\n▇▇▇▇▇\n\n\nsurvived\n0\n1.0\n0.38\n0.49\n0.00\n0.00\n0.00\n1.0\n1.00\n▇▁▁▁▅\n\n\npclass\n0\n1.0\n2.31\n0.84\n1.00\n2.00\n3.00\n3.0\n3.00\n▃▁▃▁▇\n\n\nage\n177\n0.8\n29.70\n14.53\n0.42\n20.12\n28.00\n38.0\n80.00\n▂▇▅▂▁\n\n\nsib_sp\n0\n1.0\n0.52\n1.10\n0.00\n0.00\n0.00\n1.0\n8.00\n▇▁▁▁▁\n\n\nparch\n0\n1.0\n0.38\n0.81\n0.00\n0.00\n0.00\n0.0\n6.00\n▇▁▁▁▁\n\n\nfare\n0\n1.0\n32.20\n49.69\n0.00\n7.91\n14.45\n31.0\n512.33\n▇▁▁▁▁"
  },
  {
    "objectID": "posts/post-with-code/index.html#some-initial-wrangling",
    "href": "posts/post-with-code/index.html#some-initial-wrangling",
    "title": "Titanic from Kaggle",
    "section": "4 Some Initial Wrangling",
    "text": "4 Some Initial Wrangling\n\n\nCode\nall_proc <- all %>% \n  mutate(title = str_extract(name,\"(\\\\w)([a-z]+)(\\\\.)\")) %>% \n  mutate(pax_type = case_when(\n    title %in% c(\"Miss.\",\"Ms.\",\"Mlle.\")         ~ \"F_unmarried\",\n    title %in% c(\"Mme.\",\"Mrs.\")                 ~ \"F_married\",\n    title %in% c(\"Countess.\",\"Lady.\",\"Dona.\")   ~ \"F_titled\",\n    title %in% c(\"Capt.\",\"Col.\",\"Major.\")       ~ \"Military\",\n    title %in% c(\"Dr.\",\"Rev.\")                  ~ \"M_Professional\",\n    title %in% c(\"Don.\",\"Jonkheer.\",\"Sir.\")     ~ \"M_titled\",\n    TRUE ~ title\n  ),\n  surname        = str_extract(name,\"(\\\\w+)(\\\\,)\"),\n  survival       = ifelse(survived==0,\"No\",\"Yes\"),\n  ticket_preface = str_extract(ticket,\"([:graph:]+)(\\\\s)\"),\n  ticket_preface = ifelse(is.na(ticket_preface),\"none\",ticket_preface),\n  cabin_preface  = ifelse(is.na(cabin),\"nk\",\n                    substr(cabin,1,1)),\n  embarked       = ifelse(is.na(embarked),\"S\",embarked)\n  ) %>% \n  group_by(pax_type,pclass) %>% \n  mutate(age     = ifelse(is.na(age),median(age,na.rm = T), age)) %>% \n  ungroup() %>% \n  add_count(ticket,name = \"ticket_group\") %>% \n  mutate(ticket_group = case_when(\n    ticket_group == 1 ~ \"single\",\n    ticket_group == 2 ~ \"couple\",\n    TRUE              ~ \"group\"\n  ),\n    family_group = as.numeric(sib_sp)+as.numeric(parch)+1\n  ) %>% \n  mutate(family_group = factor(\n    case_when(\n        family_group < 2  ~ \"single\",\n        family_group < 3  ~ \"couple\",\n        TRUE              ~ \"family\"\n        ),\n    ordered = TRUE)\n  ) %>% \n  mutate(age_group = factor(case_when(\n    age < 13      ~ \"child\",\n    age < 20      ~ \"teen\",\n    age < 30      ~ \"20s\",\n    age < 40      ~ \"30s\",\n    age < 50      ~ \"40s\",\n    age < 60      ~ \"50s\",\n    TRUE          ~ \"60+\"\n    \n  ),\n  ordered = TRUE)\n  ) %>% \n  mutate(across(where(is.character),as_factor)) %>% \n  mutate(pclass = factor(pclass,levels = c(\"1\",\"2\",\"3\")),\n         survived = factor(survived)\n         ) %>% \nselect(-c(title,ticket_preface))\n  \n#all_proc %>% glimpse()"
  },
  {
    "objectID": "posts/post-with-code/index.html#a-bit-more-eda",
    "href": "posts/post-with-code/index.html#a-bit-more-eda",
    "title": "Titanic from Kaggle",
    "section": "5 A bit more EDA",
    "text": "5 A bit more EDA\n\n\nCode\nall_proc %>% \n  select(-c(name,ticket,cabin,surname,train_test)) %>% \n  DataExplorer::plot_bar()\n\n\n\n\n\n\n\n\n\n\nCode\nall_proc %>% DataExplorer::plot_histogram(ggtheme = theme_light() )"
  },
  {
    "objectID": "posts/post-with-code/index.html#eyeballing-survival-graphs-on-training-data",
    "href": "posts/post-with-code/index.html#eyeballing-survival-graphs-on-training-data",
    "title": "Titanic from Kaggle",
    "section": "6 Eyeballing Survival Graphs on Training Data",
    "text": "6 Eyeballing Survival Graphs on Training Data\n\n\nCode\nno_f <- all_proc %>%\n  filter(train_test == \"train\") %>% \n  select(passenger_id,pclass,sex,embarked,pax_type,ticket_group,family_group,age_group,cabin_preface,survival) %>% \n  droplevels() %>%\n  mutate(across(where(is.factor),~ factor(.x,ordered = FALSE))) %>%\n  pivot_longer(cols = c(pclass:cabin_preface)) \n\n\ng_l <- no_f %>% \n  split(.$name) %>% \n  map(~ ggplot(.,aes(y=value,fill=survival)) +\n                geom_bar() +\n              ggtitle(.$name) +\n        theme_bw() +\n        labs(x=NULL,y=NULL)+\n        scale_fill_viridis_d(option = \"cividis\")\n      \n            ) \n\nlibrary(patchwork)\nwrap_plots(g_l, ncol = 2)"
  },
  {
    "objectID": "posts/post-with-code/index.html#split-data-back-to-traintestvalidation",
    "href": "posts/post-with-code/index.html#split-data-back-to-traintestvalidation",
    "title": "Titanic from Kaggle",
    "section": "7 Split Data back to Train/Test/Validation",
    "text": "7 Split Data back to Train/Test/Validation\n\n\nCode\ntrain_proc_adj_tbl <- all_proc %>% \n  filter(train_test ==\"train\") %>% \n  select(-c(survival))\n  \ntrain_split <- initial_split(train_proc_adj_tbl,strata = survived)"
  },
  {
    "objectID": "posts/post-with-code/index.html#recipe-base",
    "href": "posts/post-with-code/index.html#recipe-base",
    "title": "Titanic from Kaggle",
    "section": "0.3 Recipe-Base",
    "text": "0.3 Recipe-Base\n\n\nCode\nrecipe_base <- \n  recipe(survived ~ ., data = train_train) %>% \n  update_role(passenger_id, name,surname,ticket,cabin,new_role = \"ID\") %>%\n  step_impute_knn(all_numeric_predictors()) %>% \n  step_dummy(all_nominal_predictors()) %>%\n  step_factor2string(all_nominal_predictors()) %>% \n  step_zv(all_predictors()) %>% \n  step_pca()\nrecipe_base\n\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          5\n   outcome          1\n predictor         13\n\nOperations:\n\nK-nearest neighbor imputation for all_numeric_predictors()\nDummy variables from all_nominal_predictors()\nCharacter variables from all_nominal_predictors()\nZero variance filter on all_predictors()\nPCA extraction with <none>\n\n\n\n0.3.1 Save Files\n\n\nCode\nwrite_rds(all_proc,\"artifacts/all_proc.rds\")\nwrite_rds(train_split,\"artifacts/train_split.rds\")\nwrite_rds(recipe_base,\"artifacts/recipe_base.rds\")\n# \n# all_proc <- read_rds(\"artifacts/all_proc.rds\")\n# train_split <- read_rds(\"artifacts/train_split.rds\")\n# recipe_base <- read_rds(\"artifacts/recipe_base.rds\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#save-files",
    "href": "posts/post-with-code/index.html#save-files",
    "title": "Titanic from Kaggle",
    "section": "9 Save Files",
    "text": "9 Save Files\n\n\nCode\nwrite_rds(all_proc,\"artifacts/all_proc.rds\")\nwrite_rds(train_split,\"artifacts/train_split.rds\")\nwrite_rds(recipe_base,\"artifacts/recipe_base.rds\")\n\nall_proc <- read_rds(\"artifacts/all_proc.rds\")\ntrain_split <- read_rds(\"artifacts/train_split.rds\")\nrecipe_base <- read_rds(\"artifacts/recipe_base.rds\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#models",
    "href": "posts/post-with-code/index.html#models",
    "title": "Titanic from Kaggle",
    "section": "0.4 Models",
    "text": "0.4 Models\n\n0.4.1 Logistic Regression\n\nLR Model Spec\n\n\nCode\nlr_spec <-  \n  logistic_reg() %>% \n  set_engine(\"glm\")\n\nlr_spec\n\n\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\n\nLR Workflow\n\n\nCode\nlr_wflow <- \n  workflow() %>% \n  add_model(lr_spec) %>% \n  add_recipe(recipe_base)\n\nlr_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\n\nLR Fit Model\n\n\nCode\nlr_fit <- \n  lr_wflow %>% \n  last_fit(train_split)\n\n#lr_fit\n\nlr_final_metrics <- lr_fit %>% collect_metrics()\nlr_final_metrics \n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.799 Preprocessor1_Model1\n2 roc_auc  binary         0.829 Preprocessor1_Model1\n\n\nCode\n#show_notes(.Last.tune.result)\n\n\n\n\nLR Predict\n\n\nCode\nlr_test_predictions <- lr_fit %>% collect_predictions() %>% \n  rename(survived_pred = survived) %>% \n  bind_cols(train_test)\nlr_test_predictions\n\n\n# A tibble: 224 × 26\n   id       .pred_0 .pred_1  .row .pred…¹ survi…² .config passe…³ survi…⁴ pclass\n   <chr>      <dbl>   <dbl> <int> <fct>   <fct>   <chr>     <dbl> <fct>   <fct> \n 1 train/t…  0.961   0.0391     1 0       0       Prepro…       1 0       3     \n 2 train/t…  0.0726  0.927      4 1       1       Prepro…       4 1       1     \n 3 train/t…  0.273   0.727     12 1       1       Prepro…      12 1       1     \n 4 train/t…  0.925   0.0754    13 0       0       Prepro…      13 0       3     \n 5 train/t…  0.296   0.704     15 1       0       Prepro…      15 0       3     \n 6 train/t…  0.129   0.871     20 1       1       Prepro…      20 1       3     \n 7 train/t…  0.834   0.166     21 0       0       Prepro…      21 0       2     \n 8 train/t…  0.715   0.285     25 0       0       Prepro…      25 0       3     \n 9 train/t…  0.961   0.0386    26 0       1       Prepro…      26 1       3     \n10 train/t…  0.927   0.0734    28 0       0       Prepro…      28 0       1     \n# … with 214 more rows, 16 more variables: name <fct>, sex <fct>, age <dbl>,\n#   sib_sp <dbl>, parch <dbl>, ticket <fct>, fare <dbl>, cabin <fct>,\n#   embarked <fct>, train_test <fct>, pax_type <fct>, surname <fct>,\n#   cabin_preface <fct>, ticket_group <fct>, family_group <ord>,\n#   age_group <ord>, and abbreviated variable names ¹​.pred_class,\n#   ²​survived_pred, ³​passenger_id, ⁴​survived\n\n\n\n\nLR Performance on validation set\n\nAUC Curve\n\n\nCode\nlr_test_predictions %>% \n  roc_curve(truth = survived,.pred_1,event_level=\"second\") %>% \n  autoplot()\n\n\n\n\n\n\n\nConfusion Matrix\n\n\nCode\nlr_test_predictions %>% \n  conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")\n\n\n\n\n\n\n\n\nLR Resampling\n\n\nCode\nfolds <- vfold_cv(train_train, strata = survived, v=5)\n#folds\n\ncontrol <- control_resamples(save_pred = TRUE,save_workflow = TRUE)\n\ncores <- parallel::detectCores()\nset.seed(1234)\ndoParallel::registerDoParallel(cores = cores)\n\nlr_fit_cv <- \n  lr_wflow %>% \n  fit_resamples(folds, control = control)\n\n#show_best(lr_fit_cv,metric= \"accuracy\")\n\n#lr_fit_cv\nlr_metrics_resample <- collect_metrics(lr_fit_cv)\nlr_metrics_resample\n\n\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy binary     0.835     5  0.0221 Preprocessor1_Model1\n2 roc_auc  binary     0.868     5  0.0220 Preprocessor1_Model1\n\n\nFollowing still to be fixed!\n\n\nCode\n#lr_param <- extract_parameter_set_dials(lr_spec)\n\nlr_resample_test_predictions <- collect_predictions(lr_fit_cv) %>% \n  rename(survived_pred = survived) \n#  bind_cols(testing(train_split))\nlr_resample_test_predictions\n\n\n# A tibble: 667 × 7\n   id    .pred_0 .pred_1  .row .pred_class survived_pred .config             \n   <chr>   <dbl>   <dbl> <int> <fct>       <fct>         <chr>               \n 1 Fold1   0.952  0.0476     1 0           0             Preprocessor1_Model1\n 2 Fold1   0.964  0.0360    15 0           0             Preprocessor1_Model1\n 3 Fold1   0.936  0.0643    16 0           0             Preprocessor1_Model1\n 4 Fold1   0.957  0.0429    34 0           0             Preprocessor1_Model1\n 5 Fold1   0.954  0.0459    44 0           0             Preprocessor1_Model1\n 6 Fold1   0.857  0.143     45 0           0             Preprocessor1_Model1\n 7 Fold1   0.932  0.0684    47 0           0             Preprocessor1_Model1\n 8 Fold1   0.441  0.559     48 1           0             Preprocessor1_Model1\n 9 Fold1   0.254  0.746     49 1           0             Preprocessor1_Model1\n10 Fold1   0.923  0.0773    52 0           0             Preprocessor1_Model1\n# … with 657 more rows\n\n\n\n\nCode\nset.seed(1234)\nlm_fit <- lr_wflow %>% fit(data = train_proc_adj_tbl)\nextract_recipe(lm_fit, estimated = TRUE)\n\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          5\n   outcome          1\n predictor         13\n\nTraining data contained 891 data points and 687 incomplete rows. \n\nOperations:\n\nK-nearest neighbor imputation for age, sib_sp, parch, fare [trained]\nDummy variables from pclass, sex, embarked, train_test, pax_type, cabin_prefac... [trained]\nCharacter variables from <none> [trained]\nZero variance filter removed train_test_test [trained]\nNo PCA components were extracted from <none> [trained]"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "What is this for?",
    "section": "",
    "text": "This is my public notebook created in Quarto after seeing all the recent webinars from the amazing people at RStudio (eg JJ Allaire, Tom Mock and Isabella Velasquez)\nIt is intended that it will contain public ‘Notes to Myself’ on some of my interests which professionally are likely to centre on things like:\n\nR Programming\nPython Programming\nML analytics in R and Python\nFinance and data analytics (my day job)\nOther analytics and notes collected from wherever\n\nNot sure that it will be much use to anyone else, but feel free to wander through."
  },
  {
    "objectID": "posts/post-with-code/index.html#review-data",
    "href": "posts/post-with-code/index.html#review-data",
    "title": "Titanic from Kaggle",
    "section": "0.2 Review Data",
    "text": "0.2 Review Data\n\n0.2.1 Load Some Kaggle Data\nNot the…? Yes, the Titanic again….\n\n\nCode\ntrain <- read_csv(\"data_raw/train.csv\",show_col_types = FALSE) %>% clean_names() %>% mutate(train_test = \"train\")\ntest <- read_csv(\"data_raw/test.csv\",show_col_types = FALSE) %>% clean_names() %>% \n  mutate(train_test = \"test\")\nall <- train %>% bind_rows(test)\n\n# colnames(data)\n# cwd()\n\n\n\n\n0.2.2 Some Initial EDA\nA quick look.\n\n\nCode\ntrain %>% skim() \n\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n891\n\n\nNumber of columns\n13\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nname\n0\n1.00\n12\n82\n0\n891\n0\n\n\nsex\n0\n1.00\n4\n6\n0\n2\n0\n\n\nticket\n0\n1.00\n3\n18\n0\n681\n0\n\n\ncabin\n687\n0.23\n1\n15\n0\n147\n0\n\n\nembarked\n2\n1.00\n1\n1\n0\n3\n0\n\n\ntrain_test\n0\n1.00\n5\n5\n0\n1\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\npassenger_id\n0\n1.0\n446.00\n257.35\n1.00\n223.50\n446.00\n668.5\n891.00\n▇▇▇▇▇\n\n\nsurvived\n0\n1.0\n0.38\n0.49\n0.00\n0.00\n0.00\n1.0\n1.00\n▇▁▁▁▅\n\n\npclass\n0\n1.0\n2.31\n0.84\n1.00\n2.00\n3.00\n3.0\n3.00\n▃▁▃▁▇\n\n\nage\n177\n0.8\n29.70\n14.53\n0.42\n20.12\n28.00\n38.0\n80.00\n▂▇▅▂▁\n\n\nsib_sp\n0\n1.0\n0.52\n1.10\n0.00\n0.00\n0.00\n1.0\n8.00\n▇▁▁▁▁\n\n\nparch\n0\n1.0\n0.38\n0.81\n0.00\n0.00\n0.00\n0.0\n6.00\n▇▁▁▁▁\n\n\nfare\n0\n1.0\n32.20\n49.69\n0.00\n7.91\n14.45\n31.0\n512.33\n▇▁▁▁▁\n\n\n\n\n\n\n\n0.2.3 Some Initial Wrangling\n\n\nCode\nall_proc <- all %>% \n  mutate(title = str_extract(name,\"(\\\\w)([a-z]+)(\\\\.)\")) %>% \n  mutate(pax_type = case_when(\n    title %in% c(\"Miss.\",\"Ms.\",\"Mlle.\")         ~ \"F_unmarried\",\n    title %in% c(\"Mme.\",\"Mrs.\")                 ~ \"F_married\",\n    title %in% c(\"Countess.\",\"Lady.\",\"Dona.\")   ~ \"F_titled\",\n    title %in% c(\"Capt.\",\"Col.\",\"Major.\")       ~ \"Military\",\n    title %in% c(\"Dr.\",\"Rev.\")                  ~ \"M_Professional\",\n    title %in% c(\"Don.\",\"Jonkheer.\",\"Sir.\")     ~ \"M_titled\",\n    TRUE ~ title\n  ),\n  surname        = str_extract(name,\"(\\\\w+)(\\\\,)\"),\n  survival       = ifelse(survived==0,\"No\",\"Yes\"),\n  ticket_preface = str_extract(ticket,\"([:graph:]+)(\\\\s)\"),\n  ticket_preface = ifelse(is.na(ticket_preface),\"none\",ticket_preface),\n  cabin_preface  = ifelse(is.na(cabin),\"nk\",\n                    substr(cabin,1,1)),\n  embarked       = ifelse(is.na(embarked),\"S\",embarked)\n  ) %>% \n  group_by(pax_type,pclass) %>% \n  mutate(age     = ifelse(is.na(age),median(age,na.rm = T), age)) %>% \n  ungroup() %>% \n  add_count(ticket,name = \"ticket_group\") %>% \n  mutate(ticket_group = case_when(\n    ticket_group == 1 ~ \"single\",\n    ticket_group == 2 ~ \"couple\",\n    TRUE              ~ \"group\"\n  ),\n    family_group = as.numeric(sib_sp)+as.numeric(parch)+1\n  ) %>% \n  mutate(family_group = factor(\n    case_when(\n        family_group < 2  ~ \"single\",\n        family_group < 3  ~ \"couple\",\n        TRUE              ~ \"family\"\n        ),\n    ordered = TRUE)\n  ) %>% \n  mutate(age_group = factor(case_when(\n    age < 13      ~ \"child\",\n    age < 20      ~ \"teen\",\n    age < 30      ~ \"20s\",\n    age < 40      ~ \"30s\",\n    age < 50      ~ \"40s\",\n    age < 60      ~ \"50s\",\n    TRUE          ~ \"60+\"\n    \n  ),\n  ordered = TRUE)\n  ) %>% \n  mutate(across(where(is.character),as_factor)) %>% \n  mutate(pclass = factor(pclass,levels = c(\"1\",\"2\",\"3\")),\n         survived = factor(survived)\n         ) %>% \nselect(-c(title,ticket_preface))\n  \n#all_proc %>% glimpse() \n\n\n\n\n0.2.4 A bit more EDA\n\n\nCode\nall_proc %>% \n  select(-c(name,ticket,cabin,surname,train_test)) %>% \n  DataExplorer::plot_bar()\n\n\n\n\n\n\n\n\n\n\nCode\nall_proc %>% DataExplorer::plot_histogram(ggtheme = theme_light() )\n\n\n\n\n\n\n\n0.2.5 Eyeballing Survival Graphs on Training Data\n\n\nCode\nno_f <- all_proc %>%\n  filter(train_test == \"train\") %>% \n  select(passenger_id,pclass,sex,embarked,pax_type,ticket_group,family_group,age_group,cabin_preface,survival) %>% \n  droplevels() %>%\n  mutate(across(where(is.factor),~ factor(.x,ordered = FALSE))) %>%\n  pivot_longer(cols = c(pclass:cabin_preface)) \n\n\ng_l <- no_f %>% \n  split(.$name) %>% \n  map(~ ggplot(.,aes(y=value,fill=survival)) +\n                geom_bar() +\n              ggtitle(.$name) +\n        theme_bw() +\n        labs(x=NULL,y=NULL)+\n        scale_fill_viridis_d(option = \"cividis\")\n      \n            ) \n\nlibrary(patchwork)\nwrap_plots(g_l, ncol = 2)\n\n\n\n\n\n\n\n0.2.6 Split Data back to Train/Test/Validation\n\n\nCode\ntrain_proc_adj_tbl <- all_proc %>% \n  filter(train_test ==\"train\") %>% \n  select(-c(survival))\n\n\n  \ntrain_split <- initial_split(train_proc_adj_tbl,strata = survived)\n\ntrain_train <- training(train_split)\ntrain_test <- testing(train_split)"
  },
  {
    "objectID": "posts/post-with-code/index.html#regularised-logistic-regression---glmnet",
    "href": "posts/post-with-code/index.html#regularised-logistic-regression---glmnet",
    "title": "Titanic from Kaggle",
    "section": "0.5 Regularised Logistic Regression - GLMNET",
    "text": "0.5 Regularised Logistic Regression - GLMNET\n\n0.5.1 RLR Model Spec\n\n\nCode\nrlr_model <- \n  logistic_reg(penalty = tune(), mixture = tune()) %>% \n  set_engine(\"glmnet\")\nrlr_model\n\n\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = tune()\n\nComputational engine: glmnet \n\n\n\n\n0.5.2 RLR Parameter Tuning\n\n\nCode\nrlr_param <- extract_parameter_set_dials(rlr_model)\n\nrlr_grid <- grid_latin_hypercube(\n  penalty(),\n  mixture(),\n  size = 30\n)\nhead(rlr_grid) %>% knitr::kable(digits =3)\n\n\n\n\n\npenalty\nmixture\n\n\n\n\n0.116\n0.866\n\n\n0.095\n0.736\n\n\n0.000\n0.141\n\n\n0.000\n0.458\n\n\n0.025\n0.983\n\n\n0.484\n0.109\n\n\n\n\n\n\n\n0.5.3 RLR Workflow\n\n\nCode\nrlr_wflow <- \n  workflow() %>% \n  add_model(rlr_model) %>% \n  add_recipe(recipe_base)\nrlr_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = tune()\n\nComputational engine: glmnet \n\n\n\n\n0.5.4 RLR Hyper-parameter Tuning\n\n\nCode\n# rlr_folds <- vfold_cv(training(train_split), strata = survived, v=10,repeats = 5)\n# rlr_folds %>% tidy()\n\ndoParallel::registerDoParallel(cores = cores)\n\nset.seed(234)\nrlr_tuning_result <- tune_grid(\n  rlr_wflow,\n  resamples = folds,\n  grid      = rlr_grid,\n  control   = control_grid(save_pred = TRUE, save_workflow = TRUE)\n)\n\nrlr_tuning_metrics <- collect_metrics(rlr_tuning_result)\nhead(rlr_tuning_metrics) %>% knitr::kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npenalty\nmixture\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n0.016\n0.018\naccuracy\nbinary\n0.841\n5\n0.018\nPreprocessor1_Model01\n\n\n0.016\n0.018\nroc_auc\nbinary\n0.873\n5\n0.018\nPreprocessor1_Model01\n\n\n0.000\n0.066\naccuracy\nbinary\n0.836\n5\n0.021\nPreprocessor1_Model02\n\n\n0.000\n0.066\nroc_auc\nbinary\n0.869\n5\n0.022\nPreprocessor1_Model02\n\n\n0.000\n0.070\naccuracy\nbinary\n0.836\n5\n0.021\nPreprocessor1_Model03\n\n\n0.000\n0.070\nroc_auc\nbinary\n0.869\n5\n0.022\nPreprocessor1_Model03\n\n\n\n\n\nReview hyper-parameter tuning results and select best\n\n\nCode\nrlr_tuning_result %>%\n  collect_metrics() %>%\n  filter(.metric == \"accuracy\") %>%\n  select(mean, penalty,mixture) %>%\n  pivot_longer(penalty:mixture,\n               values_to = \"value\",\n               names_to = \"parameter\"\n  ) %>%\n  ggplot(aes(value, mean, color = parameter)) +\n  geom_point(alpha = 0.8, show.legend = FALSE) +\n  facet_wrap(~parameter, scales = \"free_x\") +\n  labs(x = NULL, y = \"AUC\")\n\n\n\n\n\nCode\nshow_best(rlr_tuning_result, \"accuracy\")\n\n\n# A tibble: 5 × 8\n  penalty mixture .metric  .estimator  mean     n std_err .config              \n    <dbl>   <dbl> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n1 0.00886  0.923  accuracy binary     0.849     5  0.0195 Preprocessor1_Model28\n2 0.0156   0.0180 accuracy binary     0.841     5  0.0180 Preprocessor1_Model01\n3 0.00349  0.598  accuracy binary     0.838     5  0.0197 Preprocessor1_Model18\n4 0.00193  0.946  accuracy binary     0.838     5  0.0197 Preprocessor1_Model29\n5 0.0255   0.983  accuracy binary     0.837     5  0.0118 Preprocessor1_Model30\n\n\nCode\nbest_rlr_auc <- select_best(rlr_tuning_result, \"accuracy\")\nbest_rlr_auc\n\n\n# A tibble: 1 × 3\n  penalty mixture .config              \n    <dbl>   <dbl> <chr>                \n1 0.00886   0.923 Preprocessor1_Model28\n\n\n\n\n0.5.5 RLR Predict\n\n\nCode\nrlr_final_wflow <- finalize_workflow(\n  rlr_wflow,\n  best_rlr_auc\n)\n\nrlr_final_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = 0.00885574773491923\n  mixture = 0.923322001239285\n\nComputational engine: glmnet \n\n\nCode\nrlr_final_wflow %>%\n  last_fit(train_split) %>%\n  extract_fit_parsnip() %>%\n  vip(geom = \"col\")\n\n\n\n\n\n\n\nCode\nrlr_final_fit <- rlr_final_wflow %>%\n  last_fit(train_split)\n\nrlr_final_metrics <- collect_metrics(rlr_final_fit)\nrlr_final_metrics %>% knitr::kable()\n\n\n\n\n\n.metric\n.estimator\n.estimate\n.config\n\n\n\n\naccuracy\nbinary\n0.7946429\nPreprocessor1_Model1\n\n\nroc_auc\nbinary\n0.8345130\nPreprocessor1_Model1\n\n\n\n\n\nCode\nrlr_test_predictions <- rlr_final_fit %>% collect_predictions()\nrlr_test_predictions_all <- rlr_test_predictions %>% \n  bind_cols(train_test %>% select(-survived)) \n\n\n\nglimpse(rlr_test_predictions_all)\n\n\nRows: 224\nColumns: 25\n$ id            <chr> \"train/test split\", \"train/test split\", \"train/test spli…\n$ .pred_0       <dbl> 0.9469919, 0.1258337, 0.1978522, 0.9142934, 0.3196989, 0…\n$ .pred_1       <dbl> 0.05300813, 0.87416629, 0.80214776, 0.08570665, 0.680301…\n$ .row          <int> 1, 4, 12, 13, 15, 20, 21, 25, 26, 28, 30, 35, 36, 37, 38…\n$ .pred_class   <fct> 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ survived      <fct> 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,…\n$ .config       <chr> \"Preprocessor1_Model1\", \"Preprocessor1_Model1\", \"Preproc…\n$ passenger_id  <dbl> 1, 4, 12, 13, 15, 20, 21, 25, 26, 28, 30, 35, 36, 37, 38…\n$ pclass        <fct> 3, 1, 1, 3, 3, 3, 2, 3, 3, 1, 3, 1, 1, 3, 3, 3, 3, 1, 3,…\n$ name          <fct> \"Braund, Mr. Owen Harris\", \"Futrelle, Mrs. Jacques Heath…\n$ sex           <fct> male, female, female, male, female, female, male, female…\n$ age           <dbl> 22, 35, 58, 20, 14, 31, 35, 8, 38, 19, 26, 28, 42, 26, 2…\n$ sib_sp        <dbl> 1, 1, 0, 0, 0, 0, 0, 3, 1, 3, 0, 1, 1, 0, 0, 0, 4, 0, 0,…\n$ parch         <dbl> 0, 0, 0, 0, 0, 0, 0, 1, 5, 2, 0, 0, 0, 0, 0, 0, 1, 1, 0,…\n$ ticket        <fct> A/5 21171, 113803, 113783, A/5. 2151, 350406, 2649, 2398…\n$ fare          <dbl> 7.2500, 53.1000, 26.5500, 8.0500, 7.8542, 7.2250, 26.000…\n$ cabin         <fct> NA, C123, C103, NA, NA, NA, NA, NA, NA, C23 C25 C27, NA,…\n$ embarked      <fct> S, S, S, S, S, C, S, S, S, S, S, C, S, C, S, S, S, C, C,…\n$ train_test    <fct> train, train, train, train, train, train, train, train, …\n$ pax_type      <fct> Mr., F_married, F_unmarried, Mr., F_unmarried, F_married…\n$ surname       <fct> \"Braund,\", \"Futrelle,\", \"Bonnell,\", \"Saundercock,\", \"Ves…\n$ cabin_preface <fct> nk, C, C, nk, nk, nk, nk, nk, nk, C, nk, nk, nk, nk, nk,…\n$ ticket_group  <fct> single, couple, single, single, single, single, couple, …\n$ family_group  <ord> couple, couple, single, single, single, single, single, …\n$ age_group     <ord> 20s, 30s, 50s, 20s, teen, 30s, 30s, child, 30s, teen, 20…\n\n\nCode\n# rlr_pred <- predict(rlr_final_fit,train_2 )%>% \n#   bind_cols(predict(rlr_final_fit, train_2,type=\"prob\")) %>% \n#   bind_cols(train_2 %>% select(survived))\n# \n# rlr_pred %>% \n#   roc_auc(truth = survived, .pred_1, event_level = \"second\")\n# \n# rlr_pred %>% \n#   roc_curve(truth = survived, .pred_1,event_level=\"second\") %>% \n#   autoplot()\n# \n# \n# rlr_metrics <- rlr_pred %>% \n# metrics(truth = survived, estimate = .pred_class) %>% \n#   filter(.metric == \"accuracy\")\n# rlr_metrics\n# survive_rlr_pred <- \n#   augment(survive_lr_fit, train_2)\n# survive_rlr_pred\n\n\n\n\n0.5.6 RLR Confusion Matrix\n\n\nCode\nrlr_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#random-forest",
    "href": "posts/post-with-code/index.html#random-forest",
    "title": "Titanic from Kaggle",
    "section": "0.6 Random Forest",
    "text": "0.6 Random Forest\n\n0.6.1 RF Model Spec - Ranger\n\n\nCode\nrf_model <- \n  rand_forest(trees = 1000) %>% \n  set_engine(\"ranger\") %>% \n  set_mode(\"classification\")\n\n\n\n\n0.6.2 RF Workflow\n\n\nCode\nrf_wflow <- \n  workflow() %>% \n  add_model(rf_model) %>% \n  add_recipe(recipe_base)\n\n\n\n\n0.6.3 RF Fit Model\n\n\nCode\nrf_fit <- \n  rf_wflow %>% \n  last_fit(train_split)\n\nrf_final_metrics <- collect_metrics(rf_fit)\nrf_final_metrics\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.821 Preprocessor1_Model1\n2 roc_auc  binary         0.847 Preprocessor1_Model1\n\n\n\n\n0.6.4 RF Predict\n\n\nCode\nrf_final_fit <- rf_wflow %>% fit(train_test)\nclass(rf_final_fit)\n\n\n[1] \"workflow\"\n\n\nCode\n rf_test_predictions <- \n  predict(rf_final_fit, new_data = train_test) %>% \n   bind_cols(predict(rf_final_fit, train_test,type = \"prob\")) %>% \n   bind_cols(train_test %>% select(survived))\n\n \n head(rf_test_predictions)\n\n\n# A tibble: 6 × 4\n  .pred_class .pred_0 .pred_1 survived\n  <fct>         <dbl>   <dbl> <fct>   \n1 0            0.776   0.224  0       \n2 1            0.0756  0.924  1       \n3 1            0.206   0.794  1       \n4 0            0.924   0.0758 0       \n5 1            0.459   0.541  0       \n6 1            0.380   0.620  1       \n\n\n\n\n0.6.5 RF Performance on Training Set\n\n\nCode\nrf_test_predictions %>% \n  roc_auc(truth = survived, .pred_1,event_level = \"second\")\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.961\n\n\nCode\nrf_metrics_accuracy <- rf_test_predictions %>% \n  metrics(truth = survived, estimate = .pred_class) %>% \n  filter(.metric == \"accuracy\")\nrf_metrics_accuracy\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.915\n\n\nCode\nrf_test_predictions %>% \n  roc_curve(truth = survived, .pred_1,event_level = \"second\") %>% \n  autoplot()\n\n\n\n\n\n\n\n0.6.6 RF Confusion Matrix\n\n\nCode\nrf_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")\n\n\n\n\n\n\n\n0.6.7 RF Resampling\n\n\nCode\n#folds <- vfold_cv(training(train_split), strata = survived, v=5)\n#folds\n\ncontrol <- control_resamples(save_pred = TRUE,save_workflow = TRUE)\n\ncores <- parallel::detectCores()\nset.seed(1234)\ndoParallel::registerDoParallel(cores = cores)\n\nrf_fit_cv <- \n  rf_wflow %>% \n  fit_resamples(folds, control = control)\n\n#show_best(lr_fit_cv,metric= \"accuracy\")\n\n#lr_fit_cv\nrf_metrics_resample <- collect_metrics(rf_fit_cv)\nrf_metrics_resample\n\n\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy binary     0.838     5  0.0173 Preprocessor1_Model1\n2 roc_auc  binary     0.871     5  0.0182 Preprocessor1_Model1"
  },
  {
    "objectID": "posts/post-with-code/index.html#xg-boost---usemodel",
    "href": "posts/post-with-code/index.html#xg-boost---usemodel",
    "title": "Titanic from Kaggle",
    "section": "0.7 XG Boost - Usemodel",
    "text": "0.7 XG Boost - Usemodel\n\n0.7.1 XGB - Usemodel Library specs\n\n\nCode\nlibrary(usemodels)\n\n\nWarning: package 'usemodels' was built under R version 4.2.1\n\n\nCode\nuse_xgboost(survived ~ .,\n            data=train_train,\n            verbose = TRUE\n  \n)\n\n\nxgboost_recipe <- \n  recipe(formula = survived ~ ., data = train_train) %>% \n  step_novel(all_nominal_predictors()) %>% \n  ## This model requires the predictors to be numeric. The most common \n  ## method to convert qualitative predictors to numeric is to create \n  ## binary indicator variables (aka dummy variables) from these \n  ## predictors. However, for this model, binary indicator variables can be \n  ## made for each of the levels of the factors (known as 'one-hot \n  ## encoding'). \n  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>% \n  step_zv(all_predictors()) \n\nxgboost_spec <- \n  boost_tree(trees = tune(), min_n = tune(), tree_depth = tune(), learn_rate = tune(), \n    loss_reduction = tune(), sample_size = tune()) %>% \n  set_mode(\"classification\") %>% \n  set_engine(\"xgboost\") \n\nxgboost_workflow <- \n  workflow() %>% \n  add_recipe(xgboost_recipe) %>% \n  add_model(xgboost_spec) \n\nset.seed(33729)\nxgboost_tune <-\n  tune_grid(xgboost_workflow, resamples = stop(\"add your rsample object\"), grid = stop(\"add number of candidate points\"))\n\n\n\n\n0.7.2 XGB - Parameters\nThis grid is used for both versions of XG Boost.\n\n\nCode\nxgb_grid <- grid_latin_hypercube(\n  tree_depth(),\n  min_n(),\n  trees(),\n  loss_reduction(),\n  sample_size = sample_prop(),\n  finalize(mtry(), train_train),\n  learn_rate(),\n  size = 30\n)\n\nhead(xgb_grid)\n\n\n# A tibble: 6 × 7\n  tree_depth min_n trees loss_reduction sample_size  mtry   learn_rate\n       <int> <int> <int>          <dbl>       <dbl> <int>        <dbl>\n1          9    20  1622        4.07e-9       0.580    15 0.000000110 \n2          3    10   655        3.12e-4       0.523    13 0.0000000132\n3          1    36   208        9.59e-8       0.201    16 0.00000115  \n4         14    13  1672        1.16e-8       0.266    17 0.000000307 \n5         15    14   489        1.72e+1       0.689     8 0.0000000101\n6          4    16  1039        2.34e-2       0.986    12 0.0163      \n\n\n\n\nCode\nxgboost_usemodel_recipe <- \n  recipe(formula = survived ~ ., data = train_train) %>% \n  step_novel(all_nominal_predictors()) %>% \n  ## This model requires the predictors to be numeric. The most common \n  ## method to convert qualitative predictors to numeric is to create \n  ## binary indicator variables (aka dummy variables) from these \n  ## predictors. However, for this model, binary indicator variables can be \n  ## made for each of the levels of the factors (known as 'one-hot \n  ## encoding'). \n  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>% \n  step_zv(all_predictors()) \n\nxgboost_usemodel_model <- \n  boost_tree(trees = tune(), mtry = tune(),min_n = tune(), tree_depth = tune(), learn_rate = tune(), \n    loss_reduction = tune(), sample_size = tune()) %>% \n  set_mode(\"classification\") %>% \n  set_engine(\"xgboost\") \n\nxgboost_usemodel_wflow <- \n  workflow() %>% \n  add_recipe(xgboost_usemodel_recipe) %>% \n  add_model(xgboost_usemodel_model) \n\ndoParallel::registerDoParallel(cores = cores)\n\nset.seed(234)\nxgboost_usemodel_tune <-\n  tune_grid(xgboost_usemodel_wflow, resamples = folds, grid = xgb_grid)\n\n\n\n\n0.7.3 XGB - Usemodel Best Parameter Settings\n\n\nCode\nxgb_tuning_metrics_usemodel <- collect_metrics(xgboost_usemodel_tune)\nxgb_tuning_metrics_usemodel\n\n\n# A tibble: 60 × 13\n    mtry trees min_n tree_…¹ learn…² loss_…³ sampl…⁴ .metric .esti…⁵  mean     n\n   <int> <int> <int>   <int>   <dbl>   <dbl>   <dbl> <chr>   <chr>   <dbl> <int>\n 1    16   208    36       1 1.15e-6 9.59e-8   0.201 accura… binary  0.616     5\n 2    16   208    36       1 1.15e-6 9.59e-8   0.201 roc_auc binary  0.5       5\n 3     6  1202     4       2 4.27e-7 9.25e-4   0.944 accura… binary  0.616     5\n 4     6  1202     4       2 4.27e-7 9.25e-4   0.944 roc_auc binary  0.817     5\n 5     4   559    39       2 7.47e-3 5.95e+0   0.410 accura… binary  0.616     5\n 6     4   559    39       2 7.47e-3 5.95e+0   0.410 roc_auc binary  0.5       5\n 7    18  1107     3       3 3.83e-3 1.10e-4   0.492 accura… binary  0.681     5\n 8    18  1107     3       3 3.83e-3 1.10e-4   0.492 roc_auc binary  0.818     5\n 9    13   655    10       3 1.32e-8 3.12e-4   0.523 accura… binary  0.679     5\n10    13   655    10       3 1.32e-8 3.12e-4   0.523 roc_auc binary  0.811     5\n# … with 50 more rows, 2 more variables: std_err <dbl>, .config <chr>, and\n#   abbreviated variable names ¹​tree_depth, ²​learn_rate, ³​loss_reduction,\n#   ⁴​sample_size, ⁵​.estimator\n\n\nCode\nxgboost_usemodel_tune %>%\n  collect_metrics() %>%\n  filter(.metric == \"accuracy\") %>%\n  select(mean, mtry:sample_size) %>%\n  pivot_longer(mtry:sample_size,\n               values_to = \"value\",\n               names_to = \"parameter\"\n  ) %>%\n  ggplot(aes(value, mean, color = parameter)) +\n  geom_point(alpha = 0.8, show.legend = FALSE) +\n  facet_wrap(~parameter, scales = \"free_x\") +\n  labs(x = NULL, y = \"Accuracy\")\n\n\n\n\n\nNow select best from above\n\n\nCode\nshow_best(xgboost_usemodel_tune, \"accuracy\")\n\n\n# A tibble: 5 × 13\n   mtry trees min_n tree_d…¹ learn…² loss_…³ sampl…⁴ .metric .esti…⁵  mean     n\n  <int> <int> <int>    <int>   <dbl>   <dbl>   <dbl> <chr>   <chr>   <dbl> <int>\n1    10  1571    24       14 3.48e-2 8.60e-7   0.877 accura… binary  0.784     5\n2     9   967    32        7 5.09e-2 2.78e-2   0.710 accura… binary  0.772     5\n3    12  1039    16        4 1.63e-2 2.34e-2   0.986 accura… binary  0.759     5\n4    18  1107     3        3 3.83e-3 1.10e-4   0.492 accura… binary  0.681     5\n5    13   655    10        3 1.32e-8 3.12e-4   0.523 accura… binary  0.679     5\n# … with 2 more variables: std_err <dbl>, .config <chr>, and abbreviated\n#   variable names ¹​tree_depth, ²​learn_rate, ³​loss_reduction, ⁴​sample_size,\n#   ⁵​.estimator\n\n\nCode\nxgb_usemodel_best_params <- select_best(xgboost_usemodel_tune, \"accuracy\")\nxgb_usemodel_best_params\n\n\n# A tibble: 1 × 8\n   mtry trees min_n tree_depth learn_rate loss_reduction sample_size .config    \n  <int> <int> <int>      <int>      <dbl>          <dbl>       <dbl> <chr>      \n1    10  1571    24         14     0.0348    0.000000860       0.877 Preprocess…\n\n\nCode\nxgb_usemodel_final_wflow <- finalize_workflow(\n  xgboost_usemodel_wflow,\n  xgb_usemodel_best_params\n)\n\nxgb_usemodel_final_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: boost_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_novel()\n• step_dummy()\n• step_zv()\n\n── Model ───────────────────────────────────────────────────────────────────────\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = 10\n  trees = 1571\n  min_n = 24\n  tree_depth = 14\n  learn_rate = 0.0348129952678471\n  loss_reduction = 8.60498209075984e-07\n  sample_size = 0.877007868885994\n\nComputational engine: xgboost \n\n\n\n\n0.7.4 XGB - Usemodel Parameter Ranking - VIP\n\n\nCode\nxgb_usemodel_final_wflow %>%\n  fit(data = train_train) %>%\n  extract_fit_parsnip() %>%\n  vip(geom = \"point\")\n\n\nWarning: There are new levels in a factor: NA\n\n\n\n\n\n\n\n0.7.5 XGB - Usemodel Performance\n\nXGB - Usemodel Accuracy Measured on Test Set\n\n\nCode\nset.seed(234)\nxgb_usemodel_final_res <- last_fit(xgb_usemodel_final_wflow, train_split)\nxgb_usemodel_final_res\n\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits            id               .metrics .notes   .predictions .workflow \n  <list>            <chr>            <list>   <list>   <list>       <list>    \n1 <split [667/224]> train/test split <tibble> <tibble> <tibble>     <workflow>\n\nThere were issues with some computations:\n\n  - Warning(s) x2: There are new levels in a factor: NA\n\nRun `show_notes(.Last.tune.result)` for more information.\n\n\nCode\nxgb_usemodel_final_metrics <- collect_metrics(xgb_usemodel_final_res)\nxgb_usemodel_final_metrics\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.777 Preprocessor1_Model1\n2 roc_auc  binary         0.817 Preprocessor1_Model1\n\n\n\n\nXGB - Usemodel AUC on Test Set (within train)\n\n\nCode\nxgb_usemodel_final_res %>%\n  collect_predictions() %>%\n  roc_curve( truth = survived,.pred_1, event_level = \"second\") %>%\n  ggplot(aes(x = 1-specificity, y = sensitivity)) +\n  geom_line(size = 1.5, color = \"midnightblue\") +\n  geom_abline(\n    lty = 2, alpha = 0.5,\n    color = \"gray50\",\n    size = 1.2\n  )\n\n\n\n\n\n\n\nCode\nxgb_usemodel_test_predictions <- collect_predictions(xgb_usemodel_final_res)\nhead(xgb_usemodel_test_predictions)\n\n\n# A tibble: 6 × 7\n  id               .pred_0 .pred_1  .row .pred_class survived .config           \n  <chr>              <dbl>   <dbl> <int> <fct>       <fct>    <chr>             \n1 train/test split   0.866   0.134     1 0           0        Preprocessor1_Mod…\n2 train/test split   0.264   0.736     4 1           1        Preprocessor1_Mod…\n3 train/test split   0.273   0.727    12 1           1        Preprocessor1_Mod…\n4 train/test split   0.873   0.127    13 0           0        Preprocessor1_Mod…\n5 train/test split   0.500   0.500    15 1           0        Preprocessor1_Mod…\n6 train/test split   0.541   0.459    20 0           1        Preprocessor1_Mod…\n\n\n\n\n\n0.7.6 XGB - Usemodel Confusion Matrix\n\n\nCode\nxgb_usemodel_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#xg-boost---base-recipe",
    "href": "posts/post-with-code/index.html#xg-boost---base-recipe",
    "title": "Titanic from Kaggle",
    "section": "0.8 XG Boost - Base Recipe",
    "text": "0.8 XG Boost - Base Recipe\n\n0.8.1 XGB Model Spec\n\n\nCode\nxgb_model <- \n  boost_tree(\n    trees = tune(),\n    tree_depth = tune(),\n    min_n = tune(),\n    loss_reduction = tune(),\n    sample_size = tune(),\n    mtry = tune(),\n    learn_rate = tune()) %>% \n  set_engine(\"xgboost\") %>% \n  set_mode(\"classification\")\n\nxgb_model\n\n\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = tune()\n  min_n = tune()\n  tree_depth = tune()\n  learn_rate = tune()\n  loss_reduction = tune()\n  sample_size = tune()\n\nComputational engine: xgboost \n\n\n\n\n0.8.2 XGB Workflow\n\n\nCode\nxgb_wflow <- \n  workflow() %>% \n  add_model(xgb_model) %>% \n  add_recipe(recipe_base)\n\n\n\n\n0.8.3 XGB Hyper-Parameter Tuning\n\n\nCode\n# xgb_folds <- vfold_cv(training(train_split), strata = survived)\n# xgb_folds\n\n\ndoParallel::registerDoParallel(cores = cores)\n\nset.seed(234)\nxgb_tuning_result <- tune_grid(\n  xgb_wflow,\n  resamples = folds,\n  grid      = xgb_grid,\n  control  = control_grid(save_pred = TRUE,save_workflow = TRUE)\n)\nxgb_tuning_result\n\n\n# Tuning results\n# 5-fold cross-validation using stratification \n# A tibble: 5 × 5\n  splits            id    .metrics           .notes           .predictions\n  <list>            <chr> <list>             <list>           <list>      \n1 <split [532/135]> Fold1 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n2 <split [534/133]> Fold2 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n3 <split [534/133]> Fold3 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n4 <split [534/133]> Fold4 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n5 <split [534/133]> Fold5 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n\n\n\n\nCode\nxgb_tuning_metrics <- collect_metrics(xgb_tuning_result)\nxgb_tuning_metrics\n\n\n# A tibble: 60 × 13\n    mtry trees min_n tree_…¹ learn…² loss_…³ sampl…⁴ .metric .esti…⁵  mean     n\n   <int> <int> <int>   <int>   <dbl>   <dbl>   <dbl> <chr>   <chr>   <dbl> <int>\n 1    16   208    36       1 1.15e-6 9.59e-8   0.201 accura… binary  0.616     5\n 2    16   208    36       1 1.15e-6 9.59e-8   0.201 roc_auc binary  0.5       5\n 3     6  1202     4       2 4.27e-7 9.25e-4   0.944 accura… binary  0.798     5\n 4     6  1202     4       2 4.27e-7 9.25e-4   0.944 roc_auc binary  0.854     5\n 5     4   559    39       2 7.47e-3 5.95e+0   0.410 accura… binary  0.616     5\n 6     4   559    39       2 7.47e-3 5.95e+0   0.410 roc_auc binary  0.5       5\n 7    18  1107     3       3 3.83e-3 1.10e-4   0.492 accura… binary  0.837     5\n 8    18  1107     3       3 3.83e-3 1.10e-4   0.492 roc_auc binary  0.874     5\n 9    13   655    10       3 1.32e-8 3.12e-4   0.523 accura… binary  0.798     5\n10    13   655    10       3 1.32e-8 3.12e-4   0.523 roc_auc binary  0.852     5\n# … with 50 more rows, 2 more variables: std_err <dbl>, .config <chr>, and\n#   abbreviated variable names ¹​tree_depth, ²​learn_rate, ³​loss_reduction,\n#   ⁴​sample_size, ⁵​.estimator\n\n\nCode\nxgb_tuning_result %>%\n  collect_metrics() %>%\n  filter(.metric == \"accuracy\") %>%\n  select(mean, mtry:sample_size) %>%\n  pivot_longer(mtry:sample_size,\n               values_to = \"value\",\n               names_to = \"parameter\"\n  ) %>%\n  ggplot(aes(value, mean, color = parameter)) +\n  geom_point(alpha = 0.8, show.legend = FALSE) +\n  facet_wrap(~parameter, scales = \"free_x\") +\n  labs(x = NULL, y = \"AUC\")\n\n\n\n\n\n\nXGB Best Parameters then Finalise Workflow\n\n\nCode\nshow_best(xgb_tuning_result, \"accuracy\")\n\n\n# A tibble: 5 × 13\n   mtry trees min_n tree_d…¹ learn…² loss_…³ sampl…⁴ .metric .esti…⁵  mean     n\n  <int> <int> <int>    <int>   <dbl>   <dbl>   <dbl> <chr>   <chr>   <dbl> <int>\n1    18  1107     3        3 3.83e-3 1.10e-4   0.492 accura… binary  0.837     5\n2    12  1039    16        4 1.63e-2 2.34e-2   0.986 accura… binary  0.820     5\n3    10  1571    24       14 3.48e-2 8.60e-7   0.877 accura… binary  0.814     5\n4     3  1814     5        6 5.67e-6 3.81e-6   0.913 accura… binary  0.810     5\n5     4   840     7       11 3.22e-8 1.94e-1   0.775 accura… binary  0.799     5\n# … with 2 more variables: std_err <dbl>, .config <chr>, and abbreviated\n#   variable names ¹​tree_depth, ²​learn_rate, ³​loss_reduction, ⁴​sample_size,\n#   ⁵​.estimator\n\n\nCode\nxgb_best_params <- select_best(xgb_tuning_result, \"accuracy\")\nxgb_best_params\n\n\n# A tibble: 1 × 8\n   mtry trees min_n tree_depth learn_rate loss_reduction sample_size .config    \n  <int> <int> <int>      <int>      <dbl>          <dbl>       <dbl> <chr>      \n1    18  1107     3          3    0.00383       0.000110       0.492 Preprocess…\n\n\nCode\nxgb_final_wflow <- finalize_workflow(\n  xgb_wflow,\n  xgb_best_params\n)\n\nxgb_final_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: boost_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = 18\n  trees = 1107\n  min_n = 3\n  tree_depth = 3\n  learn_rate = 0.0038298863779315\n  loss_reduction = 0.00011029830522072\n  sample_size = 0.492113380425144\n\nComputational engine: xgboost \n\n\n\n\nCode\nxgb_final_wflow %>%\n  fit(data = train_train) %>%\n  extract_fit_parsnip() %>%\n  vip(geom = \"point\")\n\n\n\n\n\n\n\n\n0.8.4 XGB Performance on Training Test Set\n\nXGB Accuracy Measured on Test Set\n\n\nCode\nxgb_final_res <- last_fit(xgb_final_wflow, train_split)\nxgb_final_res\n\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits            id               .metrics .notes   .predictions .workflow \n  <list>            <chr>            <list>   <list>   <list>       <list>    \n1 <split [667/224]> train/test split <tibble> <tibble> <tibble>     <workflow>\n\n\nCode\nxgb_final_metrics <- collect_metrics(xgb_final_res)\nxgb_final_metrics\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.786 Preprocessor1_Model1\n2 roc_auc  binary         0.840 Preprocessor1_Model1\n\n\n\n\nXGB AUC on Test Set (within train)\n\n\nCode\nxgb_final_res %>%\n  collect_predictions() %>%\n  roc_curve( truth = survived,.pred_1, event_level = \"second\") %>%\n  ggplot(aes(x = 1-specificity, y = sensitivity)) +\n  geom_line(size = 1.5, color = \"midnightblue\") +\n  geom_abline(\n    lty = 2, alpha = 0.5,\n    color = \"gray50\",\n    size = 1.2\n  )\n\n\n\n\n\n\n\nCode\nxgb_test_predictions <- collect_predictions(xgb_final_res)\nhead(xgb_test_predictions)\n\n\n# A tibble: 6 × 7\n  id               .pred_0 .pred_1  .row .pred_class survived .config           \n  <chr>              <dbl>   <dbl> <int> <fct>       <fct>    <chr>             \n1 train/test split  0.916   0.0842     1 0           0        Preprocessor1_Mod…\n2 train/test split  0.0684  0.932      4 1           1        Preprocessor1_Mod…\n3 train/test split  0.160   0.840     12 1           1        Preprocessor1_Mod…\n4 train/test split  0.875   0.125     13 0           0        Preprocessor1_Mod…\n5 train/test split  0.309   0.691     15 1           0        Preprocessor1_Mod…\n6 train/test split  0.458   0.542     20 1           1        Preprocessor1_Mod…\n\n\n\n\n\n0.8.5 XGB Confusion Matrix\n\n\nCode\nxgb_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#neural-net",
    "href": "posts/post-with-code/index.html#neural-net",
    "title": "Titanic from Kaggle",
    "section": "0.9 Neural Net",
    "text": "0.9 Neural Net\n\n0.9.1 NN Model\n\n\nCode\nnnet_model <- \n   mlp(hidden_units = tune(), penalty = tune(), epochs = tune()) %>% \n   set_engine(\"nnet\", MaxNWts = 2600) %>% \n   set_mode(\"classification\")\n\nnnet_model %>% translate()\n\n\nSingle Layer Neural Network Model Specification (classification)\n\nMain Arguments:\n  hidden_units = tune()\n  penalty = tune()\n  epochs = tune()\n\nEngine-Specific Arguments:\n  MaxNWts = 2600\n\nComputational engine: nnet \n\nModel fit template:\nnnet::nnet(formula = missing_arg(), data = missing_arg(), size = tune(), \n    decay = tune(), maxit = tune(), MaxNWts = 2600, trace = FALSE, \n    linout = FALSE)\n\n\n\n\n0.9.2 NN Workflow\n\n\nCode\nnnet_wflow <- workflow() %>% \n  add_model(nnet_model) %>% \n  add_recipe(recipe_base)\n\n\n\n\n0.9.3 NN Parameters\n\n\nCode\nnnet_grid <- grid_latin_hypercube(\n  hidden_units(),\n  penalty (),\n  epochs ()\n)\n\nhead(nnet_grid) \n\n\n# A tibble: 3 × 3\n  hidden_units  penalty epochs\n         <int>    <dbl>  <int>\n1            2 3.13e- 4    996\n2            6 4.14e- 2    182\n3            9 2.89e-10    377\n\n\n\n\n0.9.4 NN Hyper-Parameter Tuning\n\n\nCode\nnnet_folds <- vfold_cv(train_train, strata = survived)\nnnet_folds\n\n\n#  10-fold cross-validation using stratification \n# A tibble: 10 × 2\n   splits           id    \n   <list>           <chr> \n 1 <split [599/68]> Fold01\n 2 <split [600/67]> Fold02\n 3 <split [600/67]> Fold03\n 4 <split [600/67]> Fold04\n 5 <split [600/67]> Fold05\n 6 <split [600/67]> Fold06\n 7 <split [601/66]> Fold07\n 8 <split [601/66]> Fold08\n 9 <split [601/66]> Fold09\n10 <split [601/66]> Fold10\n\n\nCode\ndoParallel::registerDoParallel(cores = cores)\n\nset.seed(234)\nnnet_tuning_result <- tune_grid(\n  nnet_wflow,\n  resamples = folds,\n  grid      = nnet_grid,\n  control   = control_grid(save_pred = TRUE,save_workflow = TRUE)\n)\nnnet_tuning_result\n\n\n# Tuning results\n# 5-fold cross-validation using stratification \n# A tibble: 5 × 5\n  splits            id    .metrics         .notes           .predictions      \n  <list>            <chr> <list>           <list>           <list>            \n1 <split [532/135]> Fold1 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [405 × 9]>\n2 <split [534/133]> Fold2 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [399 × 9]>\n3 <split [534/133]> Fold3 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [399 × 9]>\n4 <split [534/133]> Fold4 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [399 × 9]>\n5 <split [534/133]> Fold5 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [399 × 9]>\n\n\n\n\n0.9.5 NN Best Parameters and Finalise Workflow\n\n\nCode\nshow_best(nnet_tuning_result, \"accuracy\")\n\n\n# A tibble: 3 × 9\n  hidden_units  penalty epochs .metric  .estimator  mean     n std_err .config  \n         <int>    <dbl>  <int> <chr>    <chr>      <dbl> <int>   <dbl> <chr>    \n1            6 4.14e- 2    182 accuracy binary     0.810     5  0.0235 Preproce…\n2            9 2.89e-10    377 accuracy binary     0.807     5  0.0187 Preproce…\n3            2 3.13e- 4    996 accuracy binary     0.800     5  0.0182 Preproce…\n\n\nCode\nnn_best_params <- select_best(nnet_tuning_result, \"accuracy\")\n\nnnet_best_auc <- select_best(xgb_tuning_result, \"accuracy\")\nnnet_best_auc\n\n\n# A tibble: 1 × 8\n   mtry trees min_n tree_depth learn_rate loss_reduction sample_size .config    \n  <int> <int> <int>      <int>      <dbl>          <dbl>       <dbl> <chr>      \n1    18  1107     3          3    0.00383       0.000110       0.492 Preprocess…\n\n\nCode\nnnet_final_wflow <- finalize_workflow(\n  nnet_wflow,\n  nn_best_params\n)\n\nnnet_final_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: mlp()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nSingle Layer Neural Network Model Specification (classification)\n\nMain Arguments:\n  hidden_units = 6\n  penalty = 0.041396901211693\n  epochs = 182\n\nEngine-Specific Arguments:\n  MaxNWts = 2600\n\nComputational engine: nnet \n\n\n\n\nCode\nnnet_final_wflow %>%\n  fit(data = train_train) %>%\n  extract_fit_parsnip() %>%\n  vip(geom = \"point\")\n\n\n\n\n\n\n\n0.9.6 NN Accuracy - Train/Test Set\n\n\nCode\nnnet_tuning_metrics <- collect_metrics(nnet_tuning_result)\nnnet_tuning_metrics\n\n\n# A tibble: 6 × 9\n  hidden_units  penalty epochs .metric  .estimator  mean     n std_err .config  \n         <int>    <dbl>  <int> <chr>    <chr>      <dbl> <int>   <dbl> <chr>    \n1            2 3.13e- 4    996 accuracy binary     0.800     5  0.0182 Preproce…\n2            2 3.13e- 4    996 roc_auc  binary     0.851     5  0.0230 Preproce…\n3            6 4.14e- 2    182 accuracy binary     0.810     5  0.0235 Preproce…\n4            6 4.14e- 2    182 roc_auc  binary     0.839     5  0.0264 Preproce…\n5            9 2.89e-10    377 accuracy binary     0.807     5  0.0187 Preproce…\n6            9 2.89e-10    377 roc_auc  binary     0.835     5  0.0171 Preproce…\n\n\nCode\nnnet_final_res <- last_fit(nnet_final_wflow, train_split)\nnnet_final_res\n\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits            id               .metrics .notes   .predictions .workflow \n  <list>            <chr>            <list>   <list>   <list>       <list>    \n1 <split [667/224]> train/test split <tibble> <tibble> <tibble>     <workflow>\n\n\nCode\nnnet_final_metrics <- collect_metrics(nnet_final_res)\nnnet_final_metrics\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.799 Preprocessor1_Model1\n2 roc_auc  binary         0.830 Preprocessor1_Model1\n\n\n\n\n0.9.7 NN AUC\n\n\nCode\nnnet_final_res %>%\n  collect_predictions() %>%\n  roc_curve( truth = survived,.pred_1, event_level = \"second\") %>%\n  ggplot(aes(x = 1-specificity, y = sensitivity)) +\n  geom_line(size = 1.5, color = \"midnightblue\") +\n  geom_abline(\n    lty = 2, alpha = 0.5,\n    color = \"gray50\",\n    size = 1.2\n  )\n\n\n\n\n\n\n\n0.9.8 NN Predictions on Train/Test Set\n\n\nCode\nnnet_test_predictions <- nnet_final_res %>%\n  collect_predictions() \nhead(nnet_test_predictions)\n\n\n# A tibble: 6 × 7\n  id               .pred_0 .pred_1  .row .pred_class survived .config           \n  <chr>              <dbl>   <dbl> <int> <fct>       <fct>    <chr>             \n1 train/test split   0.553   0.447     1 0           0        Preprocessor1_Mod…\n2 train/test split   0.287   0.713     4 1           1        Preprocessor1_Mod…\n3 train/test split   0.485   0.515    12 1           1        Preprocessor1_Mod…\n4 train/test split   0.699   0.301    13 0           0        Preprocessor1_Mod…\n5 train/test split   0.323   0.677    15 1           0        Preprocessor1_Mod…\n6 train/test split   0.342   0.658    20 1           1        Preprocessor1_Mod…\n\n\n\n\n0.9.9 NN Confusion Matrix\n\n\nCode\nnnet_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#stack-models---not-working",
    "href": "posts/post-with-code/index.html#stack-models---not-working",
    "title": "Titanic from Kaggle",
    "section": "0.10 Stack Models - not working",
    "text": "0.10 Stack Models - not working\n\n0.10.1 Stack Recipe\n\n\nCode\nrecipe_stack <- \n  recipe(survived ~ ., data = training(train_split)) %>% \n  update_role(passenger_id, name,surname,ticket,cabin,new_role = \"ID\") %>% \n  step_impute_knn(all_numeric_predictors()) %>% \n  step_dummy(all_nominal_predictors()) %>%\n  step_factor2string(all_nominal_predictors()) %>% \n  step_zv(all_predictors()) %>% \n  step_pca()\nrecipe_stack\n\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          5\n   outcome          1\n predictor         13\n\nOperations:\n\nK-nearest neighbor imputation for all_numeric_predictors()\nDummy variables from all_nominal_predictors()\nCharacter variables from all_nominal_predictors()\nZero variance filter on all_predictors()\nPCA extraction with <none>\n\n\nCode\nrecipe_stack_trained <- prep(recipe_base)\nrecipe_stack_trained\n\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          5\n   outcome          1\n predictor         13\n\nTraining data contained 667 data points and 510 incomplete rows. \n\nOperations:\n\nK-nearest neighbor imputation for age, sib_sp, parch, fare [trained]\nDummy variables from pclass, sex, embarked, train_test, pax_type, cabin_prefac... [trained]\nCharacter variables from <none> [trained]\nZero variance filter removed train_test_test, pax_type_F_titled [trained]\nNo PCA components were extracted from <none> [trained]\n\n\n\n\n0.10.2 Stack Controls\n\n\nCode\nstack_ctrl <- control_resamples(save_pred = TRUE, save_workflow = TRUE)\n#stack_folds <- vfold_cv(training(train_split), v=10,strata = \"survived\")\n\nlibrary(stacks)\n\n\nWarning: package 'stacks' was built under R version 4.2.1\n\n\nCode\nmodel_stack <-\n  stacks() %>%\n  #add_candidates(lr_wflow) %>%\n  #add_candidates(rf_wflow) %>%\n  add_candidates(nnet_tuning_result) %>%\n  add_candidates(rlr_tuning_result) %>% \n  add_candidates(xgb_tuning_result)\n\n\nWarning: Predictions from 7 candidates were identical to those from existing\ncandidates and were removed from the data stack.\n\n\n\n\n0.10.3 Stack LR\n\n\nCode\nstack_lr_wflow <- \n  workflow() %>% \n  add_model(lr_spec) %>% \n  add_recipe(recipe_stack)\nlr_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\nCode\nstack_lr_res <- \n  lr_wflow %>% \n  tune_grid(folds,control = stack_ctrl)\n\n\nWarning: No tuning parameters have been detected, performance will be evaluated\nusing the resamples with no tuning. Did you want to [tune()] parameters?\n\n\nCode\nstack_lr_res\n\n\n# Tuning results\n# 5-fold cross-validation using stratification \n# A tibble: 5 × 5\n  splits            id    .metrics         .notes           .predictions      \n  <list>            <chr> <list>           <list>           <list>            \n1 <split [532/135]> Fold1 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [135 × 6]>\n2 <split [534/133]> Fold2 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [133 × 6]>\n3 <split [534/133]> Fold3 <tibble [2 × 4]> <tibble [1 × 3]> <tibble [133 × 6]>\n4 <split [534/133]> Fold4 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [133 × 6]>\n5 <split [534/133]> Fold5 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [133 × 6]>\n\nThere were issues with some computations:\n\n  - Warning(s) x1: prediction from a rank-deficient fit may be misleading\n\nRun `show_notes(.Last.tune.result)` for more information.\n\n\n\n\nCode\n# autoplot(stack_lr_res) + \n#   scale_color_viridis_d(direction = -1) + \n#   theme(legend.position = \"top\")\n\n\n\n\n0.10.4 Stack RLR\n\n\nCode\n# stack_rlr_wflow <- \n#   workflow() %>% \n#   add_model(rlr_model) %>% \n#   add_recipe(recipe_stack)\n# stack_rlr_wflow\n# \n# stack_rlr_res <- \n#   stack_rlr_wflow %>% \n#   fit_resamples(folds,control = stack_ctrl)\n# stack_rlr_res\n\n\n\n\n0.10.5 Initialise Stack\n\n\nCode\nstack_models <-\n  stacks()\nstack_models\n\n\n# A data stack with 0 model definitions and 0 candidate members.\n\n\nCode\nstack_models %>% \nadd_candidates(stack_lr_res)\n\n\nWarning: The inputted `candidates` argument `stack_lr_res` generated notes\nduring tuning/resampling. Model stacking may fail due to these issues; see `?\ncollect_notes` if so.\n\n\n# A data stack with 1 model definition and 1 candidate member:\n#   stack_lr_res: 1 model configuration\n# Outcome: survived (factor)"
  },
  {
    "objectID": "posts/post-with-code/index.html#join-model-prediction-data",
    "href": "posts/post-with-code/index.html#join-model-prediction-data",
    "title": "Titanic from Kaggle",
    "section": "0.11 Join Model Prediction Data",
    "text": "0.11 Join Model Prediction Data\n\n\nCode\nall_predictions <- \n  lr_test_predictions %>% mutate(model = \"LR\") %>% \n  bind_rows(nnet_test_predictions %>% mutate(model = \"NNet\")) %>% \n  bind_rows(rlr_test_predictions %>% mutate(model = \"Reg_LR\")) %>% \n  bind_rows(rf_test_predictions %>% mutate(model = \"RF\")) %>% \n  bind_rows(xgb_test_predictions %>% mutate(model = \"xgb\")) %>% \n  bind_rows(xgb_usemodel_test_predictions %>% mutate(model = \"xgb_usemodel\")) %>% \n  bind_rows(ensemble_test_predictions %>% mutate(model = \"ensemble\"))\n  \nall_predictions %>% knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\n.pred_0\n.pred_1\n.row\n.pred_class\nsurvived_pred\n.config\npassenger_id\nsurvived\npclass\nname\nsex\nage\nsib_sp\nparch\nticket\nfare\ncabin\nembarked\ntrain_test\npax_type\nsurname\ncabin_preface\nticket_group\nfamily_group\nage_group\nmodel\n\n\n\n\ntrain/test split\n0.9608811\n0.0391189\n1\n0\n0\nPreprocessor1_Model1\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.00\n1\n0\nA/5 21171\n7.2500\nNA\nS\ntrain\nMr.\nBraund,\nnk\nsingle\ncouple\n20s\nLR\n\n\ntrain/test split\n0.0726357\n0.9273643\n4\n1\n1\nPreprocessor1_Model1\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.00\n1\n0\n113803\n53.1000\nC123\nS\ntrain\nF_married\nFutrelle,\nC\ncouple\ncouple\n30s\nLR\n\n\ntrain/test split\n0.2727795\n0.7272205\n12\n1\n1\nPreprocessor1_Model1\n12\n1\n1\nBonnell, Miss. Elizabeth\nfemale\n58.00\n0\n0\n113783\n26.5500\nC103\nS\ntrain\nF_unmarried\nBonnell,\nC\nsingle\nsingle\n50s\nLR\n\n\ntrain/test split\n0.9245727\n0.0754273\n13\n0\n0\nPreprocessor1_Model1\n13\n0\n3\nSaundercock, Mr. William Henry\nmale\n20.00\n0\n0\nA/5. 2151\n8.0500\nNA\nS\ntrain\nMr.\nSaundercock,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.2960033\n0.7039967\n15\n1\n0\nPreprocessor1_Model1\n15\n0\n3\nVestrom, Miss. Hulda Amanda Adolfina\nfemale\n14.00\n0\n0\n350406\n7.8542\nNA\nS\ntrain\nF_unmarried\nVestrom,\nnk\nsingle\nsingle\nteen\nLR\n\n\ntrain/test split\n0.1286281\n0.8713719\n20\n1\n1\nPreprocessor1_Model1\n20\n1\n3\nMasselmani, Mrs. Fatima\nfemale\n31.00\n0\n0\n2649\n7.2250\nNA\nC\ntrain\nF_married\nMasselmani,\nnk\nsingle\nsingle\n30s\nLR\n\n\ntrain/test split\n0.8339019\n0.1660981\n21\n0\n0\nPreprocessor1_Model1\n21\n0\n2\nFynney, Mr. Joseph J\nmale\n35.00\n0\n0\n239865\n26.0000\nNA\nS\ntrain\nMr.\nFynney,\nnk\ncouple\nsingle\n30s\nLR\n\n\ntrain/test split\n0.7151079\n0.2848921\n25\n0\n0\nPreprocessor1_Model1\n25\n0\n3\nPalsson, Miss. Torborg Danira\nfemale\n8.00\n3\n1\n349909\n21.0750\nNA\nS\ntrain\nF_unmarried\nPalsson,\nnk\ngroup\nfamily\nchild\nLR\n\n\ntrain/test split\n0.9614303\n0.0385697\n26\n0\n1\nPreprocessor1_Model1\n26\n1\n3\nAsplund, Mrs. Carl Oscar (Selma Augusta Emilia Johansson)\nfemale\n38.00\n1\n5\n347077\n31.3875\nNA\nS\ntrain\nF_married\nAsplund,\nnk\ngroup\nfamily\n30s\nLR\n\n\ntrain/test split\n0.9265580\n0.0734420\n28\n0\n0\nPreprocessor1_Model1\n28\n0\n1\nFortune, Mr. Charles Alexander\nmale\n19.00\n3\n2\n19950\n263.0000\nC23 C25 C27\nS\ntrain\nMr.\nFortune,\nC\ngroup\nfamily\nteen\nLR\n\n\ntrain/test split\n0.9413283\n0.0586717\n30\n0\n0\nPreprocessor1_Model1\n30\n0\n3\nTodoroff, Mr. Lalio\nmale\n26.00\n0\n0\n349216\n7.8958\nNA\nS\ntrain\nMr.\nTodoroff,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.6531363\n0.3468637\n35\n0\n0\nPreprocessor1_Model1\n35\n0\n1\nMeyer, Mr. Edgar Joseph\nmale\n28.00\n1\n0\nPC 17604\n82.1708\nNA\nC\ntrain\nMr.\nMeyer,\nnk\ncouple\ncouple\n20s\nLR\n\n\ntrain/test split\n0.8401562\n0.1598438\n36\n0\n0\nPreprocessor1_Model1\n36\n0\n1\nHolverson, Mr. Alexander Oskar\nmale\n42.00\n1\n0\n113789\n52.0000\nNA\nS\ntrain\nMr.\nHolverson,\nnk\ncouple\ncouple\n40s\nLR\n\n\ntrain/test split\n0.9073903\n0.0926097\n37\n0\n1\nPreprocessor1_Model1\n37\n1\n3\nMamee, Mr. Hanna\nmale\n26.00\n0\n0\n2677\n7.2292\nNA\nC\ntrain\nMr.\nMamee,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.9276307\n0.0723693\n38\n0\n0\nPreprocessor1_Model1\n38\n0\n3\nCann, Mr. Ernest Charles\nmale\n21.00\n0\n0\nA./5. 2152\n8.0500\nNA\nS\ntrain\nMr.\nCann,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.9412709\n0.0587291\n46\n0\n0\nPreprocessor1_Model1\n46\n0\n3\nRogers, Mr. William John\nmale\n26.00\n0\n0\nS.C./A.4. 23567\n8.0500\nNA\nS\ntrain\nMr.\nRogers,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.8342932\n0.1657068\n51\n0\n0\nPreprocessor1_Model1\n51\n0\n3\nPanula, Master. Juha Niilo\nmale\n7.00\n4\n1\n3101295\n39.6875\nNA\nS\ntrain\nMaster.\nPanula,\nnk\ngroup\nfamily\nchild\nLR\n\n\ntrain/test split\n0.8262275\n0.1737725\n55\n0\n0\nPreprocessor1_Model1\n55\n0\n1\nOstby, Mr. Engelhart Cornelius\nmale\n65.00\n0\n1\n113509\n61.9792\nB30\nC\ntrain\nMr.\nOstby,\nB\ncouple\ncouple\n60+\nLR\n\n\ntrain/test split\n0.8912355\n0.1087645\n61\n0\n0\nPreprocessor1_Model1\n61\n0\n3\nSirayanian, Mr. Orsen\nmale\n22.00\n0\n0\n2669\n7.2292\nNA\nC\ntrain\nMr.\nSirayanian,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.0745555\n0.9254445\n67\n1\n1\nPreprocessor1_Model1\n67\n1\n2\nNye, Mrs. (Elizabeth Ramell)\nfemale\n29.00\n0\n0\nC.A. 29395\n10.5000\nF33\nS\ntrain\nF_married\nNye,\nF\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.9210724\n0.0789276\n68\n0\n0\nPreprocessor1_Model1\n68\n0\n3\nCrease, Mr. Ernest James\nmale\n19.00\n0\n0\nS.P. 3464\n8.1583\nNA\nS\ntrain\nMr.\nCrease,\nnk\nsingle\nsingle\nteen\nLR\n\n\ntrain/test split\n0.9850590\n0.0149410\n69\n0\n1\nPreprocessor1_Model1\n69\n1\n3\nAndersson, Miss. Erna Alexandra\nfemale\n17.00\n4\n2\n3101281\n7.9250\nNA\nS\ntrain\nF_unmarried\nAndersson,\nnk\nsingle\nfamily\nteen\nLR\n\n\ntrain/test split\n0.9743355\n0.0256645\n70\n0\n0\nPreprocessor1_Model1\n70\n0\n3\nKink, Mr. Vincenz\nmale\n26.00\n2\n0\n315151\n8.6625\nNA\nS\ntrain\nMr.\nKink,\nnk\nsingle\nfamily\n20s\nLR\n\n\ntrain/test split\n0.6491722\n0.3508278\n73\n0\n0\nPreprocessor1_Model1\n73\n0\n2\nHood, Mr. Ambrose Jr\nmale\n21.00\n0\n0\nS.O.C. 14879\n73.5000\nNA\nS\ntrain\nMr.\nHood,\nnk\ngroup\nsingle\n20s\nLR\n\n\ntrain/test split\n0.8775457\n0.1224543\n75\n0\n1\nPreprocessor1_Model1\n75\n1\n3\nBing, Mr. Lee\nmale\n32.00\n0\n0\n1601\n56.4958\nNA\nS\ntrain\nMr.\nBing,\nnk\ngroup\nsingle\n30s\nLR\n\n\ntrain/test split\n0.1261187\n0.8738813\n85\n1\n1\nPreprocessor1_Model1\n85\n1\n2\nIlett, Miss. Bertha\nfemale\n17.00\n0\n0\nSO/C 14885\n10.5000\nNA\nS\ntrain\nF_unmarried\nIlett,\nnk\nsingle\nsingle\nteen\nLR\n\n\ntrain/test split\n0.6679585\n0.3320415\n86\n0\n1\nPreprocessor1_Model1\n86\n1\n3\nBackstrom, Mrs. Karl Alfred (Maria Mathilda Gustafsson)\nfemale\n33.00\n3\n0\n3101278\n15.8500\nNA\nS\ntrain\nF_married\nBackstrom,\nnk\ncouple\nfamily\n30s\nLR\n\n\ntrain/test split\n0.9412709\n0.0587291\n88\n0\n0\nPreprocessor1_Model1\n88\n0\n3\nSlocovski, Mr. Selman Francis\nmale\n26.00\n0\n0\nSOTON/OQ 392086\n8.0500\nNA\nS\ntrain\nMr.\nSlocovski,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.9246646\n0.0753354\n92\n0\n0\nPreprocessor1_Model1\n92\n0\n3\nAndreasson, Mr. Paul Edvin\nmale\n20.00\n0\n0\n347466\n7.8542\nNA\nS\ntrain\nMr.\nAndreasson,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.9412709\n0.0587291\n96\n0\n0\nPreprocessor1_Model1\n96\n0\n3\nShorney, Mr. Charles Joseph\nmale\n26.00\n0\n0\n374910\n8.0500\nNA\nS\ntrain\nMr.\nShorney,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.9757676\n0.0242324\n105\n0\n0\nPreprocessor1_Model1\n105\n0\n3\nGustafsson, Mr. Anders Vilhelm\nmale\n37.00\n2\n0\n3101276\n7.9250\nNA\nS\ntrain\nMr.\nGustafsson,\nnk\nsingle\nfamily\n30s\nLR\n\n\ntrain/test split\n0.9465431\n0.0534569\n109\n0\n0\nPreprocessor1_Model1\n109\n0\n3\nRekic, Mr. Tido\nmale\n38.00\n0\n0\n349249\n7.8958\nNA\nS\ntrain\nMr.\nRekic,\nnk\nsingle\nsingle\n30s\nLR\n\n\ntrain/test split\n0.9276872\n0.0723128\n116\n0\n0\nPreprocessor1_Model1\n116\n0\n3\nPekoniemi, Mr. Edvard\nmale\n21.00\n0\n0\nSTON/O 2. 3101294\n7.9250\nNA\nS\ntrain\nMr.\nPekoniemi,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.9628174\n0.0371826\n117\n0\n0\nPreprocessor1_Model1\n117\n0\n3\nConnors, Mr. Patrick\nmale\n70.50\n0\n0\n370369\n7.7500\nNA\nQ\ntrain\nMr.\nConnors,\nnk\nsingle\nsingle\n60+\nLR\n\n\ntrain/test split\n0.9412709\n0.0587291\n122\n0\n0\nPreprocessor1_Model1\n122\n0\n3\nMoore, Mr. Leonard Charles\nmale\n26.00\n0\n0\nA4. 54510\n8.0500\nNA\nS\ntrain\nMr.\nMoore,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.9364955\n0.0635045\n128\n0\n1\nPreprocessor1_Model1\n128\n1\n3\nMadsen, Mr. Fridtjof Arne\nmale\n24.00\n0\n0\nC 17369\n7.1417\nNA\nS\ntrain\nMr.\nMadsen,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.2663603\n0.7336397\n129\n1\n1\nPreprocessor1_Model1\n129\n1\n3\nPeter, Miss. Anna\nfemale\n18.00\n1\n1\n2668\n22.3583\nF E69\nC\ntrain\nF_unmarried\nPeter,\nF\ngroup\nfamily\nteen\nLR\n\n\ntrain/test split\n0.9239279\n0.0760721\n139\n0\n0\nPreprocessor1_Model1\n139\n0\n3\nOsen, Mr. Olaf Elon\nmale\n16.00\n0\n0\n7534\n9.2167\nNA\nS\ntrain\nMr.\nOsen,\nnk\ncouple\nsingle\nteen\nLR\n\n\ntrain/test split\n0.1828568\n0.8171432\n141\n1\n0\nPreprocessor1_Model1\n141\n0\n3\nBoulos, Mrs. Joseph (Sultana)\nfemale\n31.00\n0\n2\n2678\n15.2458\nNA\nC\ntrain\nF_married\nBoulos,\nnk\ngroup\nfamily\n30s\nLR\n\n\ntrain/test split\n0.3764946\n0.6235054\n142\n1\n1\nPreprocessor1_Model1\n142\n1\n3\nNysten, Miss. Anna Sofia\nfemale\n22.00\n0\n0\n347081\n7.7500\nNA\nS\ntrain\nF_unmarried\nNysten,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.8309803\n0.1690197\n146\n0\n0\nPreprocessor1_Model1\n146\n0\n2\nNicholls, Mr. Joseph Charles\nmale\n19.00\n1\n1\nC.A. 33112\n36.7500\nNA\nS\ntrain\nMr.\nNicholls,\nnk\ngroup\nfamily\nteen\nLR\n\n\ntrain/test split\n0.9804875\n0.0195125\n153\n0\n0\nPreprocessor1_Model1\n153\n0\n3\nMeo, Mr. Alfonzo\nmale\n55.50\n0\n0\nA.5. 11206\n8.0500\nNA\nS\ntrain\nMr.\nMeo,\nnk\nsingle\nsingle\n50s\nLR\n\n\ntrain/test split\n0.9720498\n0.0279502\n154\n0\n0\nPreprocessor1_Model1\n154\n0\n3\nvan Billiard, Mr. Austin Blyler\nmale\n40.50\n0\n2\nA/5. 851\n14.5000\nNA\nS\ntrain\nMr.\nBilliard,\nnk\ngroup\nfamily\n40s\nLR\n\n\ntrain/test split\n0.8294089\n0.1705911\n156\n0\n0\nPreprocessor1_Model1\n156\n0\n1\nWilliams, Mr. Charles Duane\nmale\n51.00\n0\n1\nPC 17597\n61.3792\nNA\nC\ntrain\nMr.\nWilliams,\nnk\ncouple\ncouple\n50s\nLR\n\n\ntrain/test split\n0.9252139\n0.0747861\n158\n0\n0\nPreprocessor1_Model1\n158\n0\n3\nCorn, Mr. Harry\nmale\n30.00\n0\n0\nSOTON/OQ 392090\n8.0500\nNA\nS\ntrain\nMr.\nCorn,\nnk\nsingle\nsingle\n30s\nLR\n\n\ntrain/test split\n0.9813374\n0.0186626\n161\n0\n0\nPreprocessor1_Model1\n161\n0\n3\nCribb, Mr. John Hatfield\nmale\n44.00\n0\n1\n371362\n16.1000\nNA\nS\ntrain\nMr.\nCribb,\nnk\ncouple\ncouple\n40s\nLR\n\n\ntrain/test split\n0.9140591\n0.0859409\n164\n0\n0\nPreprocessor1_Model1\n164\n0\n3\nCalic, Mr. Jovo\nmale\n17.00\n0\n0\n315093\n8.6625\nNA\nS\ntrain\nMr.\nCalic,\nnk\nsingle\nsingle\nteen\nLR\n\n\ntrain/test split\n0.0211987\n0.9788013\n167\n1\n1\nPreprocessor1_Model1\n167\n1\n1\nChibnall, Mrs. (Edith Martha Bowerman)\nfemale\n45.00\n0\n1\n113505\n55.0000\nE33\nS\ntrain\nF_married\nChibnall,\nE\ncouple\ncouple\n40s\nLR\n\n\ntrain/test split\n0.9261207\n0.0738793\n180\n0\n0\nPreprocessor1_Model1\n180\n0\n3\nLeonard, Mr. Lionel\nmale\n36.00\n0\n0\nLINE\n0.0000\nNA\nS\ntrain\nMr.\nLeonard,\nnk\ngroup\nsingle\n30s\nLR\n\n\ntrain/test split\n0.9995248\n0.0004752\n181\n0\n0\nPreprocessor1_Model1\n181\n0\n3\nSage, Miss. Constance Gladys\nfemale\n18.00\n8\n2\nCA. 2343\n69.5500\nNA\nS\ntrain\nF_unmarried\nSage,\nnk\ngroup\nfamily\nteen\nLR\n\n\ntrain/test split\n0.2010783\n0.7989217\n185\n1\n1\nPreprocessor1_Model1\n185\n1\n3\nKink-Heilmann, Miss. Luise Gretchen\nfemale\n4.00\n0\n2\n315153\n22.0250\nNA\nS\ntrain\nF_unmarried\nHeilmann,\nnk\ngroup\nfamily\nchild\nLR\n\n\ntrain/test split\n0.9418360\n0.0581640\n190\n0\n0\nPreprocessor1_Model1\n190\n0\n3\nTurcin, Mr. Stjepan\nmale\n36.00\n0\n0\n349247\n7.8958\nNA\nS\ntrain\nMr.\nTurcin,\nnk\nsingle\nsingle\n30s\nLR\n\n\ntrain/test split\n0.0662186\n0.9337814\n196\n1\n1\nPreprocessor1_Model1\n196\n1\n1\nLurette, Miss. Elise\nfemale\n58.00\n0\n0\nPC 17569\n146.5208\nB80\nC\ntrain\nF_unmarried\nLurette,\nB\ngroup\nsingle\n50s\nLR\n\n\ntrain/test split\n0.2165380\n0.7834620\n209\n1\n1\nPreprocessor1_Model1\n209\n1\n3\nCarr, Miss. Helen “Ellen”\nfemale\n16.00\n0\n0\n367231\n7.7500\nNA\nQ\ntrain\nF_unmarried\nCarr,\nnk\nsingle\nsingle\nteen\nLR\n\n\ntrain/test split\n0.6414355\n0.3585645\n210\n0\n1\nPreprocessor1_Model1\n210\n1\n1\nBlank, Mr. Henry\nmale\n40.00\n0\n0\n112277\n31.0000\nA31\nC\ntrain\nMr.\nBlank,\nA\nsingle\nsingle\n40s\nLR\n\n\ntrain/test split\n0.9309213\n0.0690787\n213\n0\n0\nPreprocessor1_Model1\n213\n0\n3\nPerkin, Mr. John Henry\nmale\n22.00\n0\n0\nA/5 21174\n7.2500\nNA\nS\ntrain\nMr.\nPerkin,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.0114566\n0.9885434\n216\n1\n1\nPreprocessor1_Model1\n216\n1\n1\nNewell, Miss. Madeleine\nfemale\n31.00\n1\n0\n35273\n113.2750\nD36\nC\ntrain\nF_unmarried\nNewell,\nD\ngroup\ncouple\n30s\nLR\n\n\ntrain/test split\n0.7880694\n0.2119306\n220\n0\n0\nPreprocessor1_Model1\n220\n0\n2\nHarris, Mr. Walter\nmale\n30.00\n0\n0\nW/C 14208\n10.5000\nNA\nS\ntrain\nMr.\nHarris,\nnk\nsingle\nsingle\n30s\nLR\n\n\ntrain/test split\n0.9300063\n0.0699937\n226\n0\n0\nPreprocessor1_Model1\n226\n0\n3\nBerglund, Mr. Karl Ivar Sven\nmale\n22.00\n0\n0\nPP 4348\n9.3500\nNA\nS\ntrain\nMr.\nBerglund,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.9453775\n0.0546225\n233\n0\n0\nPreprocessor1_Model1\n233\n0\n2\nSjostedt, Mr. Ernst Adolf\nmale\n59.00\n0\n0\n237442\n13.5000\nNA\nS\ntrain\nMr.\nSjostedt,\nnk\nsingle\nsingle\n50s\nLR\n\n\ntrain/test split\n0.9395895\n0.0604105\n234\n0\n1\nPreprocessor1_Model1\n234\n1\n3\nAsplund, Miss. Lillian Gertrud\nfemale\n5.00\n4\n2\n347077\n31.3875\nNA\nS\ntrain\nF_unmarried\nAsplund,\nnk\ngroup\nfamily\nchild\nLR\n\n\ntrain/test split\n0.8150030\n0.1849970\n235\n0\n0\nPreprocessor1_Model1\n235\n0\n2\nLeyson, Mr. Robert William Norman\nmale\n24.00\n0\n0\nC.A. 29566\n10.5000\nNA\nS\ntrain\nMr.\nLeyson,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.3897704\n0.6102296\n241\n1\n0\nPreprocessor1_Model1\n241\n0\n3\nZabour, Miss. Thamine\nfemale\n18.00\n1\n0\n2665\n14.4542\nNA\nC\ntrain\nF_unmarried\nZabour,\nnk\ncouple\ncouple\nteen\nLR\n\n\ntrain/test split\n0.6299069\n0.3700931\n249\n0\n1\nPreprocessor1_Model1\n249\n1\n1\nBeckwith, Mr. Richard Leonard\nmale\n37.00\n1\n1\n11751\n52.5542\nD35\nS\ntrain\nMr.\nBeckwith,\nD\ncouple\nfamily\n30s\nLR\n\n\ntrain/test split\n0.9584306\n0.0415694\n250\n0\n0\nPreprocessor1_Model1\n250\n0\n2\nCarter, Rev. Ernest Courtenay\nmale\n54.00\n1\n0\n244252\n26.0000\nNA\nS\ntrain\nM_Professional\nCarter,\nnk\ncouple\ncouple\n50s\nLR\n\n\ntrain/test split\n0.7552202\n0.2447798\n252\n0\n0\nPreprocessor1_Model1\n252\n0\n3\nStrom, Mrs. Wilhelm (Elna Matilda Persson)\nfemale\n29.00\n1\n1\n347054\n10.4625\nG6\nS\ntrain\nF_married\nStrom,\nG\ncouple\nfamily\n20s\nLR\n\n\ntrain/test split\n0.8137424\n0.1862576\n253\n0\n0\nPreprocessor1_Model1\n253\n0\n1\nStead, Mr. William Thomas\nmale\n62.00\n0\n0\n113514\n26.5500\nC87\nS\ntrain\nMr.\nStead,\nC\nsingle\nsingle\n60+\nLR\n\n\ntrain/test split\n0.9624079\n0.0375921\n254\n0\n0\nPreprocessor1_Model1\n254\n0\n3\nLobb, Mr. William Arthur\nmale\n30.00\n1\n0\nA/5. 3336\n16.1000\nNA\nS\ntrain\nMr.\nLobb,\nnk\ncouple\ncouple\n30s\nLR\n\n\ntrain/test split\n0.2407027\n0.7592973\n256\n1\n1\nPreprocessor1_Model1\n256\n1\n3\nTouma, Mrs. Darwis (Hanne Youssef Razi)\nfemale\n29.00\n0\n2\n2650\n15.2458\nNA\nC\ntrain\nF_married\nTouma,\nnk\ngroup\nfamily\n20s\nLR\n\n\ntrain/test split\n0.0370477\n0.9629523\n258\n1\n1\nPreprocessor1_Model1\n258\n1\n1\nCherry, Miss. Gladys\nfemale\n30.00\n0\n0\n110152\n86.5000\nB77\nS\ntrain\nF_unmarried\nCherry,\nB\ngroup\nsingle\n30s\nLR\n\n\ntrain/test split\n0.9060799\n0.0939201\n261\n0\n0\nPreprocessor1_Model1\n261\n0\n3\nSmith, Mr. Thomas\nmale\n26.00\n0\n0\n384461\n7.7500\nNA\nQ\ntrain\nMr.\nSmith,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.5487780\n0.4512220\n263\n0\n0\nPreprocessor1_Model1\n263\n0\n1\nTaussig, Mr. Emil\nmale\n52.00\n1\n1\n110413\n79.6500\nE67\nS\ntrain\nMr.\nTaussig,\nE\ngroup\nfamily\n50s\nLR\n\n\ntrain/test split\n0.9655030\n0.0344970\n268\n0\n1\nPreprocessor1_Model1\n268\n1\n3\nPersson, Mr. Ernst Ulrik\nmale\n25.00\n1\n0\n347083\n7.7750\nNA\nS\ntrain\nMr.\nPersson,\nnk\nsingle\ncouple\n20s\nLR\n\n\ntrain/test split\n0.0543810\n0.9456190\n276\n1\n1\nPreprocessor1_Model1\n276\n1\n1\nAndrews, Miss. Kornelia Theodosia\nfemale\n63.00\n1\n0\n13502\n77.9583\nD7\nS\ntrain\nF_unmarried\nAndrews,\nD\ngroup\ncouple\n60+\nLR\n\n\ntrain/test split\n0.5556378\n0.4443622\n277\n0\n0\nPreprocessor1_Model1\n277\n0\n3\nLindblom, Miss. Augusta Charlotta\nfemale\n45.00\n0\n0\n347073\n7.7500\nNA\nS\ntrain\nF_unmarried\nLindblom,\nnk\nsingle\nsingle\n40s\nLR\n\n\ntrain/test split\n0.3077261\n0.6922739\n280\n1\n1\nPreprocessor1_Model1\n280\n1\n3\nAbbott, Mrs. Stanton (Rosa Hunt)\nfemale\n35.00\n1\n1\nC.A. 2673\n20.2500\nNA\nS\ntrain\nF_married\nAbbott,\nnk\ngroup\nfamily\n30s\nLR\n\n\ntrain/test split\n0.9211254\n0.0788746\n284\n0\n1\nPreprocessor1_Model1\n284\n1\n3\nDorking, Mr. Edward Arthur\nmale\n19.00\n0\n0\nA/5. 10482\n8.0500\nNA\nS\ntrain\nMr.\nDorking,\nnk\nsingle\nsingle\nteen\nLR\n\n\ntrain/test split\n0.0419207\n0.9580793\n291\n1\n1\nPreprocessor1_Model1\n291\n1\n1\nBarber, Miss. Ellen “Nellie”\nfemale\n26.00\n0\n0\n19877\n78.8500\nNA\nS\ntrain\nF_unmarried\nBarber,\nnk\ngroup\nsingle\n20s\nLR\n\n\ntrain/test split\n0.5206509\n0.4793491\n293\n0\n0\nPreprocessor1_Model1\n293\n0\n2\nLevy, Mr. Rene Jacques\nmale\n36.00\n0\n0\nSC/Paris 2163\n12.8750\nD\nC\ntrain\nMr.\nLevy,\nD\nsingle\nsingle\n30s\nLR\n\n\ntrain/test split\n0.6274830\n0.3725170\n296\n0\n0\nPreprocessor1_Model1\n296\n0\n1\nLewy, Mr. Ervin G\nmale\n41.50\n0\n0\nPC 17612\n27.7208\nNA\nC\ntrain\nMr.\nLewy,\nnk\nsingle\nsingle\n40s\nLR\n\n\ntrain/test split\n0.0435936\n0.9564064\n298\n1\n0\nPreprocessor1_Model1\n298\n0\n1\nAllison, Miss. Helen Loraine\nfemale\n2.00\n1\n2\n113781\n151.5500\nC22 C26\nS\ntrain\nF_unmarried\nAllison,\nC\ngroup\nfamily\nchild\nLR\n\n\ntrain/test split\n0.9381749\n0.0618251\n302\n0\n1\nPreprocessor1_Model1\n302\n1\n3\nMcCoy, Mr. Bernard\nmale\n26.00\n2\n0\n367226\n23.2500\nNA\nQ\ntrain\nMr.\nMcCoy,\nnk\ngroup\nfamily\n20s\nLR\n\n\ntrain/test split\n0.9460742\n0.0539258\n314\n0\n0\nPreprocessor1_Model1\n314\n0\n3\nHendekovic, Mr. Ignjac\nmale\n28.00\n0\n0\n349243\n7.8958\nNA\nS\ntrain\nMr.\nHendekovic,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.9198014\n0.0801986\n315\n0\n0\nPreprocessor1_Model1\n315\n0\n2\nHart, Mr. Benjamin\nmale\n43.00\n1\n1\nF.C.C. 13529\n26.2500\nNA\nS\ntrain\nMr.\nHart,\nnk\ngroup\nfamily\n40s\nLR\n\n\ntrain/test split\n0.4191167\n0.5808833\n316\n1\n1\nPreprocessor1_Model1\n316\n1\n3\nNilsson, Miss. Helmina Josefina\nfemale\n26.00\n0\n0\n347470\n7.8542\nNA\nS\ntrain\nF_unmarried\nNilsson,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.1392900\n0.8607100\n317\n1\n1\nPreprocessor1_Model1\n317\n1\n2\nKantor, Mrs. Sinai (Miriam Sternin)\nfemale\n24.00\n1\n0\n244367\n26.0000\nNA\nS\ntrain\nF_married\nKantor,\nnk\ncouple\ncouple\n20s\nLR\n\n\ntrain/test split\n0.8194856\n0.1805144\n337\n0\n0\nPreprocessor1_Model1\n337\n0\n1\nPears, Mr. Thomas Clinton\nmale\n29.00\n1\n0\n113776\n66.6000\nC2\nS\ntrain\nMr.\nPears,\nC\ncouple\ncouple\n20s\nLR\n\n\ntrain/test split\n0.1324020\n0.8675980\n346\n1\n1\nPreprocessor1_Model1\n346\n1\n2\nBrown, Miss. Amelia “Mildred”\nfemale\n24.00\n0\n0\n248733\n13.0000\nF33\nS\ntrain\nF_unmarried\nBrown,\nF\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.9984311\n0.0015689\n361\n0\n0\nPreprocessor1_Model1\n361\n0\n3\nSkoog, Mr. Wilhelm\nmale\n40.00\n1\n4\n347088\n27.9000\nNA\nS\ntrain\nMr.\nSkoog,\nnk\ngroup\nfamily\n40s\nLR\n\n\ntrain/test split\n0.8669377\n0.1330623\n362\n0\n0\nPreprocessor1_Model1\n362\n0\n2\ndel Carlo, Mr. Sebastiano\nmale\n29.00\n1\n0\nSC/PARIS 2167\n27.7208\nNA\nC\ntrain\nMr.\nCarlo,\nnk\ncouple\ncouple\n20s\nLR\n\n\ntrain/test split\n0.9523910\n0.0476090\n365\n0\n0\nPreprocessor1_Model1\n365\n0\n3\nO’Brien, Mr. Thomas\nmale\n26.00\n1\n0\n370365\n15.5000\nNA\nQ\ntrain\nMr.\nBrien,\nnk\ncouple\ncouple\n20s\nLR\n\n\ntrain/test split\n0.2886197\n0.7113803\n371\n1\n1\nPreprocessor1_Model1\n371\n1\n1\nHarder, Mr. George Achilles\nmale\n25.00\n1\n0\n11765\n55.4417\nE50\nC\ntrain\nMr.\nHarder,\nE\ncouple\ncouple\n20s\nLR\n\n\ntrain/test split\n0.9536392\n0.0463608\n372\n0\n0\nPreprocessor1_Model1\n372\n0\n3\nWiklund, Mr. Jakob Alfred\nmale\n18.00\n1\n0\n3101267\n6.4958\nNA\nS\ntrain\nMr.\nWiklund,\nnk\nsingle\ncouple\nteen\nLR\n\n\ntrain/test split\n0.2523918\n0.7476082\n374\n1\n0\nPreprocessor1_Model1\n374\n0\n1\nRinghini, Mr. Sante\nmale\n22.00\n0\n0\nPC 17760\n135.6333\nNA\nC\ntrain\nMr.\nRinghini,\nnk\ngroup\nsingle\n20s\nLR\n\n\ntrain/test split\n0.6674955\n0.3325045\n375\n0\n0\nPreprocessor1_Model1\n375\n0\n3\nPalsson, Miss. Stina Viola\nfemale\n3.00\n3\n1\n349909\n21.0750\nNA\nS\ntrain\nF_unmarried\nPalsson,\nnk\ngroup\nfamily\nchild\nLR\n\n\ntrain/test split\n0.3772853\n0.6227147\n377\n1\n1\nPreprocessor1_Model1\n377\n1\n3\nLandergren, Miss. Aurora Adelia\nfemale\n22.00\n0\n0\nC 7077\n7.2500\nNA\nS\ntrain\nF_unmarried\nLandergren,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.9212598\n0.0787402\n380\n0\n0\nPreprocessor1_Model1\n380\n0\n3\nGustafsson, Mr. Karl Gideon\nmale\n19.00\n0\n0\n347069\n7.7750\nNA\nS\ntrain\nMr.\nGustafsson,\nnk\nsingle\nsingle\nteen\nLR\n\n\ntrain/test split\n0.9653479\n0.0346521\n387\n0\n0\nPreprocessor1_Model1\n387\n0\n3\nGoodwin, Master. Sidney Leonard\nmale\n1.00\n5\n2\nCA 2144\n46.9000\nNA\nS\ntrain\nMaster.\nGoodwin,\nnk\ngroup\nfamily\nchild\nLR\n\n\ntrain/test split\n0.8457337\n0.1542663\n391\n0\n1\nPreprocessor1_Model1\n391\n1\n1\nCarter, Mr. William Ernest\nmale\n36.00\n1\n2\n113760\n120.0000\nB96 B98\nS\ntrain\nMr.\nCarter,\nB\ngroup\nfamily\n30s\nLR\n\n\ntrain/test split\n0.9765920\n0.0234080\n393\n0\n0\nPreprocessor1_Model1\n393\n0\n3\nGustafsson, Mr. Johan Birger\nmale\n28.00\n2\n0\n3101277\n7.9250\nNA\nS\ntrain\nMr.\nGustafsson,\nnk\nsingle\nfamily\n20s\nLR\n\n\ntrain/test split\n0.0124007\n0.9875993\n394\n1\n1\nPreprocessor1_Model1\n394\n1\n1\nNewell, Miss. Marjorie\nfemale\n23.00\n1\n0\n35273\n113.2750\nD36\nC\ntrain\nF_unmarried\nNewell,\nD\ngroup\ncouple\n20s\nLR\n\n\ntrain/test split\n0.5810948\n0.4189052\n395\n0\n1\nPreprocessor1_Model1\n395\n1\n3\nSandstrom, Mrs. Hjalmar (Agnes Charlotta Bengtsson)\nfemale\n24.00\n0\n2\nPP 9549\n16.7000\nG6\nS\ntrain\nF_married\nSandstrom,\nG\ngroup\nfamily\n20s\nLR\n\n\ntrain/test split\n0.9040329\n0.0959671\n398\n0\n0\nPreprocessor1_Model1\n398\n0\n2\nMcKane, Mr. Peter David\nmale\n46.00\n0\n0\n28403\n26.0000\nNA\nS\ntrain\nMr.\nMcKane,\nnk\ncouple\nsingle\n40s\nLR\n\n\ntrain/test split\n0.9487502\n0.0512498\n401\n0\n1\nPreprocessor1_Model1\n401\n1\n3\nNiskanen, Mr. Juha\nmale\n39.00\n0\n0\nSTON/O 2. 3101289\n7.9250\nNA\nS\ntrain\nMr.\nNiskanen,\nnk\nsingle\nsingle\n30s\nLR\n\n\ntrain/test split\n0.5092998\n0.4907002\n403\n0\n0\nPreprocessor1_Model1\n403\n0\n3\nJussila, Miss. Mari Aina\nfemale\n21.00\n1\n0\n4137\n9.8250\nNA\nS\ntrain\nF_unmarried\nJussila,\nnk\nsingle\ncouple\n20s\nLR\n\n\ntrain/test split\n0.9732110\n0.0267890\n404\n0\n0\nPreprocessor1_Model1\n404\n0\n3\nHakkarainen, Mr. Pekka Pietari\nmale\n28.00\n1\n0\nSTON/O2. 3101279\n15.8500\nNA\nS\ntrain\nMr.\nHakkarainen,\nnk\ncouple\ncouple\n20s\nLR\n\n\ntrain/test split\n0.9762912\n0.0237088\n407\n0\n0\nPreprocessor1_Model1\n407\n0\n3\nWidegren, Mr. Carl/Charles Peter\nmale\n51.00\n0\n0\n347064\n7.7500\nNA\nS\ntrain\nMr.\nWidegren,\nnk\nsingle\nsingle\n50s\nLR\n\n\ntrain/test split\n0.8555161\n0.1444839\n410\n0\n0\nPreprocessor1_Model1\n410\n0\n3\nLefebre, Miss. Ida\nfemale\n18.00\n3\n1\n4133\n25.4667\nNA\nS\ntrain\nF_unmarried\nLefebre,\nnk\ngroup\nfamily\nteen\nLR\n\n\ntrain/test split\n0.9060799\n0.0939201\n429\n0\n0\nPreprocessor1_Model1\n429\n0\n3\nFlynn, Mr. James\nmale\n26.00\n0\n0\n364851\n7.7500\nNA\nQ\ntrain\nMr.\nFlynn,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.7224015\n0.2775985\n431\n0\n1\nPreprocessor1_Model1\n431\n1\n1\nBjornstrom-Steffansson, Mr. Mauritz Hakan\nmale\n28.00\n0\n0\n110564\n26.5500\nC52\nS\ntrain\nMr.\nSteffansson,\nC\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.8596900\n0.1403100\n437\n0\n0\nPreprocessor1_Model1\n437\n0\n3\nFord, Miss. Doolina Margaret “Daisy”\nfemale\n21.00\n2\n2\nW./C. 6608\n34.3750\nNA\nS\ntrain\nF_unmarried\nFord,\nnk\ngroup\nfamily\n20s\nLR\n\n\ntrain/test split\n0.7954370\n0.2045630\n440\n0\n0\nPreprocessor1_Model1\n440\n0\n2\nKvillner, Mr. Johan Henrik Johannesson\nmale\n31.00\n0\n0\nC.A. 18723\n10.5000\nNA\nS\ntrain\nMr.\nKvillner,\nnk\nsingle\nsingle\n30s\nLR\n\n\ntrain/test split\n0.1919701\n0.8080299\n447\n1\n1\nPreprocessor1_Model1\n447\n1\n2\nMellinger, Miss. Madeleine Violet\nfemale\n13.00\n0\n1\n250644\n19.5000\nNA\nS\ntrain\nF_unmarried\nMellinger,\nnk\ncouple\ncouple\nteen\nLR\n\n\ntrain/test split\n0.3241630\n0.6758370\n449\n1\n1\nPreprocessor1_Model1\n449\n1\n3\nBaclini, Miss. Marie Catherine\nfemale\n5.00\n2\n1\n2666\n19.2583\nNA\nC\ntrain\nF_unmarried\nBaclini,\nnk\ngroup\nfamily\nchild\nLR\n\n\ntrain/test split\n0.9366805\n0.0633195\n462\n0\n0\nPreprocessor1_Model1\n462\n0\n3\nMorley, Mr. William\nmale\n34.00\n0\n0\n364506\n8.0500\nNA\nS\ntrain\nMr.\nMorley,\nnk\nsingle\nsingle\n30s\nLR\n\n\ntrain/test split\n0.4040571\n0.5959429\n463\n1\n0\nPreprocessor1_Model1\n463\n0\n1\nGee, Mr. Arthur H\nmale\n47.00\n0\n0\n111320\n38.5000\nE63\nS\ntrain\nMr.\nGee,\nE\nsingle\nsingle\n40s\nLR\n\n\ntrain/test split\n0.7455222\n0.2544778\n467\n0\n0\nPreprocessor1_Model1\n467\n0\n2\nCampbell, Mr. William\nmale\n30.00\n0\n0\n239853\n0.0000\nNA\nS\ntrain\nMr.\nCampbell,\nnk\ngroup\nsingle\n30s\nLR\n\n\ntrain/test split\n0.2840148\n0.7159852\n470\n1\n1\nPreprocessor1_Model1\n470\n1\n3\nBaclini, Miss. Helene Barbara\nfemale\n0.75\n2\n1\n2666\n19.2583\nNA\nC\ntrain\nF_unmarried\nBaclini,\nnk\ngroup\nfamily\nchild\nLR\n\n\ntrain/test split\n0.0171585\n0.9828415\n474\n1\n1\nPreprocessor1_Model1\n474\n1\n2\nJerwan, Mrs. Amin S (Marie Marthe Thuillard)\nfemale\n23.00\n0\n0\nSC/AH Basle 541\n13.7917\nD\nC\ntrain\nF_married\nJerwan,\nD\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.9005039\n0.0994961\n477\n0\n0\nPreprocessor1_Model1\n477\n0\n2\nRenouf, Mr. Peter Henry\nmale\n34.00\n1\n0\n31027\n21.0000\nNA\nS\ntrain\nMr.\nRenouf,\nnk\ncouple\ncouple\n30s\nLR\n\n\ntrain/test split\n0.9308039\n0.0691961\n479\n0\n0\nPreprocessor1_Model1\n479\n0\n3\nKarlsson, Mr. Nils August\nmale\n22.00\n0\n0\n350060\n7.5208\nNA\nS\ntrain\nMr.\nKarlsson,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.2431293\n0.7568707\n480\n1\n1\nPreprocessor1_Model1\n480\n1\n3\nHirvonen, Miss. Hildur E\nfemale\n2.00\n0\n1\n3101298\n12.2875\nNA\nS\ntrain\nF_unmarried\nHirvonen,\nnk\ncouple\ncouple\nchild\nLR\n\n\ntrain/test split\n0.6503480\n0.3496520\n485\n0\n1\nPreprocessor1_Model1\n485\n1\n1\nBishop, Mr. Dickinson H\nmale\n25.00\n1\n0\n11967\n91.0792\nB49\nC\ntrain\nMr.\nBishop,\nB\ncouple\ncouple\n20s\nLR\n\n\ntrain/test split\n0.8555161\n0.1444839\n486\n0\n0\nPreprocessor1_Model1\n486\n0\n3\nLefebre, Miss. Jeannie\nfemale\n18.00\n3\n1\n4133\n25.4667\nNA\nS\ntrain\nF_unmarried\nLefebre,\nnk\ngroup\nfamily\nteen\nLR\n\n\ntrain/test split\n0.2243083\n0.7756917\n490\n1\n1\nPreprocessor1_Model1\n490\n1\n3\nCoutts, Master. Eden Leslie “Neville”\nmale\n9.00\n1\n1\nC.A. 37671\n15.9000\nNA\nS\ntrain\nMaster.\nCoutts,\nnk\ngroup\nfamily\nchild\nLR\n\n\ntrain/test split\n0.9642352\n0.0357648\n491\n0\n0\nPreprocessor1_Model1\n491\n0\n3\nHagland, Mr. Konrad Mathias Reiersen\nmale\n26.00\n1\n0\n65304\n19.9667\nNA\nS\ntrain\nMr.\nHagland,\nnk\nsingle\ncouple\n20s\nLR\n\n\ntrain/test split\n0.9279915\n0.0720085\n492\n0\n0\nPreprocessor1_Model1\n492\n0\n3\nWindelov, Mr. Einar\nmale\n21.00\n0\n0\nSOTON/OQ 3101317\n7.2500\nNA\nS\ntrain\nMr.\nWindelov,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.8766178\n0.1233822\n493\n0\n0\nPreprocessor1_Model1\n493\n0\n1\nMolson, Mr. Harry Markland\nmale\n55.00\n0\n0\n113787\n30.5000\nC30\nS\ntrain\nMr.\nMolson,\nC\nsingle\nsingle\n50s\nLR\n\n\ntrain/test split\n0.9276307\n0.0723693\n495\n0\n0\nPreprocessor1_Model1\n495\n0\n3\nStanley, Mr. Edward Roland\nmale\n21.00\n0\n0\nA/4 45380\n8.0500\nNA\nS\ntrain\nMr.\nStanley,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.9179368\n0.0820632\n496\n0\n0\nPreprocessor1_Model1\n496\n0\n3\nYousseff, Mr. Gerious\nmale\n26.00\n0\n0\n2627\n14.4583\nNA\nC\ntrain\nMr.\nYousseff,\nnk\ncouple\nsingle\n20s\nLR\n\n\ntrain/test split\n0.9482386\n0.0517614\n498\n0\n0\nPreprocessor1_Model1\n498\n0\n3\nShellard, Mr. Frederick William\nmale\n26.00\n0\n0\nC.A. 6212\n15.1000\nNA\nS\ntrain\nMr.\nShellard,\nnk\ncouple\nsingle\n20s\nLR\n\n\ntrain/test split\n0.9140591\n0.0859409\n501\n0\n0\nPreprocessor1_Model1\n501\n0\n3\nCalic, Mr. Petar\nmale\n17.00\n0\n0\n315086\n8.6625\nNA\nS\ntrain\nMr.\nCalic,\nnk\nsingle\nsingle\nteen\nLR\n\n\ntrain/test split\n0.2575436\n0.7424564\n502\n1\n0\nPreprocessor1_Model1\n502\n0\n3\nCanavan, Miss. Mary\nfemale\n21.00\n0\n0\n364846\n7.7500\nNA\nQ\ntrain\nF_unmarried\nCanavan,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.2322293\n0.7677707\n503\n1\n0\nPreprocessor1_Model1\n503\n0\n3\nO’Sullivan, Miss. Bridget Mary\nfemale\n18.00\n0\n0\n330909\n7.6292\nNA\nQ\ntrain\nF_unmarried\nSullivan,\nnk\nsingle\nsingle\nteen\nLR\n\n\ntrain/test split\n0.4294359\n0.5705641\n504\n1\n0\nPreprocessor1_Model1\n504\n0\n3\nLaitinen, Miss. Kristina Sofia\nfemale\n37.00\n0\n0\n4135\n9.5875\nNA\nS\ntrain\nF_unmarried\nLaitinen,\nnk\nsingle\nsingle\n30s\nLR\n\n\ntrain/test split\n0.0307832\n0.9692168\n505\n1\n1\nPreprocessor1_Model1\n505\n1\n1\nMaioni, Miss. Roberta\nfemale\n16.00\n0\n0\n110152\n86.5000\nB79\nS\ntrain\nF_unmarried\nMaioni,\nB\ngroup\nsingle\nteen\nLR\n\n\ntrain/test split\n0.9312345\n0.0687655\n520\n0\n0\nPreprocessor1_Model1\n520\n0\n3\nPavlovic, Mr. Stefo\nmale\n32.00\n0\n0\n349242\n7.8958\nNA\nS\ntrain\nMr.\nPavlovic,\nnk\nsingle\nsingle\n30s\nLR\n\n\ntrain/test split\n0.9318054\n0.0681946\n526\n0\n0\nPreprocessor1_Model1\n526\n0\n3\nFarrell, Mr. James\nmale\n40.50\n0\n0\n367232\n7.7500\nNA\nQ\ntrain\nMr.\nFarrell,\nnk\nsingle\nsingle\n40s\nLR\n\n\ntrain/test split\n0.9484366\n0.0515634\n539\n0\n0\nPreprocessor1_Model1\n539\n0\n3\nRisien, Mr. Samuel Beard\nmale\n26.00\n0\n0\n364498\n14.5000\nNA\nS\ntrain\nMr.\nRisien,\nnk\ncouple\nsingle\n20s\nLR\n\n\ntrain/test split\n0.0880416\n0.9119584\n540\n1\n1\nPreprocessor1_Model1\n540\n1\n1\nFrolicher, Miss. Hedwig Margaritha\nfemale\n22.00\n0\n2\n13568\n49.5000\nB39\nC\ntrain\nF_unmarried\nFrolicher,\nB\nsingle\nfamily\n20s\nLR\n\n\ntrain/test split\n0.8889233\n0.1110767\n544\n0\n1\nPreprocessor1_Model1\n544\n1\n2\nBeane, Mr. Edward\nmale\n32.00\n1\n0\n2908\n26.0000\nNA\nS\ntrain\nMr.\nBeane,\nnk\ncouple\ncouple\n30s\nLR\n\n\ntrain/test split\n0.0684091\n0.9315909\n550\n1\n1\nPreprocessor1_Model1\n550\n1\n2\nDavies, Master. John Morgan Jr\nmale\n8.00\n1\n1\nC.A. 33112\n36.7500\nNA\nS\ntrain\nMaster.\nDavies,\nnk\ngroup\nfamily\nchild\nLR\n\n\ntrain/test split\n0.9060345\n0.0939655\n553\n0\n0\nPreprocessor1_Model1\n553\n0\n3\nO’Brien, Mr. Timothy\nmale\n26.00\n0\n0\n330979\n7.8292\nNA\nQ\ntrain\nMr.\nBrien,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.2435805\n0.7564195\n558\n1\n0\nPreprocessor1_Model1\n558\n0\n1\nRobbins, Mr. Victor\nmale\n41.50\n0\n0\nPC 17757\n227.5250\nNA\nC\ntrain\nMr.\nRobbins,\nnk\ngroup\nsingle\n40s\nLR\n\n\ntrain/test split\n0.9060799\n0.0939201\n561\n0\n0\nPreprocessor1_Model1\n561\n0\n3\nMorrow, Mr. Thomas Rowan\nmale\n26.00\n0\n0\n372622\n7.7500\nNA\nQ\ntrain\nMr.\nMorrow,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.9212008\n0.0787992\n567\n0\n0\nPreprocessor1_Model1\n567\n0\n3\nStoytcheff, Mr. Ilia\nmale\n19.00\n0\n0\n349205\n7.8958\nNA\nS\ntrain\nMr.\nStoytcheff,\nnk\nsingle\nsingle\nteen\nLR\n\n\ntrain/test split\n0.9312524\n0.0687476\n570\n0\n1\nPreprocessor1_Model1\n570\n1\n3\nJonsson, Mr. Carl\nmale\n32.00\n0\n0\n350417\n7.8542\nNA\nS\ntrain\nMr.\nJonsson,\nnk\nsingle\nsingle\n30s\nLR\n\n\ntrain/test split\n0.2308740\n0.7691260\n572\n1\n1\nPreprocessor1_Model1\n572\n1\n1\nAppleton, Mrs. Edward Dale (Charlotte Lamson)\nfemale\n53.00\n2\n0\n11769\n51.4792\nC101\nS\ntrain\nF_married\nAppleton,\nC\ncouple\nfamily\n50s\nLR\n\n\ntrain/test split\n0.0147640\n0.9852360\n578\n1\n1\nPreprocessor1_Model1\n578\n1\n1\nSilvey, Mrs. William Baird (Alice Munger)\nfemale\n39.00\n1\n0\n13507\n55.9000\nE44\nS\ntrain\nF_married\nSilvey,\nE\ncouple\ncouple\n30s\nLR\n\n\ntrain/test split\n0.2349815\n0.7650185\n579\n1\n0\nPreprocessor1_Model1\n579\n0\n3\nCaram, Mrs. Joseph (Maria Elias)\nfemale\n31.00\n1\n0\n2689\n14.4583\nNA\nC\ntrain\nF_married\nCaram,\nnk\ncouple\ncouple\n30s\nLR\n\n\ntrain/test split\n0.0286745\n0.9713255\n582\n1\n1\nPreprocessor1_Model1\n582\n1\n1\nThayer, Mrs. John Borland (Marian Longstreth Morris)\nfemale\n39.00\n1\n1\n17421\n110.8833\nC68\nC\ntrain\nF_married\nThayer,\nC\ngroup\nfamily\n30s\nLR\n\n\ntrain/test split\n0.9384663\n0.0615337\n583\n0\n0\nPreprocessor1_Model1\n583\n0\n2\nDownton, Mr. William James\nmale\n54.00\n0\n0\n28403\n26.0000\nNA\nS\ntrain\nMr.\nDownton,\nnk\ncouple\nsingle\n50s\nLR\n\n\ntrain/test split\n0.9065475\n0.0934525\n585\n0\n0\nPreprocessor1_Model1\n585\n0\n3\nPaulner, Mr. Uscher\nmale\n26.00\n0\n0\n3411\n8.7125\nNA\nC\ntrain\nMr.\nPaulner,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.9412709\n0.0587291\n590\n0\n0\nPreprocessor1_Model1\n590\n0\n3\nMurdlin, Mr. Joseph\nmale\n26.00\n0\n0\nA./5. 3235\n8.0500\nNA\nS\ntrain\nMr.\nMurdlin,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.9682696\n0.0317304\n593\n0\n0\nPreprocessor1_Model1\n593\n0\n3\nElsbury, Mr. William James\nmale\n47.00\n0\n0\nA/5 3902\n7.2500\nNA\nS\ntrain\nMr.\nElsbury,\nnk\nsingle\nsingle\n40s\nLR\n\n\ntrain/test split\n0.9073927\n0.0926073\n599\n0\n0\nPreprocessor1_Model1\n599\n0\n3\nBoulos, Mr. Hanna\nmale\n26.00\n0\n0\n2664\n7.2250\nNA\nC\ntrain\nMr.\nBoulos,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.3821209\n0.6178791\n616\n1\n1\nPreprocessor1_Model1\n616\n1\n2\nHerman, Miss. Alice\nfemale\n24.00\n1\n2\n220845\n65.0000\nNA\nS\ntrain\nF_unmarried\nHerman,\nnk\ngroup\nfamily\n20s\nLR\n\n\ntrain/test split\n0.3823489\n0.6176511\n618\n1\n0\nPreprocessor1_Model1\n618\n0\n3\nLobb, Mrs. William Arthur (Cordelia K Stanlick)\nfemale\n26.00\n1\n0\nA/5. 3336\n16.1000\nNA\nS\ntrain\nF_married\nLobb,\nnk\ncouple\ncouple\n20s\nLR\n\n\ntrain/test split\n0.9413283\n0.0586717\n629\n0\n0\nPreprocessor1_Model1\n629\n0\n3\nBostandyeff, Mr. Guentcho\nmale\n26.00\n0\n0\n349224\n7.8958\nNA\nS\ntrain\nMr.\nBostandyeff,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.8711279\n0.1288721\n635\n0\n0\nPreprocessor1_Model1\n635\n0\n3\nSkoog, Miss. Mabel\nfemale\n9.00\n3\n2\n347088\n27.9000\nNA\nS\ntrain\nF_unmarried\nSkoog,\nnk\ngroup\nfamily\nchild\nLR\n\n\ntrain/test split\n0.9212008\n0.0787992\n647\n0\n0\nPreprocessor1_Model1\n647\n0\n3\nCor, Mr. Liudevit\nmale\n19.00\n0\n0\n349231\n7.8958\nNA\nS\ntrain\nMr.\nCor,\nnk\nsingle\nsingle\nteen\nLR\n\n\ntrain/test split\n0.7000087\n0.2999913\n648\n0\n1\nPreprocessor1_Model1\n648\n1\n1\nSimonius-Blumer, Col. Oberst Alfons\nmale\n56.00\n0\n0\n13213\n35.5000\nA26\nC\ntrain\nMilitary\nBlumer,\nA\nsingle\nsingle\n50s\nLR\n\n\ntrain/test split\n0.9414567\n0.0585433\n649\n0\n0\nPreprocessor1_Model1\n649\n0\n3\nWilley, Mr. Edward\nmale\n26.00\n0\n0\nS.O./P.P. 751\n7.5500\nNA\nS\ntrain\nMr.\nWilley,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.9413283\n0.0586717\n651\n0\n0\nPreprocessor1_Model1\n651\n0\n3\nMitkoff, Mr. Mito\nmale\n26.00\n0\n0\n349221\n7.8958\nNA\nS\ntrain\nMr.\nMitkoff,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.2248917\n0.7751083\n652\n1\n1\nPreprocessor1_Model1\n652\n1\n2\nDoling, Miss. Elsie\nfemale\n18.00\n0\n1\n231919\n23.0000\nNA\nS\ntrain\nF_unmarried\nDoling,\nnk\ncouple\ncouple\nteen\nLR\n\n\ntrain/test split\n0.2319893\n0.7680107\n654\n1\n1\nPreprocessor1_Model1\n654\n1\n3\nO’Leary, Miss. Hanora “Norah”\nfemale\n18.00\n0\n0\n330919\n7.8292\nNA\nQ\ntrain\nF_unmarried\nLeary,\nnk\nsingle\nsingle\nteen\nLR\n\n\ntrain/test split\n0.2316196\n0.7683804\n681\n1\n0\nPreprocessor1_Model1\n681\n0\n3\nPeters, Miss. Katie\nfemale\n18.00\n0\n0\n330935\n8.1375\nNA\nQ\ntrain\nF_unmarried\nPeters,\nnk\nsingle\nsingle\nteen\nLR\n\n\ntrain/test split\n0.9200816\n0.0799184\n688\n0\n0\nPreprocessor1_Model1\n688\n0\n3\nDakic, Mr. Branko\nmale\n19.00\n0\n0\n349228\n10.1708\nNA\nS\ntrain\nMr.\nDakic,\nnk\nsingle\nsingle\nteen\nLR\n\n\ntrain/test split\n0.9179459\n0.0820541\n689\n0\n0\nPreprocessor1_Model1\n689\n0\n3\nFischer, Mr. Eberhard Thelander\nmale\n18.00\n0\n0\n350036\n7.7958\nNA\nS\ntrain\nMr.\nFischer,\nnk\nsingle\nsingle\nteen\nLR\n\n\ntrain/test split\n0.0223539\n0.9776461\n690\n1\n1\nPreprocessor1_Model1\n690\n1\n1\nMadill, Miss. Georgette Alexandra\nfemale\n15.00\n0\n1\n24160\n211.3375\nB5\nS\ntrain\nF_unmarried\nMadill,\nB\ngroup\ncouple\nteen\nLR\n\n\ntrain/test split\n0.8946285\n0.1053715\n693\n0\n1\nPreprocessor1_Model1\n693\n1\n3\nLam, Mr. Ali\nmale\n26.00\n0\n0\n1601\n56.4958\nNA\nS\ntrain\nMr.\nLam,\nnk\ngroup\nsingle\n20s\nLR\n\n\ntrain/test split\n0.9035684\n0.0964316\n694\n0\n0\nPreprocessor1_Model1\n694\n0\n3\nSaad, Mr. Khalil\nmale\n25.00\n0\n0\n2672\n7.2250\nNA\nC\ntrain\nMr.\nSaad,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.9636937\n0.0363063\n697\n0\n0\nPreprocessor1_Model1\n697\n0\n3\nKelly, Mr. James\nmale\n44.00\n0\n0\n363592\n8.0500\nNA\nS\ntrain\nMr.\nKelly,\nnk\nsingle\nsingle\n40s\nLR\n\n\ntrain/test split\n0.2728194\n0.7271806\n702\n1\n1\nPreprocessor1_Model1\n702\n1\n1\nSilverthorne, Mr. Spencer Victor\nmale\n35.00\n0\n0\nPC 17475\n26.2875\nE24\nS\ntrain\nMr.\nSilverthorne,\nE\nsingle\nsingle\n30s\nLR\n\n\ntrain/test split\n0.3794427\n0.6205573\n703\n1\n0\nPreprocessor1_Model1\n703\n0\n3\nBarbara, Miss. Saiide\nfemale\n18.00\n0\n1\n2691\n14.4542\nNA\nC\ntrain\nF_unmarried\nBarbara,\nnk\ncouple\ncouple\nteen\nLR\n\n\ntrain/test split\n0.8966324\n0.1033676\n713\n0\n1\nPreprocessor1_Model1\n713\n1\n1\nTaylor, Mr. Elmer Zebley\nmale\n48.00\n1\n0\n19996\n52.0000\nC126\nS\ntrain\nMr.\nTaylor,\nC\ncouple\ncouple\n40s\nLR\n\n\ntrain/test split\n0.9017251\n0.0982749\n716\n0\n0\nPreprocessor1_Model1\n716\n0\n3\nSoholt, Mr. Peter Andreas Lauritz Andersen\nmale\n19.00\n0\n0\n348124\n7.6500\nF G73\nS\ntrain\nMr.\nSoholt,\nF\nsingle\nsingle\nteen\nLR\n\n\ntrain/test split\n0.0445331\n0.9554669\n718\n1\n1\nPreprocessor1_Model1\n718\n1\n2\nTroutt, Miss. Edwina Celia “Winnie”\nfemale\n27.00\n0\n0\n34218\n10.5000\nE101\nS\ntrain\nF_unmarried\nTroutt,\nE\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.0588460\n0.9411540\n721\n1\n1\nPreprocessor1_Model1\n721\n1\n2\nHarper, Miss. Annie Jessie “Nina”\nfemale\n6.00\n0\n1\n248727\n33.0000\nNA\nS\ntrain\nF_unmarried\nHarper,\nnk\ngroup\ncouple\nchild\nLR\n\n\ntrain/test split\n0.3417856\n0.6582144\n727\n1\n1\nPreprocessor1_Model1\n727\n1\n2\nRenouf, Mrs. Peter Henry (Lillian Jefferys)\nfemale\n30.00\n3\n0\n31027\n21.0000\nNA\nS\ntrain\nF_married\nRenouf,\nnk\ncouple\nfamily\n30s\nLR\n\n\ntrain/test split\n0.0239991\n0.9760009\n731\n1\n1\nPreprocessor1_Model1\n731\n1\n1\nAllen, Miss. Elisabeth Walton\nfemale\n29.00\n0\n0\n24160\n211.3375\nB5\nS\ntrain\nF_unmarried\nAllen,\nB\ngroup\nsingle\n20s\nLR\n\n\ntrain/test split\n0.7996376\n0.2003624\n733\n0\n0\nPreprocessor1_Model1\n733\n0\n2\nKnight, Mr. Robert J\nmale\n30.00\n0\n0\n239855\n0.0000\nNA\nS\ntrain\nMr.\nKnight,\nnk\nsingle\nsingle\n30s\nLR\n\n\ntrain/test split\n0.6932258\n0.3067742\n742\n0\n0\nPreprocessor1_Model1\n742\n0\n1\nCavendish, Mr. Tyrell William\nmale\n36.00\n1\n0\n19877\n78.8500\nC46\nS\ntrain\nMr.\nCavendish,\nC\ngroup\ncouple\n30s\nLR\n\n\ntrain/test split\n0.9283039\n0.0716961\n745\n0\n1\nPreprocessor1_Model1\n745\n1\n3\nStranden, Mr. Juho\nmale\n31.00\n0\n0\nSTON/O 2. 3101288\n7.9250\nNA\nS\ntrain\nMr.\nStranden,\nnk\nsingle\nsingle\n30s\nLR\n\n\ntrain/test split\n0.9334707\n0.0665293\n754\n0\n0\nPreprocessor1_Model1\n754\n0\n3\nJonkoff, Mr. Lalio\nmale\n23.00\n0\n0\n349204\n7.8958\nNA\nS\ntrain\nMr.\nJonkoff,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.7692797\n0.2307203\n758\n0\n0\nPreprocessor1_Model1\n758\n0\n2\nBailey, Mr. Percy Andrew\nmale\n18.00\n0\n0\n29108\n11.5000\nNA\nS\ntrain\nMr.\nBailey,\nnk\nsingle\nsingle\nteen\nLR\n\n\ntrain/test split\n0.8822639\n0.1177361\n763\n0\n1\nPreprocessor1_Model1\n763\n1\n3\nBarah, Mr. Hanna Assi\nmale\n20.00\n0\n0\n2663\n7.2292\nNA\nC\ntrain\nMr.\nBarah,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.0928255\n0.9071745\n764\n1\n1\nPreprocessor1_Model1\n764\n1\n1\nCarter, Mrs. William Ernest (Lucile Polk)\nfemale\n36.00\n1\n2\n113760\n120.0000\nB96 B98\nS\ntrain\nF_married\nCarter,\nB\ngroup\nfamily\n30s\nLR\n\n\ntrain/test split\n0.6432641\n0.3567359\n767\n0\n0\nPreprocessor1_Model1\n767\n0\n1\nBrewe, Dr. Arthur Jackson\nmale\n49.00\n0\n0\n112379\n39.6000\nNA\nC\ntrain\nM_Professional\nBrewe,\nnk\nsingle\nsingle\n40s\nLR\n\n\ntrain/test split\n0.2550439\n0.7449561\n768\n1\n0\nPreprocessor1_Model1\n768\n0\n3\nMangan, Miss. Mary\nfemale\n30.50\n0\n0\n364850\n7.7500\nNA\nQ\ntrain\nF_unmarried\nMangan,\nnk\nsingle\nsingle\n30s\nLR\n\n\ntrain/test split\n0.9694941\n0.0305059\n772\n0\n0\nPreprocessor1_Model1\n772\n0\n3\nJensen, Mr. Niels Peder\nmale\n48.00\n0\n0\n350047\n7.8542\nNA\nS\ntrain\nMr.\nJensen,\nnk\nsingle\nsingle\n40s\nLR\n\n\ntrain/test split\n0.0240763\n0.9759237\n780\n1\n1\nPreprocessor1_Model1\n780\n1\n1\nRobert, Mrs. Edward Scott (Elisabeth Walton McMillan)\nfemale\n43.00\n0\n1\n24160\n211.3375\nB3\nS\ntrain\nF_married\nRobert,\nB\ngroup\ncouple\n40s\nLR\n\n\ntrain/test split\n0.1970987\n0.8029013\n781\n1\n1\nPreprocessor1_Model1\n781\n1\n3\nAyoub, Miss. Banoura\nfemale\n13.00\n0\n0\n2687\n7.2292\nNA\nC\ntrain\nF_unmarried\nAyoub,\nnk\nsingle\nsingle\nteen\nLR\n\n\ntrain/test split\n0.0476662\n0.9523338\n782\n1\n1\nPreprocessor1_Model1\n782\n1\n1\nDick, Mrs. Albert Adrian (Vera Gillespie)\nfemale\n17.00\n1\n0\n17474\n57.0000\nB20\nS\ntrain\nF_married\nDick,\nB\ncouple\ncouple\nteen\nLR\n\n\ntrain/test split\n0.3457419\n0.6542581\n789\n1\n1\nPreprocessor1_Model1\n789\n1\n3\nDean, Master. Bertram Vere\nmale\n1.00\n1\n2\nC.A. 2315\n20.5750\nNA\nS\ntrain\nMaster.\nDean,\nnk\ngroup\nfamily\nchild\nLR\n\n\ntrain/test split\n0.9060799\n0.0939201\n791\n0\n0\nPreprocessor1_Model1\n791\n0\n3\nKeane, Mr. Andrew “Andy”\nmale\n26.00\n0\n0\n12460\n7.7500\nNA\nQ\ntrain\nMr.\nKeane,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.7682348\n0.2317652\n792\n0\n0\nPreprocessor1_Model1\n792\n0\n2\nGaskell, Mr. Alfred\nmale\n16.00\n0\n0\n239865\n26.0000\nNA\nS\ntrain\nMr.\nGaskell,\nnk\ncouple\nsingle\nteen\nLR\n\n\ntrain/test split\n0.9995248\n0.0004752\n793\n0\n0\nPreprocessor1_Model1\n793\n0\n3\nSage, Miss. Stella Anna\nfemale\n18.00\n8\n2\nCA. 2343\n69.5500\nNA\nS\ntrain\nF_unmarried\nSage,\nnk\ngroup\nfamily\nteen\nLR\n\n\ntrain/test split\n0.8453638\n0.1546362\n796\n0\n0\nPreprocessor1_Model1\n796\n0\n2\nOtter, Mr. Richard\nmale\n39.00\n0\n0\n28213\n13.0000\nNA\nS\ntrain\nMr.\nOtter,\nnk\nsingle\nsingle\n30s\nLR\n\n\ntrain/test split\n0.0633178\n0.9366822\n803\n1\n1\nPreprocessor1_Model1\n803\n1\n1\nCarter, Master. William Thornton II\nmale\n11.00\n1\n2\n113760\n120.0000\nB96 B98\nS\ntrain\nMaster.\nCarter,\nB\ngroup\nfamily\nchild\nLR\n\n\ntrain/test split\n0.1361138\n0.8638862\n804\n1\n1\nPreprocessor1_Model1\n804\n1\n3\nThomas, Master. Assad Alexander\nmale\n0.42\n0\n1\n2625\n8.5167\nNA\nC\ntrain\nMaster.\nThomas,\nnk\ncouple\ncouple\nchild\nLR\n\n\ntrain/test split\n0.8453638\n0.1546362\n809\n0\n0\nPreprocessor1_Model1\n809\n0\n2\nMeyer, Mr. August\nmale\n39.00\n0\n0\n248723\n13.0000\nNA\nS\ntrain\nMr.\nMeyer,\nnk\nsingle\nsingle\n30s\nLR\n\n\ntrain/test split\n0.0115441\n0.9884559\n810\n1\n1\nPreprocessor1_Model1\n810\n1\n1\nChambers, Mrs. Norman Campbell (Bertha Griggs)\nfemale\n33.00\n1\n0\n113806\n53.1000\nE8\nS\ntrain\nF_married\nChambers,\nE\ncouple\ncouple\n30s\nLR\n\n\ntrain/test split\n0.8229948\n0.1770052\n813\n0\n0\nPreprocessor1_Model1\n813\n0\n2\nSlemen, Mr. Richard James\nmale\n35.00\n0\n0\n28206\n10.5000\nNA\nS\ntrain\nMr.\nSlemen,\nnk\nsingle\nsingle\n30s\nLR\n\n\ntrain/test split\n0.9434736\n0.0565264\n822\n0\n1\nPreprocessor1_Model1\n822\n1\n3\nLulic, Mr. Nikola\nmale\n27.00\n0\n0\n315098\n8.6625\nNA\nS\ntrain\nMr.\nLulic,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.4722924\n0.5277076\n823\n1\n0\nPreprocessor1_Model1\n823\n0\n1\nReuchlin, Jonkheer. John George\nmale\n38.00\n0\n0\n19972\n0.0000\nNA\nS\ntrain\nM_titled\nReuchlin,\nnk\nsingle\nsingle\n30s\nLR\n\n\ntrain/test split\n0.0302600\n0.9697400\n828\n1\n1\nPreprocessor1_Model1\n828\n1\n2\nMallet, Master. Andre\nmale\n1.00\n0\n2\nS.C./PARIS 2079\n37.0042\nNA\nC\ntrain\nMaster.\nMallet,\nnk\ngroup\nfamily\nchild\nLR\n\n\ntrain/test split\n0.9060799\n0.0939201\n829\n0\n1\nPreprocessor1_Model1\n829\n1\n3\nMcCormack, Mr. Thomas Joseph\nmale\n26.00\n0\n0\n367228\n7.7500\nNA\nQ\ntrain\nMr.\nMcCormack,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.0608557\n0.9391443\n830\n1\n1\nPreprocessor1_Model1\n830\n1\n1\nStone, Mrs. George Nelson (Martha Evelyn)\nfemale\n62.00\n0\n0\n113572\n80.0000\nB28\nS\ntrain\nF_married\nStone,\nB\ncouple\nsingle\n60+\nLR\n\n\ntrain/test split\n0.9176898\n0.0823102\n835\n0\n0\nPreprocessor1_Model1\n835\n0\n3\nAllum, Mr. Owen George\nmale\n18.00\n0\n0\n2223\n8.3000\nNA\nS\ntrain\nMr.\nAllum,\nnk\nsingle\nsingle\nteen\nLR\n\n\ntrain/test split\n0.9412709\n0.0587291\n838\n0\n0\nPreprocessor1_Model1\n838\n0\n3\nSirota, Mr. Maurice\nmale\n26.00\n0\n0\n392092\n8.0500\nNA\nS\ntrain\nMr.\nSirota,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.6772007\n0.3227993\n840\n0\n1\nPreprocessor1_Model1\n840\n1\n1\nMarechal, Mr. Pierre\nmale\n41.50\n0\n0\n11774\n29.7000\nC47\nC\ntrain\nMr.\nMarechal,\nC\nsingle\nsingle\n40s\nLR\n\n\ntrain/test split\n0.9246314\n0.0753686\n841\n0\n0\nPreprocessor1_Model1\n841\n0\n3\nAlhomaki, Mr. Ilmari Rudolf\nmale\n20.00\n0\n0\nSOTON/O2 3101287\n7.9250\nNA\nS\ntrain\nMr.\nAlhomaki,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.7862963\n0.2137037\n842\n0\n0\nPreprocessor1_Model1\n842\n0\n2\nMudd, Mr. Thomas Charles\nmale\n16.00\n0\n0\nS.O./P.P. 3\n10.5000\nNA\nS\ntrain\nMr.\nMudd,\nnk\ncouple\nsingle\nteen\nLR\n\n\ntrain/test split\n0.0442268\n0.9557732\n843\n1\n1\nPreprocessor1_Model1\n843\n1\n1\nSerepeca, Miss. Augusta\nfemale\n30.00\n0\n0\n113798\n31.0000\nNA\nC\ntrain\nF_unmarried\nSerepeca,\nnk\ncouple\nsingle\n30s\nLR\n\n\ntrain/test split\n0.9262771\n0.0737229\n851\n0\n0\nPreprocessor1_Model1\n851\n0\n3\nAndersson, Master. Sigvard Harald Elias\nmale\n4.00\n4\n2\n347082\n31.2750\nNA\nS\ntrain\nMaster.\nAndersson,\nnk\ngroup\nfamily\nchild\nLR\n\n\ntrain/test split\n0.1730043\n0.8269957\n853\n1\n0\nPreprocessor1_Model1\n853\n0\n3\nBoulos, Miss. Nourelain\nfemale\n9.00\n1\n1\n2678\n15.2458\nNA\nC\ntrain\nF_unmarried\nBoulos,\nnk\ngroup\nfamily\nchild\nLR\n\n\ntrain/test split\n0.3017407\n0.6982593\n856\n1\n1\nPreprocessor1_Model1\n856\n1\n3\nAks, Mrs. Sam (Leah Rosen)\nfemale\n18.00\n0\n1\n392091\n9.3500\nNA\nS\ntrain\nF_married\nAks,\nnk\ncouple\ncouple\nteen\nLR\n\n\ntrain/test split\n0.1970183\n0.8029817\n867\n1\n1\nPreprocessor1_Model1\n867\n1\n2\nDuran y More, Miss. Asuncion\nfemale\n27.00\n1\n0\nSC/PARIS 2149\n13.8583\nNA\nC\ntrain\nF_unmarried\nMore,\nnk\nsingle\ncouple\n20s\nLR\n\n\ntrain/test split\n0.0539272\n0.9460728\n872\n1\n1\nPreprocessor1_Model1\n872\n1\n1\nBeckwith, Mrs. Richard Leonard (Sallie Monypeny)\nfemale\n47.00\n1\n1\n11751\n52.5542\nD35\nS\ntrain\nF_married\nBeckwith,\nD\ncouple\nfamily\n40s\nLR\n\n\ntrain/test split\n0.9679056\n0.0320944\n874\n0\n0\nPreprocessor1_Model1\n874\n0\n3\nVander Cruyssen, Mr. Victor\nmale\n47.00\n0\n0\n345765\n9.0000\nNA\nS\ntrain\nMr.\nCruyssen,\nnk\nsingle\nsingle\n40s\nLR\n\n\ntrain/test split\n0.2116311\n0.7883689\n876\n1\n1\nPreprocessor1_Model1\n876\n1\n3\nNajib, Miss. Adele Kiamie “Jane”\nfemale\n15.00\n0\n0\n2667\n7.2250\nNA\nC\ntrain\nF_unmarried\nNajib,\nnk\nsingle\nsingle\nteen\nLR\n\n\ntrain/test split\n0.3721314\n0.6278686\n883\n1\n0\nPreprocessor1_Model1\n883\n0\n3\nDahlberg, Miss. Gerda Ulrika\nfemale\n22.00\n0\n0\n7552\n10.5167\nNA\nS\ntrain\nF_unmarried\nDahlberg,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.9391373\n0.0608627\n885\n0\n0\nPreprocessor1_Model1\n885\n0\n3\nSutehall, Mr. Henry Jr\nmale\n25.00\n0\n0\nSOTON/OQ 392076\n7.0500\nNA\nS\ntrain\nMr.\nSutehall,\nnk\nsingle\nsingle\n20s\nLR\n\n\ntrain/test split\n0.5533032\n0.4466968\n1\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2874791\n0.7125209\n4\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.4847601\n0.5152399\n12\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6992532\n0.3007468\n13\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.3230314\n0.6769686\n15\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.3423944\n0.6576056\n20\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7224349\n0.2775651\n21\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6907752\n0.3092248\n25\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7014344\n0.2985656\n26\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6890184\n0.3109816\n28\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6961622\n0.3038378\n30\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.4211007\n0.5788993\n35\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6480749\n0.3519251\n36\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6908555\n0.3091445\n37\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6994829\n0.3005171\n38\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6962519\n0.3037481\n46\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7264173\n0.2735827\n51\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.4812299\n0.5187701\n55\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.5986598\n0.4013402\n61\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.3236937\n0.6763063\n67\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6514197\n0.3485803\n68\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6286603\n0.3713397\n69\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7247461\n0.2752539\n70\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7253493\n0.2746507\n73\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.4884268\n0.5115732\n75\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2690722\n0.7309278\n85\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6710602\n0.3289398\n86\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6962519\n0.3037481\n88\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6991921\n0.3008079\n92\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6962519\n0.3037481\n96\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7310304\n0.2689696\n105\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7302087\n0.2697913\n109\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6994634\n0.3005366\n116\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7292263\n0.2707737\n117\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6962519\n0.3037481\n122\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6974304\n0.3025696\n128\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7102496\n0.2897504\n129\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7301461\n0.2698539\n139\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2697687\n0.7302313\n141\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.4928657\n0.5071343\n142\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7299197\n0.2700803\n146\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7158450\n0.2841550\n153\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7310441\n0.2689559\n154\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7233508\n0.2766492\n156\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6833824\n0.3166176\n158\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7308638\n0.2691362\n161\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6628300\n0.3371700\n164\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2719647\n0.7280353\n167\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.5740016\n0.4259984\n180\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7291650\n0.2708350\n181\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.5679048\n0.4320952\n185\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7295145\n0.2704855\n190\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2849021\n0.7150979\n196\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2851632\n0.7148368\n209\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6718844\n0.3281156\n210\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6986666\n0.3013334\n213\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2689562\n0.7310438\n216\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6759368\n0.3240632\n220\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6976797\n0.3023203\n226\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7308743\n0.2691257\n233\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7176979\n0.2823021\n234\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7191026\n0.2808974\n235\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6731106\n0.3268894\n241\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2736523\n0.7263477\n249\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7306106\n0.2693894\n250\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7104445\n0.2895555\n252\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7244483\n0.2755517\n253\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7098304\n0.2901696\n254\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2945617\n0.7054383\n256\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2689762\n0.7310238\n258\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7024908\n0.2975092\n261\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7154007\n0.2845993\n263\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6784574\n0.3215426\n268\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2694586\n0.7305414\n276\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.5446979\n0.4553021\n277\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6004374\n0.3995626\n280\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6521626\n0.3478374\n284\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2976805\n0.7023195\n291\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2908575\n0.7091425\n293\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.5971387\n0.4028613\n296\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2689611\n0.7310389\n298\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7308984\n0.2691016\n302\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6931824\n0.3068176\n314\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7310182\n0.2689818\n315\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.5031434\n0.4968566\n316\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.3109863\n0.6890137\n317\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.4696800\n0.5303200\n337\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.5566979\n0.4433021\n346\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7309609\n0.2690391\n361\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7292562\n0.2707438\n362\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7310049\n0.2689951\n365\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.3618754\n0.6381246\n371\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6716998\n0.3283002\n372\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6074688\n0.3925312\n374\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6201269\n0.3798731\n375\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.4931458\n0.5068542\n377\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6581278\n0.3418722\n380\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7274492\n0.2725508\n387\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.3478255\n0.6521745\n391\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7292486\n0.2707514\n393\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2741795\n0.7258205\n394\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6856742\n0.3143258\n395\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7270738\n0.2729262\n398\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7303195\n0.2696805\n401\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6693938\n0.3306062\n403\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7263188\n0.2736812\n404\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7242160\n0.2757840\n407\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7243381\n0.2756619\n410\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7024908\n0.2975092\n429\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.5586193\n0.4413807\n431\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7286913\n0.2713087\n437\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6883128\n0.3116872\n440\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.3740425\n0.6259575\n447\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.3038184\n0.6961816\n449\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7246525\n0.2753475\n462\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.3693918\n0.6306082\n463\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7124760\n0.2875240\n467\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2807302\n0.7192698\n470\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2700126\n0.7299874\n474\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7272013\n0.2727987\n477\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6990742\n0.3009258\n479\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6731164\n0.3268836\n480\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6521612\n0.3478388\n485\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7243381\n0.2756619\n486\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.4475244\n0.5524756\n490\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7245566\n0.2754434\n491\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6987267\n0.3012733\n492\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6157505\n0.3842495\n493\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6994829\n0.3005171\n495\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6826185\n0.3173815\n496\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6392062\n0.3607938\n498\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6628300\n0.3371700\n501\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2819790\n0.7180210\n502\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.3258171\n0.6741829\n503\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7296574\n0.2703426\n504\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2689689\n0.7310311\n505\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7163217\n0.2836783\n520\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7142901\n0.2857099\n526\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6471940\n0.3528060\n539\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2793136\n0.7206864\n540\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7231425\n0.2768575\n544\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2699627\n0.7300373\n550\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7039354\n0.2960646\n553\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6958837\n0.3041163\n558\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7024908\n0.2975092\n561\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6547513\n0.3452487\n567\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7177142\n0.2822858\n570\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.3045674\n0.6954326\n572\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2736695\n0.7263305\n578\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2700798\n0.7299202\n579\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2700238\n0.7299762\n582\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7278001\n0.2721999\n583\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6978481\n0.3021519\n585\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6962519\n0.3037481\n590\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6108550\n0.3891450\n593\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6908709\n0.3091291\n599\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.3023514\n0.6976486\n616\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.4756165\n0.5243835\n618\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6961622\n0.3038378\n629\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7265330\n0.2734670\n635\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6547513\n0.3452487\n647\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6039448\n0.3960552\n648\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6958862\n0.3041138\n649\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6961622\n0.3038378\n651\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.4201660\n0.5798340\n652\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.3060754\n0.6939246\n654\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2897449\n0.7102551\n681\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6960103\n0.3039897\n688\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6469361\n0.3530639\n689\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2690112\n0.7309888\n690\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.4734303\n0.5265697\n693\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6750733\n0.3249267\n694\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6398253\n0.3601747\n697\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2993320\n0.7006680\n702\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7063383\n0.2936617\n703\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6672351\n0.3327649\n713\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7186695\n0.2813305\n716\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2815475\n0.7184525\n718\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2695779\n0.7304221\n721\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.3402515\n0.6597485\n727\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2830091\n0.7169909\n731\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7303458\n0.2696542\n733\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.5163102\n0.4836898\n742\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7044710\n0.2955290\n745\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6989780\n0.3010220\n754\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6535317\n0.3464683\n758\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.5216786\n0.4783214\n763\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2689521\n0.7310479\n764\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.4440195\n0.5559805\n767\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6750768\n0.3249232\n768\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6094116\n0.3905884\n772\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2689706\n0.7310294\n780\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.3344767\n0.6655233\n781\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2690032\n0.7309968\n782\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.3021084\n0.6978916\n789\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7024908\n0.2975092\n791\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7126925\n0.2873075\n792\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7291650\n0.2708350\n793\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7080565\n0.2919435\n796\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2692203\n0.7307797\n803\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2689511\n0.7310489\n804\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7080565\n0.2919435\n809\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2706777\n0.7293223\n810\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7236028\n0.2763972\n813\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6949053\n0.3050947\n822\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7294553\n0.2705447\n823\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2718888\n0.7281112\n828\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7024908\n0.2975092\n829\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2756689\n0.7243311\n830\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6502271\n0.3497729\n835\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6962519\n0.3037481\n838\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6584616\n0.3415384\n840\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6992245\n0.3007755\n841\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6793777\n0.3206223\n842\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2739118\n0.7260882\n843\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6528734\n0.3471266\n851\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2829201\n0.7170799\n853\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.4988725\n0.5011275\n856\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.7130049\n0.2869951\n867\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.2690843\n0.7309157\n872\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6290533\n0.3709467\n874\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.4028212\n0.5971788\n876\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6386809\n0.3613191\n883\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.6964879\n0.3035121\n885\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNNet\n\n\ntrain/test split\n0.9469919\n0.0530081\n1\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.1258337\n0.8741663\n4\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.1978522\n0.8021478\n12\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9142934\n0.0857066\n13\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.3196989\n0.6803011\n15\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.2007953\n0.7992047\n20\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.7549714\n0.2450286\n21\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.6400138\n0.3599862\n25\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.7863246\n0.2136754\n26\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.8364176\n0.1635824\n28\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9213806\n0.0786194\n30\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.6827626\n0.3172374\n35\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.8244377\n0.1755623\n36\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.8792058\n0.1207942\n37\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9155032\n0.0844968\n38\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9213227\n0.0786773\n46\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.7407168\n0.2592832\n51\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.7748306\n0.2251694\n55\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.8724474\n0.1275526\n61\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.1290170\n0.8709830\n67\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9043894\n0.0956106\n68\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.8775315\n0.1224685\n69\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9682650\n0.0317350\n70\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.6729791\n0.3270209\n73\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.8744402\n0.1255598\n75\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.1308702\n0.8691298\n85\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.6285591\n0.3714409\n86\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9213227\n0.0786773\n88\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9143728\n0.0856272\n92\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9213227\n0.0786773\n96\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9671332\n0.0328668\n105\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9195881\n0.0804119\n109\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9155533\n0.0844467\n116\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9455738\n0.0544262\n117\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9213227\n0.0786773\n122\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9193897\n0.0806103\n128\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.3681488\n0.6318512\n129\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.8997883\n0.1002117\n139\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.3063478\n0.6936522\n141\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.3714134\n0.6285866\n142\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.8369294\n0.1630706\n146\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9490623\n0.0509377\n153\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9602490\n0.0397510\n154\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.7568545\n0.2431455\n156\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9098374\n0.0901626\n158\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9527229\n0.0472771\n161\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9014362\n0.0985638\n164\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.0456092\n0.9543908\n167\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9085180\n0.0914820\n180\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9688166\n0.0311834\n181\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.3648032\n0.6351968\n185\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9172598\n0.0827402\n190\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.0658620\n0.9341380\n196\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.2861933\n0.7138067\n209\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.6602156\n0.3397844\n210\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9170135\n0.0829865\n213\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.0296626\n0.9703374\n216\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.7554543\n0.2445457\n220\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9161817\n0.0838183\n226\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.8556944\n0.1443056\n233\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.7915109\n0.2084891\n234\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.7765449\n0.2234551\n235\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.3259474\n0.6740526\n241\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.7016307\n0.2983693\n249\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.8926328\n0.1073672\n250\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.5300232\n0.4699768\n252\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.8137005\n0.1862995\n253\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9399328\n0.0600672\n254\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.3458421\n0.6541579\n256\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.0749260\n0.9250740\n258\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9064978\n0.0935022\n261\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.6415357\n0.3584643\n263\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9491527\n0.0508473\n268\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.0975338\n0.9024662\n276\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.4397461\n0.5602539\n277\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.4503834\n0.5496166\n280\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9044379\n0.0955621\n284\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.0890790\n0.9109210\n291\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.4693507\n0.5306493\n293\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.6691966\n0.3308034\n296\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.1073621\n0.8926379\n298\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9526272\n0.0473728\n302\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9236026\n0.0763974\n314\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.8902804\n0.1097196\n315\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.3859091\n0.6140909\n316\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.1697667\n0.8302333\n317\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.7928990\n0.2071010\n337\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.1553396\n0.8446604\n346\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9871860\n0.0128140\n361\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.7746468\n0.2253532\n362\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9377223\n0.0622777\n365\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.3952635\n0.6047365\n371\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9382227\n0.0617773\n372\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.4415042\n0.5584958\n374\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.6219253\n0.3780747\n375\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.3720185\n0.6279815\n377\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9045610\n0.0954390\n380\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.8554218\n0.1445782\n387\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.8276789\n0.1723211\n391\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9693200\n0.0306800\n393\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.0322608\n0.9677392\n394\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.4395919\n0.5604081\n395\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.8074868\n0.1925132\n398\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9207186\n0.0792814\n401\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.4819960\n0.5180040\n403\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9493829\n0.0506171\n404\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9456536\n0.0543464\n407\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.7077142\n0.2922858\n410\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9064978\n0.0935022\n429\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.7415528\n0.2584472\n431\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.7082282\n0.2917718\n437\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.7583137\n0.2416863\n440\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.1646823\n0.8353177\n447\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.3960478\n0.6039522\n449\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9148081\n0.0851919\n462\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.4825924\n0.5174076\n463\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.7371867\n0.2628133\n467\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.3803644\n0.6196356\n470\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.0338439\n0.9661561\n474\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.8342527\n0.1657473\n477\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9169067\n0.0830933\n479\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.3180903\n0.6819097\n480\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.6623363\n0.3376637\n485\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.7077142\n0.2922858\n486\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.4409816\n0.5590184\n490\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9468043\n0.0531957\n491\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9158233\n0.0841767\n492\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.8114036\n0.1885964\n493\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9155032\n0.0844968\n495\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.8751711\n0.1248289\n496\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9186339\n0.0813661\n498\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9014362\n0.0985638\n501\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.3247331\n0.6752669\n502\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.2927137\n0.7072863\n503\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.3743612\n0.6256388\n504\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.0676031\n0.9323969\n505\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9124185\n0.0875815\n520\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9186007\n0.0813993\n526\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9188660\n0.0811340\n539\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.1409627\n0.8590373\n540\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.8262225\n0.1737775\n544\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.1777325\n0.8222675\n550\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9064630\n0.0935370\n553\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.3818772\n0.6181228\n558\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9064978\n0.0935022\n561\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9045069\n0.0954931\n567\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9124357\n0.0875643\n570\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.2783150\n0.7216850\n572\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.0401457\n0.9598543\n578\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.2812222\n0.7187778\n579\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.0810655\n0.9189345\n582\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.8371972\n0.1628028\n583\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.8783872\n0.1216128\n585\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9213227\n0.0786773\n590\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9380507\n0.0619493\n593\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.8792081\n0.1207919\n599\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.2938616\n0.7061384\n616\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.4172995\n0.5827005\n618\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9213806\n0.0786194\n629\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.7178622\n0.2821378\n635\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9045069\n0.0954931\n647\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.7249224\n0.2750776\n648\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9215103\n0.0784897\n649\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9213806\n0.0786194\n651\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.1730402\n0.8269598\n652\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.2924992\n0.7075008\n654\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.2921687\n0.7078313\n681\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9034840\n0.0965160\n688\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9032016\n0.0967984\n689\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.0517513\n0.9482487\n690\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.8868065\n0.1131935\n693\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.8775481\n0.1224519\n694\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9350344\n0.0649656\n697\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.4181483\n0.5818517\n702\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.3039215\n0.6960785\n703\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.8375272\n0.1624728\n713\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9046169\n0.0953831\n716\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.0513022\n0.9486978\n718\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.1062451\n0.8937549\n721\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.3277674\n0.6722326\n727\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.0490437\n0.9509563\n731\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.7653646\n0.2346354\n733\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.7361223\n0.2638777\n742\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9111565\n0.0888435\n745\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9179367\n0.0820633\n754\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.7394444\n0.2605556\n758\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.8689487\n0.1310513\n763\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.1592590\n0.8407410\n764\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.6812559\n0.3187441\n767\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.3110009\n0.6889991\n768\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9387679\n0.0612321\n772\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.0601223\n0.9398777\n780\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.2231791\n0.7768209\n781\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.1060818\n0.8939182\n782\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.4981414\n0.5018586\n789\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9064978\n0.0935022\n791\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.7184685\n0.2815315\n792\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9688166\n0.0311834\n793\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.7781326\n0.2218674\n796\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.1533183\n0.8466817\n803\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.2420435\n0.7579565\n804\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.7781326\n0.2218674\n809\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.0372194\n0.9627806\n810\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.7695218\n0.2304782\n813\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9222144\n0.0777856\n822\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.6994463\n0.3005537\n823\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.0976356\n0.9023644\n828\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9064978\n0.0935022\n829\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.1155038\n0.8844962\n830\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9029730\n0.0970270\n835\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9213227\n0.0786773\n838\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.6669226\n0.3330774\n840\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9143441\n0.0856559\n841\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.7344240\n0.2655760\n842\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.0721131\n0.9278869\n843\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.8061128\n0.1938872\n851\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.3058879\n0.6941121\n853\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.3476296\n0.6523704\n856\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.1610376\n0.8389624\n867\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.1105609\n0.8894391\n872\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9375217\n0.0624783\n874\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.2286173\n0.7713827\n876\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.3680730\n0.6319270\n883\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\ntrain/test split\n0.9205686\n0.0794314\n885\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nReg_LR\n\n\nNA\n0.7762219\n0.2237781\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.0755606\n0.9244394\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.2063686\n0.7936314\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9242450\n0.0757550\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.4593056\n0.5406944\nNA\n1\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.3795290\n0.6204710\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.7704073\n0.2295927\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.6884791\n0.3115209\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.1613539\n0.8386461\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.7683930\n0.2316070\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9310740\n0.0689260\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.6570605\n0.3429395\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.6890414\n0.3109586\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.7089905\n0.2910095\nNA\n0\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9465636\n0.0534364\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9337832\n0.0662168\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.6286324\n0.3713676\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.6499976\n0.3500024\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.7140769\n0.2859231\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.1697257\n0.8302743\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8986292\n0.1013708\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.4700128\n0.5299872\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8454485\n0.1545515\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.6930000\n0.3070000\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.3911973\n0.6088027\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.1970902\n0.8029098\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.3166583\n0.6833417\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9337832\n0.0662168\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9051170\n0.0948830\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9337832\n0.0662168\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.7683570\n0.2316430\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.7717394\n0.2282606\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9427300\n0.0572700\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9244721\n0.0755279\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9337832\n0.0662168\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.7129292\n0.2870708\nNA\n0\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.4436181\n0.5563819\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9032501\n0.0967499\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.4192149\n0.5807851\nNA\n1\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.4255277\n0.5744723\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.7717105\n0.2282895\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9423243\n0.0576757\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8727015\n0.1272985\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.7784797\n0.2215203\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.7507378\n0.2492622\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8760978\n0.1239022\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9042983\n0.0957017\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.1217701\n0.8782299\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.7378743\n0.2621257\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8087760\n0.1912240\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.3370532\n0.6629468\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.7764896\n0.2235104\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.1041287\n0.8958713\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.4714410\n0.5285590\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.4374228\n0.5625772\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9032419\n0.0967581\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.1208599\n0.8791401\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9306074\n0.0693926\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9233119\n0.0766881\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9368255\n0.0631745\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.5600449\n0.4399551\nNA\n0\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8626427\n0.1373573\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.6936130\n0.3063870\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.2946442\n0.7053558\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8726673\n0.1273327\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.5498262\n0.4501738\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.7594651\n0.2405349\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.7521067\n0.2478933\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.3241965\n0.6758035\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.0831192\n0.9168808\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8561940\n0.1438060\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.7560969\n0.2439031\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.7177368\n0.2822632\nNA\n0\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.1505944\n0.8494056\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.7354061\n0.2645939\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.1817345\n0.8182655\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8806736\n0.1193264\nNA\n0\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.1033367\n0.8966633\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8011717\n0.1988283\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.7583026\n0.2416974\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.4892968\n0.5107032\nNA\n1\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.4865869\n0.5134131\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8476681\n0.1523319\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8237384\n0.1762616\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.4140891\n0.5859109\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.1635896\n0.8364104\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.6236943\n0.3763057\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.1077336\n0.8922664\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8302088\n0.1697912\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.7082109\n0.2917891\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8579654\n0.1420346\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.4307251\n0.5692749\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8222304\n0.1777696\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.6431475\n0.3568525\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.6183445\n0.3816555\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.3933691\n0.6066309\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8962617\n0.1037383\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.5853174\n0.4146826\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.2317280\n0.7682720\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8481451\n0.1518549\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.1013262\n0.8986738\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.2787718\n0.7212282\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9203856\n0.0796144\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.6817299\n0.3182701\nNA\n0\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.6918377\n0.3081623\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8630819\n0.1369181\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9457332\n0.0542668\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8188920\n0.1811080\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8561940\n0.1438060\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.4944071\n0.5055929\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.6114065\n0.3885935\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9202658\n0.0797342\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.1396390\n0.8603610\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.3310145\n0.6689855\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.7667450\n0.2332550\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.7138258\n0.2861742\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8607977\n0.1392023\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.3111141\n0.6888859\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.1566978\n0.8433022\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.6969709\n0.3030291\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9151192\n0.0848808\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.3143725\n0.6856275\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.3537710\n0.6462290\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8188920\n0.1811080\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.3726825\n0.6273175\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.7968973\n0.2031027\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9052272\n0.0947728\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.7381580\n0.2618420\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9465636\n0.0534364\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8672686\n0.1327314\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9348169\n0.0651831\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9042983\n0.0957017\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.5883689\n0.4116311\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.5716329\n0.4283671\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.7062483\n0.2937517\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.1092066\n0.8907934\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.7196402\n0.2803598\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9568925\n0.0431075\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9403245\n0.0596755\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.1185667\n0.8814333\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.5962124\n0.4037876\nNA\n0\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.3200556\n0.6799444\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8730719\n0.1269281\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.7267031\n0.2732969\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8561940\n0.1438060\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8982455\n0.1017545\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.6819726\n0.3180274\nNA\n0\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.1477042\n0.8522958\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.0596475\n0.9403525\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.5301739\n0.4698261\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.1103226\n0.8896774\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9250775\n0.0749225\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8172979\n0.1827021\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9337832\n0.0662168\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9747583\n0.0252417\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.7193907\n0.2806093\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.1724448\n0.8275552\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.5362008\n0.4637992\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9310740\n0.0689260\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.6864747\n0.3135253\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8982455\n0.1017545\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.3966636\n0.6033364\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8931940\n0.1068060\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9310740\n0.0689260\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.1769660\n0.8230340\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.5680408\n0.4319592\nNA\n0\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.6353839\n0.3646161\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9088096\n0.0911904\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9138744\n0.0861256\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.1255969\n0.8744031\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.4448356\n0.5551644\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.7120456\n0.2879544\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9773772\n0.0226228\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.4342844\n0.5657156\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.6108029\n0.3891971\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.5643841\n0.4356159\nNA\n0\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8602582\n0.1397418\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.1191922\n0.8808078\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.1666131\n0.8333869\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.1379960\n0.8620040\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.0613005\n0.9386995\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8939137\n0.1060863\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.5500143\n0.4499857\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.6842057\n0.3157943\nNA\n0\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9430182\n0.0569818\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9306972\n0.0693028\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.6699407\n0.3300593\nNA\n0\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.0512896\n0.9487104\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.7521694\n0.2478306\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.7199641\n0.2800359\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9724136\n0.0275864\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.1131106\n0.8868894\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.2869807\n0.7130193\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.1151343\n0.8848657\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.3207507\n0.6792493\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8561940\n0.1438060\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8730851\n0.1269149\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8087760\n0.1912240\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9165322\n0.0834678\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.2212647\n0.7787353\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.2846203\n0.7153797\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9165322\n0.0834678\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.0591249\n0.9408751\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9401880\n0.0598120\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.7799494\n0.2200506\nNA\n0\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8450775\n0.1549225\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.2650668\n0.7349332\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.8561940\n0.1438060\nNA\n0\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.1162877\n0.8837123\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9205423\n0.0794577\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9337832\n0.0662168\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.5638657\n0.4361343\nNA\n0\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9200405\n0.0799595\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9095548\n0.0904452\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.1629418\n0.8370582\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.6018628\n0.3981372\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.4899457\n0.5100543\nNA\n1\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.3721109\n0.6278891\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.1697707\n0.8302293\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.1169185\n0.8830815\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.9782348\n0.0217652\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.3016766\n0.6983234\nNA\n1\nNA\nNA\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.5091333\n0.4908667\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\nNA\n0.7453044\n0.2546956\nNA\n0\nNA\nNA\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nRF\n\n\ntrain/test split\n0.9157760\n0.0842240\n1\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.0683806\n0.9316194\n4\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.1596558\n0.8403442\n12\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8745404\n0.1254596\n13\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.3089518\n0.6910482\n15\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.4580080\n0.5419920\n20\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.7558831\n0.2441169\n21\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.7178608\n0.2821392\n25\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.7189888\n0.2810112\n26\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.7815179\n0.2184821\n28\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.9084729\n0.0915271\n30\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.5318293\n0.4681707\n35\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.7261217\n0.2738783\n36\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.9025003\n0.0974997\n37\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8804833\n0.1195167\n38\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.9012634\n0.0987366\n46\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8028349\n0.1971651\n51\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.6089439\n0.3910561\n55\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8826891\n0.1173109\n61\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.1991681\n0.8008319\n67\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8487911\n0.1512089\n68\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.7075632\n0.2924368\n69\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.9367483\n0.0632517\n70\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.6640565\n0.3359435\n73\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.6613008\n0.3386992\n75\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.1285075\n0.8714925\n85\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.6292630\n0.3707370\n86\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.9012634\n0.0987366\n88\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8798813\n0.1201187\n92\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.9012634\n0.0987366\n96\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.9262223\n0.0737777\n105\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8996544\n0.1003456\n109\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8780692\n0.1219308\n116\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.9009880\n0.0990120\n117\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.9012634\n0.0987366\n122\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.9247388\n0.0752612\n128\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.4807119\n0.5192881\n129\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8243794\n0.1756206\n139\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.4512252\n0.5487748\n141\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.4557579\n0.5442421\n142\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.7763262\n0.2236738\n146\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.9032997\n0.0967003\n153\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8710875\n0.1289125\n154\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.6199270\n0.3800730\n156\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8620089\n0.1379911\n158\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8557300\n0.1442700\n161\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8374791\n0.1625209\n164\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.1031291\n0.8968709\n167\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.9077277\n0.0922723\n180\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.7407601\n0.2592399\n181\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.4379247\n0.5620753\n185\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8884162\n0.1115838\n190\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.0900935\n0.9099065\n196\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.2543009\n0.7456991\n209\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.6735808\n0.3264192\n210\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.9113119\n0.0886881\n213\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.0481958\n0.9518042\n216\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.7934673\n0.2065327\n220\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8878046\n0.1121954\n226\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8600432\n0.1399568\n233\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.7694902\n0.2305098\n234\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8778092\n0.1221908\n235\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.3475530\n0.6524470\n241\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.6771725\n0.3228275\n249\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8574208\n0.1425792\n250\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.6446517\n0.3553483\n252\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.7567740\n0.2432260\n253\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8417047\n0.1582953\n254\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.5044625\n0.4955375\n256\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.0512890\n0.9487110\n258\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.9028429\n0.0971571\n261\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.6966824\n0.3033176\n263\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.9161224\n0.0838776\n268\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.0966704\n0.9033296\n276\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.5341263\n0.4658737\n277\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.5614582\n0.4385418\n280\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8487911\n0.1512089\n284\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.0878552\n0.9121448\n291\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.7502190\n0.2497810\n293\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.6667574\n0.3332426\n296\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.0795980\n0.9204020\n298\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.9254571\n0.0745429\n302\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8960647\n0.1039353\n314\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.7836707\n0.2163293\n315\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.5096442\n0.4903558\n316\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.1697918\n0.8302082\n317\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.6385896\n0.3614104\n337\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.1975003\n0.8024997\n346\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8790580\n0.1209420\n361\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.7273470\n0.2726530\n362\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8907307\n0.1092693\n365\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.6059100\n0.3940900\n371\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8879499\n0.1120501\n372\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.5239214\n0.4760786\n374\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.6445460\n0.3554540\n375\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.5095811\n0.4904189\n377\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8614759\n0.1385241\n380\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.7365806\n0.2634194\n387\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.5800062\n0.4199938\n391\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.9262110\n0.0737890\n393\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.0729202\n0.9270798\n394\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.5952972\n0.4047028\n395\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8056747\n0.1943253\n398\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8872894\n0.1127106\n401\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.5231125\n0.4768875\n403\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8849716\n0.1150284\n404\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.9144018\n0.0855982\n407\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.7520497\n0.2479503\n410\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.9028429\n0.0971571\n429\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.7214040\n0.2785960\n431\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.7684512\n0.2315488\n437\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.7923456\n0.2076544\n440\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.1034029\n0.8965971\n447\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.3959125\n0.6040875\n449\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8730214\n0.1269786\n462\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.7227691\n0.2772309\n463\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8669865\n0.1330135\n467\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.3921070\n0.6078930\n470\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.1494149\n0.8505851\n474\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.7953593\n0.2046407\n477\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.9065371\n0.0934629\n479\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.2680596\n0.7319404\n480\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.5622448\n0.4377552\n485\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.7520497\n0.2479503\n486\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.5085179\n0.4914821\n490\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8972213\n0.1027787\n491\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.9075975\n0.0924025\n492\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.7556856\n0.2443144\n493\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8804833\n0.1195167\n495\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8551775\n0.1448225\n496\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8888683\n0.1111317\n498\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8374791\n0.1625209\n501\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.3625378\n0.6374622\n502\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.2854604\n0.7145396\n503\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.4918996\n0.5081004\n504\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.0581371\n0.9418629\n505\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8788862\n0.1211138\n520\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8825755\n0.1174245\n526\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8893330\n0.1106670\n539\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.1288220\n0.8711780\n540\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.7818021\n0.2181979\n544\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.4102594\n0.5897406\n550\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8997146\n0.1002854\n553\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.5118371\n0.4881629\n558\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.9028429\n0.0971571\n561\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8581640\n0.1418360\n567\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8787792\n0.1212208\n570\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.1912761\n0.8087239\n572\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.0762554\n0.9237446\n578\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.3537704\n0.6462296\n579\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.0758259\n0.9241741\n582\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8477482\n0.1522518\n583\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8723879\n0.1276121\n585\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.9012634\n0.0987366\n590\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.9078486\n0.0921514\n593\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.9025003\n0.0974997\n599\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.1560753\n0.8439247\n616\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.4976013\n0.5023987\n618\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.9084729\n0.0915271\n629\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8220661\n0.1779339\n635\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8581640\n0.1418360\n647\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.7491657\n0.2508343\n648\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.9200402\n0.0799598\n649\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.9084729\n0.0915271\n651\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.1138042\n0.8861958\n652\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.2636261\n0.7363739\n654\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.2948067\n0.7051933\n681\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8397674\n0.1602326\n688\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8481539\n0.1518461\n689\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.0647759\n0.9352241\n690\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.7615044\n0.2384956\n693\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.9028575\n0.0971425\n694\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8687152\n0.1312848\n697\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.6246125\n0.3753875\n702\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.3515292\n0.6484708\n703\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.7345783\n0.2654217\n713\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8734879\n0.1265121\n716\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.2074779\n0.7925221\n718\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.0668925\n0.9331075\n721\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.2068739\n0.7931261\n727\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.0802985\n0.9197015\n731\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8696356\n0.1303644\n733\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.5231245\n0.4768755\n742\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8615708\n0.1384292\n745\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.9034062\n0.0965938\n754\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.7985556\n0.2014444\n758\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8732247\n0.1267753\n763\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.0974890\n0.9025110\n764\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.6861611\n0.3138389\n767\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.3707916\n0.6292084\n768\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8834094\n0.1165906\n772\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.0900579\n0.9099421\n780\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.3355599\n0.6644401\n781\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.0726032\n0.9273968\n782\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.4042515\n0.5957485\n789\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.9028429\n0.0971571\n791\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.7636250\n0.2363750\n792\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.7407601\n0.2592399\n793\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8119431\n0.1880569\n796\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.3647504\n0.6352496\n803\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.3794713\n0.6205287\n804\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8119431\n0.1880569\n809\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.0672408\n0.9327592\n810\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8000583\n0.1999417\n813\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8892617\n0.1107383\n822\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8766081\n0.1233919\n823\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.2441389\n0.7558611\n828\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.9028429\n0.0971571\n829\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.0909648\n0.9090352\n830\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8412238\n0.1587762\n835\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.9012634\n0.0987366\n838\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.6645187\n0.3354813\n840\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8720237\n0.1279763\n841\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.7863930\n0.2136070\n842\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.0826145\n0.9173855\n843\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.7341010\n0.2658990\n851\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.3299523\n0.6700477\n853\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.4414580\n0.5585420\n856\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.1714423\n0.8285577\n867\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.1389736\n0.8610264\n872\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8748301\n0.1251699\n874\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.3481462\n0.6518538\n876\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.4614718\n0.5385282\n883\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.9261052\n0.0738948\n885\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb\n\n\ntrain/test split\n0.8656659\n0.1343341\n1\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.2636808\n0.7363192\n4\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.2732737\n0.7267263\n12\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8727245\n0.1272755\n13\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4995574\n0.5004426\n15\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.5408335\n0.4591665\n20\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.7051446\n0.2948554\n21\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4072737\n0.5927263\n25\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4901533\n0.5098467\n26\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4252480\n0.5747520\n28\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8861833\n0.1138167\n30\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.7290734\n0.2709266\n35\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.7366726\n0.2633274\n36\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8685755\n0.1314245\n37\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8747494\n0.1252506\n38\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8861833\n0.1138167\n46\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.6952119\n0.3047881\n51\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4069948\n0.5930052\n55\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8556607\n0.1443393\n61\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.3066536\n0.6933464\n67\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8530962\n0.1469038\n68\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4777468\n0.5222532\n69\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8791696\n0.1208304\n70\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.7336950\n0.2663050\n73\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8271967\n0.1728033\n75\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.3273503\n0.6726497\n85\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4961266\n0.5038734\n86\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8861833\n0.1138167\n88\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8727245\n0.1272755\n92\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8861833\n0.1138167\n96\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8627400\n0.1372600\n105\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8705671\n0.1294329\n109\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8747494\n0.1252506\n116\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8586752\n0.1413248\n117\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8861833\n0.1138167\n122\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8861833\n0.1138167\n128\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.2050499\n0.7949501\n129\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8178816\n0.1821184\n139\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4434845\n0.5565155\n141\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.5444973\n0.4555027\n142\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.6769263\n0.3230737\n146\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8734682\n0.1265318\n153\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8236461\n0.1763539\n154\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.7022070\n0.2977930\n156\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8672875\n0.1327125\n158\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8164798\n0.1835202\n161\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8530962\n0.1469038\n164\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.2678273\n0.7321727\n167\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8356491\n0.1643509\n180\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4084057\n0.5915943\n181\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4103081\n0.5896919\n185\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8663225\n0.1336775\n190\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.2033919\n0.7966081\n196\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4656104\n0.5343896\n209\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4866555\n0.5133445\n210\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8738308\n0.1261692\n213\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.1863377\n0.8136623\n216\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.7595848\n0.2404152\n220\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8738308\n0.1261692\n226\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.7694483\n0.2305517\n233\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4093911\n0.5906089\n234\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.7901043\n0.2098957\n235\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.3797976\n0.6202024\n241\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4317137\n0.5682863\n249\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.5828150\n0.4171850\n250\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.3203733\n0.6796267\n252\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.5204521\n0.4795479\n253\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8061183\n0.1938817\n254\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4832445\n0.5167555\n256\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.2185248\n0.7814752\n258\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8704319\n0.1295681\n261\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4504370\n0.5495630\n263\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8756623\n0.1243377\n268\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.2198014\n0.7801986\n276\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.5377305\n0.4622695\n277\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4737204\n0.5262796\n280\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8505842\n0.1494158\n284\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.3740439\n0.6259561\n291\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4359638\n0.5640362\n293\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.7698629\n0.2301371\n296\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.1962648\n0.8037352\n298\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8200349\n0.1799651\n302\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8832137\n0.1167863\n314\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.6977322\n0.3022678\n315\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.5641599\n0.4358401\n316\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.3703197\n0.6296803\n317\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4590633\n0.5409367\n337\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.2542015\n0.7457985\n346\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8186257\n0.1813743\n361\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.6853197\n0.3146803\n362\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8127553\n0.1872447\n365\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4200424\n0.5799576\n371\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8388274\n0.1611726\n372\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.7307096\n0.2692904\n374\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4002652\n0.5997348\n375\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.5372678\n0.4627322\n377\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8494101\n0.1505899\n380\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.6863375\n0.3136625\n387\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4299917\n0.5700083\n391\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8760426\n0.1239574\n393\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.2028107\n0.7971893\n394\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.3087307\n0.6912693\n395\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.7104557\n0.2895443\n398\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8672512\n0.1327488\n401\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.5072659\n0.4927341\n403\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8314112\n0.1685888\n404\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8702155\n0.1297845\n407\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4002652\n0.5997348\n410\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8693897\n0.1306103\n429\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.5342856\n0.4657144\n431\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4496048\n0.5503952\n437\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.7557741\n0.2442259\n440\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.2655518\n0.7344482\n447\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.3616351\n0.6383649\n449\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8639005\n0.1360995\n462\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.5224268\n0.4775732\n463\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.7198409\n0.2801591\n467\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.3616351\n0.6383649\n470\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.2671362\n0.7328638\n474\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.6818643\n0.3181357\n477\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8715248\n0.1284752\n479\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4100184\n0.5899816\n480\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4177009\n0.5822991\n485\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4002652\n0.5997348\n486\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.6853275\n0.3146725\n490\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8673543\n0.1326457\n491\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8715248\n0.1284752\n492\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.5224268\n0.4775732\n493\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8715248\n0.1284752\n495\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8193871\n0.1806129\n496\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8423892\n0.1576108\n498\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8494101\n0.1505899\n501\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.5054247\n0.4945753\n502\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4604501\n0.5395499\n503\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.5166279\n0.4833721\n504\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.2074387\n0.7925613\n505\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8639005\n0.1360995\n520\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8551052\n0.1448948\n526\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8423892\n0.1576108\n539\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.2207654\n0.7792346\n540\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.6818643\n0.3181357\n544\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.5354571\n0.4645429\n550\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8693897\n0.1306103\n553\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.7215241\n0.2784759\n558\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8711427\n0.1288573\n561\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8513854\n0.1486146\n567\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8657158\n0.1342842\n570\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.2649683\n0.7350317\n572\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.2614045\n0.7385955\n578\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4487555\n0.5512445\n579\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.2170042\n0.7829958\n582\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.7136393\n0.2863607\n583\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8690097\n0.1309903\n585\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8865670\n0.1134330\n590\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8738887\n0.1261113\n593\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8690097\n0.1309903\n599\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.3260487\n0.6739513\n616\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.5462872\n0.4537128\n618\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8895672\n0.1104328\n629\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4196693\n0.5803307\n635\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8573055\n0.1426945\n647\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4048175\n0.5951825\n648\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8895672\n0.1104328\n649\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8895672\n0.1104328\n651\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.2884594\n0.7115406\n652\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4889768\n0.5110232\n654\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4889768\n0.5110232\n681\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8575324\n0.1424676\n688\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8634698\n0.1365302\n689\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.2019420\n0.7980580\n690\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8618921\n0.1381079\n693\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8780122\n0.1219878\n694\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8826012\n0.1173988\n697\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.5147313\n0.4852687\n702\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.3981041\n0.6018959\n703\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4533479\n0.5466521\n713\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.5611985\n0.4388015\n716\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.2627230\n0.7372770\n718\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.2867222\n0.7132778\n721\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.3615659\n0.6384341\n727\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.2518885\n0.7481115\n731\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.7898639\n0.2101361\n733\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4524787\n0.5475213\n742\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8784170\n0.1215830\n745\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8959183\n0.1040817\n754\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.7578653\n0.2421347\n758\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8654941\n0.1345059\n763\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.2521049\n0.7478951\n764\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.6849038\n0.3150962\n767\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.5222380\n0.4777620\n768\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8841487\n0.1158513\n772\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.2652492\n0.7347508\n780\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4836699\n0.5163301\n781\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.2528907\n0.7471093\n782\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.7125532\n0.2874468\n789\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8833997\n0.1166003\n791\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.7076454\n0.2923546\n792\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4328529\n0.5671471\n793\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.7837913\n0.2162087\n796\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.3556338\n0.6443662\n803\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.7024550\n0.2975450\n804\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.7837913\n0.2162087\n809\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.2648166\n0.7351834\n810\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.7788714\n0.2211286\n813\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8959183\n0.1040817\n822\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.7235621\n0.2764379\n823\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.5324044\n0.4675956\n828\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8833997\n0.1166003\n829\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.2921895\n0.7078105\n830\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8652310\n0.1347690\n835\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8959183\n0.1040817\n838\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4970578\n0.5029422\n840\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8834594\n0.1165406\n841\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.7076454\n0.2923546\n842\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.3360129\n0.6639871\n843\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.7160474\n0.2839526\n851\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.3920219\n0.6079781\n853\n1\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.5104631\n0.4895369\n856\n0\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.3622444\n0.6377556\n867\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.2714811\n0.7285189\n872\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8841487\n0.1158513\n874\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.4836699\n0.5163301\n876\n1\nNA\nPreprocessor1_Model1\nNA\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.5532464\n0.4467536\n883\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\ntrain/test split\n0.8959183\n0.1040817\n885\n0\nNA\nPreprocessor1_Model1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nxgb_usemodel\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.00\n1\n0\nA/5 21171\n7.2500\nNA\nS\ntrain\nMr.\nBraund,\nnk\nsingle\ncouple\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.00\n1\n0\n113803\n53.1000\nC123\nS\ntrain\nF_married\nFutrelle,\nC\ncouple\ncouple\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n12\n1\n1\nBonnell, Miss. Elizabeth\nfemale\n58.00\n0\n0\n113783\n26.5500\nC103\nS\ntrain\nF_unmarried\nBonnell,\nC\nsingle\nsingle\n50s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n13\n0\n3\nSaundercock, Mr. William Henry\nmale\n20.00\n0\n0\nA/5. 2151\n8.0500\nNA\nS\ntrain\nMr.\nSaundercock,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n15\n0\n3\nVestrom, Miss. Hulda Amanda Adolfina\nfemale\n14.00\n0\n0\n350406\n7.8542\nNA\nS\ntrain\nF_unmarried\nVestrom,\nnk\nsingle\nsingle\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n20\n1\n3\nMasselmani, Mrs. Fatima\nfemale\n31.00\n0\n0\n2649\n7.2250\nNA\nC\ntrain\nF_married\nMasselmani,\nnk\nsingle\nsingle\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n21\n0\n2\nFynney, Mr. Joseph J\nmale\n35.00\n0\n0\n239865\n26.0000\nNA\nS\ntrain\nMr.\nFynney,\nnk\ncouple\nsingle\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n25\n0\n3\nPalsson, Miss. Torborg Danira\nfemale\n8.00\n3\n1\n349909\n21.0750\nNA\nS\ntrain\nF_unmarried\nPalsson,\nnk\ngroup\nfamily\nchild\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n26\n1\n3\nAsplund, Mrs. Carl Oscar (Selma Augusta Emilia Johansson)\nfemale\n38.00\n1\n5\n347077\n31.3875\nNA\nS\ntrain\nF_married\nAsplund,\nnk\ngroup\nfamily\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n28\n0\n1\nFortune, Mr. Charles Alexander\nmale\n19.00\n3\n2\n19950\n263.0000\nC23 C25 C27\nS\ntrain\nMr.\nFortune,\nC\ngroup\nfamily\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n30\n0\n3\nTodoroff, Mr. Lalio\nmale\n26.00\n0\n0\n349216\n7.8958\nNA\nS\ntrain\nMr.\nTodoroff,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n35\n0\n1\nMeyer, Mr. Edgar Joseph\nmale\n28.00\n1\n0\nPC 17604\n82.1708\nNA\nC\ntrain\nMr.\nMeyer,\nnk\ncouple\ncouple\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n36\n0\n1\nHolverson, Mr. Alexander Oskar\nmale\n42.00\n1\n0\n113789\n52.0000\nNA\nS\ntrain\nMr.\nHolverson,\nnk\ncouple\ncouple\n40s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n37\n1\n3\nMamee, Mr. Hanna\nmale\n26.00\n0\n0\n2677\n7.2292\nNA\nC\ntrain\nMr.\nMamee,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n38\n0\n3\nCann, Mr. Ernest Charles\nmale\n21.00\n0\n0\nA./5. 2152\n8.0500\nNA\nS\ntrain\nMr.\nCann,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n46\n0\n3\nRogers, Mr. William John\nmale\n26.00\n0\n0\nS.C./A.4. 23567\n8.0500\nNA\nS\ntrain\nMr.\nRogers,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n51\n0\n3\nPanula, Master. Juha Niilo\nmale\n7.00\n4\n1\n3101295\n39.6875\nNA\nS\ntrain\nMaster.\nPanula,\nnk\ngroup\nfamily\nchild\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n55\n0\n1\nOstby, Mr. Engelhart Cornelius\nmale\n65.00\n0\n1\n113509\n61.9792\nB30\nC\ntrain\nMr.\nOstby,\nB\ncouple\ncouple\n60+\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n61\n0\n3\nSirayanian, Mr. Orsen\nmale\n22.00\n0\n0\n2669\n7.2292\nNA\nC\ntrain\nMr.\nSirayanian,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n67\n1\n2\nNye, Mrs. (Elizabeth Ramell)\nfemale\n29.00\n0\n0\nC.A. 29395\n10.5000\nF33\nS\ntrain\nF_married\nNye,\nF\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n68\n0\n3\nCrease, Mr. Ernest James\nmale\n19.00\n0\n0\nS.P. 3464\n8.1583\nNA\nS\ntrain\nMr.\nCrease,\nnk\nsingle\nsingle\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n69\n1\n3\nAndersson, Miss. Erna Alexandra\nfemale\n17.00\n4\n2\n3101281\n7.9250\nNA\nS\ntrain\nF_unmarried\nAndersson,\nnk\nsingle\nfamily\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n70\n0\n3\nKink, Mr. Vincenz\nmale\n26.00\n2\n0\n315151\n8.6625\nNA\nS\ntrain\nMr.\nKink,\nnk\nsingle\nfamily\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n73\n0\n2\nHood, Mr. Ambrose Jr\nmale\n21.00\n0\n0\nS.O.C. 14879\n73.5000\nNA\nS\ntrain\nMr.\nHood,\nnk\ngroup\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n75\n1\n3\nBing, Mr. Lee\nmale\n32.00\n0\n0\n1601\n56.4958\nNA\nS\ntrain\nMr.\nBing,\nnk\ngroup\nsingle\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n85\n1\n2\nIlett, Miss. Bertha\nfemale\n17.00\n0\n0\nSO/C 14885\n10.5000\nNA\nS\ntrain\nF_unmarried\nIlett,\nnk\nsingle\nsingle\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n86\n1\n3\nBackstrom, Mrs. Karl Alfred (Maria Mathilda Gustafsson)\nfemale\n33.00\n3\n0\n3101278\n15.8500\nNA\nS\ntrain\nF_married\nBackstrom,\nnk\ncouple\nfamily\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n88\n0\n3\nSlocovski, Mr. Selman Francis\nmale\n26.00\n0\n0\nSOTON/OQ 392086\n8.0500\nNA\nS\ntrain\nMr.\nSlocovski,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n92\n0\n3\nAndreasson, Mr. Paul Edvin\nmale\n20.00\n0\n0\n347466\n7.8542\nNA\nS\ntrain\nMr.\nAndreasson,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n96\n0\n3\nShorney, Mr. Charles Joseph\nmale\n26.00\n0\n0\n374910\n8.0500\nNA\nS\ntrain\nMr.\nShorney,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n105\n0\n3\nGustafsson, Mr. Anders Vilhelm\nmale\n37.00\n2\n0\n3101276\n7.9250\nNA\nS\ntrain\nMr.\nGustafsson,\nnk\nsingle\nfamily\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n109\n0\n3\nRekic, Mr. Tido\nmale\n38.00\n0\n0\n349249\n7.8958\nNA\nS\ntrain\nMr.\nRekic,\nnk\nsingle\nsingle\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n116\n0\n3\nPekoniemi, Mr. Edvard\nmale\n21.00\n0\n0\nSTON/O 2. 3101294\n7.9250\nNA\nS\ntrain\nMr.\nPekoniemi,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n117\n0\n3\nConnors, Mr. Patrick\nmale\n70.50\n0\n0\n370369\n7.7500\nNA\nQ\ntrain\nMr.\nConnors,\nnk\nsingle\nsingle\n60+\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n122\n0\n3\nMoore, Mr. Leonard Charles\nmale\n26.00\n0\n0\nA4. 54510\n8.0500\nNA\nS\ntrain\nMr.\nMoore,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n128\n1\n3\nMadsen, Mr. Fridtjof Arne\nmale\n24.00\n0\n0\nC 17369\n7.1417\nNA\nS\ntrain\nMr.\nMadsen,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n129\n1\n3\nPeter, Miss. Anna\nfemale\n18.00\n1\n1\n2668\n22.3583\nF E69\nC\ntrain\nF_unmarried\nPeter,\nF\ngroup\nfamily\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n139\n0\n3\nOsen, Mr. Olaf Elon\nmale\n16.00\n0\n0\n7534\n9.2167\nNA\nS\ntrain\nMr.\nOsen,\nnk\ncouple\nsingle\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n141\n0\n3\nBoulos, Mrs. Joseph (Sultana)\nfemale\n31.00\n0\n2\n2678\n15.2458\nNA\nC\ntrain\nF_married\nBoulos,\nnk\ngroup\nfamily\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n142\n1\n3\nNysten, Miss. Anna Sofia\nfemale\n22.00\n0\n0\n347081\n7.7500\nNA\nS\ntrain\nF_unmarried\nNysten,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n146\n0\n2\nNicholls, Mr. Joseph Charles\nmale\n19.00\n1\n1\nC.A. 33112\n36.7500\nNA\nS\ntrain\nMr.\nNicholls,\nnk\ngroup\nfamily\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n153\n0\n3\nMeo, Mr. Alfonzo\nmale\n55.50\n0\n0\nA.5. 11206\n8.0500\nNA\nS\ntrain\nMr.\nMeo,\nnk\nsingle\nsingle\n50s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n154\n0\n3\nvan Billiard, Mr. Austin Blyler\nmale\n40.50\n0\n2\nA/5. 851\n14.5000\nNA\nS\ntrain\nMr.\nBilliard,\nnk\ngroup\nfamily\n40s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n156\n0\n1\nWilliams, Mr. Charles Duane\nmale\n51.00\n0\n1\nPC 17597\n61.3792\nNA\nC\ntrain\nMr.\nWilliams,\nnk\ncouple\ncouple\n50s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n158\n0\n3\nCorn, Mr. Harry\nmale\n30.00\n0\n0\nSOTON/OQ 392090\n8.0500\nNA\nS\ntrain\nMr.\nCorn,\nnk\nsingle\nsingle\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n161\n0\n3\nCribb, Mr. John Hatfield\nmale\n44.00\n0\n1\n371362\n16.1000\nNA\nS\ntrain\nMr.\nCribb,\nnk\ncouple\ncouple\n40s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n164\n0\n3\nCalic, Mr. Jovo\nmale\n17.00\n0\n0\n315093\n8.6625\nNA\nS\ntrain\nMr.\nCalic,\nnk\nsingle\nsingle\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n167\n1\n1\nChibnall, Mrs. (Edith Martha Bowerman)\nfemale\n45.00\n0\n1\n113505\n55.0000\nE33\nS\ntrain\nF_married\nChibnall,\nE\ncouple\ncouple\n40s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n180\n0\n3\nLeonard, Mr. Lionel\nmale\n36.00\n0\n0\nLINE\n0.0000\nNA\nS\ntrain\nMr.\nLeonard,\nnk\ngroup\nsingle\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n181\n0\n3\nSage, Miss. Constance Gladys\nfemale\n18.00\n8\n2\nCA. 2343\n69.5500\nNA\nS\ntrain\nF_unmarried\nSage,\nnk\ngroup\nfamily\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n185\n1\n3\nKink-Heilmann, Miss. Luise Gretchen\nfemale\n4.00\n0\n2\n315153\n22.0250\nNA\nS\ntrain\nF_unmarried\nHeilmann,\nnk\ngroup\nfamily\nchild\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n190\n0\n3\nTurcin, Mr. Stjepan\nmale\n36.00\n0\n0\n349247\n7.8958\nNA\nS\ntrain\nMr.\nTurcin,\nnk\nsingle\nsingle\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n196\n1\n1\nLurette, Miss. Elise\nfemale\n58.00\n0\n0\nPC 17569\n146.5208\nB80\nC\ntrain\nF_unmarried\nLurette,\nB\ngroup\nsingle\n50s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n209\n1\n3\nCarr, Miss. Helen “Ellen”\nfemale\n16.00\n0\n0\n367231\n7.7500\nNA\nQ\ntrain\nF_unmarried\nCarr,\nnk\nsingle\nsingle\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n210\n1\n1\nBlank, Mr. Henry\nmale\n40.00\n0\n0\n112277\n31.0000\nA31\nC\ntrain\nMr.\nBlank,\nA\nsingle\nsingle\n40s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n213\n0\n3\nPerkin, Mr. John Henry\nmale\n22.00\n0\n0\nA/5 21174\n7.2500\nNA\nS\ntrain\nMr.\nPerkin,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n216\n1\n1\nNewell, Miss. Madeleine\nfemale\n31.00\n1\n0\n35273\n113.2750\nD36\nC\ntrain\nF_unmarried\nNewell,\nD\ngroup\ncouple\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n220\n0\n2\nHarris, Mr. Walter\nmale\n30.00\n0\n0\nW/C 14208\n10.5000\nNA\nS\ntrain\nMr.\nHarris,\nnk\nsingle\nsingle\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n226\n0\n3\nBerglund, Mr. Karl Ivar Sven\nmale\n22.00\n0\n0\nPP 4348\n9.3500\nNA\nS\ntrain\nMr.\nBerglund,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n233\n0\n2\nSjostedt, Mr. Ernst Adolf\nmale\n59.00\n0\n0\n237442\n13.5000\nNA\nS\ntrain\nMr.\nSjostedt,\nnk\nsingle\nsingle\n50s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n234\n1\n3\nAsplund, Miss. Lillian Gertrud\nfemale\n5.00\n4\n2\n347077\n31.3875\nNA\nS\ntrain\nF_unmarried\nAsplund,\nnk\ngroup\nfamily\nchild\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n235\n0\n2\nLeyson, Mr. Robert William Norman\nmale\n24.00\n0\n0\nC.A. 29566\n10.5000\nNA\nS\ntrain\nMr.\nLeyson,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n241\n0\n3\nZabour, Miss. Thamine\nfemale\n18.00\n1\n0\n2665\n14.4542\nNA\nC\ntrain\nF_unmarried\nZabour,\nnk\ncouple\ncouple\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n249\n1\n1\nBeckwith, Mr. Richard Leonard\nmale\n37.00\n1\n1\n11751\n52.5542\nD35\nS\ntrain\nMr.\nBeckwith,\nD\ncouple\nfamily\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n250\n0\n2\nCarter, Rev. Ernest Courtenay\nmale\n54.00\n1\n0\n244252\n26.0000\nNA\nS\ntrain\nM_Professional\nCarter,\nnk\ncouple\ncouple\n50s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n252\n0\n3\nStrom, Mrs. Wilhelm (Elna Matilda Persson)\nfemale\n29.00\n1\n1\n347054\n10.4625\nG6\nS\ntrain\nF_married\nStrom,\nG\ncouple\nfamily\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n253\n0\n1\nStead, Mr. William Thomas\nmale\n62.00\n0\n0\n113514\n26.5500\nC87\nS\ntrain\nMr.\nStead,\nC\nsingle\nsingle\n60+\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n254\n0\n3\nLobb, Mr. William Arthur\nmale\n30.00\n1\n0\nA/5. 3336\n16.1000\nNA\nS\ntrain\nMr.\nLobb,\nnk\ncouple\ncouple\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n256\n1\n3\nTouma, Mrs. Darwis (Hanne Youssef Razi)\nfemale\n29.00\n0\n2\n2650\n15.2458\nNA\nC\ntrain\nF_married\nTouma,\nnk\ngroup\nfamily\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n258\n1\n1\nCherry, Miss. Gladys\nfemale\n30.00\n0\n0\n110152\n86.5000\nB77\nS\ntrain\nF_unmarried\nCherry,\nB\ngroup\nsingle\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n261\n0\n3\nSmith, Mr. Thomas\nmale\n26.00\n0\n0\n384461\n7.7500\nNA\nQ\ntrain\nMr.\nSmith,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n263\n0\n1\nTaussig, Mr. Emil\nmale\n52.00\n1\n1\n110413\n79.6500\nE67\nS\ntrain\nMr.\nTaussig,\nE\ngroup\nfamily\n50s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n268\n1\n3\nPersson, Mr. Ernst Ulrik\nmale\n25.00\n1\n0\n347083\n7.7750\nNA\nS\ntrain\nMr.\nPersson,\nnk\nsingle\ncouple\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n276\n1\n1\nAndrews, Miss. Kornelia Theodosia\nfemale\n63.00\n1\n0\n13502\n77.9583\nD7\nS\ntrain\nF_unmarried\nAndrews,\nD\ngroup\ncouple\n60+\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n277\n0\n3\nLindblom, Miss. Augusta Charlotta\nfemale\n45.00\n0\n0\n347073\n7.7500\nNA\nS\ntrain\nF_unmarried\nLindblom,\nnk\nsingle\nsingle\n40s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n280\n1\n3\nAbbott, Mrs. Stanton (Rosa Hunt)\nfemale\n35.00\n1\n1\nC.A. 2673\n20.2500\nNA\nS\ntrain\nF_married\nAbbott,\nnk\ngroup\nfamily\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n284\n1\n3\nDorking, Mr. Edward Arthur\nmale\n19.00\n0\n0\nA/5. 10482\n8.0500\nNA\nS\ntrain\nMr.\nDorking,\nnk\nsingle\nsingle\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n291\n1\n1\nBarber, Miss. Ellen “Nellie”\nfemale\n26.00\n0\n0\n19877\n78.8500\nNA\nS\ntrain\nF_unmarried\nBarber,\nnk\ngroup\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n293\n0\n2\nLevy, Mr. Rene Jacques\nmale\n36.00\n0\n0\nSC/Paris 2163\n12.8750\nD\nC\ntrain\nMr.\nLevy,\nD\nsingle\nsingle\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n296\n0\n1\nLewy, Mr. Ervin G\nmale\n41.50\n0\n0\nPC 17612\n27.7208\nNA\nC\ntrain\nMr.\nLewy,\nnk\nsingle\nsingle\n40s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n298\n0\n1\nAllison, Miss. Helen Loraine\nfemale\n2.00\n1\n2\n113781\n151.5500\nC22 C26\nS\ntrain\nF_unmarried\nAllison,\nC\ngroup\nfamily\nchild\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n302\n1\n3\nMcCoy, Mr. Bernard\nmale\n26.00\n2\n0\n367226\n23.2500\nNA\nQ\ntrain\nMr.\nMcCoy,\nnk\ngroup\nfamily\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n314\n0\n3\nHendekovic, Mr. Ignjac\nmale\n28.00\n0\n0\n349243\n7.8958\nNA\nS\ntrain\nMr.\nHendekovic,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n315\n0\n2\nHart, Mr. Benjamin\nmale\n43.00\n1\n1\nF.C.C. 13529\n26.2500\nNA\nS\ntrain\nMr.\nHart,\nnk\ngroup\nfamily\n40s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n316\n1\n3\nNilsson, Miss. Helmina Josefina\nfemale\n26.00\n0\n0\n347470\n7.8542\nNA\nS\ntrain\nF_unmarried\nNilsson,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n317\n1\n2\nKantor, Mrs. Sinai (Miriam Sternin)\nfemale\n24.00\n1\n0\n244367\n26.0000\nNA\nS\ntrain\nF_married\nKantor,\nnk\ncouple\ncouple\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n337\n0\n1\nPears, Mr. Thomas Clinton\nmale\n29.00\n1\n0\n113776\n66.6000\nC2\nS\ntrain\nMr.\nPears,\nC\ncouple\ncouple\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n346\n1\n2\nBrown, Miss. Amelia “Mildred”\nfemale\n24.00\n0\n0\n248733\n13.0000\nF33\nS\ntrain\nF_unmarried\nBrown,\nF\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n361\n0\n3\nSkoog, Mr. Wilhelm\nmale\n40.00\n1\n4\n347088\n27.9000\nNA\nS\ntrain\nMr.\nSkoog,\nnk\ngroup\nfamily\n40s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n362\n0\n2\ndel Carlo, Mr. Sebastiano\nmale\n29.00\n1\n0\nSC/PARIS 2167\n27.7208\nNA\nC\ntrain\nMr.\nCarlo,\nnk\ncouple\ncouple\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n365\n0\n3\nO’Brien, Mr. Thomas\nmale\n26.00\n1\n0\n370365\n15.5000\nNA\nQ\ntrain\nMr.\nBrien,\nnk\ncouple\ncouple\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n371\n1\n1\nHarder, Mr. George Achilles\nmale\n25.00\n1\n0\n11765\n55.4417\nE50\nC\ntrain\nMr.\nHarder,\nE\ncouple\ncouple\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n372\n0\n3\nWiklund, Mr. Jakob Alfred\nmale\n18.00\n1\n0\n3101267\n6.4958\nNA\nS\ntrain\nMr.\nWiklund,\nnk\nsingle\ncouple\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n374\n0\n1\nRinghini, Mr. Sante\nmale\n22.00\n0\n0\nPC 17760\n135.6333\nNA\nC\ntrain\nMr.\nRinghini,\nnk\ngroup\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n375\n0\n3\nPalsson, Miss. Stina Viola\nfemale\n3.00\n3\n1\n349909\n21.0750\nNA\nS\ntrain\nF_unmarried\nPalsson,\nnk\ngroup\nfamily\nchild\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n377\n1\n3\nLandergren, Miss. Aurora Adelia\nfemale\n22.00\n0\n0\nC 7077\n7.2500\nNA\nS\ntrain\nF_unmarried\nLandergren,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n380\n0\n3\nGustafsson, Mr. Karl Gideon\nmale\n19.00\n0\n0\n347069\n7.7750\nNA\nS\ntrain\nMr.\nGustafsson,\nnk\nsingle\nsingle\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n387\n0\n3\nGoodwin, Master. Sidney Leonard\nmale\n1.00\n5\n2\nCA 2144\n46.9000\nNA\nS\ntrain\nMaster.\nGoodwin,\nnk\ngroup\nfamily\nchild\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n391\n1\n1\nCarter, Mr. William Ernest\nmale\n36.00\n1\n2\n113760\n120.0000\nB96 B98\nS\ntrain\nMr.\nCarter,\nB\ngroup\nfamily\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n393\n0\n3\nGustafsson, Mr. Johan Birger\nmale\n28.00\n2\n0\n3101277\n7.9250\nNA\nS\ntrain\nMr.\nGustafsson,\nnk\nsingle\nfamily\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n394\n1\n1\nNewell, Miss. Marjorie\nfemale\n23.00\n1\n0\n35273\n113.2750\nD36\nC\ntrain\nF_unmarried\nNewell,\nD\ngroup\ncouple\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n395\n1\n3\nSandstrom, Mrs. Hjalmar (Agnes Charlotta Bengtsson)\nfemale\n24.00\n0\n2\nPP 9549\n16.7000\nG6\nS\ntrain\nF_married\nSandstrom,\nG\ngroup\nfamily\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n398\n0\n2\nMcKane, Mr. Peter David\nmale\n46.00\n0\n0\n28403\n26.0000\nNA\nS\ntrain\nMr.\nMcKane,\nnk\ncouple\nsingle\n40s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n401\n1\n3\nNiskanen, Mr. Juha\nmale\n39.00\n0\n0\nSTON/O 2. 3101289\n7.9250\nNA\nS\ntrain\nMr.\nNiskanen,\nnk\nsingle\nsingle\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n403\n0\n3\nJussila, Miss. Mari Aina\nfemale\n21.00\n1\n0\n4137\n9.8250\nNA\nS\ntrain\nF_unmarried\nJussila,\nnk\nsingle\ncouple\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n404\n0\n3\nHakkarainen, Mr. Pekka Pietari\nmale\n28.00\n1\n0\nSTON/O2. 3101279\n15.8500\nNA\nS\ntrain\nMr.\nHakkarainen,\nnk\ncouple\ncouple\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n407\n0\n3\nWidegren, Mr. Carl/Charles Peter\nmale\n51.00\n0\n0\n347064\n7.7500\nNA\nS\ntrain\nMr.\nWidegren,\nnk\nsingle\nsingle\n50s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n410\n0\n3\nLefebre, Miss. Ida\nfemale\n18.00\n3\n1\n4133\n25.4667\nNA\nS\ntrain\nF_unmarried\nLefebre,\nnk\ngroup\nfamily\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n429\n0\n3\nFlynn, Mr. James\nmale\n26.00\n0\n0\n364851\n7.7500\nNA\nQ\ntrain\nMr.\nFlynn,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n431\n1\n1\nBjornstrom-Steffansson, Mr. Mauritz Hakan\nmale\n28.00\n0\n0\n110564\n26.5500\nC52\nS\ntrain\nMr.\nSteffansson,\nC\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n437\n0\n3\nFord, Miss. Doolina Margaret “Daisy”\nfemale\n21.00\n2\n2\nW./C. 6608\n34.3750\nNA\nS\ntrain\nF_unmarried\nFord,\nnk\ngroup\nfamily\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n440\n0\n2\nKvillner, Mr. Johan Henrik Johannesson\nmale\n31.00\n0\n0\nC.A. 18723\n10.5000\nNA\nS\ntrain\nMr.\nKvillner,\nnk\nsingle\nsingle\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n447\n1\n2\nMellinger, Miss. Madeleine Violet\nfemale\n13.00\n0\n1\n250644\n19.5000\nNA\nS\ntrain\nF_unmarried\nMellinger,\nnk\ncouple\ncouple\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n449\n1\n3\nBaclini, Miss. Marie Catherine\nfemale\n5.00\n2\n1\n2666\n19.2583\nNA\nC\ntrain\nF_unmarried\nBaclini,\nnk\ngroup\nfamily\nchild\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n462\n0\n3\nMorley, Mr. William\nmale\n34.00\n0\n0\n364506\n8.0500\nNA\nS\ntrain\nMr.\nMorley,\nnk\nsingle\nsingle\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n463\n0\n1\nGee, Mr. Arthur H\nmale\n47.00\n0\n0\n111320\n38.5000\nE63\nS\ntrain\nMr.\nGee,\nE\nsingle\nsingle\n40s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n467\n0\n2\nCampbell, Mr. William\nmale\n30.00\n0\n0\n239853\n0.0000\nNA\nS\ntrain\nMr.\nCampbell,\nnk\ngroup\nsingle\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n470\n1\n3\nBaclini, Miss. Helene Barbara\nfemale\n0.75\n2\n1\n2666\n19.2583\nNA\nC\ntrain\nF_unmarried\nBaclini,\nnk\ngroup\nfamily\nchild\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n474\n1\n2\nJerwan, Mrs. Amin S (Marie Marthe Thuillard)\nfemale\n23.00\n0\n0\nSC/AH Basle 541\n13.7917\nD\nC\ntrain\nF_married\nJerwan,\nD\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n477\n0\n2\nRenouf, Mr. Peter Henry\nmale\n34.00\n1\n0\n31027\n21.0000\nNA\nS\ntrain\nMr.\nRenouf,\nnk\ncouple\ncouple\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n479\n0\n3\nKarlsson, Mr. Nils August\nmale\n22.00\n0\n0\n350060\n7.5208\nNA\nS\ntrain\nMr.\nKarlsson,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n480\n1\n3\nHirvonen, Miss. Hildur E\nfemale\n2.00\n0\n1\n3101298\n12.2875\nNA\nS\ntrain\nF_unmarried\nHirvonen,\nnk\ncouple\ncouple\nchild\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n485\n1\n1\nBishop, Mr. Dickinson H\nmale\n25.00\n1\n0\n11967\n91.0792\nB49\nC\ntrain\nMr.\nBishop,\nB\ncouple\ncouple\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n486\n0\n3\nLefebre, Miss. Jeannie\nfemale\n18.00\n3\n1\n4133\n25.4667\nNA\nS\ntrain\nF_unmarried\nLefebre,\nnk\ngroup\nfamily\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n490\n1\n3\nCoutts, Master. Eden Leslie “Neville”\nmale\n9.00\n1\n1\nC.A. 37671\n15.9000\nNA\nS\ntrain\nMaster.\nCoutts,\nnk\ngroup\nfamily\nchild\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n491\n0\n3\nHagland, Mr. Konrad Mathias Reiersen\nmale\n26.00\n1\n0\n65304\n19.9667\nNA\nS\ntrain\nMr.\nHagland,\nnk\nsingle\ncouple\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n492\n0\n3\nWindelov, Mr. Einar\nmale\n21.00\n0\n0\nSOTON/OQ 3101317\n7.2500\nNA\nS\ntrain\nMr.\nWindelov,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n493\n0\n1\nMolson, Mr. Harry Markland\nmale\n55.00\n0\n0\n113787\n30.5000\nC30\nS\ntrain\nMr.\nMolson,\nC\nsingle\nsingle\n50s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n495\n0\n3\nStanley, Mr. Edward Roland\nmale\n21.00\n0\n0\nA/4 45380\n8.0500\nNA\nS\ntrain\nMr.\nStanley,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n496\n0\n3\nYousseff, Mr. Gerious\nmale\n26.00\n0\n0\n2627\n14.4583\nNA\nC\ntrain\nMr.\nYousseff,\nnk\ncouple\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n498\n0\n3\nShellard, Mr. Frederick William\nmale\n26.00\n0\n0\nC.A. 6212\n15.1000\nNA\nS\ntrain\nMr.\nShellard,\nnk\ncouple\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n501\n0\n3\nCalic, Mr. Petar\nmale\n17.00\n0\n0\n315086\n8.6625\nNA\nS\ntrain\nMr.\nCalic,\nnk\nsingle\nsingle\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n502\n0\n3\nCanavan, Miss. Mary\nfemale\n21.00\n0\n0\n364846\n7.7500\nNA\nQ\ntrain\nF_unmarried\nCanavan,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n503\n0\n3\nO’Sullivan, Miss. Bridget Mary\nfemale\n18.00\n0\n0\n330909\n7.6292\nNA\nQ\ntrain\nF_unmarried\nSullivan,\nnk\nsingle\nsingle\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n504\n0\n3\nLaitinen, Miss. Kristina Sofia\nfemale\n37.00\n0\n0\n4135\n9.5875\nNA\nS\ntrain\nF_unmarried\nLaitinen,\nnk\nsingle\nsingle\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n505\n1\n1\nMaioni, Miss. Roberta\nfemale\n16.00\n0\n0\n110152\n86.5000\nB79\nS\ntrain\nF_unmarried\nMaioni,\nB\ngroup\nsingle\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n520\n0\n3\nPavlovic, Mr. Stefo\nmale\n32.00\n0\n0\n349242\n7.8958\nNA\nS\ntrain\nMr.\nPavlovic,\nnk\nsingle\nsingle\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n526\n0\n3\nFarrell, Mr. James\nmale\n40.50\n0\n0\n367232\n7.7500\nNA\nQ\ntrain\nMr.\nFarrell,\nnk\nsingle\nsingle\n40s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n539\n0\n3\nRisien, Mr. Samuel Beard\nmale\n26.00\n0\n0\n364498\n14.5000\nNA\nS\ntrain\nMr.\nRisien,\nnk\ncouple\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n540\n1\n1\nFrolicher, Miss. Hedwig Margaritha\nfemale\n22.00\n0\n2\n13568\n49.5000\nB39\nC\ntrain\nF_unmarried\nFrolicher,\nB\nsingle\nfamily\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n544\n1\n2\nBeane, Mr. Edward\nmale\n32.00\n1\n0\n2908\n26.0000\nNA\nS\ntrain\nMr.\nBeane,\nnk\ncouple\ncouple\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n550\n1\n2\nDavies, Master. John Morgan Jr\nmale\n8.00\n1\n1\nC.A. 33112\n36.7500\nNA\nS\ntrain\nMaster.\nDavies,\nnk\ngroup\nfamily\nchild\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n553\n0\n3\nO’Brien, Mr. Timothy\nmale\n26.00\n0\n0\n330979\n7.8292\nNA\nQ\ntrain\nMr.\nBrien,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n558\n0\n1\nRobbins, Mr. Victor\nmale\n41.50\n0\n0\nPC 17757\n227.5250\nNA\nC\ntrain\nMr.\nRobbins,\nnk\ngroup\nsingle\n40s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n561\n0\n3\nMorrow, Mr. Thomas Rowan\nmale\n26.00\n0\n0\n372622\n7.7500\nNA\nQ\ntrain\nMr.\nMorrow,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n567\n0\n3\nStoytcheff, Mr. Ilia\nmale\n19.00\n0\n0\n349205\n7.8958\nNA\nS\ntrain\nMr.\nStoytcheff,\nnk\nsingle\nsingle\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n570\n1\n3\nJonsson, Mr. Carl\nmale\n32.00\n0\n0\n350417\n7.8542\nNA\nS\ntrain\nMr.\nJonsson,\nnk\nsingle\nsingle\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n572\n1\n1\nAppleton, Mrs. Edward Dale (Charlotte Lamson)\nfemale\n53.00\n2\n0\n11769\n51.4792\nC101\nS\ntrain\nF_married\nAppleton,\nC\ncouple\nfamily\n50s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n578\n1\n1\nSilvey, Mrs. William Baird (Alice Munger)\nfemale\n39.00\n1\n0\n13507\n55.9000\nE44\nS\ntrain\nF_married\nSilvey,\nE\ncouple\ncouple\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n579\n0\n3\nCaram, Mrs. Joseph (Maria Elias)\nfemale\n31.00\n1\n0\n2689\n14.4583\nNA\nC\ntrain\nF_married\nCaram,\nnk\ncouple\ncouple\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n582\n1\n1\nThayer, Mrs. John Borland (Marian Longstreth Morris)\nfemale\n39.00\n1\n1\n17421\n110.8833\nC68\nC\ntrain\nF_married\nThayer,\nC\ngroup\nfamily\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n583\n0\n2\nDownton, Mr. William James\nmale\n54.00\n0\n0\n28403\n26.0000\nNA\nS\ntrain\nMr.\nDownton,\nnk\ncouple\nsingle\n50s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n585\n0\n3\nPaulner, Mr. Uscher\nmale\n26.00\n0\n0\n3411\n8.7125\nNA\nC\ntrain\nMr.\nPaulner,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n590\n0\n3\nMurdlin, Mr. Joseph\nmale\n26.00\n0\n0\nA./5. 3235\n8.0500\nNA\nS\ntrain\nMr.\nMurdlin,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n593\n0\n3\nElsbury, Mr. William James\nmale\n47.00\n0\n0\nA/5 3902\n7.2500\nNA\nS\ntrain\nMr.\nElsbury,\nnk\nsingle\nsingle\n40s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n599\n0\n3\nBoulos, Mr. Hanna\nmale\n26.00\n0\n0\n2664\n7.2250\nNA\nC\ntrain\nMr.\nBoulos,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n616\n1\n2\nHerman, Miss. Alice\nfemale\n24.00\n1\n2\n220845\n65.0000\nNA\nS\ntrain\nF_unmarried\nHerman,\nnk\ngroup\nfamily\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n618\n0\n3\nLobb, Mrs. William Arthur (Cordelia K Stanlick)\nfemale\n26.00\n1\n0\nA/5. 3336\n16.1000\nNA\nS\ntrain\nF_married\nLobb,\nnk\ncouple\ncouple\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n629\n0\n3\nBostandyeff, Mr. Guentcho\nmale\n26.00\n0\n0\n349224\n7.8958\nNA\nS\ntrain\nMr.\nBostandyeff,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n635\n0\n3\nSkoog, Miss. Mabel\nfemale\n9.00\n3\n2\n347088\n27.9000\nNA\nS\ntrain\nF_unmarried\nSkoog,\nnk\ngroup\nfamily\nchild\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n647\n0\n3\nCor, Mr. Liudevit\nmale\n19.00\n0\n0\n349231\n7.8958\nNA\nS\ntrain\nMr.\nCor,\nnk\nsingle\nsingle\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n648\n1\n1\nSimonius-Blumer, Col. Oberst Alfons\nmale\n56.00\n0\n0\n13213\n35.5000\nA26\nC\ntrain\nMilitary\nBlumer,\nA\nsingle\nsingle\n50s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n649\n0\n3\nWilley, Mr. Edward\nmale\n26.00\n0\n0\nS.O./P.P. 751\n7.5500\nNA\nS\ntrain\nMr.\nWilley,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n651\n0\n3\nMitkoff, Mr. Mito\nmale\n26.00\n0\n0\n349221\n7.8958\nNA\nS\ntrain\nMr.\nMitkoff,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n652\n1\n2\nDoling, Miss. Elsie\nfemale\n18.00\n0\n1\n231919\n23.0000\nNA\nS\ntrain\nF_unmarried\nDoling,\nnk\ncouple\ncouple\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n654\n1\n3\nO’Leary, Miss. Hanora “Norah”\nfemale\n18.00\n0\n0\n330919\n7.8292\nNA\nQ\ntrain\nF_unmarried\nLeary,\nnk\nsingle\nsingle\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n681\n0\n3\nPeters, Miss. Katie\nfemale\n18.00\n0\n0\n330935\n8.1375\nNA\nQ\ntrain\nF_unmarried\nPeters,\nnk\nsingle\nsingle\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n688\n0\n3\nDakic, Mr. Branko\nmale\n19.00\n0\n0\n349228\n10.1708\nNA\nS\ntrain\nMr.\nDakic,\nnk\nsingle\nsingle\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n689\n0\n3\nFischer, Mr. Eberhard Thelander\nmale\n18.00\n0\n0\n350036\n7.7958\nNA\nS\ntrain\nMr.\nFischer,\nnk\nsingle\nsingle\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n690\n1\n1\nMadill, Miss. Georgette Alexandra\nfemale\n15.00\n0\n1\n24160\n211.3375\nB5\nS\ntrain\nF_unmarried\nMadill,\nB\ngroup\ncouple\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n693\n1\n3\nLam, Mr. Ali\nmale\n26.00\n0\n0\n1601\n56.4958\nNA\nS\ntrain\nMr.\nLam,\nnk\ngroup\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n694\n0\n3\nSaad, Mr. Khalil\nmale\n25.00\n0\n0\n2672\n7.2250\nNA\nC\ntrain\nMr.\nSaad,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n697\n0\n3\nKelly, Mr. James\nmale\n44.00\n0\n0\n363592\n8.0500\nNA\nS\ntrain\nMr.\nKelly,\nnk\nsingle\nsingle\n40s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n702\n1\n1\nSilverthorne, Mr. Spencer Victor\nmale\n35.00\n0\n0\nPC 17475\n26.2875\nE24\nS\ntrain\nMr.\nSilverthorne,\nE\nsingle\nsingle\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n703\n0\n3\nBarbara, Miss. Saiide\nfemale\n18.00\n0\n1\n2691\n14.4542\nNA\nC\ntrain\nF_unmarried\nBarbara,\nnk\ncouple\ncouple\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n713\n1\n1\nTaylor, Mr. Elmer Zebley\nmale\n48.00\n1\n0\n19996\n52.0000\nC126\nS\ntrain\nMr.\nTaylor,\nC\ncouple\ncouple\n40s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n716\n0\n3\nSoholt, Mr. Peter Andreas Lauritz Andersen\nmale\n19.00\n0\n0\n348124\n7.6500\nF G73\nS\ntrain\nMr.\nSoholt,\nF\nsingle\nsingle\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n718\n1\n2\nTroutt, Miss. Edwina Celia “Winnie”\nfemale\n27.00\n0\n0\n34218\n10.5000\nE101\nS\ntrain\nF_unmarried\nTroutt,\nE\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n721\n1\n2\nHarper, Miss. Annie Jessie “Nina”\nfemale\n6.00\n0\n1\n248727\n33.0000\nNA\nS\ntrain\nF_unmarried\nHarper,\nnk\ngroup\ncouple\nchild\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n727\n1\n2\nRenouf, Mrs. Peter Henry (Lillian Jefferys)\nfemale\n30.00\n3\n0\n31027\n21.0000\nNA\nS\ntrain\nF_married\nRenouf,\nnk\ncouple\nfamily\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n731\n1\n1\nAllen, Miss. Elisabeth Walton\nfemale\n29.00\n0\n0\n24160\n211.3375\nB5\nS\ntrain\nF_unmarried\nAllen,\nB\ngroup\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n733\n0\n2\nKnight, Mr. Robert J\nmale\n30.00\n0\n0\n239855\n0.0000\nNA\nS\ntrain\nMr.\nKnight,\nnk\nsingle\nsingle\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n742\n0\n1\nCavendish, Mr. Tyrell William\nmale\n36.00\n1\n0\n19877\n78.8500\nC46\nS\ntrain\nMr.\nCavendish,\nC\ngroup\ncouple\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n745\n1\n3\nStranden, Mr. Juho\nmale\n31.00\n0\n0\nSTON/O 2. 3101288\n7.9250\nNA\nS\ntrain\nMr.\nStranden,\nnk\nsingle\nsingle\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n754\n0\n3\nJonkoff, Mr. Lalio\nmale\n23.00\n0\n0\n349204\n7.8958\nNA\nS\ntrain\nMr.\nJonkoff,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n758\n0\n2\nBailey, Mr. Percy Andrew\nmale\n18.00\n0\n0\n29108\n11.5000\nNA\nS\ntrain\nMr.\nBailey,\nnk\nsingle\nsingle\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n763\n1\n3\nBarah, Mr. Hanna Assi\nmale\n20.00\n0\n0\n2663\n7.2292\nNA\nC\ntrain\nMr.\nBarah,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n764\n1\n1\nCarter, Mrs. William Ernest (Lucile Polk)\nfemale\n36.00\n1\n2\n113760\n120.0000\nB96 B98\nS\ntrain\nF_married\nCarter,\nB\ngroup\nfamily\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n767\n0\n1\nBrewe, Dr. Arthur Jackson\nmale\n49.00\n0\n0\n112379\n39.6000\nNA\nC\ntrain\nM_Professional\nBrewe,\nnk\nsingle\nsingle\n40s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n768\n0\n3\nMangan, Miss. Mary\nfemale\n30.50\n0\n0\n364850\n7.7500\nNA\nQ\ntrain\nF_unmarried\nMangan,\nnk\nsingle\nsingle\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n772\n0\n3\nJensen, Mr. Niels Peder\nmale\n48.00\n0\n0\n350047\n7.8542\nNA\nS\ntrain\nMr.\nJensen,\nnk\nsingle\nsingle\n40s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n780\n1\n1\nRobert, Mrs. Edward Scott (Elisabeth Walton McMillan)\nfemale\n43.00\n0\n1\n24160\n211.3375\nB3\nS\ntrain\nF_married\nRobert,\nB\ngroup\ncouple\n40s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n781\n1\n3\nAyoub, Miss. Banoura\nfemale\n13.00\n0\n0\n2687\n7.2292\nNA\nC\ntrain\nF_unmarried\nAyoub,\nnk\nsingle\nsingle\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n782\n1\n1\nDick, Mrs. Albert Adrian (Vera Gillespie)\nfemale\n17.00\n1\n0\n17474\n57.0000\nB20\nS\ntrain\nF_married\nDick,\nB\ncouple\ncouple\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n789\n1\n3\nDean, Master. Bertram Vere\nmale\n1.00\n1\n2\nC.A. 2315\n20.5750\nNA\nS\ntrain\nMaster.\nDean,\nnk\ngroup\nfamily\nchild\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n791\n0\n3\nKeane, Mr. Andrew “Andy”\nmale\n26.00\n0\n0\n12460\n7.7500\nNA\nQ\ntrain\nMr.\nKeane,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n792\n0\n2\nGaskell, Mr. Alfred\nmale\n16.00\n0\n0\n239865\n26.0000\nNA\nS\ntrain\nMr.\nGaskell,\nnk\ncouple\nsingle\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n793\n0\n3\nSage, Miss. Stella Anna\nfemale\n18.00\n8\n2\nCA. 2343\n69.5500\nNA\nS\ntrain\nF_unmarried\nSage,\nnk\ngroup\nfamily\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n796\n0\n2\nOtter, Mr. Richard\nmale\n39.00\n0\n0\n28213\n13.0000\nNA\nS\ntrain\nMr.\nOtter,\nnk\nsingle\nsingle\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n803\n1\n1\nCarter, Master. William Thornton II\nmale\n11.00\n1\n2\n113760\n120.0000\nB96 B98\nS\ntrain\nMaster.\nCarter,\nB\ngroup\nfamily\nchild\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n804\n1\n3\nThomas, Master. Assad Alexander\nmale\n0.42\n0\n1\n2625\n8.5167\nNA\nC\ntrain\nMaster.\nThomas,\nnk\ncouple\ncouple\nchild\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n809\n0\n2\nMeyer, Mr. August\nmale\n39.00\n0\n0\n248723\n13.0000\nNA\nS\ntrain\nMr.\nMeyer,\nnk\nsingle\nsingle\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n810\n1\n1\nChambers, Mrs. Norman Campbell (Bertha Griggs)\nfemale\n33.00\n1\n0\n113806\n53.1000\nE8\nS\ntrain\nF_married\nChambers,\nE\ncouple\ncouple\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n813\n0\n2\nSlemen, Mr. Richard James\nmale\n35.00\n0\n0\n28206\n10.5000\nNA\nS\ntrain\nMr.\nSlemen,\nnk\nsingle\nsingle\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n822\n1\n3\nLulic, Mr. Nikola\nmale\n27.00\n0\n0\n315098\n8.6625\nNA\nS\ntrain\nMr.\nLulic,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n823\n0\n1\nReuchlin, Jonkheer. John George\nmale\n38.00\n0\n0\n19972\n0.0000\nNA\nS\ntrain\nM_titled\nReuchlin,\nnk\nsingle\nsingle\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n828\n1\n2\nMallet, Master. Andre\nmale\n1.00\n0\n2\nS.C./PARIS 2079\n37.0042\nNA\nC\ntrain\nMaster.\nMallet,\nnk\ngroup\nfamily\nchild\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n829\n1\n3\nMcCormack, Mr. Thomas Joseph\nmale\n26.00\n0\n0\n367228\n7.7500\nNA\nQ\ntrain\nMr.\nMcCormack,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n830\n1\n1\nStone, Mrs. George Nelson (Martha Evelyn)\nfemale\n62.00\n0\n0\n113572\n80.0000\nB28\nS\ntrain\nF_married\nStone,\nB\ncouple\nsingle\n60+\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n835\n0\n3\nAllum, Mr. Owen George\nmale\n18.00\n0\n0\n2223\n8.3000\nNA\nS\ntrain\nMr.\nAllum,\nnk\nsingle\nsingle\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n838\n0\n3\nSirota, Mr. Maurice\nmale\n26.00\n0\n0\n392092\n8.0500\nNA\nS\ntrain\nMr.\nSirota,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n840\n1\n1\nMarechal, Mr. Pierre\nmale\n41.50\n0\n0\n11774\n29.7000\nC47\nC\ntrain\nMr.\nMarechal,\nC\nsingle\nsingle\n40s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n841\n0\n3\nAlhomaki, Mr. Ilmari Rudolf\nmale\n20.00\n0\n0\nSOTON/O2 3101287\n7.9250\nNA\nS\ntrain\nMr.\nAlhomaki,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n842\n0\n2\nMudd, Mr. Thomas Charles\nmale\n16.00\n0\n0\nS.O./P.P. 3\n10.5000\nNA\nS\ntrain\nMr.\nMudd,\nnk\ncouple\nsingle\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n843\n1\n1\nSerepeca, Miss. Augusta\nfemale\n30.00\n0\n0\n113798\n31.0000\nNA\nC\ntrain\nF_unmarried\nSerepeca,\nnk\ncouple\nsingle\n30s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n851\n0\n3\nAndersson, Master. Sigvard Harald Elias\nmale\n4.00\n4\n2\n347082\n31.2750\nNA\nS\ntrain\nMaster.\nAndersson,\nnk\ngroup\nfamily\nchild\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n853\n0\n3\nBoulos, Miss. Nourelain\nfemale\n9.00\n1\n1\n2678\n15.2458\nNA\nC\ntrain\nF_unmarried\nBoulos,\nnk\ngroup\nfamily\nchild\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n856\n1\n3\nAks, Mrs. Sam (Leah Rosen)\nfemale\n18.00\n0\n1\n392091\n9.3500\nNA\nS\ntrain\nF_married\nAks,\nnk\ncouple\ncouple\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n867\n1\n2\nDuran y More, Miss. Asuncion\nfemale\n27.00\n1\n0\nSC/PARIS 2149\n13.8583\nNA\nC\ntrain\nF_unmarried\nMore,\nnk\nsingle\ncouple\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n872\n1\n1\nBeckwith, Mrs. Richard Leonard (Sallie Monypeny)\nfemale\n47.00\n1\n1\n11751\n52.5542\nD35\nS\ntrain\nF_married\nBeckwith,\nD\ncouple\nfamily\n40s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n874\n0\n3\nVander Cruyssen, Mr. Victor\nmale\n47.00\n0\n0\n345765\n9.0000\nNA\nS\ntrain\nMr.\nCruyssen,\nnk\nsingle\nsingle\n40s\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n876\n1\n3\nNajib, Miss. Adele Kiamie “Jane”\nfemale\n15.00\n0\n0\n2667\n7.2250\nNA\nC\ntrain\nF_unmarried\nNajib,\nnk\nsingle\nsingle\nteen\nensemble\n\n\nNA\nNA\nNA\nNA\n1\nNA\nNA\n883\n0\n3\nDahlberg, Miss. Gerda Ulrika\nfemale\n22.00\n0\n0\n7552\n10.5167\nNA\nS\ntrain\nF_unmarried\nDahlberg,\nnk\nsingle\nsingle\n20s\nensemble\n\n\nNA\nNA\nNA\nNA\n0\nNA\nNA\n885\n0\n3\nSutehall, Mr. Henry Jr\nmale\n25.00\n0\n0\nSOTON/OQ 392076\n7.0500\nNA\nS\ntrain\nMr.\nSutehall,\nnk\nsingle\nsingle\n20s\nensemble"
  },
  {
    "objectID": "posts/post-with-code/index.html#all-metrics",
    "href": "posts/post-with-code/index.html#all-metrics",
    "title": "Titanic from Kaggle",
    "section": "0.12 All Metrics",
    "text": "0.12 All Metrics\nOrdered by descending Accuracy metric\n\n\nCode\nall_metrics <- \n  lr_final_metrics %>% mutate(model = \"LR\") %>% \n  bind_rows(nnet_final_metrics %>% mutate(model = \"NNet\")) %>% \n  bind_rows(rlr_final_metrics %>% mutate(model = \"Reg_LR\")) %>% \n  bind_rows(rf_final_metrics %>% mutate(model = \"RF\")) %>% \n  bind_rows(xgb_final_metrics %>% mutate(model = \"xgb\")) %>% \n  bind_rows(xgb_usemodel_final_metrics %>% mutate(model = \"xgb-usemodel\")) \n\nall_metrics_table <- all_metrics %>% \n   pivot_wider(names_from = .metric,values_from = .estimate) %>% \n   arrange(desc(accuracy))\n  \nwrite_rds(all_metrics,\"artifacts/all_metrics.rds\")\n\nall_metrics_table %>% knitr::kable(digits=3)\n\n\n\n\n\n.estimator\n.config\nmodel\naccuracy\nroc_auc\n\n\n\n\nbinary\nPreprocessor1_Model1\nRF\n0.821\n0.847\n\n\nbinary\nPreprocessor1_Model1\nLR\n0.799\n0.829\n\n\nbinary\nPreprocessor1_Model1\nNNet\n0.799\n0.830\n\n\nbinary\nPreprocessor1_Model1\nReg_LR\n0.795\n0.835\n\n\nbinary\nPreprocessor1_Model1\nxgb\n0.786\n0.840\n\n\nbinary\nPreprocessor1_Model1\nxgb-usemodel\n0.777\n0.817\n\n\n\n\n\nand a graph:\n\n\nCode\nall_metrics %>% \n  filter(.metric == \"accuracy\") %>% \n  select(model, accuracy = .estimate) %>% \n  ggplot(aes(model, accuracy)) +\n  geom_col()"
  },
  {
    "objectID": "posts/post-with-code/index.html#ensemble---workflow-sets---not-working",
    "href": "posts/post-with-code/index.html#ensemble---workflow-sets---not-working",
    "title": "Titanic from Kaggle",
    "section": "0.13 Ensemble - Workflow Sets - not working",
    "text": "0.13 Ensemble - Workflow Sets - not working\n\n\nCode\n# no_pre_proc <- \n#    workflow_set(\n#       preproc = list(base = recipe_base), \n#       models = list(RF             = lr_model, \n#                     Regularised_LR = rlr_model, \n#                     Rand_Forest    = rf_model, \n#                     boosting       = xgb_model),\n#       cross = TRUE\n#    )\n# no_pre_proc\n# \n# add_cand"
  },
  {
    "objectID": "posts/post-with-code/index.html#predict-on-test-set",
    "href": "posts/post-with-code/index.html#predict-on-test-set",
    "title": "Titanic from Kaggle",
    "section": "1.1 Predict on Test set",
    "text": "1.1 Predict on Test set\n\n\nCode\nall_predictions %>% \ndistinct(model)\n\n\n# A tibble: 7 × 1\n  model       \n  <chr>       \n1 LR          \n2 NNet        \n3 Reg_LR      \n4 RF          \n5 xgb         \n6 xgb_usemodel\n7 ensemble    \n\n\nCode\nglimpse(all_predictions)\n\n\nRows: 1,568\nColumns: 27\n$ id            <chr> \"train/test split\", \"train/test split\", \"train/test spli…\n$ .pred_0       <dbl> 0.96088114, 0.07263566, 0.27277953, 0.92457275, 0.296003…\n$ .pred_1       <dbl> 0.03911886, 0.92736434, 0.72722047, 0.07542725, 0.703996…\n$ .row          <int> 1, 4, 12, 13, 15, 20, 21, 25, 26, 28, 30, 35, 36, 37, 38…\n$ .pred_class   <fct> 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ survived_pred <fct> 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,…\n$ .config       <chr> \"Preprocessor1_Model1\", \"Preprocessor1_Model1\", \"Preproc…\n$ passenger_id  <dbl> 1, 4, 12, 13, 15, 20, 21, 25, 26, 28, 30, 35, 36, 37, 38…\n$ survived      <fct> 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,…\n$ pclass        <fct> 3, 1, 1, 3, 3, 3, 2, 3, 3, 1, 3, 1, 1, 3, 3, 3, 3, 1, 3,…\n$ name          <fct> \"Braund, Mr. Owen Harris\", \"Futrelle, Mrs. Jacques Heath…\n$ sex           <fct> male, female, female, male, female, female, male, female…\n$ age           <dbl> 22, 35, 58, 20, 14, 31, 35, 8, 38, 19, 26, 28, 42, 26, 2…\n$ sib_sp        <dbl> 1, 1, 0, 0, 0, 0, 0, 3, 1, 3, 0, 1, 1, 0, 0, 0, 4, 0, 0,…\n$ parch         <dbl> 0, 0, 0, 0, 0, 0, 0, 1, 5, 2, 0, 0, 0, 0, 0, 0, 1, 1, 0,…\n$ ticket        <fct> A/5 21171, 113803, 113783, A/5. 2151, 350406, 2649, 2398…\n$ fare          <dbl> 7.2500, 53.1000, 26.5500, 8.0500, 7.8542, 7.2250, 26.000…\n$ cabin         <fct> NA, C123, C103, NA, NA, NA, NA, NA, NA, C23 C25 C27, NA,…\n$ embarked      <fct> S, S, S, S, S, C, S, S, S, S, S, C, S, C, S, S, S, C, C,…\n$ train_test    <fct> train, train, train, train, train, train, train, train, …\n$ pax_type      <fct> Mr., F_married, F_unmarried, Mr., F_unmarried, F_married…\n$ surname       <fct> \"Braund,\", \"Futrelle,\", \"Bonnell,\", \"Saundercock,\", \"Ves…\n$ cabin_preface <fct> nk, C, C, nk, nk, nk, nk, nk, nk, C, nk, nk, nk, nk, nk,…\n$ ticket_group  <fct> single, couple, single, single, single, single, couple, …\n$ family_group  <ord> couple, couple, single, single, single, single, single, …\n$ age_group     <ord> 20s, 30s, 50s, 20s, teen, 30s, 30s, child, 30s, teen, 20…\n$ model         <chr> \"LR\", \"LR\", \"LR\", \"LR\", \"LR\", \"LR\", \"LR\", \"LR\", \"LR\", \"L…\n\n\nCode\ntest_proc <- all_proc %>% \n  filter(train_test==\"test\")\n\ntest_predictions <- \n  predict(ensemble,test_proc) %>% \n  bind_cols(test) %>% \n  select(PassengerID = passenger_id,Survived = .pred_class)\n\nglimpse(test_predictions)\n\n\nRows: 418\nColumns: 2\n$ PassengerID <dbl> 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903…\n$ Survived    <fct> 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1…"
  },
  {
    "objectID": "posts/post-with-code/index.html#write-submission-file",
    "href": "posts/post-with-code/index.html#write-submission-file",
    "title": "Titanic from Kaggle",
    "section": "1.2 Write Submission File",
    "text": "1.2 Write Submission File\n\n\nCode\nwrite_csv(test_predictions,\"titanic_submission_xgb.csv\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#stack-models",
    "href": "posts/post-with-code/index.html#stack-models",
    "title": "Titanic from Kaggle",
    "section": "0.10 Stack Models",
    "text": "0.10 Stack Models\n\n0.10.1 Stack Recipe\n\n\nCode\nrecipe_stack <- \n  recipe(survived ~ ., data = train_train) %>% \n  update_role(passenger_id, name,surname,ticket,cabin,new_role = \"ID\") %>% \n  step_impute_knn(all_numeric_predictors()) %>% \n  step_dummy(all_nominal_predictors()) %>%\n  step_factor2string(all_nominal_predictors()) %>% \n  step_zv(all_predictors()) %>% \n  step_pca()\nrecipe_stack\n\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          5\n   outcome          1\n predictor         13\n\nOperations:\n\nK-nearest neighbor imputation for all_numeric_predictors()\nDummy variables from all_nominal_predictors()\nCharacter variables from all_nominal_predictors()\nZero variance filter on all_predictors()\nPCA extraction with <none>\n\n\nCode\nrecipe_stack_trained <- prep(recipe_base)\nrecipe_stack_trained\n\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          5\n   outcome          1\n predictor         13\n\nTraining data contained 667 data points and 513 incomplete rows. \n\nOperations:\n\nK-nearest neighbor imputation for age, sib_sp, parch, fare [trained]\nDummy variables from pclass, sex, embarked, train_test, pax_type, cabin_prefac... [trained]\nCharacter variables from <none> [trained]\nZero variance filter removed train_test_test [trained]\nNo PCA components were extracted from <none> [trained]\n\n\n\n\n0.10.2 Stack Controls\n\n\nCode\nstack_ctrl <- control_resamples(save_pred = TRUE, save_workflow = TRUE)\n#stack_folds <- vfold_cv(training(train_split), v=10,strata = \"survived\")\n\nlibrary(stacks)\n\n\nWarning: package 'stacks' was built under R version 4.2.1\n\n\nCode\nmodel_stack <-\n  stacks() %>%\n  #add_candidates(lr_wflow) %>%\n  #add_candidates(rf_wflow) %>%\n  add_candidates(nnet_tuning_result) %>%\n  add_candidates(rlr_tuning_result) %>% \n  add_candidates(xgb_tuning_result)\n\n\nWarning: Predictions from 5 candidates were identical to those from existing\ncandidates and were removed from the data stack.\n\n\n\n\n0.10.3 Stack Blend\n\n\nCode\nset.seed(123)\nensemble <- blend_predictions(model_stack,penalty = 10^seq(-2, -0.5, length = 20))\nautoplot(ensemble)\n\n\n\n\n\n\n\nCode\nensemble \n\n\n── A stacked ensemble model ─────────────────────────────────────\n\nOut of 60 possible candidate members, the ensemble retained 2.\nPenalty: 0.183298071083244.\nMixture: 1.\n\nThe 2 highest weighted member classes are:\n\n\n# A tibble: 2 × 3\n  member                         type         weight\n  <chr>                          <chr>         <dbl>\n1 .pred_1_rlr_tuning_result_1_28 logistic_reg 2.03  \n2 .pred_1_xgb_tuning_result_1_04 boost_tree   0.0339\n\n\n\nMembers have not yet been fitted with `fit_members()`.\n\n\n\n\n0.10.4 Stack Weights\n\n\nCode\nautoplot(ensemble, \"weights\") +\n  geom_text(aes(x = weight + 0.01, label = model), hjust = 0) + \n  theme(legend.position = \"none\") \n\n\n\n\n\n\n\n0.10.5 Fit Member Models\n\n\nCode\nensemble <- fit_members(ensemble)\ncollect_parameters(ensemble,\"xgb_tuning_result\")\n\n\n# A tibble: 27 × 10\n   member         mtry trees min_n tree_…¹ learn…² loss_r…³ sampl…⁴ terms   coef\n   <chr>         <int> <int> <int>   <int>   <dbl>    <dbl>   <dbl> <chr>  <dbl>\n 1 xgb_tuning_r…     6  1202     4       2 4.27e-7 9.25e- 4   0.944 .pre… 0     \n 2 xgb_tuning_r…     4   559    39       2 7.47e-3 5.95e+ 0   0.410 .pre… 0     \n 3 xgb_tuning_r…    18  1107     3       3 3.83e-3 1.10e- 4   0.492 .pre… 0.0339\n 4 xgb_tuning_r…    13   655    10       3 1.32e-8 3.12e- 4   0.523 .pre… 0     \n 5 xgb_tuning_r…    12  1039    16       4 1.63e-2 2.34e- 2   0.986 .pre… 0     \n 6 xgb_tuning_r…     5  1454    18       4 6.86e-8 2.40e- 7   0.328 .pre… 0     \n 7 xgb_tuning_r…     1  1357    21       4 1.48e-5 6.11e-10   0.909 .pre… 0     \n 8 xgb_tuning_r…    16   697    36       5 1.03e-4 4.74e- 7   0.454 .pre… 0     \n 9 xgb_tuning_r…     3  1814     5       6 5.67e-6 3.81e- 6   0.913 .pre… 0     \n10 xgb_tuning_r…     5   795    30       6 1.47e-9 7.54e- 4   0.573 .pre… 0     \n# … with 17 more rows, and abbreviated variable names ¹​tree_depth, ²​learn_rate,\n#   ³​loss_reduction, ⁴​sample_size\n\n\n\n\n0.10.6 Stack Predict\n\n\nCode\n#ensemble_metrics <- metric_set(roc_auc,accuracy)\n\nensemble_test_predictions <- \n  predict(ensemble,train_test) %>% \n  bind_cols(train_test) \n\n\n# ensemble_test_predictions <- ensemble_test_predictions %>% \n#   mutate(.pred_class=as.numeric(.pred_class)) %>% \n#    mutate(survived =as.numeric(survived)) \n# \n# ensemble_test_predictions <- ensemble_test_predictions %>% \n#   mutate(roc = roc_auc(truth=survived, estimate = .pred_class))\n\n\n\nglimpse(ensemble_test_predictions)\n\n\nRows: 224\nColumns: 20\n$ .pred_class   <fct> 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ passenger_id  <dbl> 1, 4, 12, 13, 15, 20, 21, 25, 26, 28, 30, 35, 36, 37, 38…\n$ survived      <fct> 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,…\n$ pclass        <fct> 3, 1, 1, 3, 3, 3, 2, 3, 3, 1, 3, 1, 1, 3, 3, 3, 3, 1, 3,…\n$ name          <fct> \"Braund, Mr. Owen Harris\", \"Futrelle, Mrs. Jacques Heath…\n$ sex           <fct> male, female, female, male, female, female, male, female…\n$ age           <dbl> 22, 35, 58, 20, 14, 31, 35, 8, 38, 19, 26, 28, 42, 26, 2…\n$ sib_sp        <dbl> 1, 1, 0, 0, 0, 0, 0, 3, 1, 3, 0, 1, 1, 0, 0, 0, 4, 0, 0,…\n$ parch         <dbl> 0, 0, 0, 0, 0, 0, 0, 1, 5, 2, 0, 0, 0, 0, 0, 0, 1, 1, 0,…\n$ ticket        <fct> A/5 21171, 113803, 113783, A/5. 2151, 350406, 2649, 2398…\n$ fare          <dbl> 7.2500, 53.1000, 26.5500, 8.0500, 7.8542, 7.2250, 26.000…\n$ cabin         <fct> NA, C123, C103, NA, NA, NA, NA, NA, NA, C23 C25 C27, NA,…\n$ embarked      <fct> S, S, S, S, S, C, S, S, S, S, S, C, S, C, S, S, S, C, C,…\n$ train_test    <fct> train, train, train, train, train, train, train, train, …\n$ pax_type      <fct> Mr., F_married, F_unmarried, Mr., F_unmarried, F_married…\n$ surname       <fct> \"Braund,\", \"Futrelle,\", \"Bonnell,\", \"Saundercock,\", \"Ves…\n$ cabin_preface <fct> nk, C, C, nk, nk, nk, nk, nk, nk, C, nk, nk, nk, nk, nk,…\n$ ticket_group  <fct> single, couple, single, single, single, single, couple, …\n$ family_group  <ord> couple, couple, single, single, single, single, single, …\n$ age_group     <ord> 20s, 30s, 50s, 20s, teen, 30s, 30s, child, 30s, teen, 20…"
  }
]