[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Notes Index",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\ntitanic\n\n\n\n\n\n\n\n\n\n\n\nSep 1, 2022\n\n\nStephen Parton\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nAug 29, 2022\n\n\nStephen Parton\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/model-01-logistic_regression/index.html#summary",
    "href": "posts/model-01-logistic_regression/index.html#summary",
    "title": "Titanic Logistic Regression",
    "section": "Summary",
    "text": "Summary\nThis analysis looks at the previously processed Titanic analysis, using logistic regression."
  },
  {
    "objectID": "posts/model-01-logistic_regression/index.html#load-some-pre-prepared-kaggle-data",
    "href": "posts/model-01-logistic_regression/index.html#load-some-pre-prepared-kaggle-data",
    "title": "Titanic Logistic Regression",
    "section": "Load Some Pre-prepared Kaggle Data",
    "text": "Load Some Pre-prepared Kaggle Data\n\n\nCode\n#getwd()\n\nall_proc <- read_rds(\"../../posts/post-with-code/artifacts/all_proc.rds\")\ntrain_split <- read_rds(\"../../posts/post-with-code/artifacts/train_split.rds\")\nrecipe_base <- read_rds(\"../../posts/post-with-code/artifacts/recipe_base.rds\")"
  },
  {
    "objectID": "posts/model-01-logistic_regression/index.html#models",
    "href": "posts/model-01-logistic_regression/index.html#models",
    "title": "Titanic Logistic Regression",
    "section": "Models",
    "text": "Models\n\nLogistic Regression- GLM\n\nLR Model Spec\n\n\nCode\nlr_spec <-  \n  logistic_reg() %>% \n  set_engine(\"glm\")\n\nlr_spec\n\n\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\n\nLR Workflow\n\n\nCode\nlr_wflow <- \n  workflow() %>% \n  add_model(lr_spec) %>% \n  add_recipe(recipe_base)\n\nlr_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\n\nLR Fit Model\n\n\nCode\nlr_fit <- \n  lr_wflow %>% \n  last_fit(train_split)\n\n#lr_fit\n\nlr_final_metrics <- lr_fit %>% collect_metrics()\nlr_final_metrics \n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.835 Preprocessor1_Model1\n2 roc_auc  binary         0.867 Preprocessor1_Model1\n\n\nCode\n#show_notes(.Last.tune.result)\n\n\n\n\nLR Predict\n\n\nCode\nlr_test_predictions <- lr_fit %>% collect_predictions()\nlr_test_predictions\n\n\n# A tibble: 224 × 7\n   id               .pred_0 .pred_1  .row .pred_class survived .config          \n   <chr>              <dbl>   <dbl> <int> <fct>       <fct>    <chr>            \n 1 train/test split  0.346   0.654      3 1           1        Preprocessor1_Mo…\n 2 train/test split  0.0685  0.931      4 1           1        Preprocessor1_Mo…\n 3 train/test split  0.920   0.0802     5 0           0        Preprocessor1_Mo…\n 4 train/test split  0.569   0.431     11 0           1        Preprocessor1_Mo…\n 5 train/test split  0.622   0.378     31 0           0        Preprocessor1_Mo…\n 6 train/test split  0.277   0.723     33 1           1        Preprocessor1_Mo…\n 7 train/test split  0.670   0.330     35 0           0        Preprocessor1_Mo…\n 8 train/test split  0.811   0.189     36 0           0        Preprocessor1_Mo…\n 9 train/test split  0.902   0.0975    37 0           1        Preprocessor1_Mo…\n10 train/test split  0.554   0.446     39 0           0        Preprocessor1_Mo…\n# … with 214 more rows\n\n\n\n\nLR Performance on validation set\n\nAUC Curve\n\n\nCode\nlr_test_predictions %>% \n  roc_curve(truth = survived,.pred_1,event_level=\"second\") %>% \n  autoplot()\n\n\n\n\n\n\n\nConfusion Matrix\n\n\nCode\nlr_test_predictions %>% \n  conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")\n\n\n\n\n\n\n\n\nLR Resampling\n\n\nCode\nfolds <- vfold_cv(training(train_split), strata = survived, v=10)\n#folds\n\ncontrol <- control_resamples(save_pred = TRUE)\n\nlr_fit_cv <- \n  lr_wflow %>% \n  fit_resamples(folds, control = control)\n\n#show_best(lr_fit_cv,metric= \"accuracy\")\n\n#lr_fit_cv\nlr_metrics_resample <- collect_metrics(lr_fit_cv)\nlr_metrics_resample\n\n\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy binary     0.811    10  0.0130 Preprocessor1_Model1\n2 roc_auc  binary     0.854    10  0.0125 Preprocessor1_Model1"
  },
  {
    "objectID": "posts/post-with-code/index.html#summary",
    "href": "posts/post-with-code/index.html#summary",
    "title": "Titanic from Kaggle",
    "section": "0.1 Summary",
    "text": "0.1 Summary\nThis is just a first test with code in a blog using the new Quarto framework! Guess what I am using.."
  },
  {
    "objectID": "posts/post-with-code/index.html#load-some-kaggle-data",
    "href": "posts/post-with-code/index.html#load-some-kaggle-data",
    "title": "Titanic from Kaggle",
    "section": "2 Load Some Kaggle Data",
    "text": "2 Load Some Kaggle Data\nNot the…? Yes, the Titanic again….\n\n\nCode\ntrain <- read_csv(\"data_raw/train.csv\",show_col_types = FALSE) %>% clean_names() %>% mutate(train_test = \"train\")\ntest <- read_csv(\"data_raw/test.csv\",show_col_types = FALSE) %>% clean_names() %>% \n  mutate(train_test = \"test\")\nall <- train %>% bind_rows(test)\n\n# colnames(data)\n# cwd()"
  },
  {
    "objectID": "posts/post-with-code/index.html#some-initial-eda",
    "href": "posts/post-with-code/index.html#some-initial-eda",
    "title": "Titanic from Kaggle",
    "section": "3 Some Initial EDA",
    "text": "3 Some Initial EDA\nA quick look.\n\n\nCode\ntrain %>% skim() \n\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n891\n\n\nNumber of columns\n13\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nname\n0\n1.00\n12\n82\n0\n891\n0\n\n\nsex\n0\n1.00\n4\n6\n0\n2\n0\n\n\nticket\n0\n1.00\n3\n18\n0\n681\n0\n\n\ncabin\n687\n0.23\n1\n15\n0\n147\n0\n\n\nembarked\n2\n1.00\n1\n1\n0\n3\n0\n\n\ntrain_test\n0\n1.00\n5\n5\n0\n1\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\npassenger_id\n0\n1.0\n446.00\n257.35\n1.00\n223.50\n446.00\n668.5\n891.00\n▇▇▇▇▇\n\n\nsurvived\n0\n1.0\n0.38\n0.49\n0.00\n0.00\n0.00\n1.0\n1.00\n▇▁▁▁▅\n\n\npclass\n0\n1.0\n2.31\n0.84\n1.00\n2.00\n3.00\n3.0\n3.00\n▃▁▃▁▇\n\n\nage\n177\n0.8\n29.70\n14.53\n0.42\n20.12\n28.00\n38.0\n80.00\n▂▇▅▂▁\n\n\nsib_sp\n0\n1.0\n0.52\n1.10\n0.00\n0.00\n0.00\n1.0\n8.00\n▇▁▁▁▁\n\n\nparch\n0\n1.0\n0.38\n0.81\n0.00\n0.00\n0.00\n0.0\n6.00\n▇▁▁▁▁\n\n\nfare\n0\n1.0\n32.20\n49.69\n0.00\n7.91\n14.45\n31.0\n512.33\n▇▁▁▁▁"
  },
  {
    "objectID": "posts/post-with-code/index.html#some-initial-wrangling",
    "href": "posts/post-with-code/index.html#some-initial-wrangling",
    "title": "Titanic from Kaggle",
    "section": "4 Some Initial Wrangling",
    "text": "4 Some Initial Wrangling\n\n\nCode\nall_proc <- all %>% \n  mutate(title = str_extract(name,\"(\\\\w)([a-z]+)(\\\\.)\")) %>% \n  mutate(pax_type = case_when(\n    title %in% c(\"Miss.\",\"Ms.\",\"Mlle.\")         ~ \"F_unmarried\",\n    title %in% c(\"Mme.\",\"Mrs.\")                 ~ \"F_married\",\n    title %in% c(\"Countess.\",\"Lady.\",\"Dona.\")   ~ \"F_titled\",\n    title %in% c(\"Capt.\",\"Col.\",\"Major.\")       ~ \"Military\",\n    title %in% c(\"Dr.\",\"Rev.\")                  ~ \"M_Professional\",\n    title %in% c(\"Don.\",\"Jonkheer.\",\"Sir.\")     ~ \"M_titled\",\n    TRUE ~ title\n  ),\n  surname        = str_extract(name,\"(\\\\w+)(\\\\,)\"),\n  survival       = ifelse(survived==0,\"No\",\"Yes\"),\n  ticket_preface = str_extract(ticket,\"([:graph:]+)(\\\\s)\"),\n  ticket_preface = ifelse(is.na(ticket_preface),\"none\",ticket_preface),\n  cabin_preface  = ifelse(is.na(cabin),\"nk\",\n                    substr(cabin,1,1)),\n  embarked       = ifelse(is.na(embarked),\"S\",embarked)\n  ) %>% \n  group_by(pax_type,pclass) %>% \n  mutate(age     = ifelse(is.na(age),median(age,na.rm = T), age)) %>% \n  ungroup() %>% \n  add_count(ticket,name = \"ticket_group\") %>% \n  mutate(ticket_group = case_when(\n    ticket_group == 1 ~ \"single\",\n    ticket_group == 2 ~ \"couple\",\n    TRUE              ~ \"group\"\n  ),\n    family_group = as.numeric(sib_sp)+as.numeric(parch)+1\n  ) %>% \n  mutate(family_group = factor(\n    case_when(\n        family_group < 2  ~ \"single\",\n        family_group < 3  ~ \"couple\",\n        TRUE              ~ \"family\"\n        ),\n    ordered = TRUE)\n  ) %>% \n  mutate(age_group = factor(case_when(\n    age < 13      ~ \"child\",\n    age < 20      ~ \"teen\",\n    age < 30      ~ \"20s\",\n    age < 40      ~ \"30s\",\n    age < 50      ~ \"40s\",\n    age < 60      ~ \"50s\",\n    TRUE          ~ \"60+\"\n    \n  ),\n  ordered = TRUE)\n  ) %>% \n  mutate(across(where(is.character),as_factor)) %>% \n  mutate(pclass = factor(pclass,levels = c(\"1\",\"2\",\"3\")),\n         survived = factor(survived)\n         ) %>% \nselect(-c(title,ticket_preface))\n  \n#all_proc %>% glimpse()"
  },
  {
    "objectID": "posts/post-with-code/index.html#a-bit-more-eda",
    "href": "posts/post-with-code/index.html#a-bit-more-eda",
    "title": "Titanic from Kaggle",
    "section": "5 A bit more EDA",
    "text": "5 A bit more EDA\n\n\nCode\nall_proc %>% \n  select(-c(name,ticket,cabin,surname,train_test)) %>% \n  DataExplorer::plot_bar()\n\n\n\n\n\n\n\n\n\n\nCode\nall_proc %>% DataExplorer::plot_histogram(ggtheme = theme_light() )"
  },
  {
    "objectID": "posts/post-with-code/index.html#eyeballing-survival-graphs-on-training-data",
    "href": "posts/post-with-code/index.html#eyeballing-survival-graphs-on-training-data",
    "title": "Titanic from Kaggle",
    "section": "6 Eyeballing Survival Graphs on Training Data",
    "text": "6 Eyeballing Survival Graphs on Training Data\n\n\nCode\nno_f <- all_proc %>%\n  filter(train_test == \"train\") %>% \n  select(passenger_id,pclass,sex,embarked,pax_type,ticket_group,family_group,age_group,cabin_preface,survival) %>% \n  droplevels() %>%\n  mutate(across(where(is.factor),~ factor(.x,ordered = FALSE))) %>%\n  pivot_longer(cols = c(pclass:cabin_preface)) \n\n\ng_l <- no_f %>% \n  split(.$name) %>% \n  map(~ ggplot(.,aes(y=value,fill=survival)) +\n                geom_bar() +\n              ggtitle(.$name) +\n        theme_bw() +\n        labs(x=NULL,y=NULL)+\n        scale_fill_viridis_d(option = \"cividis\")\n      \n            ) \n\nlibrary(patchwork)\nwrap_plots(g_l, ncol = 2)"
  },
  {
    "objectID": "posts/post-with-code/index.html#split-data-back-to-traintestvalidation",
    "href": "posts/post-with-code/index.html#split-data-back-to-traintestvalidation",
    "title": "Titanic from Kaggle",
    "section": "7 Split Data back to Train/Test/Validation",
    "text": "7 Split Data back to Train/Test/Validation\n\n\nCode\ntrain_proc_adj_tbl <- all_proc %>% \n  filter(train_test ==\"train\") %>% \n  select(-c(survival))\n  \ntrain_split <- initial_split(train_proc_adj_tbl,strata = survived)"
  },
  {
    "objectID": "posts/post-with-code/index.html#recipe-base",
    "href": "posts/post-with-code/index.html#recipe-base",
    "title": "Titanic from Kaggle",
    "section": "0.3 Recipe-Base",
    "text": "0.3 Recipe-Base\n\n\nCode\nrecipe_base <- \n  recipe(survived ~ ., data = training(train_split)) %>% \n  update_role(passenger_id, name,surname,ticket,cabin,new_role = \"ID\") %>%\n  step_impute_knn(all_numeric_predictors()) %>% \n  step_dummy(all_nominal_predictors()) %>%\n  step_factor2string(all_nominal_predictors()) %>% \n  step_zv(all_predictors()) %>% \n  step_pca()\nrecipe_base\n\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          5\n   outcome          1\n predictor         13\n\nOperations:\n\nK-nearest neighbor imputation for all_numeric_predictors()\nDummy variables from all_nominal_predictors()\nCharacter variables from all_nominal_predictors()\nZero variance filter on all_predictors()\nPCA extraction with <none>\n\n\n\n0.3.1 Save Files\n\n\nCode\n# write_rds(all_proc,\"artifacts/all_proc.rds\")\n# write_rds(train_split,\"artifacts/train_split.rds\")\n# write_rds(recipe_base,\"artifacts/recipe_base.rds\")\n# \n# all_proc <- read_rds(\"artifacts/all_proc.rds\")\n# train_split <- read_rds(\"artifacts/train_split.rds\")\n# recipe_base <- read_rds(\"artifacts/recipe_base.rds\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#save-files",
    "href": "posts/post-with-code/index.html#save-files",
    "title": "Titanic from Kaggle",
    "section": "9 Save Files",
    "text": "9 Save Files\n\n\nCode\nwrite_rds(all_proc,\"artifacts/all_proc.rds\")\nwrite_rds(train_split,\"artifacts/train_split.rds\")\nwrite_rds(recipe_base,\"artifacts/recipe_base.rds\")\n\nall_proc <- read_rds(\"artifacts/all_proc.rds\")\ntrain_split <- read_rds(\"artifacts/train_split.rds\")\nrecipe_base <- read_rds(\"artifacts/recipe_base.rds\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#models",
    "href": "posts/post-with-code/index.html#models",
    "title": "Titanic from Kaggle",
    "section": "0.4 Models",
    "text": "0.4 Models\n\n0.4.1 Logistic Regression\n\nLR Model Spec\n\n\nCode\nlr_spec <-  \n  logistic_reg() %>% \n  set_engine(\"glm\")\n\nlr_spec\n\n\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\n\nLR Workflow\n\n\nCode\nlr_wflow <- \n  workflow() %>% \n  add_model(lr_spec) %>% \n  add_recipe(recipe_base)\n\nlr_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\n\nLR Fit Model\n\n\nCode\nlr_fit <- \n  lr_wflow %>% \n  last_fit(train_split)\n\n#lr_fit\n\nlr_final_metrics <- lr_fit %>% collect_metrics()\nlr_final_metrics \n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.826 Preprocessor1_Model1\n2 roc_auc  binary         0.859 Preprocessor1_Model1\n\n\nCode\n#show_notes(.Last.tune.result)\n\n\n\n\nLR Predict\n\n\nCode\nlr_test_predictions <- lr_fit %>% collect_predictions()\nlr_test_predictions\n\n\n# A tibble: 224 × 7\n   id               .pred_0 .pred_1  .row .pred_class survived .config          \n   <chr>              <dbl>   <dbl> <int> <fct>       <fct>    <chr>            \n 1 train/test split   0.925 0.0754      5 0           0        Preprocessor1_Mo…\n 2 train/test split   0.196 0.804       9 1           1        Preprocessor1_Mo…\n 3 train/test split   0.999 0.00118    14 0           0        Preprocessor1_Mo…\n 4 train/test split   0.390 0.610      15 1           0        Preprocessor1_Mo…\n 5 train/test split   0.290 0.710      23 1           1        Preprocessor1_Mo…\n 6 train/test split   0.942 0.0579     26 0           1        Preprocessor1_Mo…\n 7 train/test split   0.967 0.0325     28 0           0        Preprocessor1_Mo…\n 8 train/test split   0.904 0.0960     37 0           1        Preprocessor1_Mo…\n 9 train/test split   0.910 0.0903     38 0           0        Preprocessor1_Mo…\n10 train/test split   0.529 0.471      39 0           0        Preprocessor1_Mo…\n# … with 214 more rows\n\n\n\n\nLR Performance on validation set\n\nAUC Curve\n\n\nCode\nlr_test_predictions %>% \n  roc_curve(truth = survived,.pred_1,event_level=\"second\") %>% \n  autoplot()\n\n\n\n\n\n\n\nConfusion Matrix\n\n\nCode\nlr_test_predictions %>% \n  conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")\n\n\n\n\n\n\n\n\nLR Resampling\n\n\nCode\nfolds <- vfold_cv(training(train_split), strata = survived, v=5)\n#folds\n\ncontrol <- control_resamples(save_pred = TRUE,save_workflow = TRUE)\n\ncores <- parallel::detectCores()\nset.seed(1234)\ndoParallel::registerDoParallel(cores = cores)\n\nlr_fit_cv <- \n  lr_wflow %>% \n  fit_resamples(folds, control = control)\n\n#show_best(lr_fit_cv,metric= \"accuracy\")\n\n#lr_fit_cv\nlr_metrics_resample <- collect_metrics(lr_fit_cv)\nlr_metrics_resample\n\n\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy binary     0.807     5  0.0227 Preprocessor1_Model1\n2 roc_auc  binary     0.856     5  0.0169 Preprocessor1_Model1\n\n\n\n\nCode\nlr_assess_res <- collect_predictions(lr_fit_cv)\nlr_assess_res\n\n\n# A tibble: 667 × 7\n   id    .pred_0 .pred_1  .row .pred_class survived .config             \n   <chr>   <dbl>   <dbl> <int> <fct>       <fct>    <chr>               \n 1 Fold1   0.883  0.117      2 0           0        Preprocessor1_Model1\n 2 Fold1   0.242  0.758      7 1           0        Preprocessor1_Model1\n 3 Fold1   0.945  0.0551    15 0           0        Preprocessor1_Model1\n 4 Fold1   0.889  0.111     18 0           0        Preprocessor1_Model1\n 5 Fold1   0.906  0.0941    24 0           0        Preprocessor1_Model1\n 6 Fold1   0.856  0.144     25 0           0        Preprocessor1_Model1\n 7 Fold1   0.817  0.183     30 0           0        Preprocessor1_Model1\n 8 Fold1   0.929  0.0709    34 0           0        Preprocessor1_Model1\n 9 Fold1   0.929  0.0710    37 0           0        Preprocessor1_Model1\n10 Fold1   0.919  0.0813    38 0           0        Preprocessor1_Model1\n# … with 657 more rows\n\n\n\n\nCode\nset.seed(1234)\nlm_fit <- lr_wflow %>% fit(data = train_proc_adj_tbl)\nextract_recipe(lm_fit, estimated = TRUE)\n\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          5\n   outcome          1\n predictor         13\n\nTraining data contained 891 data points and 687 incomplete rows. \n\nOperations:\n\nK-nearest neighbor imputation for age, sib_sp, parch, fare [trained]\nDummy variables from pclass, sex, embarked, train_test, pax_type, cabin_prefac... [trained]\nCharacter variables from <none> [trained]\nZero variance filter removed train_test_test [trained]\nNo PCA components were extracted from <none> [trained]"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "What is this for?",
    "section": "",
    "text": "This is my public notebook created in Quarto after seeing all the recent webinars from the amazing people at RStudio (eg JJ Allaire, Tom Mock and Isabella Velasquez)\nIt is intended that it will contain public ‘Notes to Myself’ on some of my interests which professionally are likely to centre on things like:\n\nR Programming\nPython Programming\nML analytics in R and Python\nFinance and data analytics (my day job)\nOther analytics and notes collected from wherever\n\nNot sure that it will be much use to anyone else, but feel free to wander through."
  },
  {
    "objectID": "posts/post-with-code/index.html#review-data",
    "href": "posts/post-with-code/index.html#review-data",
    "title": "Titanic from Kaggle",
    "section": "0.2 Review Data",
    "text": "0.2 Review Data\n\n0.2.1 Load Some Kaggle Data\nNot the…? Yes, the Titanic again….\n\n\nCode\ntrain <- read_csv(\"data_raw/train.csv\",show_col_types = FALSE) %>% clean_names() %>% mutate(train_test = \"train\")\ntest <- read_csv(\"data_raw/test.csv\",show_col_types = FALSE) %>% clean_names() %>% \n  mutate(train_test = \"test\")\nall <- train %>% bind_rows(test)\n\n# colnames(data)\n# cwd()\n\n\n\n\n0.2.2 Some Initial EDA\nA quick look.\n\n\nCode\ntrain %>% skim() \n\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n891\n\n\nNumber of columns\n13\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nname\n0\n1.00\n12\n82\n0\n891\n0\n\n\nsex\n0\n1.00\n4\n6\n0\n2\n0\n\n\nticket\n0\n1.00\n3\n18\n0\n681\n0\n\n\ncabin\n687\n0.23\n1\n15\n0\n147\n0\n\n\nembarked\n2\n1.00\n1\n1\n0\n3\n0\n\n\ntrain_test\n0\n1.00\n5\n5\n0\n1\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\npassenger_id\n0\n1.0\n446.00\n257.35\n1.00\n223.50\n446.00\n668.5\n891.00\n▇▇▇▇▇\n\n\nsurvived\n0\n1.0\n0.38\n0.49\n0.00\n0.00\n0.00\n1.0\n1.00\n▇▁▁▁▅\n\n\npclass\n0\n1.0\n2.31\n0.84\n1.00\n2.00\n3.00\n3.0\n3.00\n▃▁▃▁▇\n\n\nage\n177\n0.8\n29.70\n14.53\n0.42\n20.12\n28.00\n38.0\n80.00\n▂▇▅▂▁\n\n\nsib_sp\n0\n1.0\n0.52\n1.10\n0.00\n0.00\n0.00\n1.0\n8.00\n▇▁▁▁▁\n\n\nparch\n0\n1.0\n0.38\n0.81\n0.00\n0.00\n0.00\n0.0\n6.00\n▇▁▁▁▁\n\n\nfare\n0\n1.0\n32.20\n49.69\n0.00\n7.91\n14.45\n31.0\n512.33\n▇▁▁▁▁\n\n\n\n\n\n\n\n0.2.3 Some Initial Wrangling\n\n\nCode\nall_proc <- all %>% \n  mutate(title = str_extract(name,\"(\\\\w)([a-z]+)(\\\\.)\")) %>% \n  mutate(pax_type = case_when(\n    title %in% c(\"Miss.\",\"Ms.\",\"Mlle.\")         ~ \"F_unmarried\",\n    title %in% c(\"Mme.\",\"Mrs.\")                 ~ \"F_married\",\n    title %in% c(\"Countess.\",\"Lady.\",\"Dona.\")   ~ \"F_titled\",\n    title %in% c(\"Capt.\",\"Col.\",\"Major.\")       ~ \"Military\",\n    title %in% c(\"Dr.\",\"Rev.\")                  ~ \"M_Professional\",\n    title %in% c(\"Don.\",\"Jonkheer.\",\"Sir.\")     ~ \"M_titled\",\n    TRUE ~ title\n  ),\n  surname        = str_extract(name,\"(\\\\w+)(\\\\,)\"),\n  survival       = ifelse(survived==0,\"No\",\"Yes\"),\n  ticket_preface = str_extract(ticket,\"([:graph:]+)(\\\\s)\"),\n  ticket_preface = ifelse(is.na(ticket_preface),\"none\",ticket_preface),\n  cabin_preface  = ifelse(is.na(cabin),\"nk\",\n                    substr(cabin,1,1)),\n  embarked       = ifelse(is.na(embarked),\"S\",embarked)\n  ) %>% \n  group_by(pax_type,pclass) %>% \n  mutate(age     = ifelse(is.na(age),median(age,na.rm = T), age)) %>% \n  ungroup() %>% \n  add_count(ticket,name = \"ticket_group\") %>% \n  mutate(ticket_group = case_when(\n    ticket_group == 1 ~ \"single\",\n    ticket_group == 2 ~ \"couple\",\n    TRUE              ~ \"group\"\n  ),\n    family_group = as.numeric(sib_sp)+as.numeric(parch)+1\n  ) %>% \n  mutate(family_group = factor(\n    case_when(\n        family_group < 2  ~ \"single\",\n        family_group < 3  ~ \"couple\",\n        TRUE              ~ \"family\"\n        ),\n    ordered = TRUE)\n  ) %>% \n  mutate(age_group = factor(case_when(\n    age < 13      ~ \"child\",\n    age < 20      ~ \"teen\",\n    age < 30      ~ \"20s\",\n    age < 40      ~ \"30s\",\n    age < 50      ~ \"40s\",\n    age < 60      ~ \"50s\",\n    TRUE          ~ \"60+\"\n    \n  ),\n  ordered = TRUE)\n  ) %>% \n  mutate(across(where(is.character),as_factor)) %>% \n  mutate(pclass = factor(pclass,levels = c(\"1\",\"2\",\"3\")),\n         survived = factor(survived)\n         ) %>% \nselect(-c(title,ticket_preface))\n  \n#all_proc %>% glimpse() \n\n\n\n\n0.2.4 A bit more EDA\n\n\nCode\nall_proc %>% \n  select(-c(name,ticket,cabin,surname,train_test)) %>% \n  DataExplorer::plot_bar()\n\n\n\n\n\n\n\n\n\n\nCode\nall_proc %>% DataExplorer::plot_histogram(ggtheme = theme_light() )\n\n\n\n\n\n\n\n0.2.5 Eyeballing Survival Graphs on Training Data\n\n\nCode\nno_f <- all_proc %>%\n  filter(train_test == \"train\") %>% \n  select(passenger_id,pclass,sex,embarked,pax_type,ticket_group,family_group,age_group,cabin_preface,survival) %>% \n  droplevels() %>%\n  mutate(across(where(is.factor),~ factor(.x,ordered = FALSE))) %>%\n  pivot_longer(cols = c(pclass:cabin_preface)) \n\n\ng_l <- no_f %>% \n  split(.$name) %>% \n  map(~ ggplot(.,aes(y=value,fill=survival)) +\n                geom_bar() +\n              ggtitle(.$name) +\n        theme_bw() +\n        labs(x=NULL,y=NULL)+\n        scale_fill_viridis_d(option = \"cividis\")\n      \n            ) \n\nlibrary(patchwork)\nwrap_plots(g_l, ncol = 2)\n\n\n\n\n\n\n\n0.2.6 Split Data back to Train/Test/Validation\n\n\nCode\ntrain_proc_adj_tbl <- all_proc %>% \n  filter(train_test ==\"train\") %>% \n  select(-c(survival))\n  \ntrain_split <- initial_split(train_proc_adj_tbl,strata = survived)"
  },
  {
    "objectID": "posts/post-with-code/index.html#regularised-logistic-regression---glmnet",
    "href": "posts/post-with-code/index.html#regularised-logistic-regression---glmnet",
    "title": "Titanic from Kaggle",
    "section": "0.5 Regularised Logistic Regression - GLMNET",
    "text": "0.5 Regularised Logistic Regression - GLMNET\n\n0.5.1 RLR Model Spec\n\n\nCode\nrlr_model <- \n  logistic_reg(penalty = tune(), mixture = tune()) %>% \n  set_engine(\"glmnet\")\nrlr_model\n\n\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = tune()\n\nComputational engine: glmnet \n\n\n\n\n0.5.2 RLR Parameter Tuning\n\n\nCode\nrlr_grid <- grid_latin_hypercube(\n  penalty(),\n  mixture(),\n  size = 30\n)\nrlr_grid %>% tidy()\n\n\nWarning: Data frame tidiers are deprecated and will be removed in an upcoming\nrelease of broom.\n\n\n# A tibble: 2 × 13\n  column      n   mean    sd  median trimmed     mad      min   max range   skew\n  <chr>   <dbl>  <dbl> <dbl>   <dbl>   <dbl>   <dbl>    <dbl> <dbl> <dbl>  <dbl>\n1 penalty    30 0.0360 0.106 1.00e-5 0.00632 1.00e-5 1.30e-10 0.484 0.484 3.36  \n2 mixture    30 0.499  0.296 4.89e-1 0.498   2.47e-1 1.80e- 2 0.983 0.965 0.0119\n# … with 2 more variables: kurtosis <dbl>, se <dbl>\n\n\n\n\n0.5.3 RLR Workflow\n\n\nCode\nrlr_wflow <- \n  workflow() %>% \n  add_model(rlr_model) %>% \n  add_recipe(recipe_base)\nrlr_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = tune()\n\nComputational engine: glmnet \n\n\n\n\n0.5.4 RLR Hyper-parameter Tuning\n\n\nCode\n# rlr_folds <- vfold_cv(training(train_split), strata = survived, v=10,repeats = 5)\n# rlr_folds %>% tidy()\n\ndoParallel::registerDoParallel(cores = cores)\n\nset.seed(234)\nrlr_tuning_result <- tune_grid(\n  rlr_wflow,\n  resamples = folds,\n  grid      = rlr_grid,\n  control   = control_grid(save_pred = TRUE, save_workflow = TRUE)\n)\n\nrlr_tuning_metrics <- collect_metrics(rlr_tuning_result)\nhead(rlr_tuning_metrics)\n\n\n# A tibble: 6 × 8\n   penalty mixture .metric  .estimator  mean     n std_err .config              \n     <dbl>   <dbl> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n1 1.56e- 2  0.0180 accuracy binary     0.817     5  0.0205 Preprocessor1_Model01\n2 1.56e- 2  0.0180 roc_auc  binary     0.864     5  0.0203 Preprocessor1_Model01\n3 2.23e- 9  0.0656 accuracy binary     0.805     5  0.0215 Preprocessor1_Model02\n4 2.23e- 9  0.0656 roc_auc  binary     0.853     5  0.0157 Preprocessor1_Model02\n5 5.40e-10  0.0698 accuracy binary     0.805     5  0.0215 Preprocessor1_Model03\n6 5.40e-10  0.0698 roc_auc  binary     0.853     5  0.0157 Preprocessor1_Model03\n\n\nReview hyper-parameter tuning results and select best\n\n\nCode\nrlr_tuning_result %>%\n  collect_metrics() %>%\n  filter(.metric == \"accuracy\") %>%\n  select(mean, penalty,mixture) %>%\n  pivot_longer(penalty:mixture,\n               values_to = \"value\",\n               names_to = \"parameter\"\n  ) %>%\n  ggplot(aes(value, mean, color = parameter)) +\n  geom_point(alpha = 0.8, show.legend = FALSE) +\n  facet_wrap(~parameter, scales = \"free_x\") +\n  labs(x = NULL, y = \"AUC\")\n\n\n\n\n\nCode\nshow_best(rlr_tuning_result, \"accuracy\")\n\n\n# A tibble: 5 × 8\n  penalty mixture .metric  .estimator  mean     n std_err .config              \n    <dbl>   <dbl> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n1 0.0156   0.0180 accuracy binary     0.817     5  0.0205 Preprocessor1_Model01\n2 0.0255   0.983  accuracy binary     0.814     5  0.0164 Preprocessor1_Model30\n3 0.00886  0.923  accuracy binary     0.813     5  0.0215 Preprocessor1_Model28\n4 0.00349  0.598  accuracy binary     0.810     5  0.0208 Preprocessor1_Model18\n5 0.00193  0.946  accuracy binary     0.808     5  0.0220 Preprocessor1_Model29\n\n\nCode\nbest_rlr_auc <- select_best(rlr_tuning_result, \"accuracy\")\nbest_rlr_auc\n\n\n# A tibble: 1 × 3\n  penalty mixture .config              \n    <dbl>   <dbl> <chr>                \n1  0.0156  0.0180 Preprocessor1_Model01\n\n\n\n\n0.5.5 RLR Predict\n\n\nCode\nrlr_final_wflow <- finalize_workflow(\n  rlr_wflow,\n  best_rlr_auc\n)\n\nrlr_final_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = 0.0156443859188435\n  mixture = 0.0180497476753468\n\nComputational engine: glmnet \n\n\nCode\nrlr_final_wflow %>%\n  last_fit(train_split) %>%\n  extract_fit_parsnip() %>%\n  vip(geom = \"col\")\n\n\n\n\n\n\n\nCode\nrlr_final_fit <- rlr_final_wflow %>%\n  last_fit(train_split)\n\nrlr_final_metrics <- collect_metrics(rlr_final_fit)\nrlr_final_metrics\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.844 Preprocessor1_Model1\n2 roc_auc  binary         0.872 Preprocessor1_Model1\n\n\nCode\nrlr_test_predictions <- rlr_final_fit %>% collect_predictions()\nrlr_test_predictions\n\n\n# A tibble: 224 × 7\n   id               .pred_0 .pred_1  .row .pred_class survived .config          \n   <chr>              <dbl>   <dbl> <int> <fct>       <fct>    <chr>            \n 1 train/test split   0.902  0.0984     5 0           0        Preprocessor1_Mo…\n 2 train/test split   0.317  0.683      9 1           1        Preprocessor1_Mo…\n 3 train/test split   0.988  0.0118    14 0           0        Preprocessor1_Mo…\n 4 train/test split   0.423  0.577     15 1           0        Preprocessor1_Mo…\n 5 train/test split   0.331  0.669     23 1           1        Preprocessor1_Mo…\n 6 train/test split   0.757  0.243     26 0           1        Preprocessor1_Mo…\n 7 train/test split   0.884  0.116     28 0           0        Preprocessor1_Mo…\n 8 train/test split   0.879  0.121     37 0           1        Preprocessor1_Mo…\n 9 train/test split   0.902  0.0981    38 0           0        Preprocessor1_Mo…\n10 train/test split   0.576  0.424     39 0           0        Preprocessor1_Mo…\n# … with 214 more rows\n\n\nCode\n# rlr_pred <- predict(rlr_final_fit,train_2 )%>% \n#   bind_cols(predict(rlr_final_fit, train_2,type=\"prob\")) %>% \n#   bind_cols(train_2 %>% select(survived))\n# \n# rlr_pred %>% \n#   roc_auc(truth = survived, .pred_1, event_level = \"second\")\n# \n# rlr_pred %>% \n#   roc_curve(truth = survived, .pred_1,event_level=\"second\") %>% \n#   autoplot()\n# \n# \n# rlr_metrics <- rlr_pred %>% \n# metrics(truth = survived, estimate = .pred_class) %>% \n#   filter(.metric == \"accuracy\")\n# rlr_metrics\n# survive_rlr_pred <- \n#   augment(survive_lr_fit, train_2)\n# survive_rlr_pred\n\n\n\n\n0.5.6 RLR Confusion Matrix\n\n\nCode\nrlr_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#random-forest",
    "href": "posts/post-with-code/index.html#random-forest",
    "title": "Titanic from Kaggle",
    "section": "0.6 Random Forest",
    "text": "0.6 Random Forest\n\n0.6.1 RF Model Spec - Ranger\n\n\nCode\nrf_model <- \n  rand_forest(trees = 1000) %>% \n  set_engine(\"ranger\") %>% \n  set_mode(\"classification\")\n\n\n\n\n0.6.2 RF Workflow\n\n\nCode\nrf_wflow <- \n  workflow() %>% \n  add_model(rf_model) %>% \n  add_recipe(recipe_base)\n\n\n\n\n0.6.3 RF Fit Model\n\n\nCode\nrf_fit <- \n  rf_wflow %>% \n  last_fit(train_split)\n\nrf_final_metrics <- collect_metrics(rf_fit)\nrf_final_metrics\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.844 Preprocessor1_Model1\n2 roc_auc  binary         0.883 Preprocessor1_Model1\n\n\n\n\n0.6.4 RF Predict\n\n\nCode\nrf_final_fit <- rf_wflow %>% fit(testing(train_split))\nclass(rf_final_fit)\n\n\n[1] \"workflow\"\n\n\nCode\n rf_test_predictions <- \n  predict(rf_final_fit, new_data = testing(train_split)) %>% \n   bind_cols(predict(rf_final_fit, testing(train_split),type = \"prob\")) %>% \n   bind_cols(testing(train_split) %>% select(survived))\n\n \n head(rf_test_predictions)\n\n\n# A tibble: 6 × 4\n  .pred_class .pred_0 .pred_1 survived\n  <fct>         <dbl>   <dbl> <fct>   \n1 0             0.913  0.0870 0       \n2 1             0.437  0.563  1       \n3 0             0.906  0.0937 0       \n4 1             0.396  0.604  0       \n5 1             0.214  0.786  1       \n6 0             0.511  0.489  1       \n\n\n\n\n0.6.5 RF Performance on Training Set\n\n\nCode\nrf_test_predictions %>% \n  roc_auc(truth = survived, .pred_1,event_level = \"second\")\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.972\n\n\nCode\nrf_metrics_accuracy <- rf_test_predictions %>% \n  metrics(truth = survived, estimate = .pred_class) %>% \n  filter(.metric == \"accuracy\")\nrf_metrics_accuracy\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.915\n\n\nCode\nrf_test_predictions %>% \n  roc_curve(truth = survived, .pred_1,event_level = \"second\") %>% \n  autoplot()\n\n\n\n\n\n\n\n0.6.6 RF Confusion Matrix\n\n\nCode\nrf_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")\n\n\n\n\n\n\n\n0.6.7 RF Resampling\n\n\nCode\n#folds <- vfold_cv(training(train_split), strata = survived, v=5)\n#folds\n\ncontrol <- control_resamples(save_pred = TRUE,save_workflow = TRUE)\n\ncores <- parallel::detectCores()\nset.seed(1234)\ndoParallel::registerDoParallel(cores = cores)\n\nrf_fit_cv <- \n  rf_wflow %>% \n  fit_resamples(folds, control = control)\n\n#show_best(lr_fit_cv,metric= \"accuracy\")\n\n#lr_fit_cv\nrf_metrics_resample <- collect_metrics(rf_fit_cv)\nrf_metrics_resample\n\n\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy binary     0.826     5  0.0157 Preprocessor1_Model1\n2 roc_auc  binary     0.870     5  0.0176 Preprocessor1_Model1"
  },
  {
    "objectID": "posts/post-with-code/index.html#xg-boost---usemodel",
    "href": "posts/post-with-code/index.html#xg-boost---usemodel",
    "title": "Titanic from Kaggle",
    "section": "0.7 XG Boost - Usemodel",
    "text": "0.7 XG Boost - Usemodel\n\n0.7.1 XGB - Usemodel Library specs\n\n\nCode\nlibrary(usemodels)\n\n\nWarning: package 'usemodels' was built under R version 4.2.1\n\n\nCode\nuse_xgboost(survived ~ .,\n            data=training(train_split),\n            verbose = TRUE\n  \n)\n\n\nxgboost_recipe <- \n  recipe(formula = survived ~ ., data = training(train_split)) %>% \n  step_novel(all_nominal_predictors()) %>% \n  ## This model requires the predictors to be numeric. The most common \n  ## method to convert qualitative predictors to numeric is to create \n  ## binary indicator variables (aka dummy variables) from these \n  ## predictors. However, for this model, binary indicator variables can be \n  ## made for each of the levels of the factors (known as 'one-hot \n  ## encoding'). \n  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>% \n  step_zv(all_predictors()) \n\nxgboost_spec <- \n  boost_tree(trees = tune(), min_n = tune(), tree_depth = tune(), learn_rate = tune(), \n    loss_reduction = tune(), sample_size = tune()) %>% \n  set_mode(\"classification\") %>% \n  set_engine(\"xgboost\") \n\nxgboost_workflow <- \n  workflow() %>% \n  add_recipe(xgboost_recipe) %>% \n  add_model(xgboost_spec) \n\nset.seed(33729)\nxgboost_tune <-\n  tune_grid(xgboost_workflow, resamples = stop(\"add your rsample object\"), grid = stop(\"add number of candidate points\"))\n\n\n\n\n0.7.2 XGB - Parameters\nThis grid is used for both versions of XG Boost.\n\n\nCode\nxgb_grid <- grid_latin_hypercube(\n  tree_depth(),\n  min_n(),\n  trees(),\n  loss_reduction(),\n  sample_size = sample_prop(),\n  finalize(mtry(), training(train_split)),\n  learn_rate(),\n  size = 30\n)\n\nhead(xgb_grid)\n\n\n# A tibble: 6 × 7\n  tree_depth min_n trees loss_reduction sample_size  mtry   learn_rate\n       <int> <int> <int>          <dbl>       <dbl> <int>        <dbl>\n1          9    20  1622        4.07e-9       0.580    15 0.000000110 \n2          3    10   655        3.12e-4       0.523    13 0.0000000132\n3          1    36   208        9.59e-8       0.201    16 0.00000115  \n4         14    13  1672        1.16e-8       0.266    17 0.000000307 \n5         15    14   489        1.72e+1       0.689     8 0.0000000101\n6          4    16  1039        2.34e-2       0.986    12 0.0163      \n\n\n\n\n0.7.3 XGB - Usemodel Code\n\n\nCode\nlibrary(usemodels)\n\nuse_xgboost(survived ~ .,\n            data=training(train_split),\n            verbose = TRUE\n  \n)\n\n\nxgboost_recipe <- \n  recipe(formula = survived ~ ., data = training(train_split)) %>% \n  step_novel(all_nominal_predictors()) %>% \n  ## This model requires the predictors to be numeric. The most common \n  ## method to convert qualitative predictors to numeric is to create \n  ## binary indicator variables (aka dummy variables) from these \n  ## predictors. However, for this model, binary indicator variables can be \n  ## made for each of the levels of the factors (known as 'one-hot \n  ## encoding'). \n  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>% \n  step_zv(all_predictors()) \n\nxgboost_spec <- \n  boost_tree(trees = tune(), min_n = tune(), tree_depth = tune(), learn_rate = tune(), \n    loss_reduction = tune(), sample_size = tune()) %>% \n  set_mode(\"classification\") %>% \n  set_engine(\"xgboost\") \n\nxgboost_workflow <- \n  workflow() %>% \n  add_recipe(xgboost_recipe) %>% \n  add_model(xgboost_spec) \n\nset.seed(97445)\nxgboost_tune <-\n  tune_grid(xgboost_workflow, resamples = stop(\"add your rsample object\"), grid = stop(\"add number of candidate points\"))\n\n\n\n\nCode\nxgboost_usemodel_recipe <- \n  recipe(formula = survived ~ ., data = training(train_split)) %>% \n  step_novel(all_nominal_predictors()) %>% \n  ## This model requires the predictors to be numeric. The most common \n  ## method to convert qualitative predictors to numeric is to create \n  ## binary indicator variables (aka dummy variables) from these \n  ## predictors. However, for this model, binary indicator variables can be \n  ## made for each of the levels of the factors (known as 'one-hot \n  ## encoding'). \n  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>% \n  step_zv(all_predictors()) \n\nxgboost_usemodel_model <- \n  boost_tree(trees = tune(), mtry = tune(),min_n = tune(), tree_depth = tune(), learn_rate = tune(), \n    loss_reduction = tune(), sample_size = tune()) %>% \n  set_mode(\"classification\") %>% \n  set_engine(\"xgboost\") \n\nxgboost_usemodel_wflow <- \n  workflow() %>% \n  add_recipe(xgboost_usemodel_recipe) %>% \n  add_model(xgboost_usemodel_model) \n\ndoParallel::registerDoParallel(cores = cores)\n\nset.seed(234)\nxgboost_usemodel_tune <-\n  tune_grid(xgboost_usemodel_wflow, resamples = folds, grid = xgb_grid)\n\n\n\n\n0.7.4 XGB - Usemodel Best Parameter Settings\n\n\nCode\nxgb_tuning_metrics_usemodel <- collect_metrics(xgboost_usemodel_tune)\nxgb_tuning_metrics_usemodel\n\n\n# A tibble: 60 × 13\n    mtry trees min_n tree_…¹ learn…² loss_…³ sampl…⁴ .metric .esti…⁵  mean     n\n   <int> <int> <int>   <int>   <dbl>   <dbl>   <dbl> <chr>   <chr>   <dbl> <int>\n 1    16   208    36       1 1.15e-6 9.59e-8   0.201 accura… binary  0.616     5\n 2    16   208    36       1 1.15e-6 9.59e-8   0.201 roc_auc binary  0.5       5\n 3     6  1202     4       2 4.27e-7 9.25e-4   0.944 accura… binary  0.634     5\n 4     6  1202     4       2 4.27e-7 9.25e-4   0.944 roc_auc binary  0.815     5\n 5     4   559    39       2 7.47e-3 5.95e+0   0.410 accura… binary  0.616     5\n 6     4   559    39       2 7.47e-3 5.95e+0   0.410 roc_auc binary  0.5       5\n 7    18  1107     3       3 3.83e-3 1.10e-4   0.492 accura… binary  0.699     5\n 8    18  1107     3       3 3.83e-3 1.10e-4   0.492 roc_auc binary  0.818     5\n 9    13   655    10       3 1.32e-8 3.12e-4   0.523 accura… binary  0.699     5\n10    13   655    10       3 1.32e-8 3.12e-4   0.523 roc_auc binary  0.808     5\n# … with 50 more rows, 2 more variables: std_err <dbl>, .config <chr>, and\n#   abbreviated variable names ¹​tree_depth, ²​learn_rate, ³​loss_reduction,\n#   ⁴​sample_size, ⁵​.estimator\n\n\nCode\nxgboost_usemodel_tune %>%\n  collect_metrics() %>%\n  filter(.metric == \"roc_auc\") %>%\n  select(mean, mtry:sample_size) %>%\n  pivot_longer(mtry:sample_size,\n               values_to = \"value\",\n               names_to = \"parameter\"\n  ) %>%\n  ggplot(aes(value, mean, color = parameter)) +\n  geom_point(alpha = 0.8, show.legend = FALSE) +\n  facet_wrap(~parameter, scales = \"free_x\") +\n  labs(x = NULL, y = \"AUC\")\n\n\n\n\n\nNow select best from above\n\n\nCode\nshow_best(xgboost_usemodel_tune, \"roc_auc\")\n\n\n# A tibble: 5 × 13\n   mtry trees min_n tree_d…¹ learn…² loss_…³ sampl…⁴ .metric .esti…⁵  mean     n\n  <int> <int> <int>    <int>   <dbl>   <dbl>   <dbl> <chr>   <chr>   <dbl> <int>\n1    10  1571    24       14 3.48e-2 8.60e-7   0.877 roc_auc binary  0.836     5\n2    17  1672    13       14 3.07e-7 1.16e-8   0.266 roc_auc binary  0.822     5\n3     9   967    32        7 5.09e-2 2.78e-2   0.710 roc_auc binary  0.821     5\n4    12  1039    16        4 1.63e-2 2.34e-2   0.986 roc_auc binary  0.821     5\n5    15  1622    20        9 1.10e-7 4.07e-9   0.580 roc_auc binary  0.820     5\n# … with 2 more variables: std_err <dbl>, .config <chr>, and abbreviated\n#   variable names ¹​tree_depth, ²​learn_rate, ³​loss_reduction, ⁴​sample_size,\n#   ⁵​.estimator\n\n\nCode\nxgb_usemodel_best_params <- select_best(xgboost_usemodel_tune, \"roc_auc\")\nxgb_usemodel_best_params\n\n\n# A tibble: 1 × 8\n   mtry trees min_n tree_depth learn_rate loss_reduction sample_size .config    \n  <int> <int> <int>      <int>      <dbl>          <dbl>       <dbl> <chr>      \n1    10  1571    24         14     0.0348    0.000000860       0.877 Preprocess…\n\n\nCode\nxgb_usemodel_final_wflow <- finalize_workflow(\n  xgboost_usemodel_wflow,\n  xgb_usemodel_best_params\n)\n\nxgb_usemodel_final_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: boost_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_novel()\n• step_dummy()\n• step_zv()\n\n── Model ───────────────────────────────────────────────────────────────────────\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = 10\n  trees = 1571\n  min_n = 24\n  tree_depth = 14\n  learn_rate = 0.0348129952678471\n  loss_reduction = 8.60498209075984e-07\n  sample_size = 0.877007868885994\n\nComputational engine: xgboost \n\n\n\n\n0.7.5 XGB - Usemodel Parameter Ranking - VIP\n\n\nCode\nxgb_usemodel_final_wflow %>%\n  fit(data = training(train_split)) %>%\n  extract_fit_parsnip() %>%\n  vip(geom = \"point\")\n\n\nWarning: There are new levels in a factor: NA\n\n\n\n\n\n\n\n0.7.6 XGB - Usemodel Performance\n\nXGB - Usemodel Accuracy Measured on Test Set\n\n\nCode\nset.seed(234)\nxgb_usemodel_final_res <- last_fit(xgb_usemodel_final_wflow, train_split)\nxgb_usemodel_final_res\n\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits            id               .metrics .notes   .predictions .workflow \n  <list>            <chr>            <list>   <list>   <list>       <list>    \n1 <split [667/224]> train/test split <tibble> <tibble> <tibble>     <workflow>\n\nThere were issues with some computations:\n\n  - Warning(s) x2: There are new levels in a factor: NA\n\nRun `show_notes(.Last.tune.result)` for more information.\n\n\nCode\nxgb_usemodel_final_metrics <- collect_metrics(xgb_usemodel_final_res)\nxgb_usemodel_final_metrics\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.777 Preprocessor1_Model1\n2 roc_auc  binary         0.842 Preprocessor1_Model1\n\n\n\n\nXGB - Usemodel AUC on Test Set (within train)\n\n\nCode\nxgb_usemodel_final_res %>%\n  collect_predictions() %>%\n  roc_curve( truth = survived,.pred_1, event_level = \"second\") %>%\n  ggplot(aes(x = 1-specificity, y = sensitivity)) +\n  geom_line(size = 1.5, color = \"midnightblue\") +\n  geom_abline(\n    lty = 2, alpha = 0.5,\n    color = \"gray50\",\n    size = 1.2\n  )\n\n\n\n\n\n\n\nCode\nxgb_usemodel_test_predictions <- collect_predictions(xgb_usemodel_final_res)\nhead(xgb_usemodel_test_predictions)\n\n\n# A tibble: 6 × 7\n  id               .pred_0 .pred_1  .row .pred_class survived .config           \n  <chr>              <dbl>   <dbl> <int> <fct>       <fct>    <chr>             \n1 train/test split   0.868   0.132     5 0           0        Preprocessor1_Mod…\n2 train/test split   0.493   0.507     9 1           1        Preprocessor1_Mod…\n3 train/test split   0.819   0.181    14 0           0        Preprocessor1_Mod…\n4 train/test split   0.523   0.477    15 0           0        Preprocessor1_Mod…\n5 train/test split   0.479   0.521    23 1           1        Preprocessor1_Mod…\n6 train/test split   0.473   0.527    26 1           1        Preprocessor1_Mod…\n\n\n\n\n\n0.7.7 XGB - Usemodel Confusion Matrix\n\n\nCode\nxgb_usemodel_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#xg-boost---base-recipe",
    "href": "posts/post-with-code/index.html#xg-boost---base-recipe",
    "title": "Titanic from Kaggle",
    "section": "0.8 XG Boost - Base Recipe",
    "text": "0.8 XG Boost - Base Recipe\n\n0.8.1 XGB Model Spec\n\n\nCode\nxgb_model <- \n  boost_tree(\n    trees = tune(),\n    tree_depth = tune(),\n    min_n = tune(),\n    loss_reduction = tune(),\n    sample_size = tune(),\n    mtry = tune(),\n    learn_rate = tune()) %>% \n  set_engine(\"xgboost\") %>% \n  set_mode(\"classification\")\n\nxgb_model\n\n\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = tune()\n  min_n = tune()\n  tree_depth = tune()\n  learn_rate = tune()\n  loss_reduction = tune()\n  sample_size = tune()\n\nComputational engine: xgboost \n\n\n\n\n0.8.2 XGB Workflow\n\n\nCode\nxgb_wflow <- \n  workflow() %>% \n  add_model(xgb_model) %>% \n  add_recipe(recipe_base)\n\n\n\n\n0.8.3 XGB Hyper-Parameter Tuning\n\n\nCode\n# xgb_folds <- vfold_cv(training(train_split), strata = survived)\n# xgb_folds\n\n\ndoParallel::registerDoParallel(cores = cores)\n\nset.seed(234)\nxgb_tuning_result <- tune_grid(\n  xgb_wflow,\n  resamples = folds,\n  grid      = xgb_grid,\n  control  = control_grid(save_pred = TRUE,save_workflow = TRUE)\n)\nxgb_tuning_result\n\n\n# Tuning results\n# 5-fold cross-validation using stratification \n# A tibble: 5 × 5\n  splits            id    .metrics           .notes           .predictions\n  <list>            <chr> <list>             <list>           <list>      \n1 <split [532/135]> Fold1 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n2 <split [534/133]> Fold2 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n3 <split [534/133]> Fold3 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n4 <split [534/133]> Fold4 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n5 <split [534/133]> Fold5 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n\n\n\n\nCode\nxgb_tuning_metrics <- collect_metrics(xgb_tuning_result)\nxgb_tuning_metrics\n\n\n# A tibble: 60 × 13\n    mtry trees min_n tree_…¹ learn…² loss_…³ sampl…⁴ .metric .esti…⁵  mean     n\n   <int> <int> <int>   <int>   <dbl>   <dbl>   <dbl> <chr>   <chr>   <dbl> <int>\n 1    16   208    36       1 1.15e-6 9.59e-8   0.201 accura… binary  0.616     5\n 2    16   208    36       1 1.15e-6 9.59e-8   0.201 roc_auc binary  0.5       5\n 3     6  1202     4       2 4.27e-7 9.25e-4   0.944 accura… binary  0.783     5\n 4     6  1202     4       2 4.27e-7 9.25e-4   0.944 roc_auc binary  0.842     5\n 5     4   559    39       2 7.47e-3 5.95e+0   0.410 accura… binary  0.616     5\n 6     4   559    39       2 7.47e-3 5.95e+0   0.410 roc_auc binary  0.5       5\n 7    18  1107     3       3 3.83e-3 1.10e-4   0.492 accura… binary  0.822     5\n 8    18  1107     3       3 3.83e-3 1.10e-4   0.492 roc_auc binary  0.862     5\n 9    13   655    10       3 1.32e-8 3.12e-4   0.523 accura… binary  0.784     5\n10    13   655    10       3 1.32e-8 3.12e-4   0.523 roc_auc binary  0.839     5\n# … with 50 more rows, 2 more variables: std_err <dbl>, .config <chr>, and\n#   abbreviated variable names ¹​tree_depth, ²​learn_rate, ³​loss_reduction,\n#   ⁴​sample_size, ⁵​.estimator\n\n\nCode\nxgb_tuning_result %>%\n  collect_metrics() %>%\n  filter(.metric == \"roc_auc\") %>%\n  select(mean, mtry:sample_size) %>%\n  pivot_longer(mtry:sample_size,\n               values_to = \"value\",\n               names_to = \"parameter\"\n  ) %>%\n  ggplot(aes(value, mean, color = parameter)) +\n  geom_point(alpha = 0.8, show.legend = FALSE) +\n  facet_wrap(~parameter, scales = \"free_x\") +\n  labs(x = NULL, y = \"AUC\")\n\n\n\n\n\n\nXGB Best Parameters then Finalise Workflow\n\n\nCode\nshow_best(xgb_tuning_result, \"roc_auc\")\n\n\n# A tibble: 5 × 13\n   mtry trees min_n tree_d…¹ learn…² loss_…³ sampl…⁴ .metric .esti…⁵  mean     n\n  <int> <int> <int>    <int>   <dbl>   <dbl>   <dbl> <chr>   <chr>   <dbl> <int>\n1    18  1107     3        3 3.83e-3 1.10e-4   0.492 roc_auc binary  0.862     5\n2    12  1039    16        4 1.63e-2 2.34e-2   0.986 roc_auc binary  0.858     5\n3    11   191     7        9 5.47e-9 6.61e-3   0.732 roc_auc binary  0.849     5\n4     3  1814     5        6 5.67e-6 3.81e-6   0.913 roc_auc binary  0.848     5\n5     4   840     7       11 3.22e-8 1.94e-1   0.775 roc_auc binary  0.842     5\n# … with 2 more variables: std_err <dbl>, .config <chr>, and abbreviated\n#   variable names ¹​tree_depth, ²​learn_rate, ³​loss_reduction, ⁴​sample_size,\n#   ⁵​.estimator\n\n\nCode\nxgb_best_params <- select_best(xgb_tuning_result, \"roc_auc\")\nxgb_best_params\n\n\n# A tibble: 1 × 8\n   mtry trees min_n tree_depth learn_rate loss_reduction sample_size .config    \n  <int> <int> <int>      <int>      <dbl>          <dbl>       <dbl> <chr>      \n1    18  1107     3          3    0.00383       0.000110       0.492 Preprocess…\n\n\nCode\nxgb_final_wflow <- finalize_workflow(\n  xgb_wflow,\n  xgb_best_params\n)\n\nxgb_final_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: boost_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = 18\n  trees = 1107\n  min_n = 3\n  tree_depth = 3\n  learn_rate = 0.0038298863779315\n  loss_reduction = 0.00011029830522072\n  sample_size = 0.492113380425144\n\nComputational engine: xgboost \n\n\n\n\nCode\nxgb_final_wflow %>%\n  fit(data = training(train_split)) %>%\n  extract_fit_parsnip() %>%\n  vip(geom = \"point\")\n\n\n\n\n\n\n\n\n0.8.4 XGB Performance on Training Test Set\n\nXGB Accuracy Measured on Test Set\n\n\nCode\nxgb_final_res <- last_fit(xgb_final_wflow, train_split)\nxgb_final_res\n\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits            id               .metrics .notes   .predictions .workflow \n  <list>            <chr>            <list>   <list>   <list>       <list>    \n1 <split [667/224]> train/test split <tibble> <tibble> <tibble>     <workflow>\n\n\nCode\nxgb_final_metrics <- collect_metrics(xgb_final_res)\nxgb_final_metrics\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.839 Preprocessor1_Model1\n2 roc_auc  binary         0.890 Preprocessor1_Model1\n\n\n\n\nXGB AUC on Test Set (within train)\n\n\nCode\nxgb_final_res %>%\n  collect_predictions() %>%\n  roc_curve( truth = survived,.pred_1, event_level = \"second\") %>%\n  ggplot(aes(x = 1-specificity, y = sensitivity)) +\n  geom_line(size = 1.5, color = \"midnightblue\") +\n  geom_abline(\n    lty = 2, alpha = 0.5,\n    color = \"gray50\",\n    size = 1.2\n  )\n\n\n\n\n\n\n\nCode\nxgb_test_predictions <- collect_predictions(xgb_final_res)\nhead(xgb_test_predictions)\n\n\n# A tibble: 6 × 7\n  id               .pred_0 .pred_1  .row .pred_class survived .config           \n  <chr>              <dbl>   <dbl> <int> <fct>       <fct>    <chr>             \n1 train/test split   0.857   0.143     5 0           0        Preprocessor1_Mod…\n2 train/test split   0.562   0.438     9 0           1        Preprocessor1_Mod…\n3 train/test split   0.775   0.225    14 0           0        Preprocessor1_Mod…\n4 train/test split   0.363   0.637    15 1           0        Preprocessor1_Mod…\n5 train/test split   0.353   0.647    23 1           1        Preprocessor1_Mod…\n6 train/test split   0.527   0.473    26 0           1        Preprocessor1_Mod…\n\n\n\n\n\n0.8.5 XGB Confusion Matrix\n\n\nCode\nxgb_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#neural-net",
    "href": "posts/post-with-code/index.html#neural-net",
    "title": "Titanic from Kaggle",
    "section": "0.9 Neural Net",
    "text": "0.9 Neural Net\n\n0.9.1 NN Model\n\n\nCode\nnnet_model <- \n   mlp(hidden_units = tune(), penalty = tune(), epochs = tune()) %>% \n   set_engine(\"nnet\", MaxNWts = 2600) %>% \n   set_mode(\"classification\")\n\nnnet_model %>% translate()\n\n\nSingle Layer Neural Network Model Specification (classification)\n\nMain Arguments:\n  hidden_units = tune()\n  penalty = tune()\n  epochs = tune()\n\nEngine-Specific Arguments:\n  MaxNWts = 2600\n\nComputational engine: nnet \n\nModel fit template:\nnnet::nnet(formula = missing_arg(), data = missing_arg(), size = tune(), \n    decay = tune(), maxit = tune(), MaxNWts = 2600, trace = FALSE, \n    linout = FALSE)\n\n\n\n\n0.9.2 NN Workflow\n\n\nCode\nnnet_wflow <- workflow() %>% \n  add_model(nnet_model) %>% \n  add_recipe(recipe_base)\n\n\n\n\n0.9.3 NN Parameters\n\n\nCode\nnnet_grid <- grid_latin_hypercube(\n  hidden_units(),\n  penalty (),\n  epochs ()\n)\n\nhead(nnet_grid) \n\n\n# A tibble: 3 × 3\n  hidden_units  penalty epochs\n         <int>    <dbl>  <int>\n1            2 3.13e- 4    996\n2            6 4.14e- 2    182\n3            9 2.89e-10    377\n\n\n\n\n0.9.4 NN Hyper-Parameter Tuning\n\n\nCode\nnnet_folds <- vfold_cv(training(train_split), strata = survived)\nnnet_folds\n\n\n#  10-fold cross-validation using stratification \n# A tibble: 10 × 2\n   splits           id    \n   <list>           <chr> \n 1 <split [599/68]> Fold01\n 2 <split [600/67]> Fold02\n 3 <split [600/67]> Fold03\n 4 <split [600/67]> Fold04\n 5 <split [600/67]> Fold05\n 6 <split [600/67]> Fold06\n 7 <split [601/66]> Fold07\n 8 <split [601/66]> Fold08\n 9 <split [601/66]> Fold09\n10 <split [601/66]> Fold10\n\n\nCode\ndoParallel::registerDoParallel(cores = cores)\n\nset.seed(234)\nnnet_tuning_result <- tune_grid(\n  nnet_wflow,\n  resamples = folds,\n  grid      = nnet_grid,\n  control   = control_grid(save_pred = TRUE,save_workflow = TRUE)\n)\nnnet_tuning_result\n\n\n# Tuning results\n# 5-fold cross-validation using stratification \n# A tibble: 5 × 5\n  splits            id    .metrics         .notes           .predictions      \n  <list>            <chr> <list>           <list>           <list>            \n1 <split [532/135]> Fold1 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [405 × 9]>\n2 <split [534/133]> Fold2 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [399 × 9]>\n3 <split [534/133]> Fold3 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [399 × 9]>\n4 <split [534/133]> Fold4 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [399 × 9]>\n5 <split [534/133]> Fold5 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [399 × 9]>\n\n\n\n\n0.9.5 NN Best Parameters and Finalise Workflow\n\n\nCode\nshow_best(nnet_tuning_result, \"accuracy\")\n\n\n# A tibble: 3 × 9\n  hidden_units  penalty epochs .metric  .estimator  mean     n std_err .config  \n         <int>    <dbl>  <int> <chr>    <chr>      <dbl> <int>   <dbl> <chr>    \n1            6 4.14e- 2    182 accuracy binary     0.814     5  0.0158 Preproce…\n2            9 2.89e-10    377 accuracy binary     0.789     5  0.0218 Preproce…\n3            2 3.13e- 4    996 accuracy binary     0.783     5  0.0273 Preproce…\n\n\nCode\nnn_best_params <- select_best(nnet_tuning_result, \"accuracy\")\n\nnnet_best_auc <- select_best(xgb_tuning_result, \"accuracy\")\nnnet_best_auc\n\n\n# A tibble: 1 × 8\n   mtry trees min_n tree_depth learn_rate loss_reduction sample_size .config    \n  <int> <int> <int>      <int>      <dbl>          <dbl>       <dbl> <chr>      \n1    18  1107     3          3    0.00383       0.000110       0.492 Preprocess…\n\n\nCode\nnnet_final_wflow <- finalize_workflow(\n  nnet_wflow,\n  nn_best_params\n)\n\nnnet_final_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: mlp()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nSingle Layer Neural Network Model Specification (classification)\n\nMain Arguments:\n  hidden_units = 6\n  penalty = 0.041396901211693\n  epochs = 182\n\nEngine-Specific Arguments:\n  MaxNWts = 2600\n\nComputational engine: nnet \n\n\n\n\nCode\nnnet_final_wflow %>%\n  fit(data = training(train_split)) %>%\n  extract_fit_parsnip() %>%\n  vip(geom = \"point\")\n\n\n\n\n\n\n\n0.9.6 NN Accuracy - Train/Test Set\n\n\nCode\nnnet_tuning_metrics <- collect_metrics(nnet_tuning_result)\nnnet_tuning_metrics\n\n\n# A tibble: 6 × 9\n  hidden_units  penalty epochs .metric  .estimator  mean     n std_err .config  \n         <int>    <dbl>  <int> <chr>    <chr>      <dbl> <int>   <dbl> <chr>    \n1            2 3.13e- 4    996 accuracy binary     0.783     5  0.0273 Preproce…\n2            2 3.13e- 4    996 roc_auc  binary     0.818     5  0.0326 Preproce…\n3            6 4.14e- 2    182 accuracy binary     0.814     5  0.0158 Preproce…\n4            6 4.14e- 2    182 roc_auc  binary     0.832     5  0.0170 Preproce…\n5            9 2.89e-10    377 accuracy binary     0.789     5  0.0218 Preproce…\n6            9 2.89e-10    377 roc_auc  binary     0.808     5  0.0265 Preproce…\n\n\nCode\nnnet_final_res <- last_fit(nnet_final_wflow, train_split)\nnnet_final_res\n\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits            id               .metrics .notes   .predictions .workflow \n  <list>            <chr>            <list>   <list>   <list>       <list>    \n1 <split [667/224]> train/test split <tibble> <tibble> <tibble>     <workflow>\n\n\nCode\nnnet_final_metrics <- collect_metrics(nnet_final_res)\nnnet_final_metrics\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.812 Preprocessor1_Model1\n2 roc_auc  binary         0.838 Preprocessor1_Model1\n\n\n\n\n0.9.7 NN AUC\n\n\nCode\nnnet_final_res %>%\n  collect_predictions() %>%\n  roc_curve( truth = survived,.pred_1, event_level = \"second\") %>%\n  ggplot(aes(x = 1-specificity, y = sensitivity)) +\n  geom_line(size = 1.5, color = \"midnightblue\") +\n  geom_abline(\n    lty = 2, alpha = 0.5,\n    color = \"gray50\",\n    size = 1.2\n  )\n\n\n\n\n\n\n\n0.9.8 NN Predictions on Train/Test Set\n\n\nCode\nnnet_test_predictions <- nnet_final_res %>%\n  collect_predictions() \nhead(nnet_test_predictions)\n\n\n# A tibble: 6 × 7\n  id               .pred_0 .pred_1  .row .pred_class survived .config           \n  <chr>              <dbl>   <dbl> <int> <fct>       <fct>    <chr>             \n1 train/test split   0.660   0.340     5 0           0        Preprocessor1_Mod…\n2 train/test split   0.455   0.545     9 1           1        Preprocessor1_Mod…\n3 train/test split   0.728   0.272    14 0           0        Preprocessor1_Mod…\n4 train/test split   0.356   0.644    15 1           0        Preprocessor1_Mod…\n5 train/test split   0.282   0.718    23 1           1        Preprocessor1_Mod…\n6 train/test split   0.725   0.275    26 0           1        Preprocessor1_Mod…\n\n\n\n\n0.9.9 NN Confusion Matrix\n\n\nCode\nnnet_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#stack-models---not-working",
    "href": "posts/post-with-code/index.html#stack-models---not-working",
    "title": "Titanic from Kaggle",
    "section": "0.10 Stack Models - not working",
    "text": "0.10 Stack Models - not working\n\n0.10.1 Stack Recipe\n\n\nCode\nrecipe_stack <- \n  recipe(survived ~ ., data = training(train_split)) %>% \n  update_role(passenger_id, name,surname,ticket,cabin,new_role = \"ID\") %>% \n  step_impute_knn(all_numeric_predictors()) %>% \n  step_dummy(all_nominal_predictors()) %>%\n  step_factor2string(all_nominal_predictors()) %>% \n  step_zv(all_predictors()) %>% \n  step_pca()\nrecipe_stack\n\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          5\n   outcome          1\n predictor         13\n\nOperations:\n\nK-nearest neighbor imputation for all_numeric_predictors()\nDummy variables from all_nominal_predictors()\nCharacter variables from all_nominal_predictors()\nZero variance filter on all_predictors()\nPCA extraction with <none>\n\n\nCode\nrecipe_stack_trained <- prep(recipe_base)\nrecipe_stack_trained\n\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          5\n   outcome          1\n predictor         13\n\nTraining data contained 667 data points and 510 incomplete rows. \n\nOperations:\n\nK-nearest neighbor imputation for age, sib_sp, parch, fare [trained]\nDummy variables from pclass, sex, embarked, train_test, pax_type, cabin_prefac... [trained]\nCharacter variables from <none> [trained]\nZero variance filter removed train_test_test [trained]\nNo PCA components were extracted from <none> [trained]\n\n\n\n\n0.10.2 Stack Controls\n\n\nCode\nstack_ctrl <- control_resamples(save_pred = TRUE, save_workflow = TRUE)\n#stack_folds <- vfold_cv(training(train_split), v=10,strata = \"survived\")\n\nlibrary(stacks)\n\n\nWarning: package 'stacks' was built under R version 4.2.1\n\n\nCode\nmodel_stack <-\n  stacks() %>%\n  #add_candidates(lr_wflow) %>%\n  #add_candidates(rf_wflow) %>%\n  add_candidates(nnet_tuning_result) %>%\n  add_candidates(rlr_tuning_result) %>% \n  add_candidates(xgb_tuning_result)\n\n\nWarning: Predictions from 5 candidates were identical to those from existing\ncandidates and were removed from the data stack.\n\n\n\n\n0.10.3 Stack LR\n\n\nCode\nstack_lr_wflow <- \n  workflow() %>% \n  add_model(lr_spec) %>% \n  add_recipe(recipe_stack)\nlr_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\nCode\nstack_lr_res <- \n  lr_wflow %>% \n  tune_grid(folds,control = stack_ctrl)\n\n\nWarning: No tuning parameters have been detected, performance will be evaluated\nusing the resamples with no tuning. Did you want to [tune()] parameters?\n\n\nCode\nstack_lr_res\n\n\n# Tuning results\n# 5-fold cross-validation using stratification \n# A tibble: 5 × 5\n  splits            id    .metrics         .notes           .predictions      \n  <list>            <chr> <list>           <list>           <list>            \n1 <split [532/135]> Fold1 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [135 × 6]>\n2 <split [534/133]> Fold2 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [133 × 6]>\n3 <split [534/133]> Fold3 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [133 × 6]>\n4 <split [534/133]> Fold4 <tibble [2 × 4]> <tibble [0 × 3]> <tibble [133 × 6]>\n5 <split [534/133]> Fold5 <tibble [2 × 4]> <tibble [1 × 3]> <tibble [133 × 6]>\n\nThere were issues with some computations:\n\n  - Warning(s) x1: prediction from a rank-deficient fit may be misleading\n\nRun `show_notes(.Last.tune.result)` for more information.\n\n\n\n\nCode\n# autoplot(stack_lr_res) + \n#   scale_color_viridis_d(direction = -1) + \n#   theme(legend.position = \"top\")\n\n\n\n\n0.10.4 Stack RLR\n\n\nCode\n# stack_rlr_wflow <- \n#   workflow() %>% \n#   add_model(rlr_model) %>% \n#   add_recipe(recipe_stack)\n# stack_rlr_wflow\n# \n# stack_rlr_res <- \n#   stack_rlr_wflow %>% \n#   fit_resamples(folds,control = stack_ctrl)\n# stack_rlr_res\n\n\n\n\n0.10.5 Initialise Stack\n\n\nCode\nstack_models <-\n  stacks()\nstack_models\n\n\n# A data stack with 0 model definitions and 0 candidate members.\n\n\nCode\nstack_models %>% \nadd_candidates(stack_lr_res)\n\n\nWarning: The inputted `candidates` argument `stack_lr_res` generated notes\nduring tuning/resampling. Model stacking may fail due to these issues; see `?\ncollect_notes` if so.\n\n\n# A data stack with 1 model definition and 1 candidate member:\n#   stack_lr_res: 1 model configuration\n# Outcome: survived (factor)"
  },
  {
    "objectID": "posts/post-with-code/index.html#join-model-prediction-data",
    "href": "posts/post-with-code/index.html#join-model-prediction-data",
    "title": "Titanic from Kaggle",
    "section": "0.11 Join Model Prediction Data",
    "text": "0.11 Join Model Prediction Data\n\n\nCode\nall_predictions <- \n  lr_test_predictions %>% mutate(model = \"LR\") %>% \n  bind_rows(nnet_test_predictions %>% mutate(model = \"NNet\")) %>% \n  bind_rows(rlr_test_predictions %>% mutate(model = \"Reg_LR\")) %>% \n  bind_rows(rf_test_predictions %>% mutate(model = \"RF\")) %>% \n  bind_rows(xgb_test_predictions %>% mutate(model = \"xgb\")) %>% \n  bind_rows(xgb_usemodel_test_predictions %>% mutate(model = \"xgb_usemodel\")) \n  \nhead(all_predictions)\n\n\n# A tibble: 6 × 8\n  id               .pred_0 .pred_1  .row .pred_class survived .config      model\n  <chr>              <dbl>   <dbl> <int> <fct>       <fct>    <chr>        <chr>\n1 train/test split   0.925 0.0754      5 0           0        Preprocesso… LR   \n2 train/test split   0.196 0.804       9 1           1        Preprocesso… LR   \n3 train/test split   0.999 0.00118    14 0           0        Preprocesso… LR   \n4 train/test split   0.390 0.610      15 1           0        Preprocesso… LR   \n5 train/test split   0.290 0.710      23 1           1        Preprocesso… LR   \n6 train/test split   0.942 0.0579     26 0           1        Preprocesso… LR"
  },
  {
    "objectID": "posts/post-with-code/index.html#all-metrics",
    "href": "posts/post-with-code/index.html#all-metrics",
    "title": "Titanic from Kaggle",
    "section": "0.12 All Metrics",
    "text": "0.12 All Metrics\n\n\nCode\nall_metrics <- \n  lr_final_metrics %>% mutate(model = \"LR\") %>% \n  bind_rows(nnet_final_metrics %>% mutate(model = \"NNet\")) %>% \n  bind_rows(rlr_final_metrics %>% mutate(model = \"Reg_LR\")) %>% \n  bind_rows(rf_final_metrics %>% mutate(model = \"RF\")) %>% \n  bind_rows(xgb_final_metrics %>% mutate(model = \"xgb\")) %>% \n   bind_rows(xgb_usemodel_final_metrics %>% mutate(model = \"xgb-usemodel\")) \n  \nhead(all_metrics)\n\n\n# A tibble: 6 × 5\n  .metric  .estimator .estimate .config              model \n  <chr>    <chr>          <dbl> <chr>                <chr> \n1 accuracy binary         0.826 Preprocessor1_Model1 LR    \n2 roc_auc  binary         0.859 Preprocessor1_Model1 LR    \n3 accuracy binary         0.812 Preprocessor1_Model1 NNet  \n4 roc_auc  binary         0.838 Preprocessor1_Model1 NNet  \n5 accuracy binary         0.844 Preprocessor1_Model1 Reg_LR\n6 roc_auc  binary         0.872 Preprocessor1_Model1 Reg_LR\n\n\n\n\nCode\nall_metrics %>% \n  filter(.metric == \"roc_auc\") %>% \n  select(model, roc = .estimate) %>% \n  ggplot(aes(model, roc)) +\n  geom_col()"
  },
  {
    "objectID": "posts/post-with-code/index.html#ensemble---workflow-sets---not-working",
    "href": "posts/post-with-code/index.html#ensemble---workflow-sets---not-working",
    "title": "Titanic from Kaggle",
    "section": "0.13 Ensemble - Workflow Sets - not working",
    "text": "0.13 Ensemble - Workflow Sets - not working\n\n\nCode\n# no_pre_proc <- \n#    workflow_set(\n#       preproc = list(base = recipe_base), \n#       models = list(RF             = lr_model, \n#                     Regularised_LR = rlr_model, \n#                     Rand_Forest    = rf_model, \n#                     boosting       = xgb_model),\n#       cross = TRUE\n#    )\n# no_pre_proc\n# \n# add_cand"
  },
  {
    "objectID": "posts/post-with-code/index.html#predict-on-test-set",
    "href": "posts/post-with-code/index.html#predict-on-test-set",
    "title": "Titanic from Kaggle",
    "section": "1.1 Predict on Test set",
    "text": "1.1 Predict on Test set\n\n\nCode\nfinal_test_preds <- \n  nnet_final_wflow %>% \n  fit(train_proc_adj_tbl) %>% \n  predict(new_data=testing(train_split)) %>% \n  bind_cols(testing(train_split)) %>% \n  select(PassengerID = passenger_id,Survived = .pred_class)\n\n#colnames(test_2)"
  },
  {
    "objectID": "posts/post-with-code/index.html#write-submission-file",
    "href": "posts/post-with-code/index.html#write-submission-file",
    "title": "Titanic from Kaggle",
    "section": "1.2 Write Submission File",
    "text": "1.2 Write Submission File\n\n\nCode\n#write_csv(final_test_preds,\"titanic_sumission.csv\")"
  }
]