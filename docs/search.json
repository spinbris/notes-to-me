[
  {
    "objectID": "posts/forecasting_with_deep_learning/index.html",
    "href": "posts/forecasting_with_deep_learning/index.html",
    "title": "Flight Forecasting with Deep Learning - Incomplete",
    "section": "",
    "text": "This post is in relation to the part 4. of a multipart ML/DL forecast post series on Australian flight patronage by route, pre-covid. Approaches used are:\n\nGluonTS\n\nDeepAR\nN-BEATS\n\n\nAll parts of series:\n1. Some pre analysis (basic EDA analysis is not covered as already included in previous posts)\n2. ‘Sequence’ style models - ARIMA etc\n3. ML style models - XGBoost etc including nesting and ensembling\n4. Deep learning models (GLuonTS etc)\n5. Summary of conclusions"
  },
  {
    "objectID": "posts/forecasting_with_deep_learning/index.html#load-data",
    "href": "posts/forecasting_with_deep_learning/index.html#load-data",
    "title": "Flight Forecasting with Deep Learning - Incomplete",
    "section": "3 Load Data",
    "text": "3 Load Data\nLoading pre-prepared data as well as some parameters. Also setting up parallel processing.\n\n\nCode\ntop_routes_prep_df <- read_rds(here(\"./posts/aust_domestic_flights/artifacts/top_routes_prep_df.rds\"))\n\nstart          <- \"2001-01-01\"\nend            <- \"2019-07-01\"\nhorizon_nested <- 12\nend_precovid   <- dmy(\"01-02-2020\")\n\ntop_x          <- 10\n\n\n#d2 <- dmy(\"01-07-2022\")\nmax_act   <- max(top_routes_prep_df$date)\nmax_test  <- ymd(end)\nmax_pred  <- max_test %m+% months(horizon_nested)\n \n\nFORECAST_HORIZON <-  1*12\nlag_period       <-  1*12\nrolling_periods  <- c(3,6,12)\n\n# * Parallel Processing ----\n\nregisterDoFuture()\nn_cores <- parallel::detectCores()\nplan(\n  strategy = cluster,\n  workers  = parallel::makeCluster(n_cores)\n)"
  },
  {
    "objectID": "posts/forecasting_with_deep_learning/index.html#preprocessing",
    "href": "posts/forecasting_with_deep_learning/index.html#preprocessing",
    "title": "Flight Forecasting with Deep Learning - Incomplete",
    "section": "4 Preprocessing",
    "text": "4 Preprocessing\nSome additional wrangling.\n\n\nCode\n# topx list\ntopx <- top_routes_prep_df %>% \n  group_by(route) %>% \n  summarise(passenger_trips = sum(passenger_trips)) %>% \n  ungroup() %>% \n  slice_max(passenger_trips, n=top_x) %>% \n  arrange(desc(passenger_trips)) %>% \n  select(route) %>% \n  pull() %>% \n  as.character()\n\nfull_data_tbl <- top_routes_prep_df %>%\n  group_by(route) %>%\n  #initial wrangle\n  select(route,date,passenger_trips) %>%\n  mutate(route = as.character(route)) %>%\n  group_by(route) %>%\n  summarise_by_time(date, .by = \"month\", passenger_trips = sum(passenger_trips)) %>%\n  pad_by_time(\n    date,\n    .by       = \"month\",\n    .pad_value  = 0,\n    .start_date = min(top_routes_prep_df$date)) %>%\n  filter_by_time(.date_var    = date,.start_date = start, .end_date = end ) %>%\n  ungroup()\n\nfull_data_tbl <- full_data_tbl %>%\n  tk_augment_timeseries_signature() %>%\n  select(-c(day:mday7)) %>%\n  select(-contains(\".iso\"),-contains(\".xts\"))\n\nfull_data_tbl <- full_data_tbl %>%\n\n  #log transform target\n  mutate(passenger_trips      = log1p(passenger_trips),\n         index.num            = log1p(index.num),\n         diff                 = log1p(diff),\n         year                 = log1p(year)) %>%\n\n  #groupwise manipulation\n  group_by(route) %>%\n\n  future_frame(\n    .date_var   = date,\n    .length_out = FORECAST_HORIZON,\n    .bind_data  = TRUE\n  ) %>%\n\n  # Fourier\n  tk_augment_fourier(\n    .date_var = date,\n    .periods  = c(0.5 * FORECAST_HORIZON, FORECAST_HORIZON),\n    .K        = 1\n  ) %>%\n\n  # Lags\n\n  tk_augment_lags(\n    .value = passenger_trips,\n    .lags =  FORECAST_HORIZON\n  ) %>%\n\n  # Rolling Features\n  tk_augment_slidify(\n    .value   = passenger_trips_lag12,\n    .f       = ~ mean(.x,na.rm = TRUE),\n    .period  = c(6, FORECAST_HORIZON, 2 * FORECAST_HORIZON),\n    .partial = TRUE,\n    .align   = 'center'\n  ) %>%\n  ungroup() %>%\n\n  rowid_to_column(var = \"rowid\")\n\n\n\ndata_prepared_tbl <- full_data_tbl %>%\n  filter(!is.na(passenger_trips)) %>%\n  drop_na()\n\nfuture_tbl <- full_data_tbl %>%\n  filter(is.na(passenger_trips))\n\n  route_prep_validation <- top_routes_prep_df %>%\n#   filter(route %in% topx ) %>% \n  filter(date > max_test ) %>%\n  ungroup() %>%\n  mutate(passenger_trips      = log1p(passenger_trips)) %>%\n  group_by(route)"
  },
  {
    "objectID": "posts/forecasting_with_deep_learning/index.html#split-data",
    "href": "posts/forecasting_with_deep_learning/index.html#split-data",
    "title": "Flight Forecasting with Deep Learning - Incomplete",
    "section": "5 Split Data",
    "text": "5 Split Data\nSplit into training and testing sets.\n\n5.1 Training Set (top 10 routes)\n\n\nCode\nsplits <- data_prepared_tbl %>%\n  time_series_split(\n    date_var = date,\n    assess = FORECAST_HORIZON,\n    cumulative = TRUE\n  )\n\n\n\ntraining(splits) %>%\n  group_by(route) %>%\n  filter(route %in% topx) %>%\n  plot_time_series(\n    date,\n    passenger_trips,\n    .facet_ncol = 2,\n    .smooth = FALSE,\n    .title = \"Training Splits\"\n  )\n\n\n\n\n\n\nCode\nmax_train <- max(training(splits)$date)\n\n\n\n\n5.2 Testing Set (top 10 routes)\n\n\nCode\ntesting(splits) %>%\n  group_by(route) %>%\n  filter(route %in% topx) %>%\n  plot_time_series(\n    date,\n    passenger_trips,\n    .facet_ncol = 2,\n     .smooth = FALSE,\n    .title = \"Testing Splits\"\n    \n  )"
  },
  {
    "objectID": "posts/forecasting_with_deep_learning/index.html#gluonts",
    "href": "posts/forecasting_with_deep_learning/index.html#gluonts",
    "title": "Flight Forecasting with Deep Learning - Incomplete",
    "section": "6 GLUONTS",
    "text": "6 GLUONTS\nGluonTS is a Python package for probabilistic time series modeling, focusing on deep learning based models, based on PyTorch and MXNet. It was developed by Amazon.\nSome quotes from the GluonTS website are useful:\n” In forecasting, there is the implicit assumption that observable behaviours of the past that impact time series values continue into the future. ”\n” Naturally, it’s impossible to forecast the unpredictable. For instance, in 2019 it was virtually impossible to account for the possibility of travel restrictions due to the Covid-19 pandemic when trying to forecacst travel demand for 2020.\nThus, forecasting operates on the caveat that the underlying factors that generate the time series values don’t fundamentally change in the future. It is a tool to predict the ordinary and not the surprising.”\nIn this analysis we get around this ’problem, by only predicting passenger numbers up to the beginning of covid effect, and maybe soon post covid impact.\nAnother key aspect of GluonTS is that it is probabilistic - predicting distributions of outcomes not just one value per time point. This is very useful.\nAnother useful feature of GluonTS is that it includes the concept of Global models which enables many time series to be trained together and then used to make probabilistic predictions for each time series. In this analysis we have 70 or so time series - one for each route.\nGluonTS makes many models available in Python. A number of the models and concepts (eg hierarchical forecasting are based/wrapped on the Forecast package in R and the related textbook Forecasting: Principles and Practice.\nThis analysis uses the modeltime.gluonts package in R to interface to GluonTS. This R library enables an R interface to some of the GluonTS models. The following analysis uses:\n\nDeepAR\nN-Beats\n\n\n\nCode\n# 3.0 GLUONTS MODELS ----\n\n# * GLUON Recipe Specification ----\n\n#Gluon only needs Target,ID(groups) and date\n\nrecipe_spec_gluon <- recipe(\n  passenger_trips ~ route + date + rowid,\n  data = training(splits)\n) %>%\n  update_role(rowid,new_role = \"indicator\")\n\n#recipe_spec_gluon %>% prep() %>% juice()\n\nrecipe_spec_gluon %>% prep() %>% summary()\n\n\n# A tibble: 4 × 4\n  variable        type      role      source  \n  <chr>           <list>    <chr>     <chr>   \n1 route           <chr [3]> predictor original\n2 date            <chr [1]> predictor original\n3 rowid           <chr [2]> indicator original\n4 passenger_trips <chr [2]> outcome   original\n\n\n\n6.1 DeepAR\nDeepAR was also developed by Amazon (as part of Sagemaker) which is particularly suited to cross-sectional analysis (eg routes), in that the time series are trained jointly across all routes (in our case).\nA few different combinations of epoch numbers and batch sizes per epoch have been tried\n\nDeepAR Model 1 - epochs 5; batch size/ epoch:50\n\n\nCode\nmodel_spec_1_deepar <- deep_ar(\n  #Required params\n  id                = \"route\",\n  freq              = \"M\",\n  prediction_length = FORECAST_HORIZON,\n\n  #trainer\n  epochs            = 5,\n\n  #DeepAR specific\n  cell_type         =\"lstm\"\n\n) %>%\n  set_engine(\"gluonts_deepar\")\n\n#wflow\nwflw_fit_deepar_1 <- workflow() %>%\n  add_model(model_spec_1_deepar) %>%\n  add_recipe(recipe_spec_gluon) %>%\n  fit(training(splits))\n\nmodel_spec_1_deepar\n\n\nDeepAR Model Specification (regression)\n\nMain Arguments:\n  id = route\n  freq = M\n  prediction_length = FORECAST_HORIZON\n  cell_type = lstm\n  epochs = 5\n\nComputational engine: gluonts_deepar \n\n\n\n\nDeepAR Model 2 - epochs 10; batch size/ epoch: 35 \n\n\nCode\n# Model 2: Increase Epochs, Adjust Num Batches per Epoch\n#model spec\nmodel_spec_2_deepar <- deep_ar(\n  id                    = \"route\",\n  freq                  = \"M\",\n  prediction_length     = FORECAST_HORIZON,\n\n  epochs                = 10,\n  num_batches_per_epoch = 35,\n\n  #DeepAR specific\n  cell_type             = \"lstm\"\n) %>%\n  set_engine(\"gluonts_deepar\")\n\n#wflow\nwflw_fit_deepar_2 <- workflow() %>%\n  add_model(model_spec_2_deepar) %>%\n  add_recipe(recipe_spec_gluon) %>%\n  fit(training(splits))\n\nmodel_spec_2_deepar\n\n\nDeepAR Model Specification (regression)\n\nMain Arguments:\n  id = route\n  freq = M\n  prediction_length = FORECAST_HORIZON\n  cell_type = lstm\n  epochs = 10\n  num_batches_per_epoch = 35\n\nComputational engine: gluonts_deepar \n\n\n\n\nDeepAR Model 3 - epochs 10; batch size/ epoch: 50 \n\n\nCode\n# Model 3: Increase Epochs, Adjust Num Batches Per Epoch, & Add Scaling\n\nmodel_spec_3_deepar <- deep_ar(\n  id                    = \"route\",\n  freq                  = \"M\",\n  prediction_length     = FORECAST_HORIZON,\n\n  epochs                = 10,\n  num_batches_per_epoch = 50,\n\n  scale                 = TRUE,\n\n  #DeepAR specific\n  cell_type             = \"lstm\"\n) %>%\n  set_engine(\"gluonts_deepar\")\n\n#wflow\nwflw_fit_deepar_3 <- workflow() %>%\n  add_model(model_spec_3_deepar) %>%\n  add_recipe(recipe_spec_gluon) %>%\n  fit(training(splits))\n\nmodel_spec_3_deepar\n\n\nDeepAR Model Specification (regression)\n\nMain Arguments:\n  id = route\n  freq = M\n  prediction_length = FORECAST_HORIZON\n  cell_type = lstm\n  epochs = 10\n  num_batches_per_epoch = 50\n  scale = TRUE\n\nComputational engine: gluonts_deepar \n\n\n\n\n\n6.2 N-Beats (Neural Basis Expansion Analysis for Time Series)\nN-BEATS is a type of neural network that was first described in a 2019 article by Oreshkin et al\nModeltime.gluonts package allows for 2 types of implementations: Standard or Ensemble. The following models include a mix of both, also with varying hyper-parameters.\n\nN-Beats Model 4 - Default (epochs:5)\n\n\nCode\n# * N-BEATS Estimator ----\n\n# Model 4: N-BEATS default\n\nmodel_spec_nbeats_4 <- nbeats(\n  id                = \"route\",\n  freq              = \"M\",\n  prediction_length = FORECAST_HORIZON,\n\n  lookback_length   = 2 * FORECAST_HORIZON\n\n) %>%\n  set_engine(\"gluonts_nbeats\")\n\n\nwflw_fit_nbeats_4 <- workflow() %>%\n  add_model(model_spec_nbeats_4) %>%\n  add_recipe(recipe_spec_gluon) %>%\n  fit(training(splits))\n\nmodel_spec_nbeats_4\n\n\nN-BEATS Model Specification (regression)\n\nMain Arguments:\n  id = route\n  freq = M\n  prediction_length = FORECAST_HORIZON\n  lookback_length = 2 * FORECAST_HORIZON\n\nComputational engine: gluonts_nbeats \n\n\n\n\nN-Beats Model 5 - Default (epochs:5;loss fn:MASE)\n\n\nCode\n# Model 5: N-BEATS, loss function:MASE, Reduce Epochs 2\n\nmodel_spec_nbeats_5 <- nbeats(\n  id                = \"route\",\n  freq              = \"M\",\n  prediction_length = FORECAST_HORIZON,\n\n  lookback_length   = 2 * FORECAST_HORIZON,\n  epochs            = 5,\n  loss_function     = \"MASE\"\n\n\n) %>%\n  set_engine(\"gluonts_nbeats\")\n\n\nwflw_fit_nbeats_5 <- workflow() %>%\n  add_model(model_spec_nbeats_5) %>%\n  add_recipe(recipe_spec_gluon) %>%\n  fit(training(splits))\n\nmodel_spec_nbeats_5\n\n\nN-BEATS Model Specification (regression)\n\nMain Arguments:\n  id = route\n  freq = M\n  prediction_length = FORECAST_HORIZON\n  lookback_length = 2 * FORECAST_HORIZON\n  loss_function = MASE\n  epochs = 5\n\nComputational engine: gluonts_nbeats \n\n\n\n\nN-Beats Model 6 - Default (ensemble; epochs:5; loss fn:MASE)\n\n\nCode\n# Model 6: N-BEATS, Model 5 ensemble\n\nmodel_spec_nbeats_6 <- nbeats(\n  id                    = \"route\",\n  freq                  = \"M\",\n  prediction_length     = FORECAST_HORIZON,\n\n  lookback_length       = c(FORECAST_HORIZON, 2 * FORECAST_HORIZON),\n  epochs                = 5,\n  num_batches_per_epoch = 35,\n  loss_function         = \"MASE\",\n\n  bagging_size          = 2\n\n\n) %>%\n  set_engine(\"gluonts_nbeats_ensemble\")\n\n\nwflw_fit_nbeats_6 <- workflow() %>%\n  add_model(model_spec_nbeats_6) %>%\n  add_recipe(recipe_spec_gluon) %>%\n  fit(training(splits))\n\nmodel_spec_nbeats_6\n\n\nN-BEATS Model Specification (regression)\n\nMain Arguments:\n  id = route\n  freq = M\n  prediction_length = FORECAST_HORIZON\n  lookback_length = c(FORECAST_HORIZON, 2 * FORECAST_HORIZON)\n  loss_function = MASE\n  bagging_size = 2\n  epochs = 5\n  num_batches_per_epoch = 35\n\nComputational engine: gluonts_nbeats_ensemble"
  },
  {
    "objectID": "posts/aust_domestic_flights/index.html#introduction",
    "href": "posts/aust_domestic_flights/index.html#introduction",
    "title": "Australian Domestic Flights",
    "section": "1 Introduction",
    "text": "1 Introduction\nThis analysis summarises Australian domestic flight volumes and on-time performance (OTP) issues by airline over time.\nIt has been prepared mainly to get more used to Quarto, and comprises:\n\nInitial data load and preprocessing - not shown\nDomestic Flight Analysis - This document\nGlobal Flight Analysis - Next document\nForecasting - to come\n\n\n\nCode\nlibrary(tidyverse)\n\n\nlibrary(scales)\n\nlibrary(leaflet)\nlibrary(leaflet.minicharts)\n\n\nlibrary(janitor)\nlibrary(plotly)\nlibrary(gganimate)\n\nlibrary(dygraphs)\n\n\noptions(scipen = 999)"
  },
  {
    "objectID": "posts/aust_domestic_flights/index.html#data-sources",
    "href": "posts/aust_domestic_flights/index.html#data-sources",
    "title": "Australian Domestic Flights",
    "section": "2 Data Sources",
    "text": "2 Data Sources\nData is sourced from https://data.gov.au/ site, specific datasets used being:\n\nTop routes\nIndustry Totals\nOn-Time-Performance - Domestic\n\n(need to add notes/refs)\n\n\nCode\ntop_routes_prep_df <- read_rds(\"./artifacts/top_routes_prep_df.rds\")\nind_totals_prep_df <- read_rds(\"./artifacts/ind_totals_prep_df.rds\")\ndom_cargo_prep_df  <- read_rds(\"./artifacts/dom_cargo_prep_df.rds\")\notp_prep_df        <- read_rds(\"./artifacts/otp_prep_df.rds\")\n\nlatest_date        <- max(top_routes_prep_df$date)\n\n\notp_prep_df <- otp_prep_df %>% \n  mutate(across(airline,str_replace,'QantasLink','Qantas')) %>% \n  mutate(across(airline,str_replace,\"Virgin Australia - Atr/F100 Operations\",\"Virgin Australia\")) %>% \n  mutate(across(airline,str_replace,\"Virgin Australia Regional Airlines\",\"Virgin Australia\"))"
  },
  {
    "objectID": "posts/aust_domestic_flights/index.html#exploratory-data-analysis",
    "href": "posts/aust_domestic_flights/index.html#exploratory-data-analysis",
    "title": "Australian Domestic Flights",
    "section": "3 Exploratory Data Analysis",
    "text": "3 Exploratory Data Analysis\n\n3.1 All Major Routes - Total Monthly Pax\nTotal monthly passenger numbers :\n\n\nCode\ng <- ind_totals_prep_df %>% \n  #filter(year>2010) %>% \n  ggplot(aes(x=date,y=passenger_trips))+\n  geom_line()+\n  scale_y_continuous(labels=scales::comma)+\n  scale_x_date(date_breaks = \"2 year\",date_labels = \"%y\")+\n  labs(title = \"Australian Domestic Flight History\", x=\"Year\", y = \"Passenger Numbers (monthly)\")+\n  theme_bw()\nggplotly(g)\n\n\n\n\n\n\nKey “points of interest”:\n\n1987 pilot strike\n2000 Olympic Games\nCOVID!!!!\n\nSeasonality and trend both also clearly show, at least until covid.\nWe can break this down by top 10 routes (only tracked 2-way):\n\n\n3.2 Top 10 Routes - Monthly Pax by O/D City Pairs\n\n\nCode\n## * Top routes ----\ntop_routes <- top_routes_prep_df %>% \n  group_by(route,date=max(date)) %>% \n  summarise(passenger_trips = sum(passenger_trips)) %>% \n  ungroup() %>%\n  slice_max(passenger_trips, n=10) %>% \n  select(route) %>% \n  pull() %>% \n  as.character()\n  \n\ng1 <- top_routes_prep_df %>% \n  filter(route %in% top_routes) %>%\n  mutate(route = factor(route,levels=top_routes)) %>% \n  ggplot(aes(date,passenger_trips,colour =route))+\n  geom_line()+\n  scale_y_continuous(labels=scales::comma)+\n  scale_x_date(date_breaks = \"2 year\",date_labels = \"%y\")+\n  scale_colour_discrete(name  =\"Route - 2way\")+\n  labs(title = \"Australian Domestic Flight History - Top10 (2-way) Routes\", x=\"by Month\", y = \"Passenger Numbers (monthly)\")+\n  #theme_bw() +\n  theme(legend.position=\"bottom\")\nggplotly(g1)\n\n\n\n\n\n\n\n\n3.3 All Routes - Total Monthly Pax - Mapped\nFollowing map shows all routes in 2019 (precovid), thickness of line representiing pax volumes for the year (in this case with a moving monthly timeline to show impact of covid - but does not really work that well). As width of line signifies volumes of passenger trips, Sydney-Melbourne route clearly has thickest line!\n\n\nCode\n## * Routes Mapped - Leaflet ----\n\ntop_routes_short <- top_routes_prep_df %>%\n  filter(year>2019) \n  # group_by(year,city1,city2,city1_lng,city1_lat,city2_lng,city2_lat) %>% \n  # summarise(passenger_trips = sum(passenger_trips))\n\n  leaflet() %>% \n    addProviderTiles(providers$OpenTopoMap) %>% \n    addTiles() %>%\n    #addProviderTiles(providers$Esri.WorldStreetMap) %>% \n  addFlows(\n    top_routes_short$city1_lng, \n    top_routes_short$city1_lat, \n    top_routes_short$city2_lng, \n    top_routes_short$city2_lat,\n    flow = top_routes_short$passenger_trips,\n    time = top_routes_short$date,\n    dir = 0,\n    minThickness = .1,\n    maxThickness = 5,\n    popupOptions = list(closeOnClick = FALSE, autoClose = FALSE)\n  )\n\n\n\n\n\n\n\n\n3.4 On Time Performance (OTP) - All Domestic Routes\nPerformance Metric: OTP_issues_pct = (delayed arrivals + cancelled flights)/ Total Sectors Scheduled.\nAs this metric is based on arrival delays and canellations as a percentage of scheduled services, the higher the number, then the worse the performance!\n\n\nCode\notp_issues_all <- otp_prep_df %>% \n  filter(airline == \"All Airlines\") %>% \n  group_by(date) %>% \n  summarise(sectors_scheduled = sum(sectors_scheduled),\n            arrivals_delayed = sum(arrivals_delayed),\n            cancellations = sum(cancellations),\n            otp_issues_num = sum(otp_issues_num)\n            ) %>% \n  mutate(otp_issues_pct = (arrivals_delayed+cancellations)/sectors_scheduled)\n\ng_opt <- otp_issues_all %>% \n  ggplot(aes(date,otp_issues_pct))+\n  geom_line()+\n  geom_smooth(method=\"loess\")+\n  scale_y_continuous(labels=scales::percent)+\n  theme_bw()\n\nggplotly(g_opt)\n\n\n\n\n\n\nWhile the ‘loess’ smoother indicates a continual worsening of performance, most recent reporting perhaps indicates the airlines are starting to address OTP issues.\n\n\n3.5 OTP - By Airline over Time\nThis graph just focuses on the main 3 domestic carriers.\n\n\nCode\notp_issues_airline <- otp_prep_df %>% \n  filter(airline %in% c(\"Jetstar\",\"Qantas\",\"Virgin Australia\"),\n         year > 2019\n         ) %>%\n  \n  mutate(airline = str_to_title(airline)) %>% \n  group_by(date,airline) %>% \n  summarise(sectors_scheduled = sum(sectors_scheduled),\n            arrivals_delayed  = sum(arrivals_delayed),\n            cancellations     = sum(cancellations),\n            otp_issues_num    = sum(otp_issues_num)\n            ) %>% \n  mutate(arrivals_delayed_pct = arrivals_delayed/sectors_scheduled,\n         cacellations_pct     = cancellations/sectors_scheduled,\n         otp_issues_total_pct = (arrivals_delayed+cancellations)/sectors_scheduled ) %>% \n  select(date,airline,ends_with(\"pct\")) %>% \n  pivot_longer(cols = ends_with(\"pct\"), names_to = \"otp_metric\",values_to = \"pct_issues\")\n\ng_otp_issues_airline <- otp_issues_airline %>% \n  ggplot(aes(date,pct_issues,colour = airline))+\n  geom_line()+\n  #geom_smooth(method=\"loess\")+\n  scale_x_date(date_breaks = \"3 month\",date_labels = \"%m/%y\")+\n  scale_y_continuous(labels=scales::percent)+\n  xlab(\"Month\")+\n  ylab(\"Pct of Monthly Scheduled Services\") +\n  theme_bw()+\n  theme(legend.position =  \"bottom\")+\n  facet_wrap(~otp_metric,ncol=1)\n\n\nggplotly(g_otp_issues_airline)\n\n\n\n\n\n\nNote:\n\ncancellations in initial covid period\nUpswing in OTP issues (mainly non-cancellations) in more recent days\nJetstar worst performer, although all 3 airlines guilty of worsening performance.\nSigns of improvement in most recent reports.\n\nTo highlight the y-o-y changes:\n\n\nCode\nyear_select <- 2016\n\notp_issues_airline2 <- otp_prep_df %>% \n  filter(airline != \"All Airlines\",\n         year > year_select\n         ) %>%\n  mutate(airline = str_to_title(airline)) %>% \n  group_by(year,airline) %>% \n  summarise(sectors_scheduled = sum(sectors_scheduled),\n            arrivals_delayed = sum(arrivals_delayed),\n            cancellations = sum(cancellations),\n            otp_issues_num = sum(otp_issues_num)\n            ) %>% \n  mutate(otp_issues_pct = (arrivals_delayed+cancellations)/sectors_scheduled ) %>% \n  mutate(airline = fct_reorder(airline,otp_issues_pct))\n\n\ng_otp_issues_airline_2 <- otp_issues_airline2 %>% \n  filter(airline %in%c(\"Jetstar\",\"Virgin Australia\", \"Qantas\")) %>% \n  ggplot(aes(year,otp_issues_pct,fill = year))+\n  geom_col()+\n  geom_text(aes(label = percent(otp_issues_pct,accuracy = .1)),\n            hjust = 1,\n            colour = \"white\")+\n  #coord_flip()+\n  scale_y_continuous(labels=scales::percent)+\n  #scale_x_discrete(breaks = 0)+\n  ylab(\"OTP Issues/Scheduled Services\")+\n  xlab(\"\")+\n  labs(title=\"On-Time Performance Issues by Year\",\n       subtitle = \"as pct of Scheduled Services\")+\n  theme_bw()+\n  \n  coord_flip()+\n  facet_wrap(vars(airline),dir = \"v\")\n\ng_otp_issues_airline_2\n\n\n\n\n\nCode\n#ggplotly(g_otp_issues_airline_2)"
  },
  {
    "objectID": "posts/aust_international_flights/index.html#introduction",
    "href": "posts/aust_international_flights/index.html#introduction",
    "title": "Australian International Flights",
    "section": "1 Introduction",
    "text": "1 Introduction\nThis analysis summarises Australian international flight volumes over time.\nIt has been prepared mainly to get more used to Quarto, and comprises:\n\nInitial data load and preprocessing - not shown\nDomestic Flight Analysis - previous post\nGlobal Flight Analysis - this document\nForecasting - to come\n\nThis is a pretty brief look - might try it in Shiny where it will probably come together better. The biggest challenge was the great circle mapping, the solution to which was pretty much right in front of me on ‘the R Graph Gallery’…"
  },
  {
    "objectID": "posts/aust_international_flights/index.html#packages-and-data",
    "href": "posts/aust_international_flights/index.html#packages-and-data",
    "title": "Australian International Flights",
    "section": "2 Packages and Data",
    "text": "2 Packages and Data\nLoad packages:\n\n\nCode\n#| echo: false\n#| message: false\n#| warning: false\n\nlibrary(tidyverse)\nlibrary(scales)\n\nlibrary(maps)\nlibrary(geosphere)\n\nlibrary(janitor)\nlibrary(plotly)\nlibrary(gganimate)\n\n\nLoad pre-processed data:\n\n\nCode\n#| echo: false\n\nintl_flights_seats_prep_df <- read_rds(\"./artifacts/intl_flights_seats_prep_df.rds\")\nintl_flights_city_pairs_prep_df <- read_rds(\"./artifacts/intl_flights_city_pairs_prep_df.rds\")\nintl_country_of_port_prep_df <- read_rds(\"./artifacts/intl_country_of_port_prep_df.rds\")"
  },
  {
    "objectID": "posts/aust_international_flights/index.html#exploratory-data-analysis",
    "href": "posts/aust_international_flights/index.html#exploratory-data-analysis",
    "title": "Australian International Flights",
    "section": "3 Exploratory Data Analysis",
    "text": "3 Exploratory Data Analysis\n\n3.1 All Major Routes - Total Monthly Pax\nTotal monthly passenger numbers , which shows the cliff it went off, but also some solid signs of rebound:\n\n\nCode\n## * Industry Volumes by Time ----\ncity_pair_totals <- intl_flights_city_pairs_prep_df %>% \n  group_by(date) %>% \n  summarise(passengers_total =sum(passengers_total))\n  \ng <- city_pair_totals %>% \n  #filter(year>2010) %>% \n  ggplot(aes(x=date,y=passengers_total))+\n  geom_line()+\n  scale_y_continuous(labels=scales::comma)+\n  scale_x_date(date_breaks = \"2 year\",date_labels = \"%y\")+\n  labs(title = \"Australian Global Flight History\", x=\"Year\", y = \"Passenger Numbers (monthly)\")+\n  theme_bw()\nggplotly(g)"
  },
  {
    "objectID": "posts/aust_international_flights/index.html#top-routes",
    "href": "posts/aust_international_flights/index.html#top-routes",
    "title": "Australian International Flights",
    "section": "4 Top Routes",
    "text": "4 Top Routes\nYep, that will hurt:\n\n\nCode\ntop_totals <- intl_flights_city_pairs_prep_df %>% \n  filter(year ==2019) %>% \n  group_by(year, route) %>% \n  summarise(passengers_total =sum(passengers_total)) %>% \n  ungroup() %>%\n  slice_max(passengers_total, n=20) %>% \n  select(route) %>% \n  pull() %>% \n  as.character()\n\ng1 <- intl_flights_city_pairs_prep_df %>% \n  filter(route %in% top_totals,year > 2014) %>%\n  mutate(route = factor(route,levels=top_totals)) %>% \n  ggplot(aes(date,passengers_total,colour =route))+\n  geom_line()+\n  scale_y_continuous(labels=scales::comma)+\n  scale_x_date(date_breaks = \"2 year\",date_labels = \"%y\")+\n  scale_colour_discrete(name  =\"Route - 2way\")+\n  labs(title = \"Australian International Flight History - Top (2-way) Routes\", x=\"by Month\", y = \"Passenger Numbers (monthly)\")+\n  theme_bw()\n  \nggplotly(g1)"
  },
  {
    "objectID": "posts/aust_international_flights/index.html#top-destinations",
    "href": "posts/aust_international_flights/index.html#top-destinations",
    "title": "Australian International Flights",
    "section": "5 Top Destinations",
    "text": "5 Top Destinations\nWhich tells the same story all over again!\n\n\nCode\ndestination_df <- intl_flights_city_pairs_prep_df %>% \n  group_by(intl_city_country,international_city,year) %>% \n  summarise(\n    passengers_total = sum(passengers_total),\n    freight_total_tonnes = sum(freight_total_tonnes),\n    mail_total_tonnes = sum(mail_total_tonnes)\n    ) %>% \n  ungroup()\n\ntop_dest_unique <- destination_df %>%\n  group_by(international_city) %>% \n  summarise(passengers_total = sum(passengers_total)) %>% \n  ungroup() %>% \n  slice_max(passengers_total, n=10) %>% \n  select(international_city) %>% \n  unique() %>% \n  pull() %>% \n  as.character()\n\n\ng2 <- destination_df %>% \n  filter(international_city %in% top_dest_unique ,year > 2016) %>%\n  ggplot(aes(international_city,passengers_total))+\n  geom_col()+\n  scale_y_continuous(labels=scales::comma)+\n  scale_colour_discrete(name  =\"Route - 2way\")+\n  labs(title = \"Australian International Flight History - Top Destinations\", x=\"\", y = \"Passenger Numbers pa\")+\n  theme_bw() +\n  facet_wrap(~year,ncol = 1,dir = \"v\",scales = \"free_y\") +\n  coord_flip()\n\ng2"
  },
  {
    "objectID": "posts/aust_international_flights/index.html#mapping---aust-international-routes-2019",
    "href": "posts/aust_international_flights/index.html#mapping---aust-international-routes-2019",
    "title": "Australian International Flights",
    "section": "6 Mapping - Aust International Routes 2019",
    "text": "6 Mapping - Aust International Routes 2019\nUsing 2019, just because it is pre-covid. Could use later years and will in a more dynamic environment.\nSetting up required code:\n\n\nCode\ntop_routes <- intl_flights_city_pairs_prep_df %>% \n  filter(year ==2019) %>% \n  group_by(route) %>% \n  summarise(passengers_total = sum(passengers_total)) %>% \n  ungroup() %>%\n  slice_max(passengers_total, n=150) %>% \n  select(route) %>% \n  pull() %>% \n  as.character()\n\nroutes <- intl_flights_city_pairs_prep_df %>% \n  filter(route %in% top_routes) %>% \n  select(route,australian_city, international_city,\n         aust_city_lat,aust_city_lng,\n         intl_city_lat,intl_city_lng) %>% \n  unique()\n\n\nAnd the resulting map:\n\n\nCode\n# A function to plot routes\nplot_routes=function( dep_lon, dep_lat, arr_lon, arr_lat, ...){\n  inter <- gcIntermediate(c(dep_lon, dep_lat), c(arr_lon, arr_lat), n=50, addStartEnd=TRUE, breakAtDateLine=F)             \n  inter=data.frame(inter)\n  diff_of_lon=abs(dep_lon) + abs(arr_lon)\n  if(diff_of_lon > 180){\n    lines(subset(inter, lon>=0), ...)\n    lines(subset(inter, lon<0), ...)\n  }else{\n    lines(inter, ...)\n  }\n}\n\n# background map\npar(mar=c(0,0,0,0))\nmap('world',col=\"gray\", fill=TRUE, bg=\"white\", \n    lwd=0.05,border=0, mar=rep(0,4),ylim=c(-75,75) )\ntitle(\"International Flight Routes - Australia 2019\")\n\n# add all selected routes:\nfor(i in 1:nrow(routes)){\n  plot_routes(routes$aust_city_lng[i], \n              routes$aust_city_lat[i], \n              routes$intl_city_lng[i], \n              routes$intl_city_lat[i], \n              col=\"blue\", lwd=1)\n}\n\n# add points and names of cities\npoints(x=routes$intl_city_lng, \n       y=routes$intl_city_lat, col=\"slateblue\", cex=2, pch=20)\n\n\n\n\n\nThe above map is a bit(!) overloaded, because I left all routes in (to pick up London, New York etc). We can play with that in a more dynamic environment, probably Shiny (or even Power Bi)\nAs mentioned, the great circle mapping was a bit of a pain to do, but actually quite simple once you find the correct approach. I will improve this as time permits!"
  },
  {
    "objectID": "posts/forecasting_with_h20/index.html#introduction",
    "href": "posts/forecasting_with_h20/index.html#introduction",
    "title": "Forecasting Flight Passengers using H20",
    "section": "1 Introduction",
    "text": "1 Introduction\nThis analysis is one section of a multi-part set of posts looking at forecasting on domestic Australian flight volumes by route in the period prior to when covid largely shut the industry down. Its intention is just to provide me with examples over the main models to save time on future projects.It is split into:\n\nSome pre analysis (basic EDA analysis is not covered as already included in previous posts)\n‘Sequence’ style models - ARIMA etc\nML style models - XGBoost etc including nesting and ensembling\nDeep learning models (GLuonTS etc)\nSummary of conclusions\n\nThis post is in relation to the part 4 - focussing on H20, usimg the modeltime package to connect. This post is actually using ML models, but will be expanded to include deep learning approaches\nit uses the modeltime H20 documentation"
  },
  {
    "objectID": "posts/forecasting_with_h20/index.html#load-libraries",
    "href": "posts/forecasting_with_h20/index.html#load-libraries",
    "title": "Forecasting Flight Passengers using H20",
    "section": "2 Load Libraries",
    "text": "2 Load Libraries\n\n\nCode\nlibrary(tidymodels)\nlibrary(modeltime.h2o)\nlibrary(tidyverse)\nlibrary(timetk)"
  },
  {
    "objectID": "posts/forecasting_with_h20/index.html#load-data",
    "href": "posts/forecasting_with_h20/index.html#load-data",
    "title": "Forecasting Flight Passengers using H20",
    "section": "3 Load Data",
    "text": "3 Load Data\nAll data is loaded, except Brisbane-Emerald route is excluded as it caused problems, probably due to lack of data.\nThe top 10 routes are shown in order of overall patronage\n\n\nCode\ntop_x   <- 10\nstart   <- \"2001-01-01\"\nend     <- \"2019-07-01\"\nhorizon <-  \"1 year\"\n\ntop_routes_prep_df <- read_rds(\"./artifacts/top_routes_prep_df.rds\") %>%  \n  filter(route != \"BRISBANE-EMERALD\") %>% #dodgy for some reason\n  #rowid_to_column(var = \"id\") %>% \n  select(date,route,passenger_trips)\n\ntopx <- top_routes_prep_df %>% \n  group_by(route) %>% \n  summarise(passenger_trips = sum(passenger_trips)) %>% \n  ungroup() %>% \n  slice_max(passenger_trips, n=top_x) %>% \n  arrange(desc(passenger_trips)) %>% \n  select(route) %>% \n  pull() %>% \n  as.character()\n\ntopx %>% knitr::kable()\n\n\n\n\n\nx\n\n\n\n\nMELBOURNE-SYDNEY\n\n\nBRISBANE-SYDNEY\n\n\nBRISBANE-MELBOURNE\n\n\nGOLD COAST-SYDNEY\n\n\nADELAIDE-MELBOURNE\n\n\nADELAIDE-SYDNEY\n\n\nMELBOURNE-PERTH\n\n\nPERTH-SYDNEY\n\n\nMELBOURNE-GOLD COAST\n\n\nBRISBANE-CAIRNS"
  },
  {
    "objectID": "posts/forecasting_with_h20/index.html#graph-plots-for-top-routes-to-save-space",
    "href": "posts/forecasting_with_h20/index.html#graph-plots-for-top-routes-to-save-space",
    "title": "Forecasting Flight Passengers using H20",
    "section": "4 Graph Plots for top routes (to save space)",
    "text": "4 Graph Plots for top routes (to save space)\nThese graphs include full history. Covid period will be excluded for future analysis (bit hard to predict that little black swan).\n\n\nCode\ntop_routes_prep_df %>% \n  filter(route %in% topx) %>%\n  group_by(route) %>% \n  plot_time_series(\n    .date_var    = date,\n    .value       = passenger_trips/1000,\n    .facet_ncol  = 2,\n    .smooth      = F,\n    .interactive = F,\n    .title       = \"Passenger Trips(000) by Route\"\n  )"
  },
  {
    "objectID": "posts/forecasting_with_h20/index.html#split-data",
    "href": "posts/forecasting_with_h20/index.html#split-data",
    "title": "Forecasting Flight Passengers using H20",
    "section": "5 Split data",
    "text": "5 Split data\nData filtered to targetted period and then is split into trainig and test sets. Test set is 12 months.\n\n\nCode\ndata_tbl <- top_routes_prep_df %>% \n  filter(date %>% between_time(start,end))\n  \n\nsplits <- time_series_split(data_tbl, assess = horizon, cumulative = TRUE)\n\nrecipe_spec <- recipe(passenger_trips ~ ., data = training(splits)) %>%\n    step_timeseries_signature(date) \n\ntrain_tbl <- training(splits) %>% bake(prep(recipe_spec), .)\ntest_tbl  <- testing(splits)  %>% bake(prep(recipe_spec), .)\n\n#min(test_tbl$date)\nsplits\n\n\n<Analysis/Assess/Total>\n<12751/828/13579>"
  },
  {
    "objectID": "posts/forecasting_with_h20/index.html#connect-to-h20",
    "href": "posts/forecasting_with_h20/index.html#connect-to-h20",
    "title": "Forecasting Flight Passengers using H20",
    "section": "6 Connect to H20",
    "text": "6 Connect to H20\n\n\nCode\n# Initialize H2O\nh2o.init(\n    nthreads = -1,\n    ip       = 'localhost',\n    port     = 54321\n)\n\n\n Connection successful!\n\nR is connected to the H2O cluster: \n    H2O cluster uptime:         2 hours 52 minutes \n    H2O cluster timezone:       Australia/Brisbane \n    H2O data parsing timezone:  UTC \n    H2O cluster version:        3.38.0.3 \n    H2O cluster version age:    1 month and 7 days  \n    H2O cluster name:           H2O_started_from_R_spinb_yru550 \n    H2O cluster total nodes:    1 \n    H2O cluster total memory:   3.75 GB \n    H2O cluster total cores:    8 \n    H2O cluster allowed cores:  8 \n    H2O cluster healthy:        TRUE \n    H2O Connection ip:          localhost \n    H2O Connection port:        54321 \n    H2O Connection proxy:       NA \n    H2O Internal Security:      FALSE \n    R Version:                  R version 4.2.2 (2022-10-31 ucrt) \n\n\nCode\n# Optional - Set H2O No Progress to remove progress bars\nh2o.no_progress()"
  },
  {
    "objectID": "posts/forecasting_with_h20/index.html#set-up-model-specification",
    "href": "posts/forecasting_with_h20/index.html#set-up-model-specification",
    "title": "Forecasting Flight Passengers using H20",
    "section": "7 Set up Model Specification",
    "text": "7 Set up Model Specification\n\n\nCode\nmodel_spec <- automl_reg(mode = 'regression') %>%\n    set_engine(\n         engine                     = 'h2o',\n         max_runtime_secs           = 60*60, \n         max_runtime_secs_per_model = 60,\n         max_models                 = 10,\n         nfolds                     = 5,\n         #exclude_algos              = c(\"DeepLearning\"),\n         verbosity                  = NULL,\n         seed                       = 786\n    ) \n\nmodel_spec\n\n\nH2O AutoML Model Specification (regression)\n\nEngine-Specific Arguments:\n  max_runtime_secs = 60 * 60\n  max_runtime_secs_per_model = 60\n  max_models = 10\n  nfolds = 5\n  verbosity = NULL\n  seed = 786\n\nComputational engine: h2o"
  },
  {
    "objectID": "posts/forecasting_with_h20/index.html#train-and-fit",
    "href": "posts/forecasting_with_h20/index.html#train-and-fit",
    "title": "Forecasting Flight Passengers using H20",
    "section": "8 Train and Fit",
    "text": "8 Train and Fit\n\n\nCode\nmodel_fitted <- model_spec %>%\n    fit(passenger_trips ~ ., data = train_tbl)\n\n\n                                                 model_id     rmse      mse\n1    StackedEnsemble_AllModels_1_AutoML_4_20221230_153853 4623.464 21376415\n2 StackedEnsemble_BestOfFamily_1_AutoML_4_20221230_153853 4736.108 22430716\n3                          GBM_5_AutoML_4_20221230_153853 4738.926 22457424\n4                          GBM_3_AutoML_4_20221230_153853 5017.286 25173157\n5                          GBM_4_AutoML_4_20221230_153853 5085.078 25858014\n6                          GBM_1_AutoML_4_20221230_153853 5603.475 31398934\n       mae rmsle mean_residual_deviance\n1 2625.410   NaN               21376415\n2 2789.898   NaN               22430716\n3 2787.829   NaN               22457424\n4 2800.649   NaN               25173157\n5 2843.318   NaN               25858014\n6 2889.674   NaN               31398934\n\n[12 rows x 6 columns] \n\n\nCode\nmodel_fitted \n\n\nparsnip model object\n\n\nH2O AutoML - Stackedensemble\n--------\nModel: Model Details:\n==============\n\nH2ORegressionModel: stackedensemble\nModel ID:  StackedEnsemble_AllModels_1_AutoML_4_20221230_153853 \nNumber of Base Models: 10\n\nBase Models (count by algorithm type):\n\ndeeplearning          drf          gbm          glm \n           1            2            6            1 \n\nMetalearner:\n\nMetalearner algorithm: glm\nMetalearner cross-validation fold assignment:\n  Fold assignment scheme: AUTO\n  Number of folds: 5\n  Fold column: NULL\nMetalearner hyperparameters: \n\n\nH2ORegressionMetrics: stackedensemble\n** Reported on training data. **\n\nMSE:  3217224\nRMSE:  1793.662\nMAE:  1164.881\nRMSLE:  NaN\nMean Residual Deviance :  3217224\n\n\n\nH2ORegressionMetrics: stackedensemble\n** Reported on cross-validation data. **\n** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **\n\nMSE:  21376415\nRMSE:  4623.464\nMAE:  2625.41\nRMSLE:  NaN\nMean Residual Deviance :  21376415\n\n\nCross-Validation Metrics Summary: \n                                        mean                   sd\nmae                              2620.668000            54.265266\nmean_residual_deviance       21332104.000000       1110405.600000\nmse                          21332104.000000       1110405.600000\nnull_deviance          24041516000000.000000 1477628900000.000000\nr2                                  0.997734             0.000133\nresidual_deviance         54455750000.000000    4141945600.000000\nrmse                             4617.392000           121.426810\nrmsle                                     NA             0.000000\n                                  cv_1_valid            cv_2_valid\nmae                              2665.413000           2617.336000\nmean_residual_deviance       22474568.000000       21760620.000000\nmse                          22474568.000000       21760620.000000\nnull_deviance          24430357000000.000000 22966381000000.000000\nr2                                  0.997614              0.997571\nresidual_deviance         58299027000.000000    55772467000.000000\nrmse                             4740.735000           4664.828000\nrmsle                                     NA                    NA\n                                  cv_3_valid            cv_4_valid\nmae                              2647.775100           2644.215000\nmean_residual_deviance       21071190.000000       21798888.000000\nmse                          21071190.000000       21798888.000000\nnull_deviance          25562297000000.000000 25167888000000.000000\nr2                                  0.997853              0.997777\nresidual_deviance         54869380000.000000    55935947000.000000\nrmse                             4590.336400           4668.927700\nrmsle                                     NA                    NA\n                                  cv_5_valid\nmae                              2528.600600\nmean_residual_deviance       19555256.000000\nmse                          19555256.000000\nnull_deviance          22080662000000.000000\nr2                                  0.997853\nresidual_deviance         47401940000.000000\nrmse                             4422.132300\nrmsle                                     NA"
  },
  {
    "objectID": "posts/forecasting_with_h20/index.html#leaderboard",
    "href": "posts/forecasting_with_h20/index.html#leaderboard",
    "title": "Forecasting Flight Passengers using H20",
    "section": "9 Leaderboard",
    "text": "9 Leaderboard\n\n\nCode\nleaderboard_tbl <- automl_leaderboard(model_fitted) \n\nleaderboard_tbl %>% knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\nmodel_id\nrmse\nmse\nmae\nrmsle\nmean_residual_deviance\n\n\n\n\nStackedEnsemble_AllModels_1_AutoML_4_20221230_153853\n4623.464\n21376415\n2625.410\nNA\n21376415\n\n\nStackedEnsemble_BestOfFamily_1_AutoML_4_20221230_153853\n4736.108\n22430716\n2789.898\nNA\n22430716\n\n\nGBM_5_AutoML_4_20221230_153853\n4738.926\n22457424\n2787.829\nNA\n22457424\n\n\nGBM_3_AutoML_4_20221230_153853\n5017.286\n25173157\n2800.649\nNA\n25173157\n\n\nGBM_4_AutoML_4_20221230_153853\n5085.078\n25858014\n2843.318\nNA\n25858014\n\n\nGBM_1_AutoML_4_20221230_153853\n5603.475\n31398934\n2889.674\nNA\n31398934\n\n\nGBM_2_AutoML_4_20221230_153853\n5633.260\n31733613\n2944.514\nNA\n31733613\n\n\nGBM_grid_1_AutoML_4_20221230_153853_model_1\n6170.972\n38080898\n3323.607\nNA\n38080898\n\n\nDeepLearning_1_AutoML_4_20221230_153853\n15622.131\n244050990\n11268.303\nNA\n244050990\n\n\nDRF_1_AutoML_4_20221230_153853\n23504.606\n552466523\n12546.398\n2.691383\n552466523\n\n\nXRT_1_AutoML_4_20221230_153853\n82152.863\n6749092971\n48764.480\n3.175682\n6749092971\n\n\nGLM_1_AutoML_4_20221230_153853\n97131.095\n9434449699\n56375.288\n3.267512\n9434449699\n\n\n\n\n\nSo AutoML and stacked ensembles thereof lead the way, deep learning approaches not really ranking!\nNow,\n\n\nCode\nmodeltime_tbl <- modeltime_table(\n    model_fitted\n) \n\nmodeltime_tbl\n\n\n# Modeltime Table\n# A tibble: 1 × 3\n  .model_id .model   .model_desc                 \n      <int> <list>   <chr>                       \n1         1 <fit[+]> H2O AUTOML - STACKEDENSEMBLE"
  },
  {
    "objectID": "posts/forecasting_with_h20/index.html#calibrate---test-data",
    "href": "posts/forecasting_with_h20/index.html#calibrate---test-data",
    "title": "Forecasting Flight Passengers using H20",
    "section": "10 Calibrate - test data",
    "text": "10 Calibrate - test data\n\n\nCode\ncalibration_tbl <- modeltime_tbl %>%\n  modeltime_calibrate(\n    new_data = test_tbl,\n    id      = \"route\")\n\nforecast_test_tbl <- calibration_tbl %>% \n    modeltime_forecast(\n        new_data    = test_tbl,\n        actual_data = data_tbl,\n        keep_data   = TRUE,\n        conf_by_id  = T\n    ) %>%\n    group_by(route)\n\n#calibration_tbl"
  },
  {
    "objectID": "posts/forecasting_with_h20/index.html#graph-forecast---top-10-routes",
    "href": "posts/forecasting_with_h20/index.html#graph-forecast---top-10-routes",
    "title": "Forecasting Flight Passengers using H20",
    "section": "11 Graph Forecast - Top 10 Routes",
    "text": "11 Graph Forecast - Top 10 Routes\nUsing the top model in the leaderboard- Auto_ML Stacked Ensemble\n\n\nCode\nforecast_test_tbl %>%\n  filter(route %in% topx,\n         lubridate::year(date)> 2015) %>% \n    plot_modeltime_forecast(\n        .facet_ncol = 2, \n        .interactive = T,\n        .title = \"Forecast v Test Data - top 10 Routes\"\n    )\n\n\n\n\n\n\nSo forecasts look pretty good…"
  },
  {
    "objectID": "posts/forecasting_with_h20/index.html#accuracy",
    "href": "posts/forecasting_with_h20/index.html#accuracy",
    "title": "Forecasting Flight Passengers using H20",
    "section": "12 Accuracy",
    "text": "12 Accuracy\nAnother look at accuracy measures of top model only.\n\n\nCode\ncalibration_tbl %>% \n  modeltime_accuracy(metric_set = extended_forecast_accuracy_metric_set()) %>% \n  knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n.model_id\n.model_desc\n.type\nmae\nmape\nmaape\nmase\nsmape\nrmse\nrsq\n\n\n\n\n1\nH2O AUTOML - STACKEDENSEMBLE\nTest\n2277.27\nInf\n15.97232\n0.02854\n19.08186\n3768.153\n0.9988767"
  },
  {
    "objectID": "posts/forecasting_with_h20/index.html#refit-to-full-dataset",
    "href": "posts/forecasting_with_h20/index.html#refit-to-full-dataset",
    "title": "Forecasting Flight Passengers using H20",
    "section": "13 Refit to full Dataset",
    "text": "13 Refit to full Dataset\nBefore doing any predictions, we need to refit model to full dataset (train and test), so that prediction is based on most recent data!\n\n\nCode\ndata_prepared_tbl <- bind_rows(train_tbl, test_tbl)\n\nfuture_tbl <- data_prepared_tbl %>%\n    group_by(route) %>%\n    future_frame(.date_var   = date,\n                 .length_out = \"1 year\") %>%\n    ungroup()\n\nfuture_prepared_tbl <- bake(prep(recipe_spec), future_tbl)\n\nrefit_tbl <- calibration_tbl %>%\n    modeltime_refit(data_prepared_tbl)\n\n\n                                                 model_id     rmse      mse\n1    StackedEnsemble_AllModels_1_AutoML_5_20221230_154413 4478.597 20057827\n2 StackedEnsemble_BestOfFamily_1_AutoML_5_20221230_154413 4653.480 21654877\n3                          GBM_5_AutoML_5_20221230_154413 4663.906 21752021\n4                          GBM_3_AutoML_5_20221230_154413 4874.181 23757643\n5                          GBM_4_AutoML_5_20221230_154413 5018.797 25188324\n6                          GBM_1_AutoML_5_20221230_154413 5148.774 26509875\n       mae rmsle mean_residual_deviance\n1 2525.244   NaN               20057827\n2 2708.357   NaN               21654877\n3 2704.795   NaN               21752021\n4 2737.018   NaN               23757643\n5 2806.473   NaN               25188324\n6 2758.185   NaN               26509875\n\n[12 rows x 6 columns]"
  },
  {
    "objectID": "posts/forecasting_with_h20/index.html#prediction",
    "href": "posts/forecasting_with_h20/index.html#prediction",
    "title": "Forecasting Flight Passengers using H20",
    "section": "14 Prediction",
    "text": "14 Prediction\n\n\nCode\nprediction <- refit_tbl %>%\n    modeltime_forecast(\n        new_data    = future_prepared_tbl,\n        actual_data = data_prepared_tbl,\n        keep_data   = TRUE,\n        conf_by_id  = T\n    ) %>%\n    group_by(route) \n\nprediction %>% \n  filter(route %in% topx,\n         lubridate::year(date)> 2015) %>% \n  plot_modeltime_forecast(\n        .facet_ncol  = 2,\n        .interactive = T,\n        .title       = \"Passenger Trip Prediction - top 10 Routes\"\n        \n    )\n\n\n\n\n\n\nI could compare the above prediction to the actuals, and i did on the base analyses, but it is a bit pointless due to the covid cliff, which is not in the analysis. Might include it as/if data is updated and some normality resumes."
  },
  {
    "objectID": "posts/forecasting_with_h20/index.html#save-model-and-close-h2o-connection",
    "href": "posts/forecasting_with_h20/index.html#save-model-and-close-h2o-connection",
    "title": "Forecasting Flight Passengers using H20",
    "section": "15 Save Model and Close H2o connection",
    "text": "15 Save Model and Close H2o connection\n\n\nCode\nmodel_fitted %>% \n  save_h2o_model(path = \"./artifacts/h20_model1\", overwrite = TRUE)\n\n#model_h2o <- load_h2o_model(path = \"./artifacts/h20_model1\")\n\n#h2o.shutdown(prompt = FALSE)"
  },
  {
    "objectID": "posts/nested_forecasting/index.html#introduction",
    "href": "posts/nested_forecasting/index.html#introduction",
    "title": "Flight Forecast with ML Nested models",
    "section": "1 Introduction",
    "text": "1 Introduction\nThis file runs a nested forecasting approach on top Australian domestic routes (70 or so) prior to covid. This is just an exploratory exercise and remains a work in progress.\nThis analysis uses ML Models as follows\n\nAuto ARIMA\nXGBoost\nProphet Boost\nRandom Forest\nSVM\nNeural Net\nMARS\nTHIEF\n\nOnly XGBoost/ Prophet Boost have been tuned (based on Syd-Melb route only and using the same hyper-parameters as appropriate).\nThe forecast period is 12 months from end of testing, which is July 2019, so missing the Covid dive, which is still shown.\nThis will all look better in a Shiny app, coming soon…"
  },
  {
    "objectID": "posts/nested_forecasting/index.html#load-packages",
    "href": "posts/nested_forecasting/index.html#load-packages",
    "title": "Flight Forecast with ML Nested models",
    "section": "2 Load Packages",
    "text": "2 Load Packages\nTidyverse, Tidymodels, Modeltime, parallel processing etc."
  },
  {
    "objectID": "posts/nested_forecasting/index.html#load-data",
    "href": "posts/nested_forecasting/index.html#load-data",
    "title": "Flight Forecast with ML Nested models",
    "section": "3 Load Data",
    "text": "3 Load Data\nData has largely been pre-processed, and is loaded from rds files.\n\n\nCode\n#here()\ntop_routes_prep_df <- read_rds(here(\"./posts/aust_domestic_flights/artifacts/top_routes_prep_df.rds\"))\n\nstart          <- \"2001-01-01\"\nend            <- \"2019-07-01\"\nhorizon_nested <- 12\nend_precovid <- dmy(\"01-02-2020\")\n#d2 <- dmy(\"01-07-2022\")\nmax_act   <- max(top_routes_prep_df$date)\nmax_test  <- ymd(end)\nmax_pred  <- max_test %m+% months(horizon_nested)\n\n\nfilter_r       <- \"N\"\ncity           <- \"BRISBANE\"\ntop_x          <- 10\n\n# * Parallel Processing ----\nregisterDoFuture()\nn_cores <- parallel::detectCores()\nplan(\n  strategy = cluster,\n  workers  = parallel::makeCluster(n_cores)\n)"
  },
  {
    "objectID": "posts/nested_forecasting/index.html#wrangling",
    "href": "posts/nested_forecasting/index.html#wrangling",
    "title": "Flight Forecast with ML Nested models",
    "section": "4 Wrangling",
    "text": "4 Wrangling\nSome initial wrangling\n\n\nCode\nroute_prep <- top_routes_prep_df %>%\n  select(route,date,passenger_trips) %>%\n  group_by(route) %>%\n  summarise_by_time(date, .by = \"month\", passenger_trips = sum(passenger_trips)) %>%\n  pad_by_time(date, .by       = \"month\",.pad_value = 0)\n\n\ntopx <- top_routes_prep_df %>% \n  group_by(route) %>% \n  summarise(passenger_trips = sum(passenger_trips)) %>% \n  ungroup() %>% \n  slice_max(passenger_trips, n=top_x) %>% \n  arrange(desc(passenger_trips)) %>% \n  select(route) %>% \n  pull() %>% \n  as.character()\n\nroute_prep_raw <- route_prep %>%\n  filter(route %in% topx ) %>% \n  filter_by_time(.date_var    = date,.start_date = start, .end_date = end ) %>%\n  ungroup() %>%\n  mutate(passenger_trips      = log1p(passenger_trips)) %>%\n  group_by(route)\n\nroute_prep_validation <- route_prep %>%\n  filter(route %in% topx ) %>% \n  filter(date > max_test ) %>%\n  ungroup() %>%\n  mutate(passenger_trips      = log1p(passenger_trips)) %>%\n  group_by(route)\n\n\n# * Nested Time Series ----\nroute_prep_nested <- route_prep_raw %>%\n  extend_timeseries(\n    .id_var        = route,\n    .date_var      = date,\n    .length_future = horizon_nested\n\n  ) %>%\n  tk_augment_fourier(date,.periods = c(3,6,12)) %>%\n  tk_augment_lags(passenger_trips, .lags = 12) %>%\n  tk_augment_slidify(\n    passenger_trips_lag12,\n     .f       = ~mean(.x,na.rm = T),\n     .period  = c(.25 * 12,.5 * 12, 12),\n     .partial = T,\n     .align   = \"center\"\n  ) %>%\n\n  nest_timeseries(\n    .id_var        = route,\n    .length_future = horizon_nested\n  ) %>%\n  split_nested_timeseries(\n    .length_test   = horizon_nested\n  ) %>%\n  ungroup()\n  #rowid_to_column(var = \"rowid\")\n\nroute_prep_nested_train <- extract_nested_train_split(route_prep_nested)\nroute_prep_nested_test  <- extract_nested_test_split(route_prep_nested)\n\n\n\nmax_train <- max(route_prep_nested_train$date)\n\n\nTop Routes, ordered in descending order (of passengers numbers over total review period) :\n\n\nCode\ntopx %>% kable()\n\n\n\n\n \n  \n    x \n  \n \n\n  \n    MELBOURNE-SYDNEY \n  \n  \n    BRISBANE-SYDNEY \n  \n  \n    BRISBANE-MELBOURNE \n  \n  \n    GOLD COAST-SYDNEY \n  \n  \n    ADELAIDE-MELBOURNE \n  \n  \n    ADELAIDE-SYDNEY \n  \n  \n    MELBOURNE-PERTH \n  \n  \n    PERTH-SYDNEY \n  \n  \n    MELBOURNE-GOLD COAST \n  \n  \n    BRISBANE-CAIRNS"
  },
  {
    "objectID": "posts/nested_forecasting/index.html#recipes",
    "href": "posts/nested_forecasting/index.html#recipes",
    "title": "Flight Forecast with ML Nested models",
    "section": "5 Recipes",
    "text": "5 Recipes\n3 Recipes have been established:\n\nBase Recipe\nAuto Arima Recipe\nTunable XG Boost Recipe - which is not run here as hyperparameter tuning results were hard-coded into recipe to save processing time here.\n\n\n5.1 Recipe - Base\nUsed in all\n\n\nCode\n# * Base Recipe ----\nrecipe_spec <- recipe(\n  passenger_trips ~ .,\n  route_prep_nested_train) %>%\n  step_timeseries_signature(date) %>%\n  step_rm(matches(\"(.xts$)|(.iso$)|(hour)|(minute)|(second)|(am.pm)|(day)|(week)\")) %>%\n  #step_rm(date) %>%\n  step_normalize(date_index.num,date_year) %>%\n  #step_log(passenger_trips,offset = 1) %>%\n  #step_rm(date) %>%\n  step_zv(all_predictors()) %>%\n  step_impute_knn(all_predictors()) %>%\n  #step_other(route) %>%\n  step_dummy(all_nominal_predictors(), one_hot = TRUE)\n\n#recipe_spec %>% prep() %>% summary() %>% kable()\n\n\n\n\n5.2 Auto ARIMA\n\n\nCode\n# * Auto Arima Recipe ----\n\nrecipe_spec_auto_arima <- recipe(\n  passenger_trips ~ date, data = route_prep_nested_train)\n\n\nrecipe_spec_auto_arima %>% prep() %>% summary() %>% kable()\n\n\n\n\n \n  \n    variable \n    type \n    role \n    source \n  \n \n\n  \n    date \n    date \n    predictor \n    original \n  \n  \n    passenger_trips \n    double , numeric \n    outcome \n    original \n  \n\n\n\n\n\nCode\n  # + fourier_vec(date,period = 3)\n  # + fourier_vec(date,period = 6)\n  # + fourier_vec(date,period = 12)\n  # + month(date,label = T) ,\n  # data = route_prep_nested_train)"
  },
  {
    "objectID": "posts/nested_forecasting/index.html#models-and-workflows",
    "href": "posts/nested_forecasting/index.html#models-and-workflows",
    "title": "Flight Forecast with ML Nested models",
    "section": "6 Models and Workflows",
    "text": "6 Models and Workflows\n\n6.1 Auto ARIMA\n\nModel\n\n\nCode\n# ** Model----\nmodel_spec_auto_arima <- arima_reg() %>%\n  set_engine(\"auto_arima\")\n\nmodel_spec_auto_arima\n\n\nARIMA Regression Model Specification (regression)\n\nComputational engine: auto_arima \n\n\nCode\nrecipe_spec_auto_arima %>% prep() %>% summary()\n\n\n# A tibble: 2 × 4\n  variable        type      role      source  \n  <chr>           <list>    <chr>     <chr>   \n1 date            <chr [1]> predictor original\n2 passenger_trips <chr [2]> outcome   original\n\n\n\n\nWorkflow\n\n\nCode\n# ** Workflow ----\nwflw_fit_auto_arima <- workflow() %>%\n  add_model(model_spec_auto_arima) %>%\n  add_recipe(recipe_spec_auto_arima)\n\nwflw_fit_auto_arima\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: arima_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n0 Recipe Steps\n\n── Model ───────────────────────────────────────────────────────────────────────\nARIMA Regression Model Specification (regression)\n\nComputational engine: auto_arima \n\n\n\n\n\n6.2 XGBoost\nParameters for this model were selected from a hyper-parameter tuning grid search, not shown here for brevity reasons. This, and related Prophet Boost models (using same parameters) are only models yet tuned.\n\nModel\n\n\nCode\n# ** Model/Recipe ----\nmodel_spec_xgboost <- boost_tree(\n  mode           = \"regression\",\n  #copied from tuned xgboost:\n  mtry               = 20, \n  min_n              = 3,\n  tree_depth         = 4,\n  learn_rate         = 0.075,\n  loss_reduction     = 0.000001,\n  trees              = 300\n) %>%\n  set_engine(\"xgboost\")\n\nmodel_spec_xgboost \n\n\nBoosted Tree Model Specification (regression)\n\nMain Arguments:\n  mtry = 20\n  trees = 300\n  min_n = 3\n  tree_depth = 4\n  learn_rate = 0.075\n  loss_reduction = 1e-06\n\nComputational engine: xgboost \n\n\n\n\nWorkflow\n\n\nCode\n# ** workflow  ----\nwflw_fit_xgboost <- workflow() %>%\n  add_model(model_spec_xgboost) %>%\n  add_recipe(recipe_spec %>% update_role(date,new_role=\"indicator\"))\n\nwflw_fit_xgboost\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: boost_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n6 Recipe Steps\n\n• step_timeseries_signature()\n• step_rm()\n• step_normalize()\n• step_zv()\n• step_impute_knn()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nBoosted Tree Model Specification (regression)\n\nMain Arguments:\n  mtry = 20\n  trees = 300\n  min_n = 3\n  tree_depth = 4\n  learn_rate = 0.075\n  loss_reduction = 1e-06\n\nComputational engine: xgboost \n\n\n\n\n\n6.3 Prophet Boost\n\nModel\nAs mentioned, hyper parameters have been hard coded from the results a grid-search, which is not repeated in this doc, just to save time. The code is included, although all commented out:\n\n\nCode\n# * XGBoost-tuned (maybe) ----\n# ** Model/Recipe\n\n#     model_spec_xgboost_tune <- boost_tree(\n#       mode           = \"regression\",\n#       mtry           = tune(),\n#       trees          = 300,\n#       min_n          = tune(),\n#       tree_depth     = tune(),\n#       learn_rate     = tune(),\n#       loss_reduction = tune()\n#       ) %>%\n#       set_engine(\"xgboost\")\n#\n#\n# # ** ML Recipe - date as indicator ----\n# recipe_spec %>% prep() %>% summary()\n# recipe_spec_ml <- recipe_spec %>%\n#   update_role(date,new_role = \"indicator\")\n# recipe_spec_ml %>% prep() %>% summary()\n#\n#\n# # ** workflow for tuning ----\n# wflw_xgboost_tune <- workflow() %>%\n#   add_model(model_spec_xgboost_tune) %>%\n#   add_recipe(recipe_spec_ml)\n  #fit(route_prep_nested_train)\n\n\n\n# ** resamples - K-Fold -----\n\n# set.seed(123)\n# resamples_kfold <- route_prep_nested_train %>%\n#   vfold_cv()\n#\n# # unnests and graphs\n# resamples_data <- resamples_kfold %>%\n#   tk_time_series_cv_plan()\n#\n# resamples_data%>%\n#   group_by(.id) %>%\n#   plot_time_series_cv_plan(\n#     date,\n#     passenger_trips,\n#     .facet_ncol  = 2,\n#     .facet_nrow  = 2)\n\n# wflw_spec_xgboost_tune <- workflow() %>%\n#   add_model(model_spec_xgboost_tune) %>%\n#   add_recipe(recipe_spec_ml)\n\n# route_prep_nested_train %>%\n#   plot_time_series(.date_var = date,.value = passenger_trips)\n\n\n\n\n# ** tune XGBoost----\n# tic()\n# set.seed(123)\n# tune_results_xgboost <- wflw_xgboost_tune %>%\n#   tune_grid(\n#     resamples  = resamples_kfold,\n#     param_info = hardhat::extract_parameter_set_dials(wflw_xgboost_tune) %>%\n#       update(\n#         learn_rate = learn_rate(range = c(0.001,0.400), trans = NULL)\n#       ),\n#     grid = 10,\n#     control = control_grid(verbose = T, allow_par = T)\n#   )\n# toc()\n\n# ** Results\n\n# xgb_best_params <- tune_results_xgboost %>% show_best(\"rmse\", n = Inf)\n# xgb_best_params\n#\n# wflw_fit_xgboost_tune <-wflw_xgboost_tune %>%\n#   finalize_workflow(parameters = xgb_best_params %>% slice(1))\n\n\nModel with hard coded hyper-parameters:\n\n\nCode\nmodel_spec_prophet_boost <- prophet_boost(\n  seasonality_daily  =  F,\n  seasonality_weekly = F,\n  seasonality_yearly = F,\n  #copied from tuned xgboost:\n  mtry               = 20, \n  min_n              = 3,\n  tree_depth         = 4,\n  learn_rate         = 0.075,\n  loss_reduction     = 0.000001,\n  trees              = 300\n  ) %>%\n  set_engine(\"prophet_xgboost\")\n\nmodel_spec_prophet_boost\n\n\nPROPHET Regression Model Specification (regression)\n\nMain Arguments:\n  seasonality_yearly = F\n  seasonality_weekly = F\n  seasonality_daily = F\n  mtry = 20\n  trees = 300\n  min_n = 3\n  tree_depth = 4\n  learn_rate = 0.075\n  loss_reduction = 1e-06\n\nComputational engine: prophet_xgboost \n\n\n\n\nWorkflow\n\n\nCode\nwflw_fit_prophet_boost <- workflow() %>%\n  add_model(model_spec_prophet_boost) %>%\n  add_recipe(recipe_spec)\n\nwflw_fit_prophet_boost\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: prophet_boost()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n6 Recipe Steps\n\n• step_timeseries_signature()\n• step_rm()\n• step_normalize()\n• step_zv()\n• step_impute_knn()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nPROPHET Regression Model Specification (regression)\n\nMain Arguments:\n  seasonality_yearly = F\n  seasonality_weekly = F\n  seasonality_daily = F\n  mtry = 20\n  trees = 300\n  min_n = 3\n  tree_depth = 4\n  learn_rate = 0.075\n  loss_reduction = 1e-06\n\nComputational engine: prophet_xgboost \n\n\n\n\n\n6.4 SVM\n\nWorkflow\n\n\nCode\n# * SVM ----\nwflw_fit_svm <- workflow() %>%\n  add_model(\n    spec = svm_rbf(mode=\"regression\") %>%\n      set_engine(\"kernlab\")\n  ) %>%\n  add_recipe(recipe_spec%>% update_role(date,new_role=\"indicator\"))\n  # fit(route_prep_nested_train)\n\nwflw_fit_svm\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: svm_rbf()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n6 Recipe Steps\n\n• step_timeseries_signature()\n• step_rm()\n• step_normalize()\n• step_zv()\n• step_impute_knn()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRadial Basis Function Support Vector Machine Model Specification (regression)\n\nComputational engine: kernlab \n\n\n\n\n\n6.5 Random Forest\n\nWorkflow/Model\n\n\nCode\n# * RANDOM FOREST ----\nwflw_fit_rf <- workflow() %>%\n  add_model(\n    spec = rand_forest(mode=\"regression\") %>%\n      set_engine(\"ranger\")\n  ) %>%\n  add_recipe(recipe_spec%>% update_role(date, new_role=\"indicator\"))\n  # fit(route_prep_nested_train)\nwflw_fit_rf\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n6 Recipe Steps\n\n• step_timeseries_signature()\n• step_rm()\n• step_normalize()\n• step_zv()\n• step_impute_knn()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRandom Forest Model Specification (regression)\n\nComputational engine: ranger \n\n\n\n\n\n6.6 Neural Net\n\nWorkflow/Model\n\n\nCode\n# * NNET ----\nwflw_fit_nnet <- workflow() %>%\n  add_model(\n    spec = mlp(mode=\"regression\") %>%\n      set_engine(\"nnet\")\n  ) %>%\n  add_recipe(recipe_spec%>% update_role(date, new_role=\"indicator\"))\n  # fit(route_prep_nested_train)\nwflw_fit_nnet\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: mlp()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n6 Recipe Steps\n\n• step_timeseries_signature()\n• step_rm()\n• step_normalize()\n• step_zv()\n• step_impute_knn()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nSingle Layer Neural Network Model Specification (regression)\n\nComputational engine: nnet \n\n\n\n\n\n6.7 THIEF - Temporal Hierarchical Forecasting\n\nWorkflow/Model\n\n\nCode\n# * THIEF - Temporal Hierachical Forecasting ----\n\n wflw_thief <- workflow() %>%\n   add_model(temporal_hierarchy() %>% \n               set_engine(\"thief\")) %>%\n   add_recipe(recipe(passenger_trips ~ .,route_prep_nested_train %>% \n                       select(passenger_trips,date)\n                     )\n              )\n\n wflw_thief\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: temporal_hierarchy()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n0 Recipe Steps\n\n── Model ───────────────────────────────────────────────────────────────────────\nTemporal Hierarchical Forecasting Model Specification (regression)\n\nComputational engine: thief"
  },
  {
    "objectID": "posts/nested_forecasting/index.html#nested-analysis",
    "href": "posts/nested_forecasting/index.html#nested-analysis",
    "title": "Flight Forecast with ML Nested models",
    "section": "7 Nested Analysis",
    "text": "7 Nested Analysis\n\n7.1 Combine Workflows in Modeltime Table\n\n\nCode\nnested_modeltime_tbl <- route_prep_nested %>%\n  modeltime_nested_fit(\n\n    model_list = list(\n      wflw_fit_auto_arima,\n      wflw_fit_xgboost,\n      wflw_fit_prophet_boost,\n      wflw_fit_svm,\n      wflw_fit_rf,\n      wflw_fit_nnet,\n      wflw_thief\n      # #wflw_fit_gluonts_deepar - not working because of id cols\n    ),\n\n    control = control_nested_fit(\n      verbose   = TRUE,\n      allow_par = TRUE\n    )\n  )\n\n#nested_modeltime_tbl %>% glimpse() %>% kable()\n\n\n\n\n7.2 Check Errors\n\n\nCode\n# * Review Any Errors ----\nnested_modeltime_tbl %>% \n  extract_nested_error_report()\n\n\n# A tibble: 0 × 4\n# … with 4 variables: route <fct>, .model_id <int>, .model_desc <chr>,\n#   .error_desc <chr>\n\n\n\n\n7.3 Review Model Accuracy\n\n\nCode\n# * Review Test Accuracy ----\nnested_modeltime_best <- nested_modeltime_tbl %>%\n  extract_nested_test_accuracy() %>% \n  mutate(.model_desc = str_replace_all(.model_desc,\"TEMPORAL HIERARCHICAL FORECASTING MODEL\",\"THIEF\")) %>%\n  mutate(.model_desc = str_replace_all(.model_desc,\"PROPHET W XGBOOST ERRORS\",\"PROPHET W XGBOOST\")) \n\nnested_modeltime_best%>%\n  \n  table_modeltime_accuracy(.round_digits = 3)\n\n\n\n\n\n\n\n\n\n7.4 Graph - Models Test Data\n\n\nCode\n# |fig: 500\n\n# graph data\nnested_modeltime_tbl_grph_data <- nested_modeltime_tbl %>%\n  extract_nested_test_forecast() %>%\n  #slice_head(n=10) %>%\n  separate(route, \"-\", into = c(\"origin\", \"dest\"), remove = FALSE) %>%\n  mutate(.value = expm1(.value)) %>%\n  mutate(.model_desc = str_replace_all(.model_desc,\"TEMPORAL HIERARCHICAL FORECASTING MODEL\",\"THIEF\")) %>%\n  mutate(.model_desc = str_replace_all(.model_desc,\"PROPHET W XGBOOST ERRORS\",\"PROPHET W XGBOOST\")) %>%\n  #filter(origin == city) %>%\n  #filter(dest %in% c(\"MELBOURNE\",\"SYDNEY\",\"CAIRNS\",\"HOBART\")) %>% \n  group_by(route,.model_desc)\n\n\n\n# graph\ng <- nested_modeltime_tbl_grph_data %>%\n  select(route, model = .model_desc, date = .index,pax=.value) %>%\n  filter(year(date)>2014) %>%\n  ggplot(aes(x=date,y = pax/1000, color = model)) +\n  geom_line() +\n  scale_y_continuous(labels = comma) +\n  labs(x = \"\", y = \"pax pm(000)\") +\n  facet_wrap(~ route,  ncol=2, scales = \"free\") +\n  theme(legend.position = c(1,0)) +\n  theme(legend.text = element_text(size=5))\n\nggplotly(g)\n\n\n\n\n\n\n\n\n7.5 Select Best Models by Route\n\nSummary Count by Model\n\n\nCode\nnested_best_tbl <- nested_modeltime_tbl %>%\n  modeltime_nested_select_best(metric = \"rmse\")\n\n# * Visualize Best Models ----\nnested_best_tbl_extract <- nested_best_tbl %>%\n  extract_nested_test_forecast() %>%\n  #slice_head(n=10) %>%\n  separate(route, \"-\", into = c(\"origin\", \"dest\"), remove = FALSE) %>%\n  group_by(route)\n\n\nmodel_by_route <- nested_best_tbl_extract %>%\n  mutate(.model_desc = ifelse(.model_id ==2,\"XGBOOST-tuned\",.model_desc)) %>%\n   mutate(.model_desc = str_replace_all(.model_desc,\"TEMPORAL HIERARCHICAL FORECASTING MODEL\",\"THIEF\")) %>%\n  mutate(.model_desc = str_replace_all(.model_desc,\"PROPHET W XGBOOST ERRORS\",\"PROPHET/XGBOOST\"))\n\nmodel_by_route_summ <- model_by_route %>% \n  filter(!.model_desc==\"ACTUAL\") %>%\n  summarise(model_desc = first(.model_desc)) %>%\n  ungroup() %>%\n  count(model_desc,name = \"number\") %>% \n  arrange(desc(number))\n\n model_by_route_summ %>% kable()\n\n\n\n\n \n  \n    model_desc \n    number \n  \n \n\n  \n    THIEF \n    4 \n  \n  \n    ARIMA \n    2 \n  \n  \n    PROPHET/XGBOOST \n    2 \n  \n  \n    KERNLAB \n    1 \n  \n  \n    XGBOOST-tuned \n    1 \n  \n\n\n\n\n\n\n\nBest Model by Route\n\n\nCode\nbest_by_route_summ <- model_by_route %>% \n  filter(!.model_desc==\"ACTUAL\") %>%\n  summarise(route = first(route),model = first(.model_desc)) \n\n best_by_route_summ %>% kable()\n\n\n\n\n \n  \n    route \n    model \n  \n \n\n  \n    ADELAIDE-MELBOURNE \n    PROPHET/XGBOOST \n  \n  \n    ADELAIDE-SYDNEY \n    THIEF \n  \n  \n    BRISBANE-CAIRNS \n    THIEF \n  \n  \n    BRISBANE-MELBOURNE \n    KERNLAB \n  \n  \n    BRISBANE-SYDNEY \n    ARIMA \n  \n  \n    GOLD COAST-SYDNEY \n    THIEF \n  \n  \n    MELBOURNE-GOLD COAST \n    XGBOOST-tuned \n  \n  \n    MELBOURNE-PERTH \n    ARIMA \n  \n  \n    MELBOURNE-SYDNEY \n    THIEF \n  \n  \n    PERTH-SYDNEY \n    PROPHET/XGBOOST \n  \n\n\n\n\n\n\n\n\n7.6 Graph - Forecast v Training Data Aggregated\n\n\nCode\nnested_best_tbl_extract_graph <- nested_best_tbl_extract %>%\n  mutate(.key = ifelse(.key ==\"actual\",\"actual\",\"forecast\")) %>%\n  mutate(.value = expm1(.value),\n         .conf_lo = expm1(.conf_lo),\n         .conf_hi = expm1(.conf_hi)\n         ) %>%\n  group_by(.key,.index) %>%\n  summarise(.value = sum(.value),\n            conf_lo = sum(.conf_lo,na.rm = T),\n            conf_hi = sum(.conf_hi,na.rm = T))%>%\n  filter(.value>200) %>% \n  filter(.index>dmy(\"01-01-2015\"))\n\n\ng1 <- nested_best_tbl_extract_graph %>%\n  #filter((origin == city) | (dest == city) ) %>%\n  ggplot(aes(.index,.value/1000,color = .key)) +\n  geom_line() +\n  geom_ribbon(aes(ymin = (conf_lo)/1000, ymax = (conf_hi)/1000,\n                  color = .key), alpha = 0.2) +\n  scale_y_continuous(labels=scales::comma) +\n  labs(title = \"Forecast v Training Data\",x=\"\", y= \"pax pm (000)\")\n\nplotly::ggplotly(g1)\n\n\n\n\n\n\n\n\n7.7 Training Forecast Accuracy by Best Model - top 10 routes\n\n\n# A tibble: 10 × 8\n   route                   mae  mape maape  mase smape   rmse   rsq\n   <fct>                 <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl> <dbl>\n 1 GOLD COAST-SYDNEY     3475.  1.57  1.57 0.162  1.56  4072. 0.949\n 2 BRISBANE-SYDNEY       7510.  1.91  1.91 0.324  1.88  9369. 0.896\n 3 MELBOURNE-SYDNEY     14696.  1.96  1.96 0.317  1.93 18020. 0.810\n 4 BRISBANE-MELBOURNE    6482.  2.15  2.15 0.291  2.16  7680. 0.887\n 5 PERTH-SYDNEY          3190.  2.23  2.23 0.316  2.20  4006. 0.881\n 6 MELBOURNE-PERTH       3862.  2.20  2.20 0.249  2.21  5700. 0.833\n 7 ADELAIDE-MELBOURNE    5474.  2.66  2.66 0.413  2.66  6182. 0.712\n 8 ADELAIDE-SYDNEY       4372.  2.82  2.82 0.380  2.79  4550. 0.928\n 9 MELBOURNE-GOLD COAST  5857.  3.30  3.29 0.257  3.34  7317. 0.892\n10 BRISBANE-CAIRNS       3760.  3.56  3.56 0.536  3.48  4305. 0.907\n\n\n\n\n7.8 Refit Nested Model\n\n\n\n\nGraph\n\n\nCode\n# * Visualize Future Forecast ----\n\nnested_best_refit_tb_data <- nested_best_refit_tbl %>%\n  extract_nested_future_forecast() %>%\n\n  bind_rows(route_prep_validation %>%\n              mutate(.key = \"actual_validn\") %>%\n              select(route,.index = date,.key,.value = passenger_trips)) %>%\n  mutate(across(.value:.conf_hi, expm1)) %>%\n  separate(route, \"-\", into = c(\"origin\", \"dest\"),remove = FALSE) %>%\n  mutate(.model_desc = ifelse(.model_id ==2,\"XGBOOST-tuned\",.model_desc),\n         .model_desc = ifelse(is.na(.model_id),.key,.model_desc)) %>%\n  mutate(.model_desc = str_replace_all(.model_desc,\"TEMPORAL HIERARCHICAL FORECASTING MODEL\",\"THIEF\")) %>%\n  mutate(.model_desc = str_replace_all(.model_desc,\"PROPHET W XGBOOST ERRORS\",\"PROPHET/XGBOOST\")) %>%\n  # filter(origin == city) %>%\n  # filter(dest %in% c(\"MELBOURNE\",\"SYDNEY\",\"CAIRNS\",\"HOBART\")) %>%\n  filter(year(.index)>2015) %>%\n  group_by(route)\n\n# nested_best_refit_tb_data %>%\n#   filter(.index > end,.key ==\"actual_validn\")\n\nnested_best_refit_tb_data %>%\n  ggplot(aes(x= .index, y=.value, colour = .model_desc))+\n  geom_line() +\n  scale_y_continuous(labels = comma) +\n  labs(x = \"\", y = \"pax pm(000)\") +\n  facet_wrap(~ route,  ncol=2, scales = \"free\") +\n  theme(legend.position = c(1,0)) +\n  theme(legend.text = element_text(size=5))\n\n\n\n\n\nCode\n  #filter((origin == city) | (dest == city) ) %>%\n  # plot_modeltime_forecast(\n  #   .trelliscope = FALSE,\n  #   .facet_ncol  = 1\n  #   \n  #   #.trelliscope_params = list(width =\"100%\")\n  #   )\n\n\nNot a great performance against actuals, post covid in Feb 2020, but that is as expected! Pre-covid prediction looks good.\n\n\nAccuracy of refit - Pre/post covid\n\n\nCode\n#unique(refit_model_by_route_acc_data$.key)\n\n               \nrefit_model_by_route_acc_data <- nested_best_refit_tb_data %>% \n    # filter(.index >max(route_prep_nested_test$date),\n    #        .index <= d2\n    # ) %>% \n    #mutate(.key = ifelse(.key ==\"actual\",\"actual\",\"forecast\")) %>%\n    mutate(pax_nos = .value,\n           date = .index) %>%\n    bind_rows(route_prep_validation %>%\n              mutate(.key = \"actual\",\n                     passenger_trips = expm1(passenger_trips)\n                     ) %>%\n              select(route,date,.key, pax_nos = passenger_trips)) %>% \n    group_by(route, .key, date) %>%\n    summarise(pax_nos = sum(pax_nos,na.rm = TRUE)) %>% \n    pivot_wider(names_from = .key,\n              values_from  = pax_nos\n  )\n\n\n\naccuracy_predn_precovid <- refit_model_by_route_acc_data %>% \n   filter(date >  max_test,\n          date <= end_precovid\n   ) %>%\n    summarize_accuracy_metrics(\n        truth = actual_validn,\n        estimate = prediction,\n        metric_set = extended_forecast_accuracy_metric_set()\n    ) %>% arrange(smape)\n\naccuracy_predn_postcovid <- refit_model_by_route_acc_data %>% \n   filter(date >  end_precovid,\n          date <= max_act\n   ) %>%\n    summarize_accuracy_metrics(\n        truth = actual_validn,\n        estimate = prediction,\n        metric_set = extended_forecast_accuracy_metric_set()\n    ) %>% arrange(smape)\n\n\nFor obvious reasons the accuracy of predictions against actuals is not great after the covid started (say Feb 2020), after all we did not even give the models the benefit of ‘seeing’ the covid crash. That was not the point of this analysis..although we may revisit as more post covid data is available.\nWe can also check accuracy at an aggregated (across all routes) level.\n\n\nCode\nrefit_model_aggr_acc_data <- refit_model_by_route_acc_data %>% \n  group_by(date) %>% \n  summarise(actual   = sum(actual,na.rm = TRUE),\n            prediction = sum(prediction,na.rm = TRUE)) \n  \naccuracy_predn_agg_precovid <- refit_model_aggr_acc_data %>% \n   filter(date >  max_test,\n          date <= end_precovid\n   ) %>%\n    summarize_accuracy_metrics(\n        truth      = actual,\n        estimate   = prediction,\n        metric_set = extended_forecast_accuracy_metric_set()\n    ) %>% arrange(smape)\n\n  \n  accuracy_predn_agg_postcovid <- refit_model_aggr_acc_data %>% \n   filter(date >  end_precovid,\n          date <= max_act\n   ) %>%\n    summarize_accuracy_metrics(\n        truth      = actual,\n        estimate   = prediction,\n        metric_set = extended_forecast_accuracy_metric_set()\n    ) %>% arrange(smape)\n\nagg_pred_accuracy <- accuracy_predn_agg_precovid %>% \n  mutate(period = \"pre_covid\") %>% \n  bind_rows(accuracy_predn_agg_postcovid %>% mutate(period = \"post_covid\")) %>% \n  select(period,everything())\n\nagg_pred_accuracy %>% \n  gt::gt() %>% \n  gt::fmt_number(\n    columns = !period,\n    decimals = 3\n  )\n\n\n\n\n\n\n  \n  \n    \n      period\n      mae\n      mape\n      maape\n      mase\n      smape\n      rmse\n      rsq\n    \n  \n  \n    pre_covid\n40,507.912\n1.589\n1.588\n0.262\n1.572\n63,948.883\n0.989\n    post_covid\n1,168,496.081\n410.556\n88.088\n3.947\n192.184\n1,459,628.829\n0.065\n  \n  \n  \n\n\n\n\nObviously the pre and post covid volumes are much different so a lot of measures are not appropriate, but all look reasonable pre-covid and horrible thereafter, as expected.\nThe following graph breaks the actuals into the various periods - training, testing, pre-covid prediction, post covid (Feb2020) prediction, and more recently when no prediction was attempted, so data is just for information.\nSo the pre-covid prediction looks good, which is really all we were asking of the models.\nNow lets graph the aggregated (all routes) prediction against actuals. Actuals are colour coded to show all modelling stages. For our purposes the key is the comparison of the “prediction” to the “actual_precovid_prediction”, ie the actuals after the test period but before covid kicks in (ie pink v green line), which looks pretty good.\nThe rest just highlights why forecast/predictions can only go so far…\n\n\nCode\nrefit_model_aggr_acc_data %>%\n  pivot_longer(\n    cols      = !date,\n    names_to  = \"actual_prediction\",\n    values_to = \"pax_nos\"\n  ) %>%  \n  mutate(actual_prediction = \n    case_when(\n      actual_prediction == \"prediction\" ~ \"prediction\",\n      date              <= max_train    ~ \"actual_train\",\n      date              <= max_test     ~ \"actual_test\",\n      date              <= end_precovid ~ \"actual_precovid\",\n      date              <= max_pred     ~ \"actual_postcovid\",\n      TRUE                              ~ \"actual_post_prediction\"\n    )\n  ) %>% \n  mutate(pax_nos = ifelse(pax_nos == 0, NA,pax_nos)) %>% \n  ggplot(aes(x=date, y=pax_nos/1000,colour = actual_prediction ))+\n  geom_line() +\n  scale_y_continuous(\"Passenger No's pm (000)\",\n    breaks = scales::breaks_extended(8),\n    labels = scales::label_comma()  \n  )"
  },
  {
    "objectID": "posts/post-with-code/index.html#summary",
    "href": "posts/post-with-code/index.html#summary",
    "title": "Titanic from Kaggle",
    "section": "0.1 Summary",
    "text": "0.1 Summary\nThis is just a first test with code in a blog using the new Quarto framework! Guess what I am using..yep Titanic, Kaggle version..\nIt is not very well structured as it is pretty much in the order I did it following all instructions, books and blogs from the expert TidyModels and Quarto teams at RStudio/Posit . All errors belong to me!"
  },
  {
    "objectID": "posts/post-with-code/index.html#final-kaggle-scores",
    "href": "posts/post-with-code/index.html#final-kaggle-scores",
    "title": "Titanic from Kaggle",
    "section": "0.2 Final Kaggle Scores",
    "text": "0.2 Final Kaggle Scores\n\n\nCode\nkaggle <- tibble(\n  Model = c(\"Logistic Regression\",\n            \"Regularised Logistic Regression\",\n            \"Random Forest-final\",\n            \"Random Forest-initial\",\n            \"XG Boost\",\n            \"Neural Net\",\n            \"Ensemble\"), \n  Score = c(.76555,.77033,.77751,.78229,.77272,.76794,.77751)\n  )\n\nkaggle %>% knitr::kable()\n\n\n\n\n\nModel\nScore\n\n\n\n\nLogistic Regression\n0.76555\n\n\nRegularised Logistic Regression\n0.77033\n\n\nRandom Forest-final\n0.77751\n\n\nRandom Forest-initial\n0.78229\n\n\nXG Boost\n0.77272\n\n\nNeural Net\n0.76794\n\n\nEnsemble\n0.77751\n\n\n\n\n\nWhich when all submitted gave me a ranking of 1,872 out of 13,000 or so teams, so no grand-master!\nSeems like the value mainly comes from the feature engineering and selection process (as the experts all seem to say) given the similarity in above model scores."
  },
  {
    "objectID": "posts/post-with-code/index.html#review-data",
    "href": "posts/post-with-code/index.html#review-data",
    "title": "Titanic from Kaggle",
    "section": "0.3 Review Data",
    "text": "0.3 Review Data\n\n0.3.1 Load Some Kaggle Data\nNot the…? Yes, the Titanic again….\n\n\nCode\ntrain <- read_csv(\"data_raw/train.csv\",show_col_types = FALSE) %>% clean_names() %>% mutate(train_test = \"train\")\ntest <- read_csv(\"data_raw/test.csv\",show_col_types = FALSE) %>% clean_names() %>% \n  mutate(train_test = \"test\")\nall <- train %>% bind_rows(test)\n\n# colnames(data)\n# cwd()\n\n\n\n\n0.3.2 Some Initial EDA\nA quick look.\n\n\nCode\ntrain %>% skim() \n\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n891\n\n\nNumber of columns\n13\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nname\n0\n1.00\n12\n82\n0\n891\n0\n\n\nsex\n0\n1.00\n4\n6\n0\n2\n0\n\n\nticket\n0\n1.00\n3\n18\n0\n681\n0\n\n\ncabin\n687\n0.23\n1\n15\n0\n147\n0\n\n\nembarked\n2\n1.00\n1\n1\n0\n3\n0\n\n\ntrain_test\n0\n1.00\n5\n5\n0\n1\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\npassenger_id\n0\n1.0\n446.00\n257.35\n1.00\n223.50\n446.00\n668.5\n891.00\n▇▇▇▇▇\n\n\nsurvived\n0\n1.0\n0.38\n0.49\n0.00\n0.00\n0.00\n1.0\n1.00\n▇▁▁▁▅\n\n\npclass\n0\n1.0\n2.31\n0.84\n1.00\n2.00\n3.00\n3.0\n3.00\n▃▁▃▁▇\n\n\nage\n177\n0.8\n29.70\n14.53\n0.42\n20.12\n28.00\n38.0\n80.00\n▂▇▅▂▁\n\n\nsib_sp\n0\n1.0\n0.52\n1.10\n0.00\n0.00\n0.00\n1.0\n8.00\n▇▁▁▁▁\n\n\nparch\n0\n1.0\n0.38\n0.81\n0.00\n0.00\n0.00\n0.0\n6.00\n▇▁▁▁▁\n\n\nfare\n0\n1.0\n32.20\n49.69\n0.00\n7.91\n14.45\n31.0\n512.33\n▇▁▁▁▁\n\n\n\n\n\n\n\n0.3.3 Some Initial Wrangling\n\n\nCode\nall_proc <- all %>% \n  mutate(title = str_extract(name,\"(\\\\w)([a-z]+)(\\\\.)\")) %>% \n  mutate(pax_type = case_when(\n    title %in% c(\"Miss.\",\"Ms.\",\"Mlle.\")         ~ \"F_unmarried\",\n    title %in% c(\"Mme.\",\"Mrs.\")                 ~ \"F_married\",\n    title %in% c(\"Countess.\",\"Lady.\",\"Dona.\")   ~ \"F_titled\",\n    title %in% c(\"Capt.\",\"Col.\",\"Major.\")       ~ \"Military\",\n    title %in% c(\"Dr.\",\"Rev.\")                  ~ \"M_Professional\",\n    title %in% c(\"Don.\",\"Jonkheer.\",\"Sir.\")     ~ \"M_titled\",\n    TRUE ~ title\n  ),\n  surname        = str_extract(name,\"(\\\\w+)(\\\\,)\"),\n  survival       = ifelse(survived==0,\"No\",\"Yes\"),\n  ticket_preface = str_extract(ticket,\"([:graph:]+)(\\\\s)\"),\n  ticket_preface = ifelse(is.na(ticket_preface),\"none\",ticket_preface),\n  cabin_preface  = ifelse(is.na(cabin),\"nk\",\n                    substr(cabin,1,1)),\n  embarked       = ifelse(is.na(embarked),\"S\",embarked)\n  ) %>% \n  group_by(pax_type,pclass) %>% \n  mutate(age     = ifelse(is.na(age),median(age,na.rm = T), age)) %>% \n  ungroup() %>% \n  add_count(ticket,name = \"ticket_group\") %>% \n  mutate(ticket_group = case_when(\n    ticket_group == 1 ~ \"single\",\n    ticket_group == 2 ~ \"couple\",\n    TRUE              ~ \"group\"\n  ),\n    family_group = as.numeric(sib_sp)+as.numeric(parch)+1\n  ) %>% \n  mutate(family_group = factor(\n    case_when(\n        family_group < 2  ~ \"single\",\n        family_group < 3  ~ \"couple\",\n        TRUE              ~ \"family\"\n        ),\n    ordered = TRUE)\n  ) %>% \n  mutate(age_group = factor(case_when(\n    age < 13      ~ \"child\",\n    age < 20      ~ \"teen\",\n    age < 30      ~ \"20s\",\n    age < 40      ~ \"30s\",\n    age < 50      ~ \"40s\",\n    age < 60      ~ \"50s\",\n    TRUE          ~ \"60+\"\n    \n  ),\n  ordered = TRUE)\n  ) %>% \n  mutate(across(where(is.character),as_factor)) %>% \n  mutate(pclass = factor(pclass,levels = c(\"1\",\"2\",\"3\")),\n         survived = factor(survived)\n         ) %>% \nselect(-c(title,ticket_preface))\n  \n#all_proc %>% glimpse() \n\n\n\n\n0.3.4 A bit more EDA\n\n\nCode\nall_proc %>% \n  select(-c(name,ticket,cabin,surname,train_test)) %>% \n  DataExplorer::plot_bar()\n\n\n\n\n\n\n\n\n\n\nCode\nall_proc %>% DataExplorer::plot_histogram(ggtheme = theme_light() )\n\n\n\n\n\n\n\n0.3.5 Eyeballing Survival Graphs on Training Data\n\n\nCode\nno_f <- all_proc %>%\n  filter(train_test == \"train\") %>% \n  select(passenger_id,pclass,sex,embarked,pax_type,ticket_group,family_group,age_group,cabin_preface,survival) %>% \n  droplevels() %>%\n  mutate(across(where(is.factor),~ factor(.x,ordered = FALSE))) %>%\n  pivot_longer(cols = c(pclass:cabin_preface)) \n\n\ng_l <- no_f %>% \n  split(.$name) %>% \n  map(~ ggplot(.,aes(y=value,fill=survival)) +\n                geom_bar() +\n              ggtitle(.$name) +\n        theme_bw() +\n        labs(x=NULL,y=NULL)+\n        scale_fill_viridis_d(option = \"cividis\")\n      \n            ) \n\nlibrary(patchwork)\nwrap_plots(g_l, ncol = 2)\n\n\n\n\n\n\n\n0.3.6 Split Data back to Train/Test/Validation\n\n\nCode\ntrain_proc_adj_tbl <- all_proc %>% \n  filter(train_test ==\"train\") %>% \n  select(-c(survival))\n\n\n  \ntrain_split <- initial_split(train_proc_adj_tbl,strata = survived)\n\ntrain_train <- training(train_split)\ntrain_test <- testing(train_split)"
  },
  {
    "objectID": "posts/post-with-code/index.html#recipe-base",
    "href": "posts/post-with-code/index.html#recipe-base",
    "title": "Titanic from Kaggle",
    "section": "0.4 Recipe-Base",
    "text": "0.4 Recipe-Base\n\n\nCode\nrecipe_base <- \n  recipe(survived ~ ., data = train_train) %>% \n  update_role(passenger_id, name,surname,ticket,cabin,new_role = \"ID\") %>%\n  step_impute_knn(all_numeric_predictors()) %>% \n  step_dummy(all_nominal_predictors()) %>%\n  step_factor2string(all_nominal_predictors()) %>% \n  step_zv(all_predictors()) %>% \n  step_pca()\nrecipe_base\n\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          5\n   outcome          1\n predictor         13\n\nOperations:\n\nK-nearest neighbor imputation for all_numeric_predictors()\nDummy variables from all_nominal_predictors()\nCharacter variables from all_nominal_predictors()\nZero variance filter on all_predictors()\nPCA extraction with <none>\n\n\n\n0.4.1 Save Files\n\n\nCode\nwrite_rds(all_proc,\"artifacts/all_proc.rds\")\nwrite_rds(train_split,\"artifacts/train_split.rds\")\nwrite_rds(recipe_base,\"artifacts/recipe_base.rds\")\n# \n# all_proc <- read_rds(\"artifacts/all_proc.rds\")\n# train_split <- read_rds(\"artifacts/train_split.rds\")\n# recipe_base <- read_rds(\"artifacts/recipe_base.rds\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#models",
    "href": "posts/post-with-code/index.html#models",
    "title": "Titanic from Kaggle",
    "section": "0.5 Models",
    "text": "0.5 Models\n\n0.5.1 Logistic Regression\n\nLR Model Spec\n\n\nCode\nlr_spec <-  \n  logistic_reg() %>% \n  set_engine(\"glm\")\n\nlr_spec\n\n\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\n\nLR Workflow\n\n\nCode\nlr_wflow <- \n  workflow() %>% \n  add_model(lr_spec) %>% \n  add_recipe(recipe_base)\n\nlr_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\n\nLR Fit Model\n\n\nCode\nlr_fit <- \n  lr_wflow %>% \n  last_fit(train_split)\n\n#lr_fit\n\nlr_final_metrics <- lr_fit %>% collect_metrics()\nlr_final_metrics \n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.799 Preprocessor1_Model1\n2 roc_auc  binary         0.822 Preprocessor1_Model1\n\n\nCode\n#show_notes(.Last.tune.result)\n\n\n\n\nLR Predict\n\n\nCode\nlr_test_predictions <- lr_fit %>% collect_predictions() %>% \n  rename(survived_pred = survived) %>% \n  bind_cols(train_test)\nlr_test_predictions\n\n\n# A tibble: 224 × 26\n   id       .pred_0 .pred_1  .row .pred…¹ survi…² .config passe…³ survi…⁴ pclass\n   <chr>      <dbl>   <dbl> <int> <fct>   <fct>   <chr>     <dbl> <fct>   <fct> \n 1 train/t…  0.0948 9.05e-1    10 1       1       Prepro…      10 1       2     \n 2 train/t…  1.00   2.63e-7    11 0       1       Prepro…      11 1       3     \n 3 train/t…  0.996  4.01e-3    14 0       0       Prepro…      14 0       3     \n 4 train/t…  0.749  2.51e-1    18 0       1       Prepro…      18 1       2     \n 5 train/t…  0.122  8.78e-1    20 1       1       Prepro…      20 1       3     \n 6 train/t…  0.309  6.91e-1    23 1       1       Prepro…      23 1       3     \n 7 train/t…  0.887  1.13e-1    28 0       0       Prepro…      28 0       1     \n 8 train/t…  0.473  5.27e-1    40 1       1       Prepro…      40 1       3     \n 9 train/t…  0.468  5.32e-1    41 1       0       Prepro…      41 0       3     \n10 train/t…  0.862  1.38e-1    51 0       0       Prepro…      51 0       3     \n# … with 214 more rows, 16 more variables: name <fct>, sex <fct>, age <dbl>,\n#   sib_sp <dbl>, parch <dbl>, ticket <fct>, fare <dbl>, cabin <fct>,\n#   embarked <fct>, train_test <fct>, pax_type <fct>, surname <fct>,\n#   cabin_preface <fct>, ticket_group <fct>, family_group <ord>,\n#   age_group <ord>, and abbreviated variable names ¹​.pred_class,\n#   ²​survived_pred, ³​passenger_id, ⁴​survived\n\n\n\n\nLR Performance on validation set\n\nAUC Curve\n\n\nCode\nlr_test_predictions %>% \n  roc_curve(truth = survived,.pred_1,event_level=\"second\") %>% \n  autoplot()\n\n\n\n\n\n\n\nConfusion Matrix\n\n\nCode\nlr_test_predictions %>% \n  conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")\n\n\n\n\n\n\n\n\nLR Resampling\n\n\nCode\nfolds <- vfold_cv(train_train, strata = survived, v=5)\n#folds\n\ncontrol <- control_resamples(save_pred = TRUE,save_workflow = TRUE)\n\ncores <- parallel::detectCores()\ncl <- parallel::makePSOCKcluster(cores - 1)\n\n# doParallel::registerDoParallel(cores = cores)\nset.seed(1234)\nlr_fit_cv <- \n  lr_wflow %>% \n  fit_resamples(folds, control = control)\n\n#show_best(lr_fit_cv,metric= \"accuracy\")\n\n#lr_fit_cv\nlr_metrics_resample <- collect_metrics(lr_fit_cv)\nlr_metrics_resample\n\n\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy binary     0.823     5 0.0124  Preprocessor1_Model1\n2 roc_auc  binary     0.856     5 0.00839 Preprocessor1_Model1\n\n\nCode\nparallel::stopCluster(cl)\n\n\nFollowing still to be fixed!\n\n\nCode\n#lr_param <- extract_parameter_set_dials(lr_spec)\n\nlr_resample_test_predictions <- collect_predictions(lr_fit_cv) %>% \n  rename(survived_pred = survived) \n#  bind_cols(testing(train_split))\nlr_resample_test_predictions\n\n\n# A tibble: 667 × 7\n   id    .pred_0 .pred_1  .row .pred_class survived_pred .config             \n   <chr>   <dbl>   <dbl> <int> <fct>       <fct>         <chr>               \n 1 Fold1   0.888 0.112       2 0           0             Preprocessor1_Model1\n 2 Fold1   0.756 0.244      10 0           0             Preprocessor1_Model1\n 3 Fold1   0.932 0.0677     15 0           0             Preprocessor1_Model1\n 4 Fold1   0.187 0.813      20 1           0             Preprocessor1_Model1\n 5 Fold1   0.919 0.0810     26 0           0             Preprocessor1_Model1\n 6 Fold1   0.978 0.0219     29 0           0             Preprocessor1_Model1\n 7 Fold1   0.974 0.0265     34 0           0             Preprocessor1_Model1\n 8 Fold1   0.993 0.00666    36 0           0             Preprocessor1_Model1\n 9 Fold1   0.921 0.0793     43 0           0             Preprocessor1_Model1\n10 Fold1   0.924 0.0763     44 0           0             Preprocessor1_Model1\n# … with 657 more rows\n\n\n\n\nCode\ncl <- parallel::makePSOCKcluster(cores - 1)\n\nset.seed(1234)\nlm_fit <- lr_wflow %>% fit(data = train_proc_adj_tbl)\nextract_recipe(lm_fit, estimated = TRUE)\n\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          5\n   outcome          1\n predictor         13\n\nTraining data contained 891 data points and 687 incomplete rows. \n\nOperations:\n\nK-nearest neighbor imputation for age, sib_sp, parch, fare [trained]\nDummy variables from pclass, sex, embarked, train_test, pax_type, cabin_prefac... [trained]\nCharacter variables from <none> [trained]\nZero variance filter removed train_test_test [trained]\nNo PCA components were extracted from <none> [trained]\n\n\nCode\nparallel::stopCluster(cl)"
  },
  {
    "objectID": "posts/post-with-code/index.html#regularised-logistic-regression---glmnet",
    "href": "posts/post-with-code/index.html#regularised-logistic-regression---glmnet",
    "title": "Titanic from Kaggle",
    "section": "0.6 Regularised Logistic Regression - GLMNET",
    "text": "0.6 Regularised Logistic Regression - GLMNET\n\n0.6.1 RLR Model Spec\n\n\nCode\nrlr_model <- \n  logistic_reg(penalty = tune(), mixture = tune()) %>% \n  set_engine(\"glmnet\")\nrlr_model\n\n\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = tune()\n\nComputational engine: glmnet \n\n\n\n\n0.6.2 RLR Parameter Tuning\n\n\nCode\nrlr_param <- extract_parameter_set_dials(rlr_model)\n\nrlr_grid <- grid_latin_hypercube(\n  penalty(),\n  mixture(),\n  size = 30\n)\nhead(rlr_grid) %>% knitr::kable(digits =3)\n\n\n\n\n\npenalty\nmixture\n\n\n\n\n0.116\n0.866\n\n\n0.095\n0.736\n\n\n0.000\n0.141\n\n\n0.000\n0.458\n\n\n0.025\n0.983\n\n\n0.484\n0.109\n\n\n\n\n\n\n\n0.6.3 RLR Workflow\n\n\nCode\nrlr_wflow <- \n  workflow() %>% \n  add_model(rlr_model) %>% \n  add_recipe(recipe_base)\nrlr_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = tune()\n\nComputational engine: glmnet \n\n\n\n\n0.6.4 RLR Hyper-parameter Tuning\n\n\nCode\n# rlr_folds <- vfold_cv(training(train_split), strata = survived, v=10,repeats = 5)\n# rlr_folds %>% tidy()\n\n#doParallel::registerDoParallel(cores = cores)\ncl <- parallel::makePSOCKcluster(cores - 1)\n\nset.seed(234)\nrlr_tuning_result <- tune_grid(\n  rlr_wflow,\n  resamples = folds,\n  grid      = rlr_grid,\n  control   = control_grid(save_pred = TRUE, save_workflow = TRUE)\n)\n\nrlr_tuning_metrics <- collect_metrics(rlr_tuning_result)\nhead(rlr_tuning_metrics) %>% knitr::kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npenalty\nmixture\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n0.016\n0.018\naccuracy\nbinary\n0.821\n5\n0.016\nPreprocessor1_Model01\n\n\n0.016\n0.018\nroc_auc\nbinary\n0.865\n5\n0.009\nPreprocessor1_Model01\n\n\n0.000\n0.066\naccuracy\nbinary\n0.825\n5\n0.015\nPreprocessor1_Model02\n\n\n0.000\n0.066\nroc_auc\nbinary\n0.857\n5\n0.008\nPreprocessor1_Model02\n\n\n0.000\n0.070\naccuracy\nbinary\n0.825\n5\n0.015\nPreprocessor1_Model03\n\n\n0.000\n0.070\nroc_auc\nbinary\n0.857\n5\n0.008\nPreprocessor1_Model03\n\n\n\n\n\nCode\nparallel::stopCluster(cl)\n\n\nReview hyper-parameter tuning results and select best\n\n\nCode\nrlr_tuning_result %>%\n  collect_metrics() %>%\n  filter(.metric == \"accuracy\") %>%\n  select(mean, penalty,mixture) %>%\n  pivot_longer(penalty:mixture,\n               values_to = \"value\",\n               names_to = \"parameter\"\n  ) %>%\n  ggplot(aes(value, mean, color = parameter)) +\n  geom_point(alpha = 0.8, show.legend = FALSE) +\n  facet_wrap(~parameter, scales = \"free_x\") +\n  labs(x = NULL, y = \"AUC\")\n\n\n\n\n\nCode\nshow_best(rlr_tuning_result, \"accuracy\")\n\n\n# A tibble: 5 × 8\n   penalty mixture .metric  .estimator  mean     n std_err .config              \n     <dbl>   <dbl> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n1 8.86e- 3   0.923 accuracy binary     0.829     5  0.0169 Preprocessor1_Model28\n2 1.36e- 9   0.141 accuracy binary     0.826     5  0.0137 Preprocessor1_Model05\n3 1.30e-10   0.182 accuracy binary     0.826     5  0.0137 Preprocessor1_Model06\n4 5.43e- 9   0.211 accuracy binary     0.826     5  0.0137 Preprocessor1_Model07\n5 2.52e- 8   0.241 accuracy binary     0.826     5  0.0137 Preprocessor1_Model08\n\n\nCode\nbest_rlr_auc <- select_best(rlr_tuning_result, \"accuracy\")\nbest_rlr_auc\n\n\n# A tibble: 1 × 3\n  penalty mixture .config              \n    <dbl>   <dbl> <chr>                \n1 0.00886   0.923 Preprocessor1_Model28\n\n\n\n\n0.6.5 RLR Predict\n\n\nCode\nrlr_final_wflow <- finalize_workflow(\n  rlr_wflow,\n  best_rlr_auc\n)\n\nrlr_final_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = 0.00885574773491923\n  mixture = 0.923322001239285\n\nComputational engine: glmnet \n\n\nCode\nrlr_final_wflow %>%\n  last_fit(train_split) %>%\n  extract_fit_parsnip() %>%\n  vip(geom = \"col\")\n\n\n\n\n\n\n\nCode\nrlr_final_fit <- rlr_final_wflow %>%\n  last_fit(train_split)\n\nrlr_final_metrics <- collect_metrics(rlr_final_fit)\nrlr_final_metrics %>% knitr::kable()\n\n\n\n\n\n.metric\n.estimator\n.estimate\n.config\n\n\n\n\naccuracy\nbinary\n0.8080357\nPreprocessor1_Model1\n\n\nroc_auc\nbinary\n0.8424756\nPreprocessor1_Model1\n\n\n\n\n\nCode\nrlr_test_predictions <- rlr_final_fit %>% collect_predictions()\nrlr_test_predictions_all <- rlr_test_predictions %>% \n  bind_cols(train_test %>% select(-survived)) \n\n\n\nglimpse(rlr_test_predictions_all)\n\n\nRows: 224\nColumns: 25\n$ id            <chr> \"train/test split\", \"train/test split\", \"train/test spli…\n$ .pred_0       <dbl> 0.1216896, 0.8658490, 0.9641622, 0.7243443, 0.2225635, 0…\n$ .pred_1       <dbl> 0.87831041, 0.13415097, 0.03583775, 0.27565575, 0.777436…\n$ .row          <int> 10, 11, 14, 18, 20, 23, 28, 40, 41, 51, 54, 57, 61, 66, …\n$ .pred_class   <fct> 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0,…\n$ survived      <fct> 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1,…\n$ .config       <chr> \"Preprocessor1_Model1\", \"Preprocessor1_Model1\", \"Preproc…\n$ passenger_id  <dbl> 10, 11, 14, 18, 20, 23, 28, 40, 41, 51, 54, 57, 61, 66, …\n$ pclass        <fct> 2, 3, 3, 2, 3, 3, 1, 3, 3, 3, 2, 2, 3, 3, 2, 3, 3, 2, 3,…\n$ name          <fct> \"Nasser, Mrs. Nicholas (Adele Achem)\", \"Sandstrom, Miss.…\n$ sex           <fct> female, female, male, male, female, female, male, female…\n$ age           <dbl> 14, 4, 39, 30, 31, 15, 19, 14, 40, 7, 29, 21, 22, 6, 21,…\n$ sib_sp        <dbl> 1, 1, 1, 0, 0, 0, 3, 1, 1, 4, 1, 0, 0, 1, 0, 0, 0, 0, 3,…\n$ parch         <dbl> 0, 1, 5, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,…\n$ ticket        <fct> 237736, PP 9549, 347082, 244373, 2649, 330923, 19950, 26…\n$ fare          <dbl> 30.0708, 16.7000, 31.2750, 13.0000, 7.2250, 8.0292, 263.…\n$ cabin         <fct> NA, G6, NA, NA, NA, NA, C23 C25 C27, NA, NA, NA, NA, NA,…\n$ embarked      <fct> C, S, S, S, C, Q, S, C, S, S, S, S, C, C, S, S, Q, S, S,…\n$ train_test    <fct> train, train, train, train, train, train, train, train, …\n$ pax_type      <fct> F_married, F_unmarried, Mr., Mr., F_married, F_unmarried…\n$ surname       <fct> \"Nasser,\", \"Sandstrom,\", \"Andersson,\", \"Williams,\", \"Mas…\n$ cabin_preface <fct> nk, G, nk, nk, nk, nk, C, nk, nk, nk, nk, nk, nk, nk, nk…\n$ ticket_group  <fct> couple, group, group, single, single, single, group, cou…\n$ family_group  <ord> couple, family, family, single, single, single, family, …\n$ age_group     <ord> teen, child, 30s, 30s, 30s, teen, teen, teen, 40s, child…\n\n\nCode\n# rlr_pred <- predict(rlr_final_fit,train_2 )%>% \n#   bind_cols(predict(rlr_final_fit, train_2,type=\"prob\")) %>% \n#   bind_cols(train_2 %>% select(survived))\n# \n# rlr_pred %>% \n#   roc_auc(truth = survived, .pred_1, event_level = \"second\")\n# \n# rlr_pred %>% \n#   roc_curve(truth = survived, .pred_1,event_level=\"second\") %>% \n#   autoplot()\n# \n# \n# rlr_metrics <- rlr_pred %>% \n# metrics(truth = survived, estimate = .pred_class) %>% \n#   filter(.metric == \"accuracy\")\n# rlr_metrics\n# survive_rlr_pred <- \n#   augment(survive_lr_fit, train_2)\n# survive_rlr_pred\n\n\n\n\n0.6.6 RLR Confusion Matrix\n\n\nCode\nrlr_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#random-forest",
    "href": "posts/post-with-code/index.html#random-forest",
    "title": "Titanic from Kaggle",
    "section": "0.7 Random Forest",
    "text": "0.7 Random Forest\n\n0.7.1 RF Model Spec - Ranger\n\n\nCode\nrf_model <- \n  rand_forest(\n    trees = 1000,\n    mtry  = tune(),\n    min_n = tune()\n    ) %>% \n  set_engine(\"ranger\",importance = \"permutation\") %>% \n  set_mode(\"classification\")\n\n\n\n\n0.7.2 RF Workflow\n\n\nCode\nrf_wflow <- \n  workflow() %>% \n  add_model(rf_model) %>% \n  add_recipe(recipe_base)\n\n\n\n\n0.7.3 RF Tuning - Initial\n\n\nCode\ncl <- parallel::makePSOCKcluster(cores - 1)\n\nset.seed(1234)\nrf_tuning_result <- tune_grid(\n  rf_wflow,\n  resamples = folds,\n  grid = 20\n)\nparallel::stopCluster(cl)\n\nrf_tuning_result\n\n\n# Tuning results\n# 5-fold cross-validation using stratification \n# A tibble: 5 × 4\n  splits            id    .metrics          .notes          \n  <list>            <chr> <list>            <list>          \n1 <split [532/135]> Fold1 <tibble [40 × 6]> <tibble [0 × 3]>\n2 <split [534/133]> Fold2 <tibble [40 × 6]> <tibble [0 × 3]>\n3 <split [534/133]> Fold3 <tibble [40 × 6]> <tibble [0 × 3]>\n4 <split [534/133]> Fold4 <tibble [40 × 6]> <tibble [0 × 3]>\n5 <split [534/133]> Fold5 <tibble [40 × 6]> <tibble [0 × 3]>\n\n\nCode\nrf_tuning_result %>% \n  collect_metrics() %>% \n  filter(.metric == \"accuracy\") %>% \n  select(mean,min_n,mtry) %>% \n  pivot_longer(min_n:mtry) %>% \n  ggplot(aes(value, mean, color = name)) +\n  geom_point(show.legend = FALSE) +\n  facet_wrap(~name, scales = \"free_x\") +\n  labs(x = NULL, y = \"Accuracy\")\n\n\n\n\n\nBit hard to make much of it, but say min_n between 10 and 40 and mtry between 10 and 30?\n\n\nCode\nrf_grid <- grid_regular(\n  mtry(range = c(5, 40)),\n  min_n(range = c(5, 30)),\n  levels = 5\n)\n\nrf_grid\n\n\n# A tibble: 25 × 2\n    mtry min_n\n   <int> <int>\n 1     5     5\n 2    13     5\n 3    22     5\n 4    31     5\n 5    40     5\n 6     5    11\n 7    13    11\n 8    22    11\n 9    31    11\n10    40    11\n# … with 15 more rows\n\n\n\n\n0.7.4 RF Graph Results\n\n\nCode\ncl <- parallel::makePSOCKcluster(cores - 1)\n\n\nset.seed(1234)\nrf_grid_tune <- tune_grid(\n  rf_wflow,\n  resamples = folds,\n  grid = rf_grid\n)\nrf_grid_tune\n\n\n# Tuning results\n# 5-fold cross-validation using stratification \n# A tibble: 5 × 4\n  splits            id    .metrics          .notes          \n  <list>            <chr> <list>            <list>          \n1 <split [532/135]> Fold1 <tibble [50 × 6]> <tibble [5 × 3]>\n2 <split [534/133]> Fold2 <tibble [50 × 6]> <tibble [5 × 3]>\n3 <split [534/133]> Fold3 <tibble [50 × 6]> <tibble [5 × 3]>\n4 <split [534/133]> Fold4 <tibble [50 × 6]> <tibble [5 × 3]>\n5 <split [534/133]> Fold5 <tibble [50 × 6]> <tibble [5 × 3]>\n\nThere were issues with some computations:\n\n  - Warning(s) x10: 40 columns were requested but there were 33 predictors in the dat...   - Warning(s) x15: 40 columns were requested but there were 33 predictors in the dat...\n\nRun `show_notes(.Last.tune.result)` for more information.\n\n\nCode\nparallel::stopCluster(cl)\n\nrf_grid_tune %>%\n  collect_metrics() %>%\n  filter(.metric == \"accuracy\") %>%\n  mutate(min_n = factor(min_n)) %>%\n  ggplot(aes(mtry, mean, color = min_n)) +\n  geom_line(alpha = 0.5, size = 1.5) +\n  geom_point() +\n  labs(y = \"Accuracy\")\n\n\n\n\n\nWell that’s interesting, lets see what tune thinks is best\n\n\nCode\nrf_best_params <- select_best(rf_grid_tune,\"accuracy\")\nrf_best_params %>% knitr::kable()\n\n\n\n\n\nmtry\nmin_n\n.config\n\n\n\n\n31\n17\nPreprocessor1_Model14\n\n\n\n\n\n\n\n0.7.5 RF Final Model\n\n\nCode\nrf_final_model <- finalize_model(\n  rf_model,\n  rf_best_params\n)\nrf_final_model\n\n\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = 31\n  trees = 1000\n  min_n = 17\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger \n\n\n\n\n0.7.6 RF Final Workflow\n\n\nCode\nrf_final_wflow <- finalize_workflow(\n  rf_wflow,\n  rf_best_params\n)\n\nrf_final_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = 31\n  trees = 1000\n  min_n = 17\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger \n\n\n\n\n0.7.7 RF Parameter Importance\n\n\nCode\nrf_final_wflow %>%\n  fit(data = train_proc_adj_tbl) %>%\n  extract_fit_parsnip() %>%\n  vip(geom = \"point\")\n\n\n\n\n\n\n\n0.7.8 RF Final Fit\n\n\nCode\nrf_final_fit <- \n  rf_final_wflow %>% \n  last_fit(train_split)\n\nrf_final_metrics <- collect_metrics(rf_final_fit)\nrf_final_metrics\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.821 Preprocessor1_Model1\n2 roc_auc  binary         0.874 Preprocessor1_Model1\n\n\n\n\n0.7.9 RF Predict\n\n\nCode\n# rf_final_fit <- rf_wflow %>% fit(train_test)\n# class(rf_final_fit)\n\n rf_test_predictions <- \n   collect_predictions(rf_final_fit)\n   # fit(rf_final_wflow,train_train) %>% \n   # predict(rf_final_wflow, new_data = train_test) %>% \n   #bind_cols(predict(rf_final_wflow, train_test,type = \"prob\")) %>% \n   #bind_cols(train_test %>% select(survived))\n\n \n head(rf_test_predictions)\n\n\n# A tibble: 6 × 7\n  id               .pred_0 .pred_1  .row .pred_class survived .config           \n  <chr>              <dbl>   <dbl> <int> <fct>       <fct>    <chr>             \n1 train/test split  0.0101   0.990    10 1           1        Preprocessor1_Mod…\n2 train/test split  0.386    0.614    11 1           1        Preprocessor1_Mod…\n3 train/test split  0.703    0.297    14 0           0        Preprocessor1_Mod…\n4 train/test split  0.884    0.116    18 0           1        Preprocessor1_Mod…\n5 train/test split  0.370    0.630    20 1           1        Preprocessor1_Mod…\n6 train/test split  0.598    0.402    23 0           1        Preprocessor1_Mod…\n\n\n\n\n0.7.10 RF Performance on Test Set\n\n\nCode\n# rf_test_predictions %>% \n#   roc_auc(truth = survived, .pred_1,event_level = \"second\")\n\nrf_metrics_accuracy <- rf_test_predictions %>% \n  metrics(truth = survived, estimate = .pred_class) %>% \n  filter(.metric == \"accuracy\")\nrf_metrics_accuracy\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.821\n\n\nCode\nrf_test_predictions %>% \n  roc_curve(truth = survived, .pred_1,event_level = \"second\") %>% \n  autoplot()\n\n\n\n\n\n\n\n0.7.11 RF Confusion Matrix\n\n\nCode\nrf_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#xg-boost---usemodel",
    "href": "posts/post-with-code/index.html#xg-boost---usemodel",
    "title": "Titanic from Kaggle",
    "section": "0.8 XG Boost - Usemodel",
    "text": "0.8 XG Boost - Usemodel\n\n0.8.1 XGB - Usemodel Library specs\n\n\nCode\nlibrary(usemodels)\n\nuse_xgboost(survived ~ .,\n            data=train_train,\n            verbose = TRUE\n  \n)\n\n\nxgboost_recipe <- \n  recipe(formula = survived ~ ., data = train_train) %>% \n  step_novel(all_nominal_predictors()) %>% \n  ## This model requires the predictors to be numeric. The most common \n  ## method to convert qualitative predictors to numeric is to create \n  ## binary indicator variables (aka dummy variables) from these \n  ## predictors. However, for this model, binary indicator variables can be \n  ## made for each of the levels of the factors (known as 'one-hot \n  ## encoding'). \n  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>% \n  step_zv(all_predictors()) \n\nxgboost_spec <- \n  boost_tree(trees = tune(), min_n = tune(), tree_depth = tune(), learn_rate = tune(), \n    loss_reduction = tune(), sample_size = tune()) %>% \n  set_mode(\"classification\") %>% \n  set_engine(\"xgboost\") \n\nxgboost_workflow <- \n  workflow() %>% \n  add_recipe(xgboost_recipe) %>% \n  add_model(xgboost_spec) \n\nset.seed(19336)\nxgboost_tune <-\n  tune_grid(xgboost_workflow, resamples = stop(\"add your rsample object\"), grid = stop(\"add number of candidate points\"))\n\n\n\n\n0.8.2 XGB - Parameters\nThis grid is used for both versions of XG Boost.\n\n\nCode\nxgb_grid <- grid_latin_hypercube(\n  tree_depth(),\n  min_n(),\n  trees(),\n  loss_reduction(),\n  sample_size = sample_prop(),\n  finalize(mtry(), train_train),\n  learn_rate(),\n  size = 30\n)\n\nhead(xgb_grid)\n\n\n# A tibble: 6 × 7\n  tree_depth min_n trees loss_reduction sample_size  mtry    learn_rate\n       <int> <int> <int>          <dbl>       <dbl> <int>         <dbl>\n1         14    30  1603   0.0230             0.806    13 0.00985      \n2         11     9    22   0.0000361          0.983     3 0.0000469    \n3          1    17   848   0.00581            0.539    11 0.00559      \n4         10     8  1097   0.00000104         0.652     8 0.00000000128\n5         11    19  1422   1.00               0.283     6 0.00124      \n6         15    32  1007   0.0000000318       0.919    15 0.00000608   \n\n\n\n\nCode\nxgboost_usemodel_recipe <- \n  recipe(formula = survived ~ ., data = train_train) %>% \n  step_novel(all_nominal_predictors()) %>% \n  ## This model requires the predictors to be numeric. The most common \n  ## method to convert qualitative predictors to numeric is to create \n  ## binary indicator variables (aka dummy variables) from these \n  ## predictors. However, for this model, binary indicator variables can be \n  ## made for each of the levels of the factors (known as 'one-hot \n  ## encoding'). \n  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>% \n  step_zv(all_predictors()) \n\nxgboost_usemodel_model <- \n  boost_tree(trees = tune(), mtry = tune(),min_n = tune(), tree_depth = tune(), learn_rate = tune(), \n    loss_reduction = tune(), sample_size = tune()) %>% \n  set_mode(\"classification\") %>% \n  set_engine(\"xgboost\") \n\nxgboost_usemodel_wflow <- \n  workflow() %>% \n  add_recipe(xgboost_usemodel_recipe) %>% \n  add_model(xgboost_usemodel_model) \n\n#doParallel::registerDoParallel(cores = cores)\ncl <- parallel::makePSOCKcluster(cores - 1)\n\nset.seed(1234)\nxgboost_usemodel_tune <-\n  tune_grid(xgboost_usemodel_wflow, resamples = folds, grid = xgb_grid)\n\nparallel::stopCluster(cl)\n\n\n\n\n0.8.3 XGB - Usemodel Best Parameter Settings\n\n\nCode\nxgb_tuning_metrics_usemodel <- collect_metrics(xgboost_usemodel_tune)\nxgb_tuning_metrics_usemodel\n\n\n# A tibble: 60 × 13\n    mtry trees min_n tree_depth learn_r…¹ loss_r…² sampl…³ .metric .esti…⁴  mean\n   <int> <int> <int>      <int>     <dbl>    <dbl>   <dbl> <chr>   <chr>   <dbl>\n 1    11   848    17          1   5.59e-3 5.81e- 3   0.539 accura… binary  0.708\n 2    11   848    17          1   5.59e-3 5.81e- 3   0.539 roc_auc binary  0.823\n 3     9  1145    10          2   5.20e-8 1.60e- 1   0.866 accura… binary  0.702\n 4     9  1145    10          2   5.20e-8 1.60e- 1   0.866 roc_auc binary  0.821\n 5    17   740    15          2   8.39e-2 6.64e- 9   0.252 accura… binary  0.743\n 6    17   740    15          2   8.39e-2 6.64e- 9   0.252 roc_auc binary  0.776\n 7    12   690    38          2   3.89e-9 5.16e-10   0.146 accura… binary  0.616\n 8    12   690    38          2   3.89e-9 5.16e-10   0.146 roc_auc binary  0.5  \n 9    10  1314    11          3   1.72e-5 1.25e- 1   0.163 accura… binary  0.616\n10    10  1314    11          3   1.72e-5 1.25e- 1   0.163 roc_auc binary  0.757\n# … with 50 more rows, 3 more variables: n <int>, std_err <dbl>, .config <chr>,\n#   and abbreviated variable names ¹​learn_rate, ²​loss_reduction, ³​sample_size,\n#   ⁴​.estimator\n\n\nCode\nxgboost_usemodel_tune %>%\n  collect_metrics() %>%\n  filter(.metric == \"accuracy\") %>%\n  select(mean, mtry:sample_size) %>%\n  pivot_longer(mtry:sample_size,\n               values_to = \"value\",\n               names_to = \"parameter\"\n  ) %>%\n  ggplot(aes(value, mean, color = parameter)) +\n  geom_point(alpha = 0.8, show.legend = FALSE) +\n  facet_wrap(~parameter, scales = \"free_x\") +\n  labs(x = NULL, y = \"Accuracy\")\n\n\n\n\n\nNow select best from above\n\n\nCode\nshow_best(xgboost_usemodel_tune, \"accuracy\")\n\n\n# A tibble: 5 × 13\n   mtry trees min_n tree_d…¹ learn…² loss_…³ sampl…⁴ .metric .esti…⁵  mean     n\n  <int> <int> <int>    <int>   <dbl>   <dbl>   <dbl> <chr>   <chr>   <dbl> <int>\n1    13  1603    30       14 9.85e-3 2.30e-2   0.806 accura… binary  0.766     5\n2     4  1982     4       15 4.01e-2 5.53e-8   0.393 accura… binary  0.754     5\n3    17   740    15        2 8.39e-2 6.64e-9   0.252 accura… binary  0.743     5\n4    11   848    17        1 5.59e-3 5.81e-3   0.539 accura… binary  0.708     5\n5     9  1145    10        2 5.20e-8 1.60e-1   0.866 accura… binary  0.702     5\n# … with 2 more variables: std_err <dbl>, .config <chr>, and abbreviated\n#   variable names ¹​tree_depth, ²​learn_rate, ³​loss_reduction, ⁴​sample_size,\n#   ⁵​.estimator\n\n\nCode\nxgb_usemodel_best_params <- select_best(xgboost_usemodel_tune, \"accuracy\")\nxgb_usemodel_best_params\n\n\n# A tibble: 1 × 8\n   mtry trees min_n tree_depth learn_rate loss_reduction sample_size .config    \n  <int> <int> <int>      <int>      <dbl>          <dbl>       <dbl> <chr>      \n1    13  1603    30         14    0.00985         0.0230       0.806 Preprocess…\n\n\nCode\nxgb_usemodel_final_wflow <- finalize_workflow(\n  xgboost_usemodel_wflow,\n  xgb_usemodel_best_params\n)\n\nxgb_usemodel_final_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: boost_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_novel()\n• step_dummy()\n• step_zv()\n\n── Model ───────────────────────────────────────────────────────────────────────\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = 13\n  trees = 1603\n  min_n = 30\n  tree_depth = 14\n  learn_rate = 0.00985014124434902\n  loss_reduction = 0.0230337047700143\n  sample_size = 0.80635308077326\n\nComputational engine: xgboost \n\n\n\n\n0.8.4 XGB - Usemodel Parameter Ranking - VIP\n\n\nCode\nxgb_usemodel_final_wflow %>%\n  fit(data = train_train) %>%\n  extract_fit_parsnip() %>%\n  vip(geom = \"point\")\n\n\n\n\n\n\n\n0.8.5 XGB - Usemodel Performance\n\nXGB - Usemodel Accuracy Measured on Test Set\n\n\nCode\ncl <- parallel::makePSOCKcluster(cores - 1)\n\nset.seed(1234)\nxgb_usemodel_final_res <- last_fit(xgb_usemodel_final_wflow, train_split)\nxgb_usemodel_final_res\n\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits            id               .metrics .notes   .predictions .workflow \n  <list>            <chr>            <list>   <list>   <list>       <list>    \n1 <split [667/224]> train/test split <tibble> <tibble> <tibble>     <workflow>\n\nThere were issues with some computations:\n\n  - Warning(s) x2: There are new levels in a factor: NA\n\nRun `show_notes(.Last.tune.result)` for more information.\n\n\nCode\nxgb_usemodel_final_metrics <- collect_metrics(xgb_usemodel_final_res)\nxgb_usemodel_final_metrics\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.670 Preprocessor1_Model1\n2 roc_auc  binary         0.797 Preprocessor1_Model1\n\n\nCode\nparallel::stopCluster(cl)\n\n\n\n\nXGB - Usemodel AUC on Test Set (within train)\n\n\nCode\nxgb_usemodel_final_res %>%\n  collect_predictions() %>%\n  roc_curve( truth = survived,.pred_1, event_level = \"second\") %>%\n  ggplot(aes(x = 1-specificity, y = sensitivity)) +\n  geom_line(size = 1.5, color = \"midnightblue\") +\n  geom_abline(\n    lty = 2, alpha = 0.5,\n    color = \"gray50\",\n    size = 1.2\n  )\n\n\n\n\n\n\n\nCode\nxgb_usemodel_test_predictions <- collect_predictions(xgb_usemodel_final_res)\nhead(xgb_usemodel_test_predictions)\n\n\n# A tibble: 6 × 7\n  id               .pred_0 .pred_1  .row .pred_class survived .config           \n  <chr>              <dbl>   <dbl> <int> <fct>       <fct>    <chr>             \n1 train/test split   0.534   0.466    10 0           1        Preprocessor1_Mod…\n2 train/test split   0.291   0.709    11 1           1        Preprocessor1_Mod…\n3 train/test split   0.733   0.267    14 0           0        Preprocessor1_Mod…\n4 train/test split   0.736   0.264    18 0           1        Preprocessor1_Mod…\n5 train/test split   0.640   0.360    20 0           1        Preprocessor1_Mod…\n6 train/test split   0.625   0.375    23 0           1        Preprocessor1_Mod…\n\n\n\n\n\n0.8.6 XGB - Usemodel Confusion Matrix\n\n\nCode\nxgb_usemodel_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#xg-boost---base-recipe",
    "href": "posts/post-with-code/index.html#xg-boost---base-recipe",
    "title": "Titanic from Kaggle",
    "section": "0.9 XG Boost - Base Recipe",
    "text": "0.9 XG Boost - Base Recipe\n\n0.9.1 XGB Model Spec\n\n\nCode\nxgb_model <- \n  boost_tree(\n    trees = tune(),\n    tree_depth = tune(),\n    min_n = tune(),\n    loss_reduction = tune(),\n    sample_size = tune(),\n    mtry = tune(),\n    learn_rate = tune()) %>% \n  set_engine(\"xgboost\") %>% \n  set_mode(\"classification\")\n\nxgb_model\n\n\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = tune()\n  min_n = tune()\n  tree_depth = tune()\n  learn_rate = tune()\n  loss_reduction = tune()\n  sample_size = tune()\n\nComputational engine: xgboost \n\n\n\n\n0.9.2 XGB Workflow\n\n\nCode\nxgb_wflow <- \n  workflow() %>% \n  add_model(xgb_model) %>% \n  add_recipe(recipe_base)\n\n\n\n\n0.9.3 XGB Hyper-Parameter Tuning\n\n\nCode\n# xgb_folds <- vfold_cv(training(train_split), strata = survived)\n# xgb_folds\n\n\n#doParallel::registerDoParallel(cores = cores)\n\nset.seed(1234)\ncl <- parallel::makePSOCKcluster(cores - 1)\n\nxgb_tuning_result <- tune_grid(\n  xgb_wflow,\n  resamples = folds,\n  grid      = xgb_grid,\n  control  = control_grid(save_pred = TRUE,save_workflow = TRUE)\n)\nxgb_tuning_result\n\n\n# Tuning results\n# 5-fold cross-validation using stratification \n# A tibble: 5 × 5\n  splits            id    .metrics           .notes           .predictions\n  <list>            <chr> <list>             <list>           <list>      \n1 <split [532/135]> Fold1 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n2 <split [534/133]> Fold2 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n3 <split [534/133]> Fold3 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n4 <split [534/133]> Fold4 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n5 <split [534/133]> Fold5 <tibble [60 × 11]> <tibble [0 × 3]> <tibble>    \n\n\nCode\nparallel::stopCluster(cl)\n\n\n\n\nCode\nxgb_tuning_metrics <- collect_metrics(xgb_tuning_result)\nxgb_tuning_metrics\n\n\n# A tibble: 60 × 13\n    mtry trees min_n tree_depth learn_r…¹ loss_r…² sampl…³ .metric .esti…⁴  mean\n   <int> <int> <int>      <int>     <dbl>    <dbl>   <dbl> <chr>   <chr>   <dbl>\n 1    11   848    17          1   5.59e-3 5.81e- 3   0.539 accura… binary  0.775\n 2    11   848    17          1   5.59e-3 5.81e- 3   0.539 roc_auc binary  0.844\n 3     9  1145    10          2   5.20e-8 1.60e- 1   0.866 accura… binary  0.775\n 4     9  1145    10          2   5.20e-8 1.60e- 1   0.866 roc_auc binary  0.842\n 5    17   740    15          2   8.39e-2 6.64e- 9   0.252 accura… binary  0.718\n 6    17   740    15          2   8.39e-2 6.64e- 9   0.252 roc_auc binary  0.753\n 7    12   690    38          2   3.89e-9 5.16e-10   0.146 accura… binary  0.616\n 8    12   690    38          2   3.89e-9 5.16e-10   0.146 roc_auc binary  0.5  \n 9    10  1314    11          3   1.72e-5 1.25e- 1   0.163 accura… binary  0.616\n10    10  1314    11          3   1.72e-5 1.25e- 1   0.163 roc_auc binary  0.721\n# … with 50 more rows, 3 more variables: n <int>, std_err <dbl>, .config <chr>,\n#   and abbreviated variable names ¹​learn_rate, ²​loss_reduction, ³​sample_size,\n#   ⁴​.estimator\n\n\nCode\nxgb_tuning_result %>%\n  collect_metrics() %>%\n  filter(.metric == \"accuracy\") %>%\n  select(mean, mtry:sample_size) %>%\n  pivot_longer(mtry:sample_size,\n               values_to = \"value\",\n               names_to = \"parameter\"\n  ) %>%\n  ggplot(aes(value, mean, color = parameter)) +\n  geom_point(alpha = 0.8, show.legend = FALSE) +\n  facet_wrap(~parameter, scales = \"free_x\") +\n  labs(x = NULL, y = \"AUC\")\n\n\n\n\n\n\nXGB Best Parameters then Finalise Workflow\n\n\nCode\nshow_best(xgb_tuning_result, \"accuracy\")\n\n\n# A tibble: 5 × 13\n   mtry trees min_n tree_d…¹ learn…² loss_…³ sampl…⁴ .metric .esti…⁵  mean     n\n  <int> <int> <int>    <int>   <dbl>   <dbl>   <dbl> <chr>   <chr>   <dbl> <int>\n1     4  1982     4       15 4.01e-2 5.53e-8   0.393 accura… binary  0.814     5\n2    15  1689     7       13 2.02e-9 5.67e-6   0.958 accura… binary  0.784     5\n3    16  1549     6        7 1.36e-4 4.92e-4   0.463 accura… binary  0.783     5\n4    19   259    16        9 6.05e-7 1.64e-4   0.735 accura… binary  0.781     5\n5    13  1603    30       14 9.85e-3 2.30e-2   0.806 accura… binary  0.780     5\n# … with 2 more variables: std_err <dbl>, .config <chr>, and abbreviated\n#   variable names ¹​tree_depth, ²​learn_rate, ³​loss_reduction, ⁴​sample_size,\n#   ⁵​.estimator\n\n\nCode\nxgb_best_params <- select_best(xgb_tuning_result, \"accuracy\")\nxgb_best_params\n\n\n# A tibble: 1 × 8\n   mtry trees min_n tree_depth learn_rate loss_reduction sample_size .config    \n  <int> <int> <int>      <int>      <dbl>          <dbl>       <dbl> <chr>      \n1     4  1982     4         15     0.0401   0.0000000553       0.393 Preprocess…\n\n\nCode\nxgb_final_wflow <- finalize_workflow(\n  xgb_wflow,\n  xgb_best_params\n)\n\nxgb_final_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: boost_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = 4\n  trees = 1982\n  min_n = 4\n  tree_depth = 15\n  learn_rate = 0.0400670375292599\n  loss_reduction = 5.52655767061452e-08\n  sample_size = 0.392634701682255\n\nComputational engine: xgboost \n\n\n\n\nCode\nxgb_final_wflow %>%\n  fit(data = train_train) %>%\n  extract_fit_parsnip() %>%\n  vip(geom = \"point\")\n\n\n\n\n\n\n\n\n0.9.4 XGB Performance on Training Test Set\n\nXGB Accuracy Measured on Test Set\n\n\nCode\nxgb_final_res <- last_fit(xgb_final_wflow, train_split)\nxgb_final_res\n\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits            id               .metrics .notes   .predictions .workflow \n  <list>            <chr>            <list>   <list>   <list>       <list>    \n1 <split [667/224]> train/test split <tibble> <tibble> <tibble>     <workflow>\n\n\nCode\nxgb_final_metrics <- collect_metrics(xgb_final_res)\nxgb_final_metrics\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.839 Preprocessor1_Model1\n2 roc_auc  binary         0.870 Preprocessor1_Model1\n\n\n\n\nXGB AUC on Test Set (within train)\n\n\nCode\nxgb_final_res %>%\n  collect_predictions() %>%\n  roc_curve( truth = survived,.pred_1, event_level = \"second\") %>%\n  ggplot(aes(x = 1-specificity, y = sensitivity)) +\n  geom_line(size = 1.5, color = \"midnightblue\") +\n  geom_abline(\n    lty = 2, alpha = 0.5,\n    color = \"gray50\",\n    size = 1.2\n  )\n\n\n\n\n\n\n\nCode\nxgb_test_predictions <- collect_predictions(xgb_final_res)\nhead(xgb_test_predictions)\n\n\n# A tibble: 6 × 7\n  id               .pred_0 .pred_1  .row .pred_class survived .config           \n  <chr>              <dbl>   <dbl> <int> <fct>       <fct>    <chr>             \n1 train/test split  0.0609  0.939     10 1           1        Preprocessor1_Mod…\n2 train/test split  0.346   0.654     11 1           1        Preprocessor1_Mod…\n3 train/test split  0.968   0.0321    14 0           0        Preprocessor1_Mod…\n4 train/test split  0.845   0.155     18 0           1        Preprocessor1_Mod…\n5 train/test split  0.385   0.615     20 1           1        Preprocessor1_Mod…\n6 train/test split  0.319   0.681     23 1           1        Preprocessor1_Mod…\n\n\n\n\n\n0.9.5 XGB Confusion Matrix\n\n\nCode\nxgb_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#neural-net",
    "href": "posts/post-with-code/index.html#neural-net",
    "title": "Titanic from Kaggle",
    "section": "0.10 Neural Net",
    "text": "0.10 Neural Net\n\n0.10.1 NN Model\n\n\nCode\nnnet_model <- \n   mlp(hidden_units = tune(), penalty = tune(), epochs = tune()) %>% \n   set_engine(\"nnet\", MaxNWts = 2600) %>% \n   set_mode(\"classification\")\n\nnnet_model %>% translate()\n\n\nSingle Layer Neural Network Model Specification (classification)\n\nMain Arguments:\n  hidden_units = tune()\n  penalty = tune()\n  epochs = tune()\n\nEngine-Specific Arguments:\n  MaxNWts = 2600\n\nComputational engine: nnet \n\nModel fit template:\nnnet::nnet(formula = missing_arg(), data = missing_arg(), size = tune(), \n    decay = tune(), maxit = tune(), MaxNWts = 2600, trace = FALSE, \n    linout = FALSE)\n\n\n\n\n0.10.2 NN Workflow\n\n\nCode\nnnet_wflow <- workflow() %>% \n  add_model(nnet_model) %>% \n  add_recipe(recipe_base)\n\n\n\n\n0.10.3 NN Parameters\n\n\nCode\nnnet_grid <- grid_latin_hypercube(\n  hidden_units(),\n  penalty (),\n  epochs ()\n)\n\nhead(nnet_grid) \n\n\n# A tibble: 3 × 3\n  hidden_units  penalty epochs\n         <int>    <dbl>  <int>\n1            7 7.66e- 5    944\n2            6 6.36e-10    524\n3            2 1.80e- 3    146\n\n\n\n\n0.10.4 NN Hyper-Parameter Tuning\n\n\nCode\n# nnet_folds <- vfold_cv(train_train, strata = survived)\n# nnet_folds\n\n\n# doParallel::registerDoParallel(cores = cores)\ncl <- parallel::makePSOCKcluster(cores - 1)\n\nset.seed(1234)\nnnet_tuning_result <- tune_grid(\n  nnet_wflow,\n  resamples = folds,\n  grid      = nnet_grid,\n  control   = control_grid(save_pred = TRUE,save_workflow = TRUE)\n)\nnnet_tuning_result\n\n\n# Tuning results\n# 5-fold cross-validation using stratification \n# A tibble: 5 × 5\n  splits            id    .metrics         .notes           .predictions      \n  <list>            <chr> <list>           <list>           <list>            \n1 <split [532/135]> Fold1 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [405 × 9]>\n2 <split [534/133]> Fold2 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [399 × 9]>\n3 <split [534/133]> Fold3 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [399 × 9]>\n4 <split [534/133]> Fold4 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [399 × 9]>\n5 <split [534/133]> Fold5 <tibble [6 × 7]> <tibble [0 × 3]> <tibble [399 × 9]>\n\n\nCode\nparallel::stopCluster(cl)\n\n\n\n\n0.10.5 NN Best Parameters and Finalise Workflow\n\n\nCode\nshow_best(nnet_tuning_result, \"accuracy\")\n\n\n# A tibble: 3 × 9\n  hidden_units  penalty epochs .metric  .estimator  mean     n std_err .config  \n         <int>    <dbl>  <int> <chr>    <chr>      <dbl> <int>   <dbl> <chr>    \n1            2 1.80e- 3    146 accuracy binary     0.820     5  0.0161 Preproce…\n2            7 7.66e- 5    944 accuracy binary     0.776     5  0.0372 Preproce…\n3            6 6.36e-10    524 accuracy binary     0.766     5  0.0334 Preproce…\n\n\nCode\nnn_best_params <- select_best(nnet_tuning_result, \"accuracy\")\n\nnnet_best_auc <- select_best(xgb_tuning_result, \"accuracy\")\nnnet_best_auc\n\n\n# A tibble: 1 × 8\n   mtry trees min_n tree_depth learn_rate loss_reduction sample_size .config    \n  <int> <int> <int>      <int>      <dbl>          <dbl>       <dbl> <chr>      \n1     4  1982     4         15     0.0401   0.0000000553       0.393 Preprocess…\n\n\nCode\nnnet_final_wflow <- finalize_workflow(\n  nnet_wflow,\n  nn_best_params\n)\n\nnnet_final_wflow\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: mlp()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_dummy()\n• step_factor2string()\n• step_zv()\n• step_pca()\n\n── Model ───────────────────────────────────────────────────────────────────────\nSingle Layer Neural Network Model Specification (classification)\n\nMain Arguments:\n  hidden_units = 2\n  penalty = 0.00180188446786651\n  epochs = 146\n\nEngine-Specific Arguments:\n  MaxNWts = 2600\n\nComputational engine: nnet \n\n\n\n\nCode\nnnet_final_wflow %>%\n  fit(data = train_train) %>%\n  extract_fit_parsnip() %>%\n  vip(geom = \"point\")\n\n\n\n\n\n\n\n0.10.6 NN Accuracy - Train/Test Set\n\n\nCode\nnnet_tuning_metrics <- collect_metrics(nnet_tuning_result)\nnnet_tuning_metrics\n\n\n# A tibble: 6 × 9\n  hidden_units  penalty epochs .metric  .estimator  mean     n std_err .config  \n         <int>    <dbl>  <int> <chr>    <chr>      <dbl> <int>   <dbl> <chr>    \n1            7 7.66e- 5    944 accuracy binary     0.776     5  0.0372 Preproce…\n2            7 7.66e- 5    944 roc_auc  binary     0.788     5  0.0395 Preproce…\n3            6 6.36e-10    524 accuracy binary     0.766     5  0.0334 Preproce…\n4            6 6.36e-10    524 roc_auc  binary     0.779     5  0.0421 Preproce…\n5            2 1.80e- 3    146 accuracy binary     0.820     5  0.0161 Preproce…\n6            2 1.80e- 3    146 roc_auc  binary     0.865     5  0.0153 Preproce…\n\n\nCode\nnnet_final_res <- last_fit(nnet_final_wflow, train_split)\nnnet_final_res\n\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits            id               .metrics .notes   .predictions .workflow \n  <list>            <chr>            <list>   <list>   <list>       <list>    \n1 <split [667/224]> train/test split <tibble> <tibble> <tibble>     <workflow>\n\n\nCode\nnnet_final_metrics <- collect_metrics(nnet_final_res)\nnnet_final_metrics\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.786 Preprocessor1_Model1\n2 roc_auc  binary         0.824 Preprocessor1_Model1\n\n\n\n\n0.10.7 NN AUC\n\n\nCode\nnnet_final_res %>%\n  collect_predictions() %>%\n  roc_curve( truth = survived,.pred_1, event_level = \"second\") %>%\n  ggplot(aes(x = 1-specificity, y = sensitivity)) +\n  geom_line(size = 1.5, color = \"midnightblue\") +\n  geom_abline(\n    lty = 2, alpha = 0.5,\n    color = \"gray50\",\n    size = 1.2\n  )\n\n\n\n\n\n\n\n0.10.8 NN Predictions on Train/Test Set\n\n\nCode\nnnet_test_predictions <- nnet_final_res %>%\n  collect_predictions() \nhead(nnet_test_predictions)\n\n\n# A tibble: 6 × 7\n  id               .pred_0 .pred_1  .row .pred_class survived .config           \n  <chr>              <dbl>   <dbl> <int> <fct>       <fct>    <chr>             \n1 train/test split   0.363   0.637    10 1           1        Preprocessor1_Mod…\n2 train/test split   0.603   0.397    11 0           1        Preprocessor1_Mod…\n3 train/test split   0.701   0.299    14 0           0        Preprocessor1_Mod…\n4 train/test split   0.680   0.320    18 0           1        Preprocessor1_Mod…\n5 train/test split   0.363   0.637    20 1           1        Preprocessor1_Mod…\n6 train/test split   0.363   0.637    23 1           1        Preprocessor1_Mod…\n\n\n\n\n0.10.9 NN Confusion Matrix\n\n\nCode\nnnet_test_predictions %>% conf_mat(survived,.pred_class) %>% \n  autoplot(type = \"heatmap\")"
  },
  {
    "objectID": "posts/post-with-code/index.html#stack-models",
    "href": "posts/post-with-code/index.html#stack-models",
    "title": "Titanic from Kaggle",
    "section": "0.11 Stack Models",
    "text": "0.11 Stack Models\n\n0.11.1 Stack Recipe\n\n\nCode\nrecipe_stack <- \n  recipe(survived ~ ., data = train_train) %>% \n  update_role(passenger_id, name,surname,ticket,cabin,new_role = \"ID\") %>% \n  step_impute_knn(all_numeric_predictors()) %>% \n  step_dummy(all_nominal_predictors()) %>%\n  step_factor2string(all_nominal_predictors()) %>% \n  step_zv(all_predictors()) %>% \n  step_pca()\nrecipe_stack\n\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          5\n   outcome          1\n predictor         13\n\nOperations:\n\nK-nearest neighbor imputation for all_numeric_predictors()\nDummy variables from all_nominal_predictors()\nCharacter variables from all_nominal_predictors()\nZero variance filter on all_predictors()\nPCA extraction with <none>\n\n\nCode\nrecipe_stack_trained <- prep(recipe_base)\nrecipe_stack_trained\n\n\nRecipe\n\nInputs:\n\n      role #variables\n        ID          5\n   outcome          1\n predictor         13\n\nTraining data contained 667 data points and 514 incomplete rows. \n\nOperations:\n\nK-nearest neighbor imputation for age, sib_sp, parch, fare [trained]\nDummy variables from pclass, sex, embarked, train_test, pax_type, cabin_prefac... [trained]\nCharacter variables from <none> [trained]\nZero variance filter removed train_test_test [trained]\nNo PCA components were extracted from <none> [trained]\n\n\n\n\n0.11.2 Stack Controls\n\n\nCode\nstack_ctrl <- control_resamples(save_pred = TRUE, save_workflow = TRUE)\n#stack_folds <- vfold_cv(training(train_split), v=10,strata = \"survived\")\n\nlibrary(stacks)\n\nmodel_stack <-\n  stacks() %>%\n  #add_candidates(lr_wflow) %>%\n  #add_candidates(rf_wflow) %>%\n  add_candidates(nnet_tuning_result) %>%\n  add_candidates(rlr_tuning_result) %>% \n  add_candidates(xgb_tuning_result)\n\n\n\n\n0.11.3 Stack Blend\n\n\nCode\ncl <- parallel::makePSOCKcluster(cores - 1)\n\nset.seed(1234)\nensemble <- blend_predictions(model_stack,penalty = 10^seq(-2, -0.5, length = 20))\nautoplot(ensemble)\n\n\n\n\n\nCode\nparallel::stopCluster(cl)\n\n\n\n\nCode\nensemble \n\n\n# A tibble: 4 × 3\n  member                         type         weight\n  <chr>                          <chr>         <dbl>\n1 .pred_1_nnet_tuning_result_1_3 mlp           2.25 \n2 .pred_1_rlr_tuning_result_1_30 logistic_reg  1.11 \n3 .pred_1_rlr_tuning_result_1_28 logistic_reg  1.09 \n4 .pred_1_xgb_tuning_result_1_29 boost_tree    0.658\n\n\n\n\n0.11.4 Stack Weights\n\n\nCode\nautoplot(ensemble, \"weights\") +\n  geom_text(aes(x = weight + 0.01, label = model), hjust = 0) + \n  theme(legend.position = \"none\") \n\n\n\n\n\n\n\n0.11.5 Fit Member Models\n\n\nCode\nensemble <- fit_members(ensemble)\ncollect_parameters(ensemble,\"xgb_tuning_result\")\n\n\n# A tibble: 27 × 10\n   member          mtry trees min_n tree_…¹ learn…² loss_r…³ sampl…⁴ terms  coef\n   <chr>          <int> <int> <int>   <int>   <dbl>    <dbl>   <dbl> <chr> <dbl>\n 1 xgb_tuning_re…    11   848    17       1 5.59e-3 5.81e- 3   0.539 .pre…     0\n 2 xgb_tuning_re…     9  1145    10       2 5.20e-8 1.60e- 1   0.866 .pre…     0\n 3 xgb_tuning_re…    17   740    15       2 8.39e-2 6.64e- 9   0.252 .pre…     0\n 4 xgb_tuning_re…    10  1314    11       3 1.72e-5 1.25e- 1   0.163 .pre…     0\n 5 xgb_tuning_re…    18  1475    25       3 1.50e-6 2.46e- 9   0.328 .pre…     0\n 6 xgb_tuning_re…     6    98    23       4 4.07e-4 1.02e- 3   0.897 .pre…     0\n 7 xgb_tuning_re…     7   923    13       5 1.66e-3 1.78e- 5   0.352 .pre…     0\n 8 xgb_tuning_re…    16   610    26       5 1.14e-5 1.88e-10   0.211 .pre…     0\n 9 xgb_tuning_re…    16  1549     6       7 1.36e-4 4.92e- 4   0.463 .pre…     0\n10 xgb_tuning_re…    14  1900    22       7 2.14e-7 3.46e- 6   0.447 .pre…     0\n# … with 17 more rows, and abbreviated variable names ¹​tree_depth, ²​learn_rate,\n#   ³​loss_reduction, ⁴​sample_size\n\n\n\n\n0.11.6 Stack Predict\n\n\nCode\n#ensemble_metrics <- metric_set(roc_auc,accuracy)\n\nensemble_test_predictions <- \n  predict(ensemble,train_test) %>% \n  bind_cols(train_test) \n\n\n# ensemble_test_predictions <- ensemble_test_predictions %>% \n#   mutate(.pred_class=as.numeric(.pred_class)) %>% \n#    mutate(survived =as.numeric(survived)) \n# \n# ensemble_test_predictions <- ensemble_test_predictions %>% \n#   mutate(roc = roc_auc(truth=survived, estimate = .pred_class))\n\n\n\nglimpse(ensemble_test_predictions)\n\n\nRows: 224\nColumns: 20\n$ .pred_class   <fct> 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0,…\n$ passenger_id  <dbl> 10, 11, 14, 18, 20, 23, 28, 40, 41, 51, 54, 57, 61, 66, …\n$ survived      <fct> 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1,…\n$ pclass        <fct> 2, 3, 3, 2, 3, 3, 1, 3, 3, 3, 2, 2, 3, 3, 2, 3, 3, 2, 3,…\n$ name          <fct> \"Nasser, Mrs. Nicholas (Adele Achem)\", \"Sandstrom, Miss.…\n$ sex           <fct> female, female, male, male, female, female, male, female…\n$ age           <dbl> 14, 4, 39, 30, 31, 15, 19, 14, 40, 7, 29, 21, 22, 6, 21,…\n$ sib_sp        <dbl> 1, 1, 1, 0, 0, 0, 3, 1, 1, 4, 1, 0, 0, 1, 0, 0, 0, 0, 3,…\n$ parch         <dbl> 0, 1, 5, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,…\n$ ticket        <fct> 237736, PP 9549, 347082, 244373, 2649, 330923, 19950, 26…\n$ fare          <dbl> 30.0708, 16.7000, 31.2750, 13.0000, 7.2250, 8.0292, 263.…\n$ cabin         <fct> NA, G6, NA, NA, NA, NA, C23 C25 C27, NA, NA, NA, NA, NA,…\n$ embarked      <fct> C, S, S, S, C, Q, S, C, S, S, S, S, C, C, S, S, Q, S, S,…\n$ train_test    <fct> train, train, train, train, train, train, train, train, …\n$ pax_type      <fct> F_married, F_unmarried, Mr., Mr., F_married, F_unmarried…\n$ surname       <fct> \"Nasser,\", \"Sandstrom,\", \"Andersson,\", \"Williams,\", \"Mas…\n$ cabin_preface <fct> nk, G, nk, nk, nk, nk, C, nk, nk, nk, nk, nk, nk, nk, nk…\n$ ticket_group  <fct> couple, group, group, single, single, single, group, cou…\n$ family_group  <ord> couple, family, family, single, single, single, family, …\n$ age_group     <ord> teen, child, 30s, 30s, 30s, teen, teen, teen, 40s, child…"
  },
  {
    "objectID": "posts/post-with-code/index.html#join-model-prediction-data",
    "href": "posts/post-with-code/index.html#join-model-prediction-data",
    "title": "Titanic from Kaggle",
    "section": "0.12 Join Model Prediction Data",
    "text": "0.12 Join Model Prediction Data\n\n\nCode\nall_predictions <- \n  lr_test_predictions %>% mutate(model = \"LR\") %>% \n  bind_rows(nnet_test_predictions %>% mutate(model = \"NNet\")) %>% \n  bind_rows(rlr_test_predictions %>% mutate(model = \"Reg_LR\")) %>% \n  bind_rows(rf_test_predictions %>% mutate(model = \"RF\")) %>% \n  bind_rows(xgb_test_predictions %>% mutate(model = \"xgb\")) %>% \n  bind_rows(xgb_usemodel_test_predictions %>% mutate(model = \"xgb_usemodel\")) %>% \n  bind_rows(ensemble_test_predictions %>% mutate(model = \"ensemble\"))\n  \nall_predictions %>% head() %>% knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\n.pred_0\n.pred_1\n.row\n.pred_class\nsurvived_pred\n.config\npassenger_id\nsurvived\npclass\nname\nsex\nage\nsib_sp\nparch\nticket\nfare\ncabin\nembarked\ntrain_test\npax_type\nsurname\ncabin_preface\nticket_group\nfamily_group\nage_group\nmodel\n\n\n\n\ntrain/test split\n0.0947816\n0.9052184\n10\n1\n1\nPreprocessor1_Model1\n10\n1\n2\nNasser, Mrs. Nicholas (Adele Achem)\nfemale\n14\n1\n0\n237736\n30.0708\nNA\nC\ntrain\nF_married\nNasser,\nnk\ncouple\ncouple\nteen\nLR\n\n\ntrain/test split\n0.9999997\n0.0000003\n11\n0\n1\nPreprocessor1_Model1\n11\n1\n3\nSandstrom, Miss. Marguerite Rut\nfemale\n4\n1\n1\nPP 9549\n16.7000\nG6\nS\ntrain\nF_unmarried\nSandstrom,\nG\ngroup\nfamily\nchild\nLR\n\n\ntrain/test split\n0.9959939\n0.0040061\n14\n0\n0\nPreprocessor1_Model1\n14\n0\n3\nAndersson, Mr. Anders Johan\nmale\n39\n1\n5\n347082\n31.2750\nNA\nS\ntrain\nMr.\nAndersson,\nnk\ngroup\nfamily\n30s\nLR\n\n\ntrain/test split\n0.7485089\n0.2514911\n18\n0\n1\nPreprocessor1_Model1\n18\n1\n2\nWilliams, Mr. Charles Eugene\nmale\n30\n0\n0\n244373\n13.0000\nNA\nS\ntrain\nMr.\nWilliams,\nnk\nsingle\nsingle\n30s\nLR\n\n\ntrain/test split\n0.1223361\n0.8776639\n20\n1\n1\nPreprocessor1_Model1\n20\n1\n3\nMasselmani, Mrs. Fatima\nfemale\n31\n0\n0\n2649\n7.2250\nNA\nC\ntrain\nF_married\nMasselmani,\nnk\nsingle\nsingle\n30s\nLR\n\n\ntrain/test split\n0.3091538\n0.6908462\n23\n1\n1\nPreprocessor1_Model1\n23\n1\n3\nMcGowan, Miss. Anna “Annie”\nfemale\n15\n0\n0\n330923\n8.0292\nNA\nQ\ntrain\nF_unmarried\nMcGowan,\nnk\nsingle\nsingle\nteen\nLR"
  },
  {
    "objectID": "posts/post-with-code/index.html#all-metrics",
    "href": "posts/post-with-code/index.html#all-metrics",
    "title": "Titanic from Kaggle",
    "section": "0.13 All Metrics",
    "text": "0.13 All Metrics\nOrdered by descending Accuracy metric\n\n\nCode\nall_metrics <- \n  lr_final_metrics %>% mutate(model = \"LR\") %>% \n  bind_rows(nnet_final_metrics %>% mutate(model = \"NNet\")) %>% \n  bind_rows(rlr_final_metrics %>% mutate(model = \"Reg_LR\")) %>% \n  bind_rows(rf_final_metrics %>% mutate(model = \"RF\")) %>% \n  bind_rows(xgb_final_metrics %>% mutate(model = \"xgb\")) %>% \n  bind_rows(xgb_usemodel_final_metrics %>% mutate(model = \"xgb-usemodel\")) \n\nall_metrics_table <- all_metrics %>% \n   pivot_wider(names_from = .metric,values_from = .estimate) %>% \n   arrange(desc(accuracy))\n  \nwrite_rds(all_metrics,\"artifacts/all_metrics.rds\")\n\nall_metrics_table %>% knitr::kable(digits=3)\n\n\n\n\n\n.estimator\n.config\nmodel\naccuracy\nroc_auc\n\n\n\n\nbinary\nPreprocessor1_Model1\nxgb\n0.839\n0.870\n\n\nbinary\nPreprocessor1_Model1\nRF\n0.821\n0.874\n\n\nbinary\nPreprocessor1_Model1\nReg_LR\n0.808\n0.842\n\n\nbinary\nPreprocessor1_Model1\nLR\n0.799\n0.822\n\n\nbinary\nPreprocessor1_Model1\nNNet\n0.786\n0.824\n\n\nbinary\nPreprocessor1_Model1\nxgb-usemodel\n0.670\n0.797\n\n\n\n\n\nand a graph:\n\n\nCode\nall_metrics %>% \n  filter(.metric == \"accuracy\") %>% \n  select(model, accuracy = .estimate) %>% \n  ggplot(aes(model, accuracy)) +\n  geom_col()"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "What is this for?",
    "section": "",
    "text": "This is my public notebook created in Quarto after seeing all the recent webinars from the amazing people at RStudio.\nIt is intended that it will contain public ‘Notes to Myself’ on some of my interests which professionally are likely to centre on things like:\n\nR Programming\nPython Programming\nML analytics in R and Python\nFinance and data analytics (my day job)\nOther analytics and notes collected from wherever\n\nNot sure that it will be much use to anyone else, but feel free to wander through."
  },
  {
    "objectID": "posts/forecasting_with_deep_learning/index.html#modeltime-comparison",
    "href": "posts/forecasting_with_deep_learning/index.html#modeltime-comparison",
    "title": "Flight Forecasting with Deep Learning - Incomplete",
    "section": "7 Modeltime Comparison",
    "text": "7 Modeltime Comparison\nThe following code puts all models in the one table, renames them and produces an accuracy report, sorted by ‘MAAPE’, best at top. Unfortunately it does not want to render in quarto.\n\n\nCode\n#modeltime_calibrate()\n\n# Modeltime Comparison ----\n\nmodel_tbl_submodels <- modeltime_table(\n  wflw_fit_deepar_1,\n  wflw_fit_deepar_2,\n  wflw_fit_deepar_3,\n  #\n  wflw_fit_nbeats_4,\n  wflw_fit_nbeats_5,\n  wflw_fit_nbeats_6\n)\n\nmodel_tbl_submodels <- model_tbl_submodels %>% \n  update_model_description(1,\"DEEPAR - unscaled, 5ep\") %>% \n  update_model_description(2,\"DEEPAR - unscaled, 10ep\") %>% \n  update_model_description(3,\"DEEPAR - scaled, 10ep\") %>% \n  update_model_description(4,\"N-BEATS - 5ep\") %>% \n  update_model_description(5,\"N-BEATS - 5ep,MASE\") %>% \n  update_model_description(6,\"N-BEATS - ens, 5ep,MASE\") \n\n\n # model_tbl_submodels_calibrate <- model_tbl_submodels %>% \n #   modeltime_calibrate(new_data = testing(splits))\n # \n # \n\n# # Forecast Accuracy - not rendering????\n\n# model_tbl_submodels_calibrate %>%\n#   modeltime_accuracy(\n#     #testing(splits),\n#     metric_set = extended_forecast_accuracy_metric_set()) %>%\n#   arrange(maape) %>%\n#    gt::gt() %>%\n#     gt::fmt_number(\n#      columns = 4:10,\n#       decimals = 3)"
  },
  {
    "objectID": "docs/site_libs/minichart-0.2.2/doc/introduction.html",
    "href": "docs/site_libs/minichart-0.2.2/doc/introduction.html",
    "title": "Introduction to leaflet.minicharts",
    "section": "",
    "text": "For a few years now, it has become very to create interactive maps with R thanks to the package leaflet by the Rstudio team. Nevertheless, it only provides only a few functions to create basic shapes on a map, so the information that can be represented on a single map is limited: if you have some data associated to some points, you can only represent at most two variables by drawing circles and changing their radius and color according to data.\nleaflet.minicharts is an R package that provides two functions to add and update small charts on an interactive maps created with the package leaflet. These charts can be used to represent as many variables as desired associated to geographical points. Currently, three types of chart are supported: barcharts (the default), pie charts and polar area charts.\nlet’s have a look to a concrete example."
  },
  {
    "objectID": "docs/site_libs/minichart-0.2.2/doc/introduction.html#data",
    "href": "docs/site_libs/minichart-0.2.2/doc/introduction.html#data",
    "title": "Introduction to leaflet.minicharts",
    "section": "Data",
    "text": "Data\nThe package provides a table that contains the electric production, consumption and exchanges of France from january 2010 to february 2017 and of 12 french regions from january 2013 to february 2017.\nIn addition to the total production, the table contains one column for each type of production. The table also contains the latitude and longitude of the center of the regions.\n\nlibrary(leaflet.minicharts)\ndata(\"eco2mix\")\nhead(eco2mix)\n\n                  area      lng      lat   month total nuclear coal fuel gaz\n1 Auvergne-Rhone-Alpes 4.537338 45.51266 2015-03 11430    8230    6   40 200\n2 Auvergne-Rhone-Alpes 4.537338 45.51266 2015-06 10056    7200    4   35   5\n3 Auvergne-Rhone-Alpes 4.537338 45.51266 2013-04 10532    7410    0   31   3\n4 Auvergne-Rhone-Alpes 4.537338 45.51266 2015-04 10103    7275    4   39  86\n5 Auvergne-Rhone-Alpes 4.537338 45.51266 2014-08  9052    6357    0   25  -1\n6 Auvergne-Rhone-Alpes 4.537338 45.51266 2015-11  9258    7192    5   45 250\n  hydraulic wind solar bioenergy load balance export import balanceUK balanceES\n1      2737   74    57        82 6326    4747     NA     NA        NA        NA\n2      2606   44   101        58 4848    4891     NA     NA        NA        NA\n3      2948   55    39        42   NA      NA     NA     NA        NA        NA\n4      2487   66    81        61 5283    4439     NA     NA        NA        NA\n5      2487   38    76        68 4299    4447     NA     NA        NA        NA\n6      1563   75    40        86 5829    3141     NA     NA        NA        NA\n  balanceIT balanceCH balanceDEBE\n1        NA        NA          NA\n2        NA        NA          NA\n3        NA        NA          NA\n4        NA        NA          NA\n5        NA        NA          NA\n6        NA        NA          NA"
  },
  {
    "objectID": "docs/site_libs/minichart-0.2.2/doc/introduction.html#renewable-productions-in-2016",
    "href": "docs/site_libs/minichart-0.2.2/doc/introduction.html#renewable-productions-in-2016",
    "title": "Introduction to leaflet.minicharts",
    "section": "Renewable productions in 2016",
    "text": "Renewable productions in 2016\nNowadays, France has an objective of 23% of renewable energies in the consumption of the country by 2020. Are the country close to its objective. Is the share of renewable energies similar in all regions?\nTo answer this question let us focus on the year 2016 We first prepare the required data with package dplyr:\n\nlibrary(dplyr)\n\nprod2016 <- eco2mix %>%\n  mutate(\n    renewable = bioenergy + solar + wind + hydraulic,\n    non_renewable = total - bioenergy - solar - wind - hydraulic\n  ) %>%\n  filter(grepl(\"2016\", month) & area != \"France\") %>%\n  select(-month) %>%\n  group_by(area, lat, lng) %>%\n  summarise_all(sum) %>%\n  ungroup()\n\nhead(prod2016)\n\n# A tibble: 6 × 23\n  area    lat   lng  total nuclear  coal  fuel   gaz hydra…¹  wind solar bioen…²\n  <chr> <dbl> <dbl>  <dbl>   <dbl> <dbl> <dbl> <dbl>   <dbl> <dbl> <dbl>   <dbl>\n1 Auve…  45.5  4.54 108517   75002    59   101  2318   28398   849   803     949\n2 Bour…  47.2  4.81   2762       0     0     1   644     939   773   211     172\n3 Bret…  48.2 -2.84   3141       0     0     9   543     581  1472   192     319\n4 Cent…  47.5  1.69  78430   75733     0     0   274     120  1616   238     418\n5 Gran…  48.7  5.61 107755   82734  1650    41  8282    8990  4917   462     642\n6 Haut…  50.0  2.77  45593   31222    48    17  8302       8  4851   122     982\n# … with 11 more variables: load <dbl>, balance <dbl>, export <dbl>,\n#   import <dbl>, balanceUK <dbl>, balanceES <dbl>, balanceIT <dbl>,\n#   balanceCH <dbl>, balanceDEBE <dbl>, renewable <dbl>, non_renewable <dbl>,\n#   and abbreviated variable names ¹​hydraulic, ²​bioenergy\n\n\nWe also create a base map that will be used in all the following examples\n\nlibrary(leaflet)\n\ntilesURL <- \"http://server.arcgisonline.com/ArcGIS/rest/services/Canvas/World_Light_Gray_Base/MapServer/tile/{z}/{y}/{x}\"\n\nbasemap <- leaflet(width = \"100%\", height = \"400px\") %>%\n  addTiles(tilesURL)\n\nWe now add to the base map a pie chart for each region that represents the share of renewable energies. We also change the width of the pie charts so their area is proportional to the total production of the corresponding region.\n\ncolors <- c(\"#4fc13c\", \"#cccccc\")\n\nbasemap %>%\n  addMinicharts(\n    prod2016$lng, prod2016$lat,\n    type = \"pie\",\n    chartdata = prod2016[, c(\"renewable\", \"non_renewable\")], \n    colorPalette = colors, \n    width = 60 * sqrt(prod2016$total) / sqrt(max(prod2016$total)), transitionTime = 0\n  )\n\n\n\n\n\nWe can see that the three south east regions exceed the target of 23%, but most regions are far from this objective. Globally, renewable energies represented only 19% percent of the production of 2016.\nNow let’s represent the different types of renewable production using bar charts.\n\nrenewable2016 <- prod2016 %>% select(hydraulic, solar, wind)\ncolors <- c(\"#3093e5\", \"#fcba50\", \"#a0d9e8\")\nbasemap %>%\n  addMinicharts(\n    prod2016$lng, prod2016$lat,\n    chartdata = renewable2016,\n    colorPalette = colors,\n    width = 45, height = 45\n  )\n\n\n\n\n\nHydraulic production is far more important than solar and wind. Without surprise, solar production is more important in south while wind production is more important in the north."
  },
  {
    "objectID": "docs/site_libs/minichart-0.2.2/doc/introduction.html#representing-a-single-variable",
    "href": "docs/site_libs/minichart-0.2.2/doc/introduction.html#representing-a-single-variable",
    "title": "Introduction to leaflet.minicharts",
    "section": "Representing a single variable",
    "text": "Representing a single variable\nleaflet.minicharts has been designed to represent multiple variables at once, but you still may want to use it to represent a single variable. In the next example, we represent the total load of each french region in 2016. When data passed to addMinicharts contains a single column, it automatically represents it with circle which area is proportional to the corresponding value. In the example we also use the parameter showLabels to display rounded values of the variable inside the circles.\n\nbasemap %>%\n  addMinicharts(\n    prod2016$lng, prod2016$lat,\n    chartdata = prod2016$load,\n    showLabels = TRUE,\n    width = 45\n  )\n\n\n\n\n\nThis is nice, isn’t it?"
  },
  {
    "objectID": "docs/site_libs/minichart-0.2.2/doc/introduction.html#animated-maps",
    "href": "docs/site_libs/minichart-0.2.2/doc/introduction.html#animated-maps",
    "title": "Introduction to leaflet.minicharts",
    "section": "Animated maps",
    "text": "Animated maps\nUntil now, we have only represented aggregated data but it would be nice to create a map that represents the evolution over time of some variables. It is actually easy with leaflet.minicharts. The first step is to construct a table containing longitude, latitude, a time column and the variables we want to represent. The table eco2mix already has all these columns. We only need to filter the rows containing data for the entire country.\n\nprodRegions <- eco2mix %>% filter(area != \"France\")\n\nNow we can create our animated map by using the argument “time”:\n\nbasemap %>% \n  addMinicharts(\n    prodRegions$lng, prodRegions$lat, \n    chartdata = prodRegions[, c(\"hydraulic\", \"solar\", \"wind\")],\n    time = prodRegions$month,\n    colorPalette = colors,\n    width = 45, height = 45\n  )"
  },
  {
    "objectID": "docs/site_libs/minichart-0.2.2/doc/introduction.html#represent-flows",
    "href": "docs/site_libs/minichart-0.2.2/doc/introduction.html#represent-flows",
    "title": "Introduction to leaflet.minicharts",
    "section": "Represent flows",
    "text": "Represent flows\nSince version 0.2, leaflet.minicharts has also functions to represent flows between points and their evolution. To illustrate this, let’s represent the evolution of electricity exchanges between France and Neighboring countries.\nTo do that, we use function addFlows. It requires coordinates of two points for each flow and the value of the flow. Other arguments are similar to addMinicharts.\n\ndata(\"eco2mixBalance\")\nbal <- eco2mixBalance\nbasemap %>%\n  addFlows(\n    bal$lng0, bal$lat0, bal$lng1, bal$lat1,\n    flow = bal$balance,\n    time = bal$month\n  )\n\n\n\n\n\nOf course, you can represent flows and minicharts on the same map!"
  },
  {
    "objectID": "docs/site_libs/minichart-0.2.2/doc/introduction.html#use-in-shiny-web-applications",
    "href": "docs/site_libs/minichart-0.2.2/doc/introduction.html#use-in-shiny-web-applications",
    "title": "Introduction to leaflet.minicharts",
    "section": "Use in shiny web applications",
    "text": "Use in shiny web applications\nIn shiny applications, you can create nice transition effects by using functions leafletproxy and updateMinicharts/updateFlows. In the server function you first need to initialize the map and the minicharts. The important thing here is to use parameter layerId so that updateMinicharts can know which chart to update with which values.\n\nserver <- function(input, output, session) {\n  # Initialize map\n  output$mymap <- renderLeaflet(\n    leaflet() %>% addTiles() %>%\n      addMinicharts(lon, lat, layerId = uniqueChartIds)\n  )\n}\n\nThen use leafletProxy() and updateMinicharts in your reactive code:\n\nserver <- function(input, output, session) {\n  # Initialize map\n  ...\n  \n  # Update map\n  observe({\n    newdata <- getData(input$myinput)\n    \n    leafletProxy(\"mymap\") %>% \n      updateMinicharts(uniqueChartIds, chartdata = newdata, ...)\n  })\n}\n\nYou can find a live example here."
  },
  {
    "objectID": "posts/forecasting_with_deep_learning/index.html#load-libraries",
    "href": "posts/forecasting_with_deep_learning/index.html#load-libraries",
    "title": "Flight Forecasting with Deep Learning - Incomplete",
    "section": "2 Load Libraries",
    "text": "2 Load Libraries\n\n\nCode\n#| echo: false\n\n# Time Series ML\nlibrary(tidymodels)\nlibrary(modeltime)\nlibrary(modeltime.gluonts)\nlibrary(modeltime.ensemble)\n\n# Core\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(timetk)\n\n# Timing & Parallel Processing\nlibrary(tictoc)\nlibrary(future)\nlibrary(doFuture)\n\nlibrary(skimr)\nlibrary(gt)\nlibrary(here)"
  },
  {
    "objectID": "posts/forecasting_with_deep_learning/index.html#refit-models",
    "href": "posts/forecasting_with_deep_learning/index.html#refit-models",
    "title": "Flight Forecasting with Deep Learning - Incomplete",
    "section": "8 Refit Models",
    "text": "8 Refit Models\nModels are then refit to full train/test data.\n\n\nCode\nsubmodels_refitted_tbl <- model_tbl_submodels %>% \n    modeltime_refit(data_prepared_tbl)\n\nsubmodels_refitted_tbl\n\n\n# Modeltime Table\n# A tibble: 6 × 3\n  .model_id .model     .model_desc            \n      <int> <list>     <chr>                  \n1         1 <workflow> DEEPAR - unscaled, 5ep \n2         2 <workflow> DEEPAR - unscaled, 10ep\n3         3 <workflow> DEEPAR - scaled, 10ep  \n4         4 <workflow> N-BEATS - 5ep          \n5         5 <workflow> N-BEATS - 5ep,MASE     \n6         6 <workflow> N-BEATS - ens, 5ep,MASE"
  },
  {
    "objectID": "posts/forecasting_with_deep_learning/index.html#make-predictions",
    "href": "posts/forecasting_with_deep_learning/index.html#make-predictions",
    "title": "Flight Forecasting with Deep Learning - Incomplete",
    "section": "9 Make Predictions",
    "text": "9 Make Predictions\n\n\nCode\nsubmodels_pred_ <- submodels_refitted_tbl %>% \n  modeltime_forecast(\n  new_data = future_tbl,\n  actual_data = data_prepared_tbl,\n  keep_data = TRUE\n)\n\nhead(submodels_pred_)\n\n\n# A tibble: 6 × 24\n  .mode…¹ .mode…² .key  .index     .value rowid route date       passe…³ index…⁴\n    <int> <chr>   <fct> <date>      <dbl> <int> <chr> <date>       <dbl>   <dbl>\n1      NA ACTUAL  actu… 2002-01-01   8.74    13 ADEL… 2002-01-01    8.74    20.7\n2      NA ACTUAL  actu… 2002-02-01   8.68    14 ADEL… 2002-02-01    8.68    20.7\n3      NA ACTUAL  actu… 2002-03-01   8.87    15 ADEL… 2002-03-01    8.87    20.7\n4      NA ACTUAL  actu… 2002-04-01   8.88    16 ADEL… 2002-04-01    8.88    20.7\n5      NA ACTUAL  actu… 2002-05-01   8.76    17 ADEL… 2002-05-01    8.76    20.7\n6      NA ACTUAL  actu… 2002-06-01   8.75    18 ADEL… 2002-06-01    8.75    20.7\n# … with 14 more variables: diff <dbl>, year <dbl>, half <int>, quarter <int>,\n#   month <int>, month.lbl <ord>, date_sin6_K1 <dbl>, date_cos6_K1 <dbl>,\n#   date_sin12_K1 <dbl>, date_cos12_K1 <dbl>, passenger_trips_lag12 <dbl>,\n#   passenger_trips_lag12_roll_6 <dbl>, passenger_trips_lag12_roll_12 <dbl>,\n#   passenger_trips_lag12_roll_24 <dbl>, and abbreviated variable names\n#   ¹​.model_id, ²​.model_desc, ³​passenger_trips, ⁴​index.num\n\n\n\n\n\n\n\nCode\nsubmodels_pred_ %>%\n  filter(route %in% topx) %>% \n  group_by(route) %>%\n  ggplot(aes(x = .index, y = .value,colour = .model_desc))+\n  geom_line() +\n  scale_y_continuous(labels = comma) +\n  labs(x = \"\", y = \"pax pm(000)\") +\n  facet_wrap(~ route,  ncol=2, scales = \"free\") +\n  theme(legend.position = c(1,0)) +\n  theme(legend.text = element_text(size=5))\n\n\n\n\n\nCode\n  # plot_modeltime_forecast(\n  #   .trelliscope = F,\n  #   .facet_ncol = 2,\n  #   .title = \"Predictions - Top10 Routes\"\n  # )\n\n\nThe accuracy stats and graph suggest that some of these are not so good. .."
  },
  {
    "objectID": "posts/forecasting_with_deep_learning/index.html#ensemble-model",
    "href": "posts/forecasting_with_deep_learning/index.html#ensemble-model",
    "title": "Flight Forecasting with Deep Learning - Incomplete",
    "section": "10 Ensemble Model",
    "text": "10 Ensemble Model\nEnsemble the top deep learning models:\n\nModel 6 - N-Beats ensuite\nModel 3 - DeepAR scaled, 10 epochs\nModel 2 - DeepAR unscaled 10 epochs\n\nThere is no reason not to also include some ML models in the ensemble - we will do that in a separate post.\n\n\nCode\n# Modeltime Comparison ----\n\nmodel_tbl_ensemble <- modeltime_table(\n  #wflw_fit_deepar_1,\n  wflw_fit_deepar_2,\n  wflw_fit_deepar_3,\n  #\n  #wflw_fit_nbeats_4,\n  #wflw_fit_nbeats_5,\n  wflw_fit_nbeats_6\n)\n\nmodel_tbl_ensemble <- model_tbl_ensemble %>% \n  #update_model_description(1,\"DEEPAR - unscaled, 5ep\") %>% \n  update_model_description(1,\"DEEPAR - unscaled, 10ep\") %>% \n  update_model_description(2,\"DEEPAR - scaled, 10ep\") %>% \n  #update_model_description(4,\"N-BEATS - 5ep\") %>% \n  #update_model_description(5,\"N-BEATS - 5ep,MASE\") %>% \n  update_model_description(3,\"N-BEATS - ens, 5ep,MASE\") \n\n\nmodel_tbl_ensemble_wtd <- model_tbl_ensemble %>% \n  ensemble_weighted(loadings = c(1,3,4)) %>% \n  modeltime_table()\n\n\n# model_tbl_ensemble_calibrate <- model_tbl_ensemble_wtd %>% \n#    modeltime_calibrate(new_data = testing(splits),\n#                        id       = \"route\")\n# \n# # model_tbl_ensemble_calibrate %>% \n# #     summarize_accuracy_metrics(\n# #         truth    = actual,\n# #         estimate = forecast,\n# #         metric_set = extended_forecast_accuracy_metric_set()\n# #     ) %>% arrange(smape)\n# # \n# model_tbl_ensemble_calibrate %>%\n#     modeltime_accuracy(\n#       #testing(splits),\n#       metric_set = extended_forecast_accuracy_metric_set()\n#       ) %>%\n#     arrange(rmse) %>%\n#    gt::gt() %>%\n#     gt::fmt_number(\n#      columns = 4:10,\n#       decimals = 3)"
  },
  {
    "objectID": "posts/forecasting_with_deep_learning/index.html#refit-ensemble-to-full-traintest-data-set-and-graph",
    "href": "posts/forecasting_with_deep_learning/index.html#refit-ensemble-to-full-traintest-data-set-and-graph",
    "title": "Flight Forecasting with Deep Learning - Incomplete",
    "section": "11 Refit Ensemble to Full Train/Test Data Set and Graph",
    "text": "11 Refit Ensemble to Full Train/Test Data Set and Graph\n\n\nCode\nmodel_tbl_ensemble_refit <- model_tbl_ensemble_wtd %>% \n# model_tbl_ensemble_calibrate %>% \n    modeltime_refit(data_prepared_tbl)\n\n\nmodel_tbl_ensemble_pred <- model_tbl_ensemble_refit %>% \n  modeltime_forecast(\n    new_data    = future_tbl,\n    actual_data = data_prepared_tbl,\n    keep_data   = TRUE,\n    conf_by_id = TRUE\n    ) \n\n\n\n\nCode\nmodel_tbl_ensemble_pred_data <-  model_tbl_ensemble_pred %>%\n  select(model_id    = .model_id,\n         model_desc  = .model_desc,\n         act_pred    = .key, \n         date, route, .value,) %>% \n  bind_rows(route_prep_validation %>%\n              mutate(model_desc = \"ACTUAL_VALIDN\") %>%\n              select(route,date,model_desc,.value = passenger_trips)\n            ) %>%\n  filter(route %in% topx,\n         date>lubridate::ymd(\"2018-01,01\")) %>% \n  mutate(pax_nos_000 = expm1(.value)/1000) %>% \n          \n  group_by(route)\n\n# model_tbl_ensemble_pred_data_wide <- model_tbl_ensemble_pred_data %>% \n#   select(route,date,model_desc,pax_nos_000) %>% \n#   group_by(route,date,model_desc) %>% \n#   pivot_wider(\n#     names_from = model_desc,values_from = pax_nos_000\n#   ) %>% \n#   arrange(route,date)\n\n\n\n\ng_data <- model_tbl_ensemble_pred_data %>% \n  select(date,route,model_desc,pax_nos_000) %>%  \n   group_by(route,date,model_desc) %>% \n  summarise(pax_nos_000= sum(pax_nos_000, na.rm = TRUE)) %>% \n  mutate(model_desc = \n    case_when(\n      model_desc        == \"ENSEMBLE (WEIGHTED): 3 MODELS\" ~ \"prediction\",\n      date              <= max_train    ~ \"actual_train\",\n      date              <= max_test     ~ \"actual_test\",\n      date              <= end_precovid ~ \"actual_precovid\",\n      date              <= max_pred     ~ \"actual_postcovid\",\n      TRUE                              ~ \"actual_post_prediction\"\n    )) %>% \narrange(route,date)\n\n\ng <- g_data %>% \n  ggplot(aes(x  = date, \n             y      = pax_nos_000,\n             group = route,\n             colour  = model_desc\n             )) +\n  geom_line() +\n  # geom_ribbon(aes(ymin  = conf_lo,\n  #                 ymax  = conf_hi,\n  #                 color = model_desc),\n  #             alpha     = 0.2) +\n  scale_y_continuous(labels = comma) +\n  labs(x = \"\", y = \"pax pm(000)\") +\n  facet_wrap(vars(route),  ncol = 2, scales = \"free\")+\n  theme(legend.position = c(1,0)) +\n  theme(legend.text = element_text(size=9))\n\n#g\n\n\nplotly::ggplotly(g)"
  },
  {
    "objectID": "posts/forecasting_with_deep_learning/index.html#aggregated-prediction---all-routes",
    "href": "posts/forecasting_with_deep_learning/index.html#aggregated-prediction---all-routes",
    "title": "Flight Forecasting with Deep Learning - Incomplete",
    "section": "12 Aggregated Prediction - All routes",
    "text": "12 Aggregated Prediction - All routes\n\n\nCode\ng_data_acc <- g_data %>% \n  select(date,model_desc,pax_nos_000) %>% \n  group_by(date,model_desc) %>% \n  summarise(pax_nos_000 = sum(pax_nos_000,na.rm = TRUE)) %>% \n  # select(-c(model_id,.index,.key)) %>% \n  # pivot_longer(\n  #   cols      = !date,\n  #   names_to  = \"actual_prediction\",\n  #   values_to = \"pax_nos_000\"\n  # ) %>%  \n  mutate(pax_nos_000 = ifelse(pax_nos_000 == 0, NA,pax_nos_000))\n\ng1 <- g_data_acc %>% \n  ggplot(aes(x=date, y=pax_nos_000, colour = model_desc ))+\n  geom_line() +\n  # geom_ribbon(aes(ymin  = conf_lo,\n  #                 ymax  = conf_hi,\n  #                 color = model_desc),\n  #             alpha     = 0.2) +\n  scale_y_continuous(\"Passenger No's pm (000)\",\n    breaks = scales::breaks_extended(8),\n    labels = scales::label_comma()  \n  )\n\ng1\n\n\n\n\n\nCode\n#plotly::ggplotly(g1)\n\n\nSo not too bad in for predictions precovid, which is our focus."
  }
]